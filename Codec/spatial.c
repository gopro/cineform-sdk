/*! @file spatial.c

*  @brief Wavelet tools
*
*  @version 1.0.0
*
*  (C) Copyright 2017 GoPro Inc (http://gopro.com/).
*
*  Licensed under either:
*  - Apache License, Version 2.0, http://www.apache.org/licenses/LICENSE-2.0  
*  - MIT license, http://opensource.org/licenses/MIT
*  at your option.
*
*  Unless required by applicable law or agreed to in writing, software
*  distributed under the License is distributed on an "AS IS" BASIS,
*  WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
*  See the License for the specific language governing permissions and
*  limitations under the License.
*
*/

#include "config.h"
#include "timing.h"

#ifndef DEBUG
#define DEBUG  (1 && _DEBUG)
#endif
#define TIMING (1 && _TIMING)
#define XMMOPT (1 && _XMMOPT)

#define PREFETCH (1 && _PREFETCH)

#include <assert.h>
#include <math.h>
#include <limits.h>
#include <emmintrin.h>		// SSE2 intrinsics

#include "spatial.h"
#include "filter.h"			// Declarations of filter routines
//#include "image.h"		// Image processing data types
//#include "ipp.h"			// Use Intel Performance Primitives
//#include "debug.h"
#include "codec.h"
#include "buffer.h"
#include "quantize.h"
#include "convert.h"
#include "decoder.h"
#include "bayer.h"
#include "swap.h"
#include <memory.h>


//TODO: Replace uses of _bswap with SwapInt32


#define _PREROLL 1		// Enable loop preprocessing for memory alignment

// Forward reference (to avoid including encoder.h)
//typedef struct encoder ENCODER;
struct encoder;


#if DEBUG
// Make the logfile available for debugging
#include <stdio.h>
extern FILE *logfile;
#endif

#ifndef _QUANTIZE_SPATIAL_LOWPASS
#define _QUANTIZE_SPATIAL_LOWPASS	0
#endif

//#ifndef _UNALIGNED
//#define _UNALIGNED	0
//#endif
#ifndef _UNALIGNED
#define _UNALIGNED	0
//#elif (_UNALIGNED == 1)    // Hack for VS2012 and beyond as default behavior for VS sets _UNALIGNED == __unaligned keyword)
//do nothing
#else
#undef _UNALIGNED
#define _UNALIGNED	0
#endif

#ifndef _FASTLOOP
#define _FASTLOOP	1
#endif


// Shifts used to remove prescaling in the thumbnail spatial transform
#define V210_HORIZONTAL_SHIFT	2
#define V210_VERTICAL_SHIFT		0

#if 0
static void PrescaleRow16s(PIXEL *rowptr, int width, int prescale)
{
#if (1 && XMMOPT)
	int column_step = 4;
	int post_column = width - (width % column_step);
	__m64 *mm_ptr = (__m64 *)rowptr;
	__m64 in_pi16;
#endif
	int column;

	// Return now if no prescaling is needed
	if (prescale == 0) return;

	// Start at the first column
	column = 0;

#if (1 && XMMOPT)
	for (; column < post_column; column += column_step)
	{
		in_pi16 = *mm_ptr;
		*mm_ptr++ = _mm_sra_pi16(in_pi16, _mm_cvtsi32_si64(prescale));
	}

	//_mm_empty();

	assert(column == post_column);
#endif

	for (; column < width; column++)
		rowptr[column] = (rowptr[column] >> prescale);
}
#endif
#if 0
static void PrescaleRow8s(PIXEL8S *rowptr, int width, int prescale)
{
#if (1 && XMMOPT)
	int column_step = 8;
	int post_column = width - (width % column_step);
	__m64 *mm_ptr = (__m64 *)rowptr;
	__m64 in1_pi16, in2_pi16;
	__m64 in_pi8;
	__m64 sign_pi8;
#endif
	int column;

	// Return now if no prescaling is needed
	if (prescale == 0) return;

	// Start at the first column
	column = 0;

#if (1 && XMMOPT)
	for (; column < post_column; column += column_step)
	{
		in_pi8 = *mm_ptr;

		// Compute the sign for unpacking
		sign_pi8 = _mm_cmpgt_pi8(_mm_setzero_si64(), in_pi8);

		// Unpack the lower and upper bytes
		in1_pi16 = _mm_unpacklo_pi8(in_pi8, sign_pi8);
		in2_pi16 = _mm_unpackhi_pi8(in_pi8, sign_pi8);

		// Prescale the lower and upper bytes
		in1_pi16 = _mm_sra_pi16(in1_pi16, _mm_cvtsi32_si64(prescale));
		in2_pi16 = _mm_sra_pi16(in2_pi16, _mm_cvtsi32_si64(prescale));

		// Pack the lower and upper bytes
		in_pi8 = _mm_packs_pi16(in1_pi16, in2_pi16);

		// Store the result
		*mm_ptr++ = in_pi8;
	}

	//_mm_empty();

	assert(column == post_column);
#endif

	for (; column < width; column++)
		rowptr[column] = rowptr[column] >> prescale;
}
#endif
#if 0
static void PrescaleLowpassRow16s(PIXEL *input, PIXEL *output, int width)
{
#if (1 && XMMOPT)
	int column_step = 4;
	int post_column = width - (width % column_step);
	__m64 *input_ptr = (__m64 *)input;
	__m64 *output_ptr = (__m64 *)output;
	__m64 group_pi16;
	__m64 round_pi16 = _mm_set1_pi16(1);
#endif

	// Start at the first column
	int column = 0;

#if (1 && XMMOPT)
	for (; column < post_column; column += column_step)
	{
		group_pi16 = *(input_ptr++);
		group_pi16 = _mm_srai_pi16(group_pi16, _LOWPASS_PRESCALE);
		group_pi16 = _mm_adds_pi16(group_pi16, round_pi16);
		*(output_ptr++) = group_pi16;
	}

	// Check that the loop terminated at the post processing column
	assert(column == post_column);

	//_mm_empty();	// Clear the mmx register state

#endif

	for (; column < width; column++)
	{
		//DAN 9/12/02 Fix for chroma/luma shift
		output[column] = ((input[column]) >> _LOWPASS_PRESCALE) + 1;
	}
}
#endif

#if _PROCESSOR_DISPATCH

__declspec(cpu_dispatch(Pentium_4,Generic))

void FilterHorizontalRow16s(PIXEL *input, PIXEL *lowpass, PIXEL *highpass, int width)
{
	// Stub routine for processor specific dispatch
}
#endif


#if _PROCESSOR_GENERIC

#if _PROCESSOR_DISPATCH
__declspec(cpu_specific(Generic))
#endif

// Apply the lowpass and highpass horizontal filters to one row
void FilterHorizontalRow16s(PIXEL *input, PIXEL *lowpass, PIXEL *highpass, int width)
{
	//FilterHorizontalRowPrescaled16s(input, lowpass, highpass, width, NULL);
}

#endif


#if _PROCESSOR_PENTIUM_4

#if _PROCESSOR_DISPATCH
__declspec(cpu_specific(Pentium_4))
#endif

#if 1

// Apply the lowpass and highpass horizontal filters to one row
// Original version with the loop unrolled to allow use of prefetched loads
void FilterHorizontalRow16s(PIXEL *input, PIXEL *lowpass, PIXEL *highpass, int width)
{
	int column_step = 16;				// Number of input pixels processed per loop iteration
	int last_column = width - 2;		// Column at which right border processing is done

	// The post column is the column at which end of column processing must begin
	int post_column = last_column - (last_column % column_step);

	int32_t sum;

	// Start at the left end of the row
	PIXEL *lowptr = lowpass;
	PIXEL *highptr = highpass;
	int column = 0;

	__m128i *input_ptr = (__m128i *)input;
	__m128i *lowpass_ptr;
	__m128i *highpass_ptr;
	__m128i input1_epi16;
	__m128i mask_epi16;

	int highpass_value;

	// The highpass filter on the left border uses different coefficients
	sum = 0;
	sum +=  5 * input[column + 0];
	sum -= 11 * input[column + 1];
	sum +=  4 * input[column + 2];
	sum +=  4 * input[column + 3];
	sum -=  1 * input[column + 4];
	sum -=  1 * input[column + 5];
	sum += ROUNDING(sum,8);
	sum = DivideByShift(sum, 3);
	highpass_value = SATURATE(sum);

	// Set the input pointer for the fast loop
	input_ptr = (__m128i *)&input[column];

	// Check that the pointer to the next group of pixels is properly aligned
	assert(ISALIGNED16(input_ptr));

	// Preload the first set of four pixels for fast processing
	input1_epi16 = _mm_load_si128(input_ptr++);

	// Initialize the output pointers
	lowpass_ptr = (__m128i *)lowptr;
	highpass_ptr = (__m128i *)highptr;

	// Check that the output pointers are properly aligned
	assert(ISALIGNED16(lowpass_ptr));
	assert(ISALIGNED16(highpass_ptr));

	// Intialize the mask used for downsampling the convolution results
	mask_epi16 = _mm_set1_epi32(0x0000FFFF);

#if (1 && XMMOPT)
	// Process two sets of four input pixels to get one set of four output pixels
	for (; column < post_column; column += column_step)
	{
		__m128i input2_epi16;
		__m128i shift2_epi16;
		__m128i half_epi16;		// Half of the divisor for rounding
		__m128i sum1_epi16;
		__m128i sum2_epi16;
		__m128i sum1b_epi16;
		__m128i sum2b_epi16;
		__m128i low1_epi16;
		__m128i low2_epi16;


		/***** Process the first four output points *****/

		// Initialize the highpass sum
		sum1_epi16 = _mm_setzero_si128();

		// Apply the first filter coefficient to each pixel and sum the result
		sum1_epi16 = _mm_subs_epi16(sum1_epi16, input1_epi16);

		// Check that the pointer to the next group of pixels is properly aligned
		assert(ISALIGNED16(input_ptr));

		// Load the next eight pixels
		input2_epi16 = _mm_load_si128(input_ptr++);

		// Initialize the lowpass sum
		low1_epi16 = input1_epi16;

		// Shift the first pixel from the second set into the working set
		shift2_epi16 = _mm_slli_si128(input2_epi16, 7*2);
		input1_epi16 = _mm_srli_si128(input1_epi16, 1*2);
		input1_epi16 = _mm_or_si128(input1_epi16, shift2_epi16);

		// Apply the second filter coefficient to each pixel and sum the result
		sum1_epi16 = _mm_subs_epi16(sum1_epi16, input1_epi16);

		// Add adjacent points to compute the lowpass sum
		low1_epi16 = _mm_adds_epi16(low1_epi16, input1_epi16);

		// Expand the lowpass output points to a full doubleword
#if 1
		low1_epi16 = _mm_slli_epi32(low1_epi16, 16);
		low1_epi16 = _mm_srai_epi32(low1_epi16, 16);
#else
		low1_epi16 = _mm_and_si128(low1_epi16, mask_epi16);
#endif
		// Shift the second pixel from the second set into the working set
		shift2_epi16 = _mm_slli_si128(input2_epi16, 6*2);
		input1_epi16 = _mm_srli_si128(input1_epi16, 1*2);
		input1_epi16 = _mm_or_si128(input1_epi16, shift2_epi16);

		// Apply the third filter coefficient to each pixel and sum the result
		//sum1_epi16 = _mm_adds_epi16(sum1_epi16, _mm_slli_epi16(input1_epi16, 3));
		sum1b_epi16 = input1_epi16;

		// Shift the third pixel from the second set into the working set
		shift2_epi16 = _mm_slli_si128(input2_epi16, 5*2);
		input1_epi16 = _mm_srli_si128(input1_epi16, 1*2);
		input1_epi16 = _mm_or_si128(input1_epi16, shift2_epi16);

		// Apply the fourth filter coefficient to each pixel and sum the result
		//sum1_epi16 = _mm_subs_epi16(sum1_epi16, _mm_slli_epi16(input1_epi16, 3));
		sum1b_epi16 = _mm_subs_epi16(sum1b_epi16, input1_epi16);

		// Shift the fourth pixel from the second set into the working set
		shift2_epi16 = _mm_slli_si128(input2_epi16, 4*2);
		input1_epi16 = _mm_srli_si128(input1_epi16, 1*2);
		input1_epi16 = _mm_or_si128(input1_epi16, shift2_epi16);

		// Apply the fifth filter coefficient to each pixel and sum the result
		sum1_epi16 = _mm_adds_epi16(sum1_epi16, input1_epi16);

		// Shift the fifth pixel from the second set into the working set
		shift2_epi16 = _mm_slli_si128(input2_epi16, 3*2);
		input1_epi16 = _mm_srli_si128(input1_epi16, 1*2);
		input1_epi16 = _mm_or_si128(input1_epi16, shift2_epi16);

		// Apply the sixth (last) filter coefficient to each pixel and sum the result
		sum1_epi16 = _mm_adds_epi16(sum1_epi16, input1_epi16);

		//DAN20050915 -- reversibility
		half_epi16 = _mm_set1_epi16(4);
		sum1_epi16 = _mm_adds_epi16(sum1_epi16, half_epi16);
		sum1_epi16 = _mm_srai_epi16(sum1_epi16, 3);

		sum1_epi16 = _mm_adds_epi16(sum1_epi16, sum1b_epi16);

		// Expand the even output points to a full doubleword
		sum1_epi16 = _mm_slli_epi32(sum1_epi16, 16);
		sum1_epi16 = _mm_srai_epi32(sum1_epi16, 16);

		// The second eight input points become the current input points
		input1_epi16 = input2_epi16;


		/***** Process the second four output points *****/

		// Initialize the highpass sum
		sum2_epi16 = _mm_setzero_si128();

		// Apply the first filter coefficient to each pixel and sum the result
		sum2_epi16 = _mm_subs_epi16(sum2_epi16, input1_epi16);

		// Check that the pointer to the next group of pixels is properly aligned
		assert(ISALIGNED16(input_ptr));

		// Load the next eight pixels
		input2_epi16 = _mm_load_si128(input_ptr++);

		// Initialize the lowpass sum
		low2_epi16 = input1_epi16;

		// Shift the first pixel from the second set into the working set
		shift2_epi16 = _mm_slli_si128(input2_epi16, 7*2);
		input1_epi16 = _mm_srli_si128(input1_epi16, 1*2);
		input1_epi16 = _mm_or_si128(input1_epi16, shift2_epi16);

		// Apply the second filter coefficient to each pixel and sum the result
		sum2_epi16 = _mm_subs_epi16(sum2_epi16, input1_epi16);

		// Add adjacent points to compute the lowpass sum
		low2_epi16 = _mm_adds_epi16(low2_epi16, input1_epi16);

		// Expand the lowpass output points to a full doubleword
#if 1
		low2_epi16 = _mm_slli_epi32(low2_epi16, 16);
		low2_epi16 = _mm_srai_epi32(low2_epi16, 16);
#else
		low2_epi16 = _mm_and_si128(low2_epi16, mask_epi16);
#endif
		// Shift the second pixel from the second set into the working set
		shift2_epi16 = _mm_slli_si128(input2_epi16, 6*2);
		input1_epi16 = _mm_srli_si128(input1_epi16, 1*2);
		input1_epi16 = _mm_or_si128(input1_epi16, shift2_epi16);

		// Apply the third filter coefficient to each pixel and sum the result
		//sum2_epi16 = _mm_adds_epi16(sum2_epi16, _mm_slli_epi16(input1_epi16, 3));
		sum2b_epi16 = input1_epi16;

		// Shift the third pixel from the second set into the working set
		shift2_epi16 = _mm_slli_si128(input2_epi16, 5*2);
		input1_epi16 = _mm_srli_si128(input1_epi16, 1*2);
		input1_epi16 = _mm_or_si128(input1_epi16, shift2_epi16);

		// Apply the fourth filter coefficient to each pixel and sum the result
		//sum2_epi16 = _mm_subs_epi16(sum2_epi16, _mm_slli_epi16(input1_epi16, 3));
		sum2b_epi16 = _mm_subs_epi16(sum2b_epi16, input1_epi16);

		// Shift the fourth pixel from the second set into the working set
		shift2_epi16 = _mm_slli_si128(input2_epi16, 4*2);
		input1_epi16 = _mm_srli_si128(input1_epi16, 1*2);
		input1_epi16 = _mm_or_si128(input1_epi16, shift2_epi16);

		// Apply the fifth filter coefficient to each pixel and sum the result
		sum2_epi16 = _mm_adds_epi16(sum2_epi16, input1_epi16);

		// Shift the fifth pixel from the second set into the working set
		shift2_epi16 = _mm_slli_si128(input2_epi16, 3*2);
		input1_epi16 = _mm_srli_si128(input1_epi16, 1*2);
		input1_epi16 = _mm_or_si128(input1_epi16, shift2_epi16);

		// Apply the sixth (last) filter coefficient to each pixel and sum the result
		sum2_epi16 = _mm_adds_epi16(sum2_epi16, input1_epi16);

		//DAN20050915 -- reversibility
		sum2_epi16 = _mm_adds_epi16(sum2_epi16, half_epi16);
		sum2_epi16 = _mm_srai_epi16(sum2_epi16, 3);

		sum2_epi16 = _mm_adds_epi16(sum2_epi16, sum2b_epi16);

		// Expand the even output points to a full doubleword
		sum2_epi16 = _mm_slli_epi32(sum2_epi16, 16);
		sum2_epi16 = _mm_srai_epi32(sum2_epi16, 16);


		/***** Combine the output points *****/

		low1_epi16 = _mm_packs_epi32(low1_epi16, low2_epi16);
		sum1_epi16 = _mm_packs_epi32(sum1_epi16, sum2_epi16);


		// Store the four lowpass output points
		_mm_store_si128(lowpass_ptr++, low1_epi16);

		// Get the last highpass coefficient in the group
		sum2_epi16 = _mm_srli_si128(sum1_epi16, 7*2);

		// Shift the extra highpass coefficient into the output
		sum1_epi16 = _mm_slli_si128(sum1_epi16, 1*2);
		sum1_epi16 = _mm_insert_epi16(sum1_epi16, highpass_value, 0);

		// Save the last highpass coefficient for the next loop iteration
		highpass_value = _mm_cvtsi128_si32(sum2_epi16);

		// Store the four highpass output points
		_mm_store_si128(highpass_ptr++, sum1_epi16);

		// The second set of eight input pixels becomes the working set
		input1_epi16 = input2_epi16;
	}

	// Should have exited the loop at the post processing column
	assert(column == post_column);

	lowptr = (PIXEL *)lowpass_ptr;
	highptr = (PIXEL *)highpass_ptr;

#else
	sum = input[column] + input[column + 1];
	*(lowptr++) = SATURATE(sum);
	*(highptr++) = SATURATE(highpass_value);
	column+=2;
#endif

	// Process the last group of columns as a special case to handle the border
	for (; column < last_column; column += 2)
	{
		// Compute the lowpass sum
		sum = input[column] + input[column + 1];

		// Store the lowpass sum
		*(lowptr++) = SATURATE(sum);

		// Compute the highpass sum
		sum = 0;
		sum -= input[column - 2];
		sum -= input[column - 1];
		sum += input[column + 2];
		sum += input[column + 3];
		sum += ROUNDING(sum,8);
		sum = DivideByShift(sum, 3);
		sum += input[column + 0];
		sum -= input[column + 1];

		// Store the highpass sum
		*(highptr++) = SATURATE(sum);
	}

	// Should be at the last column
	assert(column == last_column);

	// Compute the last lowpass value
	sum = input[column] + input[column + 1];

	*(lowptr++) = SATURATE(sum);

	// Compute the last highpass value using the special border coefficients
	sum = 0;
	sum += 11 * input[column + 0];
	sum -=  5 * input[column + 1];
	sum -=  4 * input[column - 1];
	sum -=  4 * input[column - 2];
	sum +=  1 * input[column - 3];
	sum +=  1 * input[column - 4];
	sum +=  ROUNDING(sum,8);
	sum = DivideByShift(sum, 3);

	*(highptr++) = SATURATE(sum);
}

#elif 1

// Apply the lowpass and highpass horizontal filters to one row
// New version that uses shorter shift operations
void FilterHorizontalRow16s(PIXEL *input, PIXEL *lowpass, PIXEL *highpass, int width)
{
	int column_step = 16;				// Number of input pixels processed per loop iteration
	int last_column = width - 2;		// Column at which right border processing is done

	// The post column is the column at which end of column processing must begin
	int post_column = last_column - (last_column % column_step);

	int32_t sum;

	// Start at the left end of the row
	PIXEL *lowptr = lowpass;
	PIXEL *highptr = highpass;
	int column = 0;

	__m128i *input_ptr = (__m128i *)input;
	__m128i *lowpass_ptr;
	__m128i *highpass_ptr;
	__m128i input1_epi16;

	int highpass_value;

	// The highpass filter on the left border uses different coefficients
	sum = 0;
	sum +=  5 * input[column + 0];
	sum -= 11 * input[column + 1];
	sum +=  4 * input[column + 2];
	sum +=  4 * input[column + 3];
	sum -=  1 * input[column + 4];
	sum -=  1 * input[column + 5];
	sum += ROUNDING(sum,8);
	sum = DivideByShift(sum, 3);
	highpass_value = SATURATE(sum);

	// Set the input pointer for the fast loop
	input_ptr = (__m128i *)&input[column];

	// Check that the pointer to the next group of pixels is properly aligned
	assert(ISALIGNED16(input_ptr));

	// Preload the first set of four pixels for fast processing
	input1_epi16 = _mm_load_si128(input_ptr++);

	// Initialize the output pointers
	lowpass_ptr = (__m128i *)lowptr;
	highpass_ptr = (__m128i *)highptr;

	// Check that the output pointers are properly aligned
	assert(ISALIGNED16(lowpass_ptr));
	assert(ISALIGNED16(highpass_ptr));


#if (1 && XMMOPT)
	// Process two sets of four input pixels to get one set of four output pixels
	for (; column < post_column; column += column_step)
	{
		__m128i input2_epi16;
		__m128i shift1_epi16;
		__m128i shift2_epi16;
		__m128i shift3_epi16;
		__m128i shift4_epi16;
		__m128i shift5_epi16;
		__m128i mask_epi16;
		__m128i sign_epi16;
		__m128i half_epi16;		// Half of the divisor for rounding
		__m128i sum1_epi16;
		__m128i sum2_epi16;
		__m128i sum1b_epi16;
		__m128i sum2b_epi16;
		__m128i low1_epi16;
		__m128i low2_epi16;


		// Intialize the mask used for downsampling the convoution results
		mask_epi16 = _mm_set1_epi32(0x0000FFFF);


		/***** Process the first four output points *****/

		// Initialize the highpass sum
		sum1_epi16 = _mm_setzero_si128();

		// Apply the first filter coefficient to each pixel and sum the result
		sum1_epi16 = _mm_subs_epi16(sum1_epi16, input1_epi16);

		// Check that the pointer to the next group of pixels is properly aligned
		assert(ISALIGNED16(input_ptr));

		// Load the next eight pixels
		input2_epi16 = _mm_load_si128(input_ptr++);

		// Initialize the lowpass sum
		low1_epi16 = input1_epi16;

		// Generate shifted versions of the second set of input values
		shift5_epi16 = _mm_slli_si128(input2_epi16, 3*2);
		shift4_epi16 = _mm_slli_si128(shift5_epi16, 1*2);
		shift3_epi16 = _mm_slli_si128(shift4_epi16, 1*2);
		shift2_epi16 = _mm_slli_si128(shift3_epi16, 1*2);
		shift1_epi16 = _mm_slli_si128(shift2_epi16, 1*2);

		// Shift the first pixel from the second set into the working set
		//shift2_epi16 = _mm_slli_si128(input2_epi16, 7*2);
		input1_epi16 = _mm_srli_si128(input1_epi16, 1*2);
		input1_epi16 = _mm_or_si128(input1_epi16, shift1_epi16);

		// Apply the second filter coefficient to each pixel and sum the result
		sum1_epi16 = _mm_subs_epi16(sum1_epi16, input1_epi16);

		// Add adjacent points to compute the lowpass sum
		low1_epi16 = _mm_adds_epi16(low1_epi16, input1_epi16);

		// Expand the lowpass output points to a full doubleword
#if 0
		low1_epi16 = _mm_slli_epi32(low1_epi16, 16);
		low1_epi16 = _mm_srai_epi32(low1_epi16, 16);
#else
		low1_epi16 = _mm_and_si128(low1_epi16, mask_epi16);
#endif
		// Shift the second pixel from the second set into the working set
		//shift2_epi16 = _mm_slli_si128(input2_epi16, 6*2);
		input1_epi16 = _mm_srli_si128(input1_epi16, 1*2);
		input1_epi16 = _mm_or_si128(input1_epi16, shift2_epi16);

		// Apply the third filter coefficient to each pixel and sum the result
		//sum1_epi16 = _mm_adds_epi16(sum1_epi16, _mm_slli_epi16(input1_epi16, 3));
		sum1b_epi16 = input1_epi16;

		// Shift the third pixel from the second set into the working set
		//shift2_epi16 = _mm_slli_si128(input2_epi16, 5*2);
		input1_epi16 = _mm_srli_si128(input1_epi16, 1*2);
		input1_epi16 = _mm_or_si128(input1_epi16, shift3_epi16);

		// Apply the fourth filter coefficient to each pixel and sum the result
		//sum1_epi16 = _mm_subs_epi16(sum1_epi16, _mm_slli_epi16(input1_epi16, 3));
		sum1b_epi16 = _mm_subs_epi16(sum1b_epi16, input1_epi16);

		// Shift the fourth pixel from the second set into the working set
		//shift2_epi16 = _mm_slli_si128(input2_epi16, 4*2);
		input1_epi16 = _mm_srli_si128(input1_epi16, 1*2);
		input1_epi16 = _mm_or_si128(input1_epi16, shift4_epi16);

		// Apply the fifth filter coefficient to each pixel and sum the result
		sum1_epi16 = _mm_adds_epi16(sum1_epi16, input1_epi16);

		// Shift the fifth pixel from the second set into the working set
		//shift2_epi16 = _mm_slli_si128(input2_epi16, 3*2);
		input1_epi16 = _mm_srli_si128(input1_epi16, 1*2);
		input1_epi16 = _mm_or_si128(input1_epi16, shift5_epi16);

		// Apply the sixth (last) filter coefficient to each pixel and sum the result
		sum1_epi16 = _mm_adds_epi16(sum1_epi16, input1_epi16);

		//DAN20050915 -- reversibility
		half_epi16 = _mm_set1_epi16(4);
		sum1_epi16 = _mm_adds_epi16(sum1_epi16, half_epi16);
		sum1_epi16 = _mm_srai_epi16(sum1_epi16, 3);

		sum1_epi16 = _mm_adds_epi16(sum1_epi16, sum1b_epi16);

		// Expand the even output points to a full doubleword
		sum1_epi16 = _mm_slli_epi32(sum1_epi16, 16);
		sum1_epi16 = _mm_srai_epi32(sum1_epi16, 16);

		// The second eight input points become the current input points
		input1_epi16 = input2_epi16;


		/***** Process the second four output points *****/

		// Initialize the highpass sum
		sum2_epi16 = _mm_setzero_si128();

		// Apply the first filter coefficient to each pixel and sum the result
		sum2_epi16 = _mm_subs_epi16(sum2_epi16, input1_epi16);

		// Check that the pointer to the next group of pixels is properly aligned
		assert(ISALIGNED16(input_ptr));

		// Load the next eight pixels
		input2_epi16 = _mm_load_si128(input_ptr++);

		// Initialize the lowpass sum
		low2_epi16 = input1_epi16;

		// Shift the first pixel from the second set into the working set
		shift2_epi16 = _mm_slli_si128(input2_epi16, 7*2);
		input1_epi16 = _mm_srli_si128(input1_epi16, 1*2);
		input1_epi16 = _mm_or_si128(input1_epi16, shift2_epi16);

		// Apply the second filter coefficient to each pixel and sum the result
		sum2_epi16 = _mm_subs_epi16(sum2_epi16, input1_epi16);

		// Add adjacent points to compute the lowpass sum
		low2_epi16 = _mm_adds_epi16(low2_epi16, input1_epi16);
#if 0
		// Expand the lowpass output points to a full doubleword
		low2_epi16 = _mm_slli_epi32(low2_epi16, 16);
		low2_epi16 = _mm_srai_epi32(low2_epi16, 16);
#else
		low2_epi16 = _mm_and_si128(low2_epi16, mask_epi16);
#endif
		// Shift the second pixel from the second set into the working set
		shift2_epi16 = _mm_slli_si128(input2_epi16, 6*2);
		input1_epi16 = _mm_srli_si128(input1_epi16, 1*2);
		input1_epi16 = _mm_or_si128(input1_epi16, shift2_epi16);

		// Apply the third filter coefficient to each pixel and sum the result
		//sum2_epi16 = _mm_adds_epi16(sum2_epi16, _mm_slli_epi16(input1_epi16, 3));
		sum2b_epi16 = input1_epi16;

		// Shift the third pixel from the second set into the working set
		shift2_epi16 = _mm_slli_si128(input2_epi16, 5*2);
		input1_epi16 = _mm_srli_si128(input1_epi16, 1*2);
		input1_epi16 = _mm_or_si128(input1_epi16, shift2_epi16);

		// Apply the fourth filter coefficient to each pixel and sum the result
		//sum2_epi16 = _mm_subs_epi16(sum2_epi16, _mm_slli_epi16(input1_epi16, 3));
		sum2b_epi16 = _mm_subs_epi16(sum2b_epi16, input1_epi16);

		// Shift the fourth pixel from the second set into the working set
		shift2_epi16 = _mm_slli_si128(input2_epi16, 4*2);
		input1_epi16 = _mm_srli_si128(input1_epi16, 1*2);
		input1_epi16 = _mm_or_si128(input1_epi16, shift2_epi16);

		// Apply the fifth filter coefficient to each pixel and sum the result
		sum2_epi16 = _mm_adds_epi16(sum2_epi16, input1_epi16);

		// Shift the fifth pixel from the second set into the working set
		shift2_epi16 = _mm_slli_si128(input2_epi16, 3*2);
		input1_epi16 = _mm_srli_si128(input1_epi16, 1*2);
		input1_epi16 = _mm_or_si128(input1_epi16, shift2_epi16);

		// Apply the sixth (last) filter coefficient to each pixel and sum the result
		sum2_epi16 = _mm_adds_epi16(sum2_epi16, input1_epi16);

		//DAN20050915 -- reversibility
		sum2_epi16 = _mm_adds_epi16(sum2_epi16, half_epi16);
		sum2_epi16 = _mm_srai_epi16(sum2_epi16, 3);

		sum2_epi16 = _mm_adds_epi16(sum2_epi16, sum2b_epi16);


		// Expand the even output points to a full doubleword
		sum2_epi16 = _mm_slli_epi32(sum2_epi16, 16);
		sum2_epi16 = _mm_srai_epi32(sum2_epi16, 16);


		/***** Combine the output points *****/

		low1_epi16 = _mm_packs_epi32(low1_epi16, low2_epi16);
		sum1_epi16 = _mm_packs_epi32(sum1_epi16, sum2_epi16);

		// Store the four lowpass output points
		_mm_store_si128(lowpass_ptr++, low1_epi16);

		// Get the last highpass coefficient in the group
		sum2_epi16 = _mm_srli_si128(sum1_epi16, 7*2);

		// Shift the extra highpass coefficient into the output
		sum1_epi16 = _mm_slli_si128(sum1_epi16, 1*2);
		sum1_epi16 = _mm_insert_epi16(sum1_epi16, highpass_value, 0);

		// Save the last highpass coefficient for the next loop iteration
		highpass_value = _mm_cvtsi128_si32(sum2_epi16);

		// Store the four highpass output points
		_mm_store_si128(highpass_ptr++, sum1_epi16);

		// The second set of eight input pixels becomes the working set
		input1_epi16 = input2_epi16;
	}

	// Should have exited the loop at the post processing column
	assert(column == post_column);

	lowptr = (PIXEL *)lowpass_ptr;
	highptr = (PIXEL *)highpass_ptr;

#else
	sum = input[column] + input[column + 1];
	*(lowptr++) = SATURATE(sum);
	*(highptr++) = SATURATE(highpass_value);
	column+=2;
#endif

	// Process the last group of columns as a special case to handle the border
	for (; column < last_column; column += 2)
	{
		// Compute the lowpass sum
		sum = input[column] + input[column + 1];

		// Store the lowpass sum
		*(lowptr++) = SATURATE(sum);

		// Compute the highpass sum
		sum = 0;
		sum -= input[column - 2];
		sum -= input[column - 1];
		sum += input[column + 2];
		sum += input[column + 3];
		sum += ROUNDING(sum,8);
		sum = DivideByShift(sum, 3);
		sum += input[column + 0];
		sum -= input[column + 1];

		// Store the highpass sum
		*(highptr++) = SATURATE(sum);
	}

	// Should be at the last column
	assert(column == last_column);

	// Compute the last lowpass value
	sum = input[column] + input[column + 1];

	*(lowptr++) = SATURATE(sum);

	// Compute the last highpass value using the special border coefficients
	sum = 0;
	sum += 11 * input[column + 0];
	sum -=  5 * input[column + 1];
	sum -=  4 * input[column - 1];
	sum -=  4 * input[column - 2];
	sum +=  1 * input[column - 3];
	sum +=  1 * input[column - 4];
	sum +=  ROUNDING(sum,8);
	sum = DivideByShift(sum, 3);

	*(highptr++) = SATURATE(sum);
}

#else

// Apply the lowpass and highpass horizontal filters to one row
// Version that replaces shift operations with extract and insert operations
void FilterHorizontalRow16s(PIXEL *input, PIXEL *lowpass, PIXEL *highpass, int width)
{
	int column_step = 16;				// Number of input pixels processed per loop iteration
	int last_column = width - 2;		// Column at which right border processing is done

	// The post column is the column at which end of column processing must begin
	int post_column = last_column - (last_column % column_step);

	int32_t sum;

	// Start at the left end of the row
	PIXEL *lowptr = lowpass;
	PIXEL *highptr = highpass;
	int column = 0;

	__m128i *input_ptr = (__m128i *)input;
	__m128i *lowpass_ptr;
	__m128i *highpass_ptr;
	__m128i input1_epi16;

	int highpass_value;

	// The highpass filter on the left border uses different coefficients
	sum = 0;
	sum +=  5 * input[column + 0];
	sum -= 11 * input[column + 1];
	sum +=  4 * input[column + 2];
	sum +=  4 * input[column + 3];
	sum -=  1 * input[column + 4];
	sum -=  1 * input[column + 5];
	sum += ROUNDING(sum,8);
	sum = DivideByShift(sum, 3);
	highpass_value = SATURATE(sum);

	// Set the input pointer for the fast loop
	input_ptr = (__m128i *)&input[column];

	// Check that the pointer to the next group of pixels is properly aligned
	assert(ISALIGNED16(input_ptr));

	// Preload the first set of four pixels for fast processing
	input1_epi16 = _mm_load_si128(input_ptr++);

	// Initialize the output pointers
	lowpass_ptr = (__m128i *)lowptr;
	highpass_ptr = (__m128i *)highptr;

	// Check that the output pointers are properly aligned
	assert(ISALIGNED16(lowpass_ptr));
	assert(ISALIGNED16(highpass_ptr));


#if (1 && XMMOPT)
	// Process two sets of four input pixels to get one set of four output pixels
	for (; column < post_column; column += column_step)
	{
		__m128i input2_epi16;
		__m128i shift2_epi16;
		__m128i mask_epi16;
		__m128i sign_epi16;
		__m128i half_epi16;		// Half of the divisor for rounding
		__m128i sum1_epi16;
		__m128i sum2_epi16;
		__m128i sum1b_epi16;
		__m128i sum2b_epi16;
		__m128i low1_epi16;
		__m128i low2_epi16;


		/***** Process the first four output points *****/

		// Initialize the highpass sum
		sum1_epi16 = _mm_setzero_si128();

		// Apply the first filter coefficient to each pixel and sum the result
		sum1_epi16 = _mm_subs_epi16(sum1_epi16, input1_epi16);

		// Check that the pointer to the next group of pixels is properly aligned
		assert(ISALIGNED16(input_ptr));

		// Load the next eight pixels
		input2_epi16 = _mm_load_si128(input_ptr++);

		// Initialize the lowpass sum
		low1_epi16 = input1_epi16;

		// Shift the first pixel from the second set into the working set
		input1_epi16 = _mm_srli_si128(input1_epi16, 1*2);
		input1_epi16 = _mm_insert_epi16(input1_epi16, _mm_extract_epi16(input2_epi16, 0), 7);

		// Apply the second filter coefficient to each pixel and sum the result
		sum1_epi16 = _mm_subs_epi16(sum1_epi16, input1_epi16);

		// Add adjacent points to compute the lowpass sum
		low1_epi16 = _mm_adds_epi16(low1_epi16, input1_epi16);

		// Expand the lowpass output points to a full doubleword
		low1_epi16 = _mm_slli_epi32(low1_epi16, 16);
		low1_epi16 = _mm_srai_epi32(low1_epi16, 16);

		// Shift the second pixel from the second set into the working set
		input1_epi16 = _mm_srli_si128(input1_epi16, 1*2);
		input1_epi16 = _mm_insert_epi16(input1_epi16, _mm_extract_epi16(input2_epi16, 1), 7);

		// Apply the third filter coefficient to each pixel and sum the result
		//sum1_epi16 = _mm_adds_epi16(sum1_epi16, _mm_slli_epi16(input1_epi16, 3));
		sum1b_epi16 = input1_epi16;

		// Shift the third pixel from the second set into the working set
		input1_epi16 = _mm_srli_si128(input1_epi16, 1*2);
		input1_epi16 = _mm_insert_epi16(input1_epi16, _mm_extract_epi16(input2_epi16, 2), 7);

		// Apply the fourth filter coefficient to each pixel and sum the result
		//sum1_epi16 = _mm_subs_epi16(sum1_epi16, _mm_slli_epi16(input1_epi16, 3));
		sum1b_epi16 = _mm_subs_epi16(sum1b_epi16, input1_epi16);

		// Shift the fourth pixel from the second set into the working set
		input1_epi16 = _mm_srli_si128(input1_epi16, 1*2);
		input1_epi16 = _mm_insert_epi16(input1_epi16, _mm_extract_epi16(input2_epi16, 3), 7);

		// Apply the fifth filter coefficient to each pixel and sum the result
		sum1_epi16 = _mm_adds_epi16(sum1_epi16, input1_epi16);

		// Shift the fifth pixel from the second set into the working set
		input1_epi16 = _mm_srli_si128(input1_epi16, 1*2);
		input1_epi16 = _mm_insert_epi16(input1_epi16, _mm_extract_epi16(input2_epi16, 4), 7);

		// Apply the sixth (last) filter coefficient to each pixel and sum the result
		sum1_epi16 = _mm_adds_epi16(sum1_epi16, input1_epi16);

		//DAN20050915 -- reversibility
		half_epi16 = _mm_set1_epi16(4);
		sum1_epi16 = _mm_adds_epi16(sum1_epi16, half_epi16);
		sum1_epi16 = _mm_srai_epi16(sum1_epi16, 3);

		sum1_epi16 = _mm_adds_epi16(sum1_epi16, sum1b_epi16);

		// Expand the even output points to a full doubleword
		sum1_epi16 = _mm_slli_epi32(sum1_epi16, 16);
		sum1_epi16 = _mm_srai_epi32(sum1_epi16, 16);

		// The second eight input points become the current input points
		input1_epi16 = input2_epi16;


		/***** Process the second four output points *****/

		// Initialize the highpass sum
		sum2_epi16 = _mm_setzero_si128();

		// Apply the first filter coefficient to each pixel and sum the result
		sum2_epi16 = _mm_subs_epi16(sum2_epi16, input1_epi16);

		// Check that the pointer to the next group of pixels is properly aligned
		assert(ISALIGNED16(input_ptr));

		// Load the next eight pixels
		input2_epi16 = _mm_load_si128(input_ptr++);

		// Initialize the lowpass sum
		low2_epi16 = input1_epi16;

		// Shift the first pixel from the second set into the working set
		input1_epi16 = _mm_srli_si128(input1_epi16, 1*2);
		input1_epi16 = _mm_insert_epi16(input1_epi16, _mm_extract_epi16(input2_epi16, 0), 7);

		// Apply the second filter coefficient to each pixel and sum the result
		sum2_epi16 = _mm_subs_epi16(sum2_epi16, input1_epi16);

		// Add adjacent points to compute the lowpass sum
		low2_epi16 = _mm_adds_epi16(low2_epi16, input1_epi16);

		// Expand the lowpass output points to a full doubleword
		low2_epi16 = _mm_slli_epi32(low2_epi16, 16);
		low2_epi16 = _mm_srai_epi32(low2_epi16, 16);

		// Shift the second pixel from the second set into the working set
		input1_epi16 = _mm_srli_si128(input1_epi16, 1*2);
		input1_epi16 = _mm_insert_epi16(input1_epi16, _mm_extract_epi16(input2_epi16, 1), 7);

		// Apply the third filter coefficient to each pixel and sum the result
		//sum2_epi16 = _mm_adds_epi16(sum2_epi16, _mm_slli_epi16(input1_epi16, 3));
		sum2b_epi16 = input1_epi16;

		// Shift the third pixel from the second set into the working set
		input1_epi16 = _mm_srli_si128(input1_epi16, 1*2);
		input1_epi16 = _mm_insert_epi16(input1_epi16, _mm_extract_epi16(input2_epi16, 2), 7);

		// Apply the fourth filter coefficient to each pixel and sum the result
		//sum2_epi16 = _mm_subs_epi16(sum2_epi16, _mm_slli_epi16(input1_epi16, 3));
		sum2b_epi16 = _mm_subs_epi16(sum2b_epi16, input1_epi16);

		// Shift the fourth pixel from the second set into the working set
		input1_epi16 = _mm_srli_si128(input1_epi16, 1*2);
		input1_epi16 = _mm_insert_epi16(input1_epi16, _mm_extract_epi16(input2_epi16, 3), 7);

		// Apply the fifth filter coefficient to each pixel and sum the result
		sum2_epi16 = _mm_adds_epi16(sum2_epi16, input1_epi16);

		// Shift the fifth pixel from the second set into the working set
		input1_epi16 = _mm_srli_si128(input1_epi16, 1*2);
		input1_epi16 = _mm_insert_epi16(input1_epi16, _mm_extract_epi16(input2_epi16, 4), 7);

		// Apply the sixth (last) filter coefficient to each pixel and sum the result
		sum2_epi16 = _mm_adds_epi16(sum2_epi16, input1_epi16);

		//DAN20050915 -- reversibility
		sum2_epi16 = _mm_adds_epi16(sum2_epi16, half_epi16);
		sum2_epi16 = _mm_srai_epi16(sum2_epi16, 3);

		sum2_epi16 = _mm_adds_epi16(sum2_epi16, sum2b_epi16);


		// Expand the even output points to a full doubleword
		sum2_epi16 = _mm_slli_epi32(sum2_epi16, 16);
		sum2_epi16 = _mm_srai_epi32(sum2_epi16, 16);


		/***** Combine the output points *****/

		low1_epi16 = _mm_packs_epi32(low1_epi16, low2_epi16);
		sum1_epi16 = _mm_packs_epi32(sum1_epi16, sum2_epi16);


		// Store the four lowpass output points
		_mm_store_si128(lowpass_ptr++, low1_epi16);

		// Get the last highpass coefficient in the group
		sum2_epi16 = _mm_srli_si128(sum1_epi16, 7*2);

		// Shift the extra highpass coefficient into the output
		sum1_epi16 = _mm_slli_si128(sum1_epi16, 1*2);
		sum1_epi16 = _mm_insert_epi16(sum1_epi16, highpass_value, 0);

		// Save the last highpass coefficient for the next loop iteration
		highpass_value = _mm_cvtsi128_si32(sum2_epi16);

		// Store the four highpass output points
		_mm_store_si128(highpass_ptr++, sum1_epi16);

		// The second set of eight input pixels becomes the working set
		input1_epi16 = input2_epi16;
	}

	// Should have exited the loop at the post processing column
	assert(column == post_column);

	lowptr = (PIXEL *)lowpass_ptr;
	highptr = (PIXEL *)highpass_ptr;

#else
	sum = input[column] + input[column + 1];
	*(lowptr++) = SATURATE(sum);
	*(highptr++) = SATURATE(highpass_value);
	column+=2;
#endif

	// Process the last group of columns as a special case to handle the border
	for (; column < last_column; column += 2)
	{
		// Compute the lowpass sum
		sum = input[column] + input[column + 1];

		// Store the lowpass sum
		*(lowptr++) = SATURATE(sum);

		// Compute the highpass sum
		sum = 0;
		sum -= input[column - 2];
		sum -= input[column - 1];
		sum += input[column + 2];
		sum += input[column + 3];
		sum += ROUNDING(sum,8);
		sum = DivideByShift(sum, 3);
		sum += input[column + 0];
		sum -= input[column + 1];

		// Store the highpass sum
		*(highptr++) = SATURATE(sum);
	}

	// Should be at the last column
	assert(column == last_column);

	// Compute the last lowpass value
	sum = input[column] + input[column + 1];

	*(lowptr++) = SATURATE(sum);

	// Compute the last highpass value using the special border coefficients
	sum = 0;
	sum += 11 * input[column + 0];
	sum -=  5 * input[column + 1];
	sum -=  4 * input[column - 1];
	sum -=  4 * input[column - 2];
	sum +=  1 * input[column - 3];
	sum +=  1 * input[column - 4];
	sum +=  ROUNDING(sum,8);
	sum = DivideByShift(sum, 3);

	*(highptr++) = SATURATE(sum);
}

#endif

#endif


// Apply the lowpass and highpass horizontal filters to one row
void FilterHorizontalRowBYR3_16s(PIXEL *input, PIXEL *lowpass, PIXEL *highpass, int width)
{
	int column_step = 16;				// Number of input pixels processed per loop iteration
	int last_column = width - 2;		// Column at which right border processing is done

	// The post column is the column at which end of column processing must begin
	int post_column = last_column - (last_column % column_step);

	int32_t g,g2,sumGG,sumRG,sumBG,sumDG;
	PIXEL *lineR,*lineG;
	PIXEL *lineg,*lineB;

	// Start at the left end of the row
	PIXEL *lowptrGG;  //GG =  Green1 + Green2
	PIXEL *highptrGG;
	PIXEL *lowptrRG;  //RG =  Red - GG;
	PIXEL *highptrRG;
	PIXEL *lowptrBG;  //BG =  Blue - GG;
	PIXEL *highptrBG;
	PIXEL *lowptrDG;  //DG (difference G) =  Green1 - Green2
	PIXEL *highptrDG;
	int column = 0;

#if 0
	// This version caused a compiler warning
	__m128i *inputR_ptr = (__m128i *)lineR;
	__m128i *inputG_ptr = (__m128i *)lineG;
	__m128i *inputg_ptr = (__m128i *)lineg;
	__m128i *inputB_ptr = (__m128i *)lineB;
#else
	__m128i *inputR_ptr;
	__m128i *inputG_ptr;
	__m128i *inputg_ptr;
	__m128i *inputB_ptr;
#endif
	__m128i *lowpassGG_ptr;
	__m128i *lowpassRG_ptr;
	__m128i *lowpassBG_ptr;
	__m128i *lowpassDG_ptr;
	__m128i *highpassGG_ptr;
	__m128i *highpassRG_ptr;
	__m128i *highpassBG_ptr;
	__m128i *highpassDG_ptr;
	__m128i inputR_epi16;
	__m128i inputG_epi16;
	__m128i inputg_epi16;
	__m128i inputB_epi16;

	int highpass_valueGG;
	int highpass_valueRG;
	int highpass_valueBG;
	int highpass_valueDG;

	lineR = input;
	lineG = input + (width);
	lineg = input + (width)*2;
	lineB = input + (width)*3;
	lowptrGG = lowpass;
	lowptrRG = lowpass + (width>>1);
	lowptrBG = lowpass + (width>>1)*2;
	lowptrDG = lowpass + (width>>1)*3;
	highptrGG = highpass;
	highptrRG = highpass + (width>>1);
	highptrBG = highpass + (width>>1)*2;
	highptrDG = highpass + (width>>1)*3;

	// The highpass filter on the left border uses different coefficients
	sumGG=sumRG=sumBG=sumDG = 0;

	//sum +=  5 * lineR[column + 0];
	g = (lineG[column + 0] + lineg[column + 0]) >> 1;
	sumGG +=  5 * g;
	sumRG +=  5 * (((lineR[column + 0]-g)>>1)+512);
	sumBG +=  5 * (((lineB[column + 0]-g)>>1)+512);
	sumDG +=  5 * ((lineG[column + 0] - lineg[column + 0]+1024)>>1);

	//sum -= 11 * lineR[column + 1];
	g = (lineG[column + 1] + lineg[column + 1]) >> 1;
	sumGG -=  11 * g;
	sumRG -=  11 * (((lineR[column + 1]-g)>>1)+512);
	sumBG -=  11 * (((lineB[column + 1]-g)>>1)+512);
	sumDG -=  11 * ((lineG[column + 1] - lineg[column + 1]+1024)>>1);

	//sum +=  4 * lineR[column + 2];
	g = (lineG[column + 2] + lineg[column + 2]) >> 1;
	sumGG +=  4 * g;
	sumRG +=  4 * (((lineR[column + 2]-g)>>1)+512);
	sumBG +=  4 * (((lineB[column + 2]-g)>>1)+512);
	sumDG +=  4 * ((lineG[column + 2] - lineg[column + 2]+1024)>>1);

	//sum +=  4 * lineR[column + 3];
	g = (lineG[column + 3] + lineg[column + 3]) >> 1;
	sumGG +=  4 * g;
	sumRG +=  4 * (((lineR[column + 3]-g)>>1)+512);
	sumBG +=  4 * (((lineB[column + 3]-g)>>1)+512);
	sumDG +=  4 * ((lineG[column + 3] - lineg[column + 3]+1024)>>1);

	//sum -=  1 * lineR[column + 4];
	g = (lineG[column + 4] + lineg[column + 4]) >> 1;
	sumGG -=  1 * g;
	sumRG -=  1 * (((lineR[column + 4]-g)>>1)+512);
	sumBG -=  1 * (((lineB[column + 4]-g)>>1)+512);
	sumDG -=  1 * ((lineG[column + 4] - lineg[column + 4]+1024)>>1);

	//sum -=  1 * lineR[column + 5];
	g = (lineG[column + 5] + lineg[column + 5]) >> 1;
	sumGG -=  1 * g;
	sumRG -=  1 * (((lineR[column + 5]-g)>>1)+512);
	sumBG -=  1 * (((lineB[column + 5]-g)>>1)+512);
	sumDG -=  1 * ((lineG[column + 5] - lineg[column + 5]+1024)>>1);

	//sum += ROUNDING(sum,8);
	sumGG += ROUNDING(sumGG,8);
	sumRG += ROUNDING(sumRG,8);
	sumBG += ROUNDING(sumBG,8);
	sumDG += ROUNDING(sumDG,8);

	//sum = DivideByShift(sum, 3);
	sumGG = DivideByShift(sumGG,3);
	sumRG = DivideByShift(sumRG,3);
	sumBG = DivideByShift(sumBG,3);
	sumDG = DivideByShift(sumDG,3);

	//highpass_value = SATURATE(sum);
	highpass_valueGG = SATURATE(sumGG);
	highpass_valueRG = SATURATE(sumRG);
	highpass_valueBG = SATURATE(sumBG);
	highpass_valueDG = SATURATE(sumDG);

	// Set the input pointer for the fast loop
	inputR_ptr = (__m128i *)&lineR[column];
	inputG_ptr = (__m128i *)&lineG[column];
	inputg_ptr = (__m128i *)&lineg[column];
	inputB_ptr = (__m128i *)&lineB[column];

	// Initialize the output pointers
	lowpassGG_ptr = (__m128i *)lowptrGG;
	lowpassRG_ptr = (__m128i *)lowptrRG;
	lowpassBG_ptr = (__m128i *)lowptrBG;
	lowpassDG_ptr = (__m128i *)lowptrDG;
	highpassGG_ptr = (__m128i *)highptrGG;
	highpassRG_ptr = (__m128i *)highptrRG;
	highpassBG_ptr = (__m128i *)highptrBG;
	highpassDG_ptr = (__m128i *)highptrDG;

	// Check that the output pointers are properly aligned
	assert(ISALIGNED16(lowpassGG_ptr));
	assert(ISALIGNED16(lowpassRG_ptr));
	assert(ISALIGNED16(lowpassBG_ptr));
	assert(ISALIGNED16(lowpassDG_ptr));
	assert(ISALIGNED16(highpassGG_ptr));
	assert(ISALIGNED16(highpassRG_ptr));
	assert(ISALIGNED16(highpassBG_ptr));
	assert(ISALIGNED16(highpassDG_ptr));

#if 1
	{
		__m128i GG1_epi16;
		__m128i RG1_epi16;
		__m128i BG1_epi16;
		__m128i DG1_epi16;

		const __m128i rounding_epi16 = _mm_set1_epi16(512);


		// Preload the first set of four pixels for fast processing
		inputR_epi16 = _mm_load_si128(inputR_ptr++);
		inputG_epi16 = _mm_load_si128(inputG_ptr++);
		inputg_epi16 = _mm_load_si128(inputg_ptr++);
		inputB_epi16 = _mm_load_si128(inputB_ptr++);


		GG1_epi16 = _mm_adds_epi16(inputG_epi16,inputg_epi16);
		GG1_epi16 = _mm_srai_epi16(GG1_epi16, 1);

		RG1_epi16 = _mm_subs_epi16(inputR_epi16, GG1_epi16);
		RG1_epi16 = _mm_srai_epi16(RG1_epi16, 1);
		RG1_epi16 = _mm_adds_epi16(RG1_epi16,rounding_epi16);

		BG1_epi16 = _mm_subs_epi16(inputB_epi16, GG1_epi16);
		BG1_epi16 = _mm_srai_epi16(BG1_epi16, 1);
		BG1_epi16 = _mm_adds_epi16(BG1_epi16,rounding_epi16);

		DG1_epi16 = _mm_subs_epi16(inputG_epi16,inputg_epi16);
		DG1_epi16 = _mm_adds_epi16(DG1_epi16,rounding_epi16);
		DG1_epi16 = _mm_adds_epi16(DG1_epi16,rounding_epi16);
		DG1_epi16 = _mm_srai_epi16(DG1_epi16, 1);


		// Process two sets of four input pixels to get one set of four output pixels
		for (; column < post_column; column += column_step)
		{
			__m128i shiftGG_epi16;
			__m128i shiftRG_epi16;
			__m128i shiftBG_epi16;
			__m128i shiftDG_epi16;
			__m128i half_epi16;		// Half of the divisor for rounding
			__m128i sumGG1_epi16;
			__m128i sumRG1_epi16;
			__m128i sumBG1_epi16;
			__m128i sumDG1_epi16;
			__m128i sumGG2_epi16;
			__m128i sumRG2_epi16;
			__m128i sumBG2_epi16;
			__m128i sumDG2_epi16;
			__m128i lowGG1_epi16;
			__m128i lowRG1_epi16;
			__m128i lowBG1_epi16;
			__m128i lowDG1_epi16;
			__m128i lowGG2_epi16;
			__m128i lowRG2_epi16;
			__m128i lowBG2_epi16;
			__m128i lowDG2_epi16;

			__m128i sumGG1b_epi16;
			__m128i sumRG1b_epi16;
			__m128i sumBG1b_epi16;
			__m128i sumDG1b_epi16;
			__m128i sumGG2b_epi16;
			__m128i sumRG2b_epi16;
			__m128i sumBG2b_epi16;
			__m128i sumDG2b_epi16;

			__m128i GG2_epi16;
			__m128i RG2_epi16;
			__m128i BG2_epi16;
			__m128i DG2_epi16;


			/***** Process the first four output points *****/

			// Initialize the highpass sum
			sumGG1_epi16 = _mm_setzero_si128();
			sumRG1_epi16 = _mm_setzero_si128();
			sumBG1_epi16 = _mm_setzero_si128();
			sumDG1_epi16 = _mm_setzero_si128();

			// Apply the first filter coefficient to each pixel and sum the result
			sumGG1_epi16 = _mm_subs_epi16(sumGG1_epi16, GG1_epi16);
			sumRG1_epi16 = _mm_subs_epi16(sumRG1_epi16, RG1_epi16);
			sumBG1_epi16 = _mm_subs_epi16(sumBG1_epi16, BG1_epi16);
			sumDG1_epi16 = _mm_subs_epi16(sumDG1_epi16, DG1_epi16);

			// Check that the pointer to the next group of pixels is properly aligned
			assert(ISALIGNED16(inputR_ptr));
			assert(ISALIGNED16(inputG_ptr));
			assert(ISALIGNED16(inputg_ptr));
			assert(ISALIGNED16(inputB_ptr));

			// Load the next eight pixels
			inputR_epi16 = _mm_load_si128(inputR_ptr++);
			inputG_epi16 = _mm_load_si128(inputG_ptr++);
			inputg_epi16 = _mm_load_si128(inputg_ptr++);
			inputB_epi16 = _mm_load_si128(inputB_ptr++);

			GG2_epi16 = _mm_adds_epi16(inputG_epi16,inputg_epi16);
			GG2_epi16 = _mm_srai_epi16(GG2_epi16, 1);

			RG2_epi16 = _mm_subs_epi16(inputR_epi16, GG2_epi16);
			RG2_epi16 = _mm_srai_epi16(RG2_epi16, 1);
			RG2_epi16 = _mm_adds_epi16(RG2_epi16,rounding_epi16);

			BG2_epi16 = _mm_subs_epi16(inputB_epi16, GG2_epi16);
			BG2_epi16 = _mm_srai_epi16(BG2_epi16, 1);
			BG2_epi16 = _mm_adds_epi16(BG2_epi16,rounding_epi16);

			DG2_epi16 = _mm_subs_epi16(inputG_epi16,inputg_epi16);
			DG2_epi16 = _mm_adds_epi16(DG2_epi16,rounding_epi16);
			DG2_epi16 = _mm_adds_epi16(DG2_epi16,rounding_epi16);
			DG2_epi16 = _mm_srai_epi16(DG2_epi16, 1);


			// Initialize the lowpass sum
			lowGG1_epi16 = GG1_epi16;
			lowRG1_epi16 = RG1_epi16;
			lowBG1_epi16 = BG1_epi16;
			lowDG1_epi16 = DG1_epi16;

			// Shift the first pixel from the second set into the working set
			shiftGG_epi16 = _mm_slli_si128(GG2_epi16, 7*2);
			shiftRG_epi16 = _mm_slli_si128(RG2_epi16, 7*2);
			shiftBG_epi16 = _mm_slli_si128(BG2_epi16, 7*2);
			shiftDG_epi16 = _mm_slli_si128(DG2_epi16, 7*2);
			GG1_epi16 = _mm_srli_si128(GG1_epi16, 1*2);
			RG1_epi16 = _mm_srli_si128(RG1_epi16, 1*2);
			BG1_epi16 = _mm_srli_si128(BG1_epi16, 1*2);
			DG1_epi16 = _mm_srli_si128(DG1_epi16, 1*2);
			GG1_epi16 = _mm_or_si128(GG1_epi16, shiftGG_epi16);
			RG1_epi16 = _mm_or_si128(RG1_epi16, shiftRG_epi16);
			BG1_epi16 = _mm_or_si128(BG1_epi16, shiftBG_epi16);
			DG1_epi16 = _mm_or_si128(DG1_epi16, shiftDG_epi16);

			// Apply the second filter coefficient to each pixel and sum the result
			sumGG1_epi16 = _mm_subs_epi16(sumGG1_epi16, GG1_epi16);
			sumRG1_epi16 = _mm_subs_epi16(sumRG1_epi16, RG1_epi16);
			sumBG1_epi16 = _mm_subs_epi16(sumBG1_epi16, BG1_epi16);
			sumDG1_epi16 = _mm_subs_epi16(sumDG1_epi16, DG1_epi16);

			// Add adjacent points to compute the lowpass sum
			lowGG1_epi16 = _mm_adds_epi16(lowGG1_epi16, GG1_epi16);
			lowRG1_epi16 = _mm_adds_epi16(lowRG1_epi16, RG1_epi16);
			lowBG1_epi16 = _mm_adds_epi16(lowBG1_epi16, BG1_epi16);
			lowDG1_epi16 = _mm_adds_epi16(lowDG1_epi16, DG1_epi16);

			// Expand the lowpass output points to a full doubleword
			lowGG1_epi16 = _mm_slli_epi32(lowGG1_epi16, 16);
			lowRG1_epi16 = _mm_slli_epi32(lowRG1_epi16, 16);
			lowBG1_epi16 = _mm_slli_epi32(lowBG1_epi16, 16);
			lowDG1_epi16 = _mm_slli_epi32(lowDG1_epi16, 16);
			lowGG1_epi16 = _mm_srai_epi32(lowGG1_epi16, 16);
			lowRG1_epi16 = _mm_srai_epi32(lowRG1_epi16, 16);
			lowBG1_epi16 = _mm_srai_epi32(lowBG1_epi16, 16);
			lowDG1_epi16 = _mm_srai_epi32(lowDG1_epi16, 16);

			// Shift the second pixel from the second set into the working set
			shiftGG_epi16 = _mm_slli_si128(GG2_epi16, 6*2);
			shiftRG_epi16 = _mm_slli_si128(RG2_epi16, 6*2);
			shiftBG_epi16 = _mm_slli_si128(BG2_epi16, 6*2);
			shiftDG_epi16 = _mm_slli_si128(DG2_epi16, 6*2);
			GG1_epi16 = _mm_srli_si128(GG1_epi16, 1*2);
			RG1_epi16 = _mm_srli_si128(RG1_epi16, 1*2);
			BG1_epi16 = _mm_srli_si128(BG1_epi16, 1*2);
			DG1_epi16 = _mm_srli_si128(DG1_epi16, 1*2);
			GG1_epi16 = _mm_or_si128(GG1_epi16, shiftGG_epi16);
			RG1_epi16 = _mm_or_si128(RG1_epi16, shiftRG_epi16);
			BG1_epi16 = _mm_or_si128(BG1_epi16, shiftBG_epi16);
			DG1_epi16 = _mm_or_si128(DG1_epi16, shiftDG_epi16);

			// Apply the third filter coefficient to each pixel and sum the result
			sumGG1b_epi16 = GG1_epi16;
			sumRG1b_epi16 = RG1_epi16;
			sumBG1b_epi16 = BG1_epi16;
			sumDG1b_epi16 = DG1_epi16;

			// Shift the third pixel from the second set into the working set
			shiftGG_epi16 = _mm_slli_si128(GG2_epi16, 5*2);
			shiftRG_epi16 = _mm_slli_si128(RG2_epi16, 5*2);
			shiftBG_epi16 = _mm_slli_si128(BG2_epi16, 5*2);
			shiftDG_epi16 = _mm_slli_si128(DG2_epi16, 5*2);
			GG1_epi16 = _mm_srli_si128(GG1_epi16, 1*2);
			RG1_epi16 = _mm_srli_si128(RG1_epi16, 1*2);
			BG1_epi16 = _mm_srli_si128(BG1_epi16, 1*2);
			DG1_epi16 = _mm_srli_si128(DG1_epi16, 1*2);
			GG1_epi16 = _mm_or_si128(GG1_epi16, shiftGG_epi16);
			RG1_epi16 = _mm_or_si128(RG1_epi16, shiftRG_epi16);
			BG1_epi16 = _mm_or_si128(BG1_epi16, shiftBG_epi16);
			DG1_epi16 = _mm_or_si128(DG1_epi16, shiftDG_epi16);

			// Apply the fourth filter coefficient to each pixel and sum the result
			sumGG1b_epi16 = _mm_subs_epi16(sumGG1b_epi16, GG1_epi16);
			sumRG1b_epi16 = _mm_subs_epi16(sumRG1b_epi16, RG1_epi16);
			sumBG1b_epi16 = _mm_subs_epi16(sumBG1b_epi16, BG1_epi16);
			sumDG1b_epi16 = _mm_subs_epi16(sumDG1b_epi16, DG1_epi16);

			// Shift the fourth pixel from the second set into the working set
			shiftGG_epi16 = _mm_slli_si128(GG2_epi16, 4*2);
			shiftRG_epi16 = _mm_slli_si128(RG2_epi16, 4*2);
			shiftBG_epi16 = _mm_slli_si128(BG2_epi16, 4*2);
			shiftDG_epi16 = _mm_slli_si128(DG2_epi16, 4*2);
			GG1_epi16 = _mm_srli_si128(GG1_epi16, 1*2);
			RG1_epi16 = _mm_srli_si128(RG1_epi16, 1*2);
			BG1_epi16 = _mm_srli_si128(BG1_epi16, 1*2);
			DG1_epi16 = _mm_srli_si128(DG1_epi16, 1*2);
			GG1_epi16 = _mm_or_si128(GG1_epi16, shiftGG_epi16);
			RG1_epi16 = _mm_or_si128(RG1_epi16, shiftRG_epi16);
			BG1_epi16 = _mm_or_si128(BG1_epi16, shiftBG_epi16);
			DG1_epi16 = _mm_or_si128(DG1_epi16, shiftDG_epi16);

			// Apply the fifth filter coefficient to each pixel and sum the result
			sumGG1_epi16 = _mm_adds_epi16(sumGG1_epi16, GG1_epi16);
			sumRG1_epi16 = _mm_adds_epi16(sumRG1_epi16, RG1_epi16);
			sumBG1_epi16 = _mm_adds_epi16(sumBG1_epi16, BG1_epi16);
			sumDG1_epi16 = _mm_adds_epi16(sumDG1_epi16, DG1_epi16);

			// Shift the fifth pixel from the second set into the working set
			shiftGG_epi16 = _mm_slli_si128(GG2_epi16, 3*2);
			shiftRG_epi16 = _mm_slli_si128(RG2_epi16, 3*2);
			shiftBG_epi16 = _mm_slli_si128(BG2_epi16, 3*2);
			shiftDG_epi16 = _mm_slli_si128(DG2_epi16, 3*2);
			GG1_epi16 = _mm_srli_si128(GG1_epi16, 1*2);
			RG1_epi16 = _mm_srli_si128(RG1_epi16, 1*2);
			BG1_epi16 = _mm_srli_si128(BG1_epi16, 1*2);
			DG1_epi16 = _mm_srli_si128(DG1_epi16, 1*2);
			GG1_epi16 = _mm_or_si128(GG1_epi16, shiftGG_epi16);
			RG1_epi16 = _mm_or_si128(RG1_epi16, shiftRG_epi16);
			BG1_epi16 = _mm_or_si128(BG1_epi16, shiftBG_epi16);
			DG1_epi16 = _mm_or_si128(DG1_epi16, shiftDG_epi16);

			// Apply the sixth (last) filter coefficient to each pixel and sum the result
			sumGG1_epi16 = _mm_adds_epi16(sumGG1_epi16, GG1_epi16);
			sumRG1_epi16 = _mm_adds_epi16(sumRG1_epi16, RG1_epi16);
			sumBG1_epi16 = _mm_adds_epi16(sumBG1_epi16, BG1_epi16);
			sumDG1_epi16 = _mm_adds_epi16(sumDG1_epi16, DG1_epi16);

			//DAN20050915 -- reversibility
			half_epi16 = _mm_set1_epi16(4);
			sumGG1_epi16 = _mm_adds_epi16(sumGG1_epi16, half_epi16);
			sumRG1_epi16 = _mm_adds_epi16(sumRG1_epi16, half_epi16);
			sumBG1_epi16 = _mm_adds_epi16(sumBG1_epi16, half_epi16);
			sumDG1_epi16 = _mm_adds_epi16(sumDG1_epi16, half_epi16);
			sumGG1_epi16 = _mm_srai_epi16(sumGG1_epi16, 3);
			sumRG1_epi16 = _mm_srai_epi16(sumRG1_epi16, 3);
			sumBG1_epi16 = _mm_srai_epi16(sumBG1_epi16, 3);
			sumDG1_epi16 = _mm_srai_epi16(sumDG1_epi16, 3);

			sumGG1_epi16 = _mm_adds_epi16(sumGG1_epi16, sumGG1b_epi16);
			sumRG1_epi16 = _mm_adds_epi16(sumRG1_epi16, sumRG1b_epi16);
			sumBG1_epi16 = _mm_adds_epi16(sumBG1_epi16, sumBG1b_epi16);
			sumDG1_epi16 = _mm_adds_epi16(sumDG1_epi16, sumDG1b_epi16);

			// Expand the even output points to a full doubleword
			sumGG1_epi16 = _mm_slli_epi32(sumGG1_epi16, 16);
			sumRG1_epi16 = _mm_slli_epi32(sumRG1_epi16, 16);
			sumBG1_epi16 = _mm_slli_epi32(sumBG1_epi16, 16);
			sumDG1_epi16 = _mm_slli_epi32(sumDG1_epi16, 16);
			sumGG1_epi16 = _mm_srai_epi32(sumGG1_epi16, 16);
			sumRG1_epi16 = _mm_srai_epi32(sumRG1_epi16, 16);
			sumBG1_epi16 = _mm_srai_epi32(sumBG1_epi16, 16);
			sumDG1_epi16 = _mm_srai_epi32(sumDG1_epi16, 16);

			// The second eight input points become the current input points
			GG1_epi16 = GG2_epi16;
			RG1_epi16 = RG2_epi16;
			BG1_epi16 = BG2_epi16;
			DG1_epi16 = DG2_epi16;


			/***** Process the second four output points *****/

			// Initialize the highpass sum
			sumGG2_epi16 = _mm_setzero_si128();
			sumRG2_epi16 = _mm_setzero_si128();
			sumBG2_epi16 = _mm_setzero_si128();
			sumDG2_epi16 = _mm_setzero_si128();

			// Apply the first filter coefficient to each pixel and sum the result
			sumGG2_epi16 = _mm_subs_epi16(sumGG2_epi16, GG1_epi16);
			sumRG2_epi16 = _mm_subs_epi16(sumRG2_epi16, RG1_epi16);
			sumBG2_epi16 = _mm_subs_epi16(sumBG2_epi16, BG1_epi16);
			sumDG2_epi16 = _mm_subs_epi16(sumDG2_epi16, DG1_epi16);

			// Check that the pointer to the next group of pixels is properly aligned
			assert(ISALIGNED16(inputR_ptr));
			assert(ISALIGNED16(inputG_ptr));
			assert(ISALIGNED16(inputg_ptr));
			assert(ISALIGNED16(inputB_ptr));

			// Load the next eight pixels
			inputR_epi16 = _mm_load_si128(inputR_ptr++);
			inputG_epi16 = _mm_load_si128(inputG_ptr++);
			inputg_epi16 = _mm_load_si128(inputg_ptr++);
			inputB_epi16 = _mm_load_si128(inputB_ptr++);

			GG2_epi16 = _mm_adds_epi16(inputG_epi16,inputg_epi16);
			GG2_epi16 = _mm_srai_epi16(GG2_epi16, 1);

			RG2_epi16 = _mm_subs_epi16(inputR_epi16, GG2_epi16);
			RG2_epi16 = _mm_srai_epi16(RG2_epi16, 1);
			RG2_epi16 = _mm_adds_epi16(RG2_epi16,rounding_epi16);

			BG2_epi16 = _mm_subs_epi16(inputB_epi16, GG2_epi16);
			BG2_epi16 = _mm_srai_epi16(BG2_epi16, 1);
			BG2_epi16 = _mm_adds_epi16(BG2_epi16,rounding_epi16);

			DG2_epi16 = _mm_subs_epi16(inputG_epi16,inputg_epi16);
			DG2_epi16 = _mm_adds_epi16(DG2_epi16,rounding_epi16);
			DG2_epi16 = _mm_adds_epi16(DG2_epi16,rounding_epi16);
			DG2_epi16 = _mm_srai_epi16(DG2_epi16, 1);



			// Initialize the lowpass sum
			lowGG2_epi16 = GG1_epi16;
			lowRG2_epi16 = RG1_epi16;
			lowBG2_epi16 = BG1_epi16;
			lowDG2_epi16 = DG1_epi16;

			// Shift the first pixel from the second set into the working set
			shiftGG_epi16 = _mm_slli_si128(GG2_epi16, 7*2);
			shiftRG_epi16 = _mm_slli_si128(RG2_epi16, 7*2);
			shiftBG_epi16 = _mm_slli_si128(BG2_epi16, 7*2);
			shiftDG_epi16 = _mm_slli_si128(DG2_epi16, 7*2);
			GG1_epi16 = _mm_srli_si128(GG1_epi16, 1*2);
			RG1_epi16 = _mm_srli_si128(RG1_epi16, 1*2);
			BG1_epi16 = _mm_srli_si128(BG1_epi16, 1*2);
			DG1_epi16 = _mm_srli_si128(DG1_epi16, 1*2);
			GG1_epi16 = _mm_or_si128(GG1_epi16, shiftGG_epi16);
			RG1_epi16 = _mm_or_si128(RG1_epi16, shiftRG_epi16);
			BG1_epi16 = _mm_or_si128(BG1_epi16, shiftBG_epi16);
			DG1_epi16 = _mm_or_si128(DG1_epi16, shiftDG_epi16);

			// Apply the second filter coefficient to each pixel and sum the result
			sumGG2_epi16 = _mm_subs_epi16(sumGG2_epi16, GG1_epi16);
			sumRG2_epi16 = _mm_subs_epi16(sumRG2_epi16, RG1_epi16);
			sumBG2_epi16 = _mm_subs_epi16(sumBG2_epi16, BG1_epi16);
			sumDG2_epi16 = _mm_subs_epi16(sumDG2_epi16, DG1_epi16);

			// Add adjacent points to compute the lowpass sum
			lowGG2_epi16 = _mm_adds_epi16(lowGG2_epi16, GG1_epi16);
			lowRG2_epi16 = _mm_adds_epi16(lowRG2_epi16, RG1_epi16);
			lowBG2_epi16 = _mm_adds_epi16(lowBG2_epi16, BG1_epi16);
			lowDG2_epi16 = _mm_adds_epi16(lowDG2_epi16, DG1_epi16);

			// Expand the lowpass output points to a full doubleword
			lowGG2_epi16 = _mm_slli_epi32(lowGG2_epi16, 16);
			lowRG2_epi16 = _mm_slli_epi32(lowRG2_epi16, 16);
			lowBG2_epi16 = _mm_slli_epi32(lowBG2_epi16, 16);
			lowDG2_epi16 = _mm_slli_epi32(lowDG2_epi16, 16);
			lowGG2_epi16 = _mm_srai_epi32(lowGG2_epi16, 16);
			lowRG2_epi16 = _mm_srai_epi32(lowRG2_epi16, 16);
			lowBG2_epi16 = _mm_srai_epi32(lowBG2_epi16, 16);
			lowDG2_epi16 = _mm_srai_epi32(lowDG2_epi16, 16);

			// Shift the second pixel from the second set into the working set
			shiftGG_epi16 = _mm_slli_si128(GG2_epi16, 6*2);
			shiftRG_epi16 = _mm_slli_si128(RG2_epi16, 6*2);
			shiftBG_epi16 = _mm_slli_si128(BG2_epi16, 6*2);
			shiftDG_epi16 = _mm_slli_si128(DG2_epi16, 6*2);
			GG1_epi16 = _mm_srli_si128(GG1_epi16, 1*2);
			RG1_epi16 = _mm_srli_si128(RG1_epi16, 1*2);
			BG1_epi16 = _mm_srli_si128(BG1_epi16, 1*2);
			DG1_epi16 = _mm_srli_si128(DG1_epi16, 1*2);
			GG1_epi16 = _mm_or_si128(GG1_epi16, shiftGG_epi16);
			RG1_epi16 = _mm_or_si128(RG1_epi16, shiftRG_epi16);
			BG1_epi16 = _mm_or_si128(BG1_epi16, shiftBG_epi16);
			DG1_epi16 = _mm_or_si128(DG1_epi16, shiftDG_epi16);

			// Apply the third filter coefficient to each pixel and sum the result
			sumGG2b_epi16 = GG1_epi16;
			sumRG2b_epi16 = RG1_epi16;
			sumBG2b_epi16 = BG1_epi16;
			sumDG2b_epi16 = DG1_epi16;

			// Shift the third pixel from the second set into the working set
			shiftGG_epi16 = _mm_slli_si128(GG2_epi16, 5*2);
			shiftRG_epi16 = _mm_slli_si128(RG2_epi16, 5*2);
			shiftBG_epi16 = _mm_slli_si128(BG2_epi16, 5*2);
			shiftDG_epi16 = _mm_slli_si128(DG2_epi16, 5*2);
			GG1_epi16 = _mm_srli_si128(GG1_epi16, 1*2);
			RG1_epi16 = _mm_srli_si128(RG1_epi16, 1*2);
			BG1_epi16 = _mm_srli_si128(BG1_epi16, 1*2);
			DG1_epi16 = _mm_srli_si128(DG1_epi16, 1*2);
			GG1_epi16 = _mm_or_si128(GG1_epi16, shiftGG_epi16);
			RG1_epi16 = _mm_or_si128(RG1_epi16, shiftRG_epi16);
			BG1_epi16 = _mm_or_si128(BG1_epi16, shiftBG_epi16);
			DG1_epi16 = _mm_or_si128(DG1_epi16, shiftDG_epi16);

			// Apply the fourth filter coefficient to each pixel and sum the result
			sumGG2b_epi16 = _mm_subs_epi16(sumGG2b_epi16, GG1_epi16);
			sumRG2b_epi16 = _mm_subs_epi16(sumRG2b_epi16, RG1_epi16);
			sumBG2b_epi16 = _mm_subs_epi16(sumBG2b_epi16, BG1_epi16);
			sumDG2b_epi16 = _mm_subs_epi16(sumDG2b_epi16, DG1_epi16);

			// Shift the fourth pixel from the second set into the working set
			shiftGG_epi16 = _mm_slli_si128(GG2_epi16, 4*2);
			shiftRG_epi16 = _mm_slli_si128(RG2_epi16, 4*2);
			shiftBG_epi16 = _mm_slli_si128(BG2_epi16, 4*2);
			shiftDG_epi16 = _mm_slli_si128(DG2_epi16, 4*2);
			GG1_epi16 = _mm_srli_si128(GG1_epi16, 1*2);
			RG1_epi16 = _mm_srli_si128(RG1_epi16, 1*2);
			BG1_epi16 = _mm_srli_si128(BG1_epi16, 1*2);
			DG1_epi16 = _mm_srli_si128(DG1_epi16, 1*2);
			GG1_epi16 = _mm_or_si128(GG1_epi16, shiftGG_epi16);
			RG1_epi16 = _mm_or_si128(RG1_epi16, shiftRG_epi16);
			BG1_epi16 = _mm_or_si128(BG1_epi16, shiftBG_epi16);
			DG1_epi16 = _mm_or_si128(DG1_epi16, shiftDG_epi16);

			// Apply the fifth filter coefficient to each pixel and sum the result
			sumGG2_epi16 = _mm_adds_epi16(sumGG2_epi16, GG1_epi16);
			sumRG2_epi16 = _mm_adds_epi16(sumRG2_epi16, RG1_epi16);
			sumBG2_epi16 = _mm_adds_epi16(sumBG2_epi16, BG1_epi16);
			sumDG2_epi16 = _mm_adds_epi16(sumDG2_epi16, DG1_epi16);

			// Shift the fifth pixel from the second set into the working set
			shiftGG_epi16 = _mm_slli_si128(GG2_epi16, 3*2);
			shiftRG_epi16 = _mm_slli_si128(RG2_epi16, 3*2);
			shiftBG_epi16 = _mm_slli_si128(BG2_epi16, 3*2);
			shiftDG_epi16 = _mm_slli_si128(DG2_epi16, 3*2);
			GG1_epi16 = _mm_srli_si128(GG1_epi16, 1*2);
			RG1_epi16 = _mm_srli_si128(RG1_epi16, 1*2);
			BG1_epi16 = _mm_srli_si128(BG1_epi16, 1*2);
			DG1_epi16 = _mm_srli_si128(DG1_epi16, 1*2);
			GG1_epi16 = _mm_or_si128(GG1_epi16, shiftGG_epi16);
			RG1_epi16 = _mm_or_si128(RG1_epi16, shiftRG_epi16);
			BG1_epi16 = _mm_or_si128(BG1_epi16, shiftBG_epi16);
			DG1_epi16 = _mm_or_si128(DG1_epi16, shiftDG_epi16);

			// Apply the sixth (last) filter coefficient to each pixel and sum the result
			sumGG2_epi16 = _mm_adds_epi16(sumGG2_epi16, GG1_epi16);
			sumRG2_epi16 = _mm_adds_epi16(sumRG2_epi16, RG1_epi16);
			sumBG2_epi16 = _mm_adds_epi16(sumBG2_epi16, BG1_epi16);
			sumDG2_epi16 = _mm_adds_epi16(sumDG2_epi16, DG1_epi16);


			//DAN20050915 -- reversibility
			half_epi16 = _mm_set1_epi16(4);
			sumGG2_epi16 = _mm_adds_epi16(sumGG2_epi16, half_epi16);
			sumRG2_epi16 = _mm_adds_epi16(sumRG2_epi16, half_epi16);
			sumBG2_epi16 = _mm_adds_epi16(sumBG2_epi16, half_epi16);
			sumDG2_epi16 = _mm_adds_epi16(sumDG2_epi16, half_epi16);
			sumGG2_epi16 = _mm_srai_epi16(sumGG2_epi16, 3);
			sumRG2_epi16 = _mm_srai_epi16(sumRG2_epi16, 3);
			sumBG2_epi16 = _mm_srai_epi16(sumBG2_epi16, 3);
			sumDG2_epi16 = _mm_srai_epi16(sumDG2_epi16, 3);

			sumGG2_epi16 = _mm_adds_epi16(sumGG2_epi16, sumGG2b_epi16);
			sumRG2_epi16 = _mm_adds_epi16(sumRG2_epi16, sumRG2b_epi16);
			sumBG2_epi16 = _mm_adds_epi16(sumBG2_epi16, sumBG2b_epi16);
			sumDG2_epi16 = _mm_adds_epi16(sumDG2_epi16, sumDG2b_epi16);


			// Expand the even output points to a full doubleword
			sumGG2_epi16 = _mm_slli_epi32(sumGG2_epi16, 16);
			sumRG2_epi16 = _mm_slli_epi32(sumRG2_epi16, 16);
			sumBG2_epi16 = _mm_slli_epi32(sumBG2_epi16, 16);
			sumDG2_epi16 = _mm_slli_epi32(sumDG2_epi16, 16);
			sumGG2_epi16 = _mm_srai_epi32(sumGG2_epi16, 16);
			sumRG2_epi16 = _mm_srai_epi32(sumRG2_epi16, 16);
			sumBG2_epi16 = _mm_srai_epi32(sumBG2_epi16, 16);
			sumDG2_epi16 = _mm_srai_epi32(sumDG2_epi16, 16);


			/***** Combine the output points *****/

			lowGG1_epi16 = _mm_packs_epi32(lowGG1_epi16, lowGG2_epi16);
			lowRG1_epi16 = _mm_packs_epi32(lowRG1_epi16, lowRG2_epi16);
			lowBG1_epi16 = _mm_packs_epi32(lowBG1_epi16, lowBG2_epi16);
			lowDG1_epi16 = _mm_packs_epi32(lowDG1_epi16, lowDG2_epi16);
			sumGG1_epi16 = _mm_packs_epi32(sumGG1_epi16, sumGG2_epi16);
			sumRG1_epi16 = _mm_packs_epi32(sumRG1_epi16, sumRG2_epi16);
			sumBG1_epi16 = _mm_packs_epi32(sumBG1_epi16, sumBG2_epi16);
			sumDG1_epi16 = _mm_packs_epi32(sumDG1_epi16, sumDG2_epi16);


			// Store the four lowpass output points
			_mm_store_si128(lowpassGG_ptr++, lowGG1_epi16);
			_mm_store_si128(lowpassRG_ptr++, lowRG1_epi16);
			_mm_store_si128(lowpassBG_ptr++, lowBG1_epi16);
			_mm_store_si128(lowpassDG_ptr++, lowDG1_epi16);

			// Get the last highpass coefficient in the group
			sumGG2_epi16 = _mm_srli_si128(sumGG1_epi16, 7*2);
			sumRG2_epi16 = _mm_srli_si128(sumRG1_epi16, 7*2);
			sumBG2_epi16 = _mm_srli_si128(sumBG1_epi16, 7*2);
			sumDG2_epi16 = _mm_srli_si128(sumDG1_epi16, 7*2);

			// Shift the extra highpass coefficient into the output
			sumGG1_epi16 = _mm_slli_si128(sumGG1_epi16, 1*2);
			sumRG1_epi16 = _mm_slli_si128(sumRG1_epi16, 1*2);
			sumBG1_epi16 = _mm_slli_si128(sumBG1_epi16, 1*2);
			sumDG1_epi16 = _mm_slli_si128(sumDG1_epi16, 1*2);
			sumGG1_epi16 = _mm_insert_epi16(sumGG1_epi16, highpass_valueGG, 0);
			sumRG1_epi16 = _mm_insert_epi16(sumRG1_epi16, highpass_valueRG, 0);
			sumBG1_epi16 = _mm_insert_epi16(sumBG1_epi16, highpass_valueBG, 0);
			sumDG1_epi16 = _mm_insert_epi16(sumDG1_epi16, highpass_valueDG, 0);

			// Save the last highpass coefficient for the next loop iteration
			highpass_valueGG = _mm_cvtsi128_si32(sumGG2_epi16);
			highpass_valueRG = _mm_cvtsi128_si32(sumRG2_epi16);
			highpass_valueBG = _mm_cvtsi128_si32(sumBG2_epi16);
			highpass_valueDG = _mm_cvtsi128_si32(sumDG2_epi16);

			// Store the four highpass output points
			_mm_store_si128(highpassGG_ptr++, sumGG1_epi16);
			_mm_store_si128(highpassRG_ptr++, sumRG1_epi16);
			_mm_store_si128(highpassBG_ptr++, sumBG1_epi16);
			_mm_store_si128(highpassDG_ptr++, sumDG1_epi16);

			// The second set of eight input pixels becomes the working set
			GG1_epi16 = GG2_epi16;
			RG1_epi16 = RG2_epi16;
			BG1_epi16 = BG2_epi16;
			DG1_epi16 = DG2_epi16;
		}
	}
	// Should have exited the loop at the post processing column
	assert(column == post_column);

	lowptrGG = (PIXEL *)lowpassGG_ptr;
	lowptrRG = (PIXEL *)lowpassRG_ptr;
	lowptrBG = (PIXEL *)lowpassBG_ptr;
	lowptrDG = (PIXEL *)lowpassDG_ptr;
	highptrGG = (PIXEL *)highpassGG_ptr;
	highptrRG = (PIXEL *)highpassRG_ptr;
	highptrBG = (PIXEL *)highpassBG_ptr;
	highptrDG = (PIXEL *)highpassDG_ptr;

#endif
	// Process the last group of columns as a special case to handle the border
	for (; column < last_column; column += 2)
	{
		// Compute the lowpass sum
		//sum = input[column] + input[column + 1];
		g = (lineG[column + 0] + lineg[column + 0]) >> 1;
		g2 = (lineG[column + 1] + lineg[column + 1]) >> 1;
		sumGG = g + g2;
		sumRG = (((lineR[column + 0]-g)>>1)+512) + (((lineR[column + 1]-g2)>>1)+512);
		sumBG = (((lineB[column + 0]-g)>>1)+512) + (((lineB[column + 1]-g2)>>1)+512);
		sumDG = ((lineG[column + 0] - lineg[column + 0]+1024)>>1) + ((lineG[column + 1] - lineg[column + 1]+1024)>>1);

		// Store the lowpass sum
		*(lowptrGG++) = SATURATE(sumGG);
		*(lowptrRG++) = SATURATE(sumRG);
		*(lowptrBG++) = SATURATE(sumBG);
		*(lowptrDG++) = SATURATE(sumDG);

		// Compute the highpass sum
		//sum = 0;
		sumGG=sumRG=sumBG=sumDG = 0;

		//sum -= input[column - 2];
		g = (lineG[column - 2] + lineg[column - 2]) >> 1;
		sumGG -= g;
		sumRG -= (((lineR[column - 2]-g)>>1)+512);
		sumBG -= (((lineB[column - 2]-g)>>1)+512);
		sumDG -= ((lineG[column - 2] - lineg[column - 2]+1024)>>1);

		//sum -= input[column - 1];
		g = (lineG[column - 1] + lineg[column - 1]) >> 1;
		sumGG -= g;
		sumRG -= (((lineR[column - 1]-g)>>1)+512);
		sumBG -= (((lineB[column - 1]-g)>>1)+512);
		sumDG -= ((lineG[column - 1] - lineg[column - 1]+1024)>>1);

		//sum += input[column + 2];
		g = (lineG[column + 2] + lineg[column + 2]) >> 1;
		sumGG += g;
		sumRG += (((lineR[column + 2]-g)>>1)+512);
		sumBG += (((lineB[column + 2]-g)>>1)+512);
		sumDG += ((lineG[column + 2] - lineg[column + 2]+1024)>>1);

		//sum += input[column + 3];
		g = (lineG[column + 3] + lineg[column + 3]) >> 1;
		sumGG += g;
		sumRG += (((lineR[column + 3]-g)>>1)+512);
		sumBG += (((lineB[column + 3]-g)>>1)+512);
		sumDG += ((lineG[column + 3] - lineg[column + 3]+1024)>>1);

		//sum += ROUNDING(sum,8);
		sumGG += ROUNDING(sumGG,8);
		sumRG += ROUNDING(sumRG,8);
		sumBG += ROUNDING(sumBG,8);
		sumDG += ROUNDING(sumDG,8);

		//sum = DivideByShift(sum, 3);
		sumGG = DivideByShift(sumGG,3);
		sumRG = DivideByShift(sumRG,3);
		sumBG = DivideByShift(sumBG,3);
		sumDG = DivideByShift(sumDG,3);

		//sum += input[column + 0];
		g = (lineG[column + 0] + lineg[column + 0]) >> 1;
		sumGG += g;
		sumRG += (((lineR[column + 0]-g)>>1)+512);
		sumBG += (((lineB[column + 0]-g)>>1)+512);
		sumDG += ((lineG[column + 0] - lineg[column + 0]+1024)>>1);

		//sum -= input[column + 1];
		g = (lineG[column + 1] + lineg[column + 1]) >> 1;
		sumGG -= g;
		sumRG -= (((lineR[column + 1]-g)>>1)+512);
		sumBG -= (((lineB[column + 1]-g)>>1)+512);
		sumDG -= ((lineG[column + 1] - lineg[column + 1]+1024)>>1);

		// Store the highpass sum
		//*(highptr++) = SATURATE(sum);
		*(highptrGG++) = SATURATE(sumGG);
		*(highptrRG++) = SATURATE(sumRG);
		*(highptrBG++) = SATURATE(sumBG);
		*(highptrDG++) = SATURATE(sumDG);
	}

	// Should be at the last column
	assert(column == last_column);

	// Compute the last lowpass value
	//sum = input[column] + input[column + 1];
	g = (lineG[column + 0] + lineg[column + 0]) >> 1;
	g2 = (lineG[column + 1] + lineg[column + 1]) >> 1;
	sumGG = g + g2;
	sumRG = (((lineR[column + 0]-g)>>1)+512) + (((lineR[column + 1]-g2)>>1)+512);
	sumBG = (((lineB[column + 0]-g)>>1)+512) + (((lineB[column + 1]-g2)>>1)+512);
	sumDG = ((lineG[column + 0] - lineg[column + 0]+1024)>>1) + ((lineG[column + 1] - lineg[column + 1]+1024)>>1);

	// Store the lowpass sum
	*(lowptrGG++) = SATURATE(sumGG);
	*(lowptrRG++) = SATURATE(sumRG);
	*(lowptrBG++) = SATURATE(sumBG);
	*(lowptrDG++) = SATURATE(sumDG);

	// Compute the last highpass value using the special border coefficients
	//sum = 0;
	sumGG=sumRG=sumBG=sumDG = 0;

	//sum += 11 * input[column + 0];
	g = (lineG[column + 0] + lineg[column + 0]) >> 1;
	sumGG += 11 * g;
	sumRG += 11 * (((lineR[column + 0]-g)>>1)+512);
	sumBG += 11 * (((lineB[column + 0]-g)>>1)+512);
	sumDG += 11 * ((lineG[column + 0] - lineg[column + 0]+1024)>>1);

	//sum -=  5 * input[column + 1];
	g = (lineG[column + 1] + lineg[column + 1]) >> 1;
	sumGG -= 5 * g;
	sumRG -= 5 * (((lineR[column + 1]-g)>>1)+512);
	sumBG -= 5 * (((lineB[column + 1]-g)>>1)+512);
	sumDG -= 5 * ((lineG[column + 1] - lineg[column + 1]+1024)>>1);

	//sum -=  4 * input[column - 1];
	g = (lineG[column - 1] + lineg[column - 1]) >> 1;
	sumGG -= 4 * g;
	sumRG -= 4 * (((lineR[column - 1]-g)>>1)+512);
	sumBG -= 4 * (((lineB[column - 1]-g)>>1)+512);
	sumDG -= 4 * ((lineG[column - 1] - lineg[column - 1]+1024)>>1);

	//sum -=  4 * input[column - 2];
	g = (lineG[column - 2] + lineg[column - 2]) >> 1;
	sumGG -= 4 * g;
	sumRG -= 4 * (((lineR[column - 2]-g)>>1)+512);
	sumBG -= 4 * (((lineB[column - 2]-g)>>1)+512);
	sumDG -= 4 * ((lineG[column - 2] - lineg[column - 2]+1024)>>1);

	//sum +=  1 * input[column - 3];
	g = (lineG[column - 3] + lineg[column - 3]) >> 1;
	sumGG += 1 * g;
	sumRG += 1 * (((lineR[column - 3]-g)>>1)+512);
	sumBG += 1 * (((lineB[column - 3]-g)>>1)+512);
	sumDG += 1 * ((lineG[column - 3] - lineg[column - 3]+1024)>>1);

	//sum +=  1 * input[column - 4];
	g = (lineG[column - 4] + lineg[column - 4]) >> 1;
	sumGG += 1 * g;
	sumRG += 1 * (((lineR[column - 4]-g)>>1)+512);
	sumBG += 1 * (((lineB[column - 4]-g)>>1)+512);
	sumDG += 1 * ((lineG[column - 4] - lineg[column - 4]+1024)>>1);

	//sum +=  ROUNDING(sum,8);
	sumGG += ROUNDING(sumGG,8);
	sumRG += ROUNDING(sumRG,8);
	sumBG += ROUNDING(sumBG,8);
	sumDG += ROUNDING(sumDG,8);

	//sum = DivideByShift(sum, 3);
	sumGG = DivideByShift(sumGG,3);
	sumRG = DivideByShift(sumRG,3);
	sumBG = DivideByShift(sumBG,3);
	sumDG = DivideByShift(sumDG,3);

	//*(highptr++) = SATURATE(sum);
	*(highptrGG++) = SATURATE(sumGG);
	*(highptrRG++) = SATURATE(sumRG);
	*(highptrBG++) = SATURATE(sumBG);
	*(highptrDG++) = SATURATE(sumDG);
}




// Apply the lowpass and highpass horizontal filters to one row
void FilterHorizontalRowRGB30_16s(PIXEL *input, PIXEL *lowpass, PIXEL *highpass, int width, int precision, int format)
{
	int column_step = 16;				// Number of input pixels processed per loop iteration
	int last_column = width - 2;		// Column at which right border processing is done

	// The post column is the column at which end of column processing must begin
	int post_column = last_column - (last_column % column_step);

	int32_t sumGG,sumRR,sumBB;
	unsigned int *pixelptr = (unsigned int *)input;
	int shift = precision-10;

	// Start at the left end of the row
	PIXEL *lowptrGG;
	PIXEL *highptrGG;
	PIXEL *lowptrRR;
	PIXEL *highptrRR;
	PIXEL *lowptrBB;
	PIXEL *highptrBB;
	int column = 0;

	__m128i *inputRGB_ptr;
	__m128i *lowpassGG_ptr;
	__m128i *lowpassRR_ptr;
	__m128i *lowpassBB_ptr;
	__m128i *highpassGG_ptr;
	__m128i *highpassRR_ptr;
	__m128i *highpassBB_ptr;

	int highpass_valueGG;
	int highpass_valueRR;
	int highpass_valueBB;

	lowptrGG = lowpass;
	lowptrRR = lowpass + (width>>1);
	lowptrBB = lowpass + (width>>1)*2;
	highptrGG = highpass;
	highptrRR = highpass + (width>>1);
	highptrBB = highpass + (width>>1)*2;

	// The highpass filter on the left border uses different coefficients
	sumGG=sumRR=sumBB=0;

	switch(format)
	{
	case DECODED_FORMAT_AB10:
	case DECODED_FORMAT_RG30:
		//sum +=  5 * lineR[column + 0];
		sumRR +=  5 * ((pixelptr[column + 0]) & 0x3ff);
		sumGG +=  5 * ((pixelptr[column + 0]>>10) & 0x3ff);
		sumBB +=  5 * ((pixelptr[column + 0]>>20) & 0x3ff);

		//sum -= 11 * lineR[column + 1];
		sumRR -=  11 * ((pixelptr[column + 1]) & 0x3ff);
		sumGG -=  11 * ((pixelptr[column + 1]>>10) & 0x3ff);
		sumBB -=  11 * ((pixelptr[column + 1]>>20) & 0x3ff);

		//sum +=  4 * lineR[column + 2];
		sumRR +=  4 * ((pixelptr[column + 2]) & 0x3ff);
		sumGG +=  4 * ((pixelptr[column + 2]>>10) & 0x3ff);
		sumBB +=  4 * ((pixelptr[column + 2]>>20) & 0x3ff);

		//sum +=  4 * lineR[column + 3];
		sumRR +=  4 * ((pixelptr[column + 3]) & 0x3ff);
		sumGG +=  4 * ((pixelptr[column + 3]>>10) & 0x3ff);
		sumBB +=  4 * ((pixelptr[column + 3]>>20) & 0x3ff);

		//sum -=  1 * lineR[column + 4];
		sumRR -=  1 * ((pixelptr[column + 4]) & 0x3ff);
		sumGG -=  1 * ((pixelptr[column + 4]>>10) & 0x3ff);
		sumBB -=  1 * ((pixelptr[column + 4]>>20) & 0x3ff);

		//sum -=  1 * lineR[column + 5];
		sumRR -=  1 * ((pixelptr[column + 5]) & 0x3ff);
		sumGG -=  1 * ((pixelptr[column + 5]>>10) & 0x3ff);
		sumBB -=  1 * ((pixelptr[column + 5]>>20) & 0x3ff);
		break;

	case DECODED_FORMAT_AR10:
		//sum +=  5 * lineR[column + 0];
		sumRR +=  5 * ((pixelptr[column + 0]>>20) & 0x3ff);
		sumGG +=  5 * ((pixelptr[column + 0]>>10) & 0x3ff);
		sumBB +=  5 * ((pixelptr[column + 0]) & 0x3ff);

		//sum -= 11 * lineR[column + 1];
		sumRR -=  11 * ((pixelptr[column + 1]>>20) & 0x3ff);
		sumGG -=  11 * ((pixelptr[column + 1]>>10) & 0x3ff);
		sumBB -=  11 * ((pixelptr[column + 1]) & 0x3ff);

		//sum +=  4 * lineR[column + 2];
		sumRR +=  4 * ((pixelptr[column + 2]>>20) & 0x3ff);
		sumGG +=  4 * ((pixelptr[column + 2]>>10) & 0x3ff);
		sumBB +=  4 * ((pixelptr[column + 2]) & 0x3ff);

		//sum +=  4 * lineR[column + 3];
		sumRR +=  4 * ((pixelptr[column + 3]>>20) & 0x3ff);
		sumGG +=  4 * ((pixelptr[column + 3]>>10) & 0x3ff);
		sumBB +=  4 * ((pixelptr[column + 3]) & 0x3ff);

		//sum -=  1 * lineR[column + 4];
		sumRR -=  1 * ((pixelptr[column + 4]>>20) & 0x3ff);
		sumGG -=  1 * ((pixelptr[column + 4]>>10) & 0x3ff);
		sumBB -=  1 * ((pixelptr[column + 4]) & 0x3ff);

		//sum -=  1 * lineR[column + 5];
		sumRR -=  1 * ((pixelptr[column + 5]>>20) & 0x3ff);
		sumGG -=  1 * ((pixelptr[column + 5]>>10) & 0x3ff);
		sumBB -=  1 * ((pixelptr[column + 5]) & 0x3ff);
		break;

	case DECODED_FORMAT_R210:
		{
		unsigned int swap = _bswap(pixelptr[column + 0]);
		//sum +=  5 * lineR[column + 0];
		sumRR +=  5 * ((swap>>20) & 0x3ff);
		sumGG +=  5 * ((swap>>10) & 0x3ff);
		sumBB +=  5 * ((swap>>0) & 0x3ff);

		swap = _bswap(pixelptr[column + 1]);
		//sum -= 11 * lineR[column + 1];
		sumRR -=  11 * ((swap>>20)& 0x3ff);
		sumGG -=  11 * ((swap>>10) & 0x3ff);
		sumBB -=  11 * ((swap>>0)  & 0x3ff);

		swap = _bswap(pixelptr[column + 2]);
		//sum +=  4 * lineR[column + 2];
		sumRR +=  4 * ((swap>>20)& 0x3ff);
		sumGG +=  4 * ((swap>>10) & 0x3ff);
		sumBB +=  4 * ((swap>>0)  & 0x3ff);

		swap = _bswap(pixelptr[column + 3]);
		//sum +=  4 * lineR[column + 3];
		sumRR +=  4 * ((swap>>20)& 0x3ff);
		sumGG +=  4 * ((swap>>10) & 0x3ff);
		sumBB +=  4 * ((swap>>0)  & 0x3ff);

		swap = _bswap(pixelptr[column + 4]);
		//sum -=  1 * lineR[column + 4];
		sumRR -=  1 * ((swap>>20)& 0x3ff);
		sumGG -=  1 * ((swap>>10) & 0x3ff);
		sumBB -=  1 * ((swap>>0)  & 0x3ff);

		swap = _bswap(pixelptr[column + 5]);
		//sum -=  1 * lineR[column + 5];
		sumRR -=  1 * ((swap>>20)& 0x3ff);
		sumGG -=  1 * ((swap>>10) & 0x3ff);
		sumBB -=  1 * ((swap>>0)  & 0x3ff);
		}
		break;

	case DECODED_FORMAT_DPX0:
		{
		unsigned int swap = _bswap(pixelptr[column + 0]);
		//sum +=  5 * lineR[column + 0];
		sumRR +=  5 * ((swap>>22) & 0x3ff);
		sumGG +=  5 * ((swap>>12) & 0x3ff);
		sumBB +=  5 * ((swap>>2) & 0x3ff);

		swap = _bswap(pixelptr[column + 1]);
		//sum -= 11 * lineR[column + 1];
		sumRR -=  11 * ((swap>>22) & 0x3ff);
		sumGG -=  11 * ((swap>>12) & 0x3ff);
		sumBB -=  11 * ((swap>>2) & 0x3ff);

		swap = _bswap(pixelptr[column + 2]);
		//sum +=  4 * lineR[column + 2];
		sumRR +=  4 * ((swap>>22) & 0x3ff);
		sumGG +=  4 * ((swap>>12) & 0x3ff);
		sumBB +=  4 * ((swap>>2) & 0x3ff);

		swap = _bswap(pixelptr[column + 3]);
		//sum +=  4 * lineR[column + 3];
		sumRR +=  4 * ((swap>>22) & 0x3ff);
		sumGG +=  4 * ((swap>>12) & 0x3ff);
		sumBB +=  4 * ((swap>>2) & 0x3ff);

		swap = _bswap(pixelptr[column + 4]);
		//sum -=  1 * lineR[column + 4];
		sumRR -=  1 * ((swap>>22) & 0x3ff);
		sumGG -=  1 * ((swap>>12) & 0x3ff);
		sumBB -=  1 * ((swap>>2) & 0x3ff);

		swap = _bswap(pixelptr[column + 5]);
		//sum -=  1 * lineR[column + 5];
		sumRR -=  1 * ((swap>>22) & 0x3ff);
		sumGG -=  1 * ((swap>>12) & 0x3ff);
		sumBB -=  1 * ((swap>>2) & 0x3ff);
		}
		break;
	}


	sumRR <<= shift;
	sumGG <<= shift;
	sumBB <<= shift;

	//sum += ROUNDING(sum,8);
	sumRR += ROUNDING(sumRR,8);
	sumGG += ROUNDING(sumGG,8);
	sumBB += ROUNDING(sumBB,8);

	//sum = DivideByShift(sum, 3);
	sumRR = DivideByShift(sumRR,3);
	sumGG = DivideByShift(sumGG,3);
	sumBB = DivideByShift(sumBB,3);

	//highpass_value = SATURATE(sum);
	highpass_valueRR = SATURATE(sumRR);
	highpass_valueGG = SATURATE(sumGG);
	highpass_valueBB = SATURATE(sumBB);

	// Set the input pointer for the fast loop
	inputRGB_ptr = (__m128i *)&pixelptr[column];

	// Initialize the output pointers
	lowpassRR_ptr = (__m128i *)lowptrRR;
	lowpassGG_ptr = (__m128i *)lowptrGG;
	lowpassBB_ptr = (__m128i *)lowptrBB;
	highpassRR_ptr = (__m128i *)highptrRR;
	highpassGG_ptr = (__m128i *)highptrGG;
	highpassBB_ptr = (__m128i *)highptrBB;

	// Check that the output pointers are properly aligned
	assert(ISALIGNED16(lowpassGG_ptr));
	assert(ISALIGNED16(lowpassRR_ptr));
	assert(ISALIGNED16(lowpassBB_ptr));
	assert(ISALIGNED16(highpassGG_ptr));
	assert(ISALIGNED16(highpassRR_ptr));
	assert(ISALIGNED16(highpassBB_ptr));

#if 1
	{
		__m128i GG1_epi32;
		__m128i RR1_epi32;
		__m128i BB1_epi32;
		__m128i GG2_epi32;
		__m128i RR2_epi32;
		__m128i BB2_epi32;
		__m128i GG1_epi16;
		__m128i RR1_epi16;
		__m128i BB1_epi16;
		__m128i RR2_epi16;
		__m128i inputRGB_epi32;
		__m128i temp_epi32;

		const __m128i mask10bit_epi32 = _mm_set1_epi32(0x3ff);


		// Preload the first set of four pixels for fast processing
		inputRGB_epi32 = _mm_load_si128(inputRGB_ptr++);

		switch(format)
		{
		case DECODED_FORMAT_AB10:
		case DECODED_FORMAT_RG30:
			RR1_epi32 = _mm_and_si128(inputRGB_epi32, mask10bit_epi32);
			inputRGB_epi32 = _mm_srai_epi32(inputRGB_epi32, 10);
			GG1_epi32 = _mm_and_si128(inputRGB_epi32, mask10bit_epi32);
			inputRGB_epi32 = _mm_srai_epi32(inputRGB_epi32, 10);
			BB1_epi32 = _mm_and_si128(inputRGB_epi32, mask10bit_epi32);

			inputRGB_epi32 = _mm_load_si128(inputRGB_ptr++);

			RR2_epi32 = _mm_and_si128(inputRGB_epi32, mask10bit_epi32);
			inputRGB_epi32 = _mm_srai_epi32(inputRGB_epi32, 10);
			GG2_epi32 = _mm_and_si128(inputRGB_epi32, mask10bit_epi32);
			inputRGB_epi32 = _mm_srai_epi32(inputRGB_epi32, 10);
			BB2_epi32 = _mm_and_si128(inputRGB_epi32, mask10bit_epi32);
			break;

		case DECODED_FORMAT_AR10:
			BB1_epi32 = _mm_and_si128(inputRGB_epi32, mask10bit_epi32);
			inputRGB_epi32 = _mm_srai_epi32(inputRGB_epi32, 10);
			GG1_epi32 = _mm_and_si128(inputRGB_epi32, mask10bit_epi32);
			inputRGB_epi32 = _mm_srai_epi32(inputRGB_epi32, 10);
			RR1_epi32 = _mm_and_si128(inputRGB_epi32, mask10bit_epi32);

			inputRGB_epi32 = _mm_load_si128(inputRGB_ptr++);

			BB2_epi32 = _mm_and_si128(inputRGB_epi32, mask10bit_epi32);
			inputRGB_epi32 = _mm_srai_epi32(inputRGB_epi32, 10);
			GG2_epi32 = _mm_and_si128(inputRGB_epi32, mask10bit_epi32);
			inputRGB_epi32 = _mm_srai_epi32(inputRGB_epi32, 10);
			RR2_epi32 = _mm_and_si128(inputRGB_epi32, mask10bit_epi32);
			break;

		case DECODED_FORMAT_R210:
			RR1_epi32 = _mm_and_si128(inputRGB_epi32, _mm_set1_epi32(0x3f));
			RR1_epi32 = _mm_slli_epi32(RR1_epi32, 4);
			temp_epi32 = _mm_and_si128(inputRGB_epi32, _mm_set1_epi32(0xf000));
			temp_epi32 = _mm_srai_epi32(temp_epi32, 12);
			RR1_epi32 = _mm_or_si128(RR1_epi32, temp_epi32);

			GG1_epi32 = _mm_and_si128(inputRGB_epi32, _mm_set1_epi32(0x0f00));
			GG1_epi32 = _mm_srai_epi32(GG1_epi32, 2);
			temp_epi32 = _mm_and_si128(inputRGB_epi32, _mm_set1_epi32(0x00fc0000));
			temp_epi32 = _mm_srai_epi32(temp_epi32, 18);
			GG1_epi32 = _mm_or_si128(GG1_epi32, temp_epi32);

			BB1_epi32 = _mm_and_si128(inputRGB_epi32, _mm_set1_epi32(0x30000));
			BB1_epi32 = _mm_srai_epi32(BB1_epi32, 8);
			temp_epi32 = _mm_and_si128(inputRGB_epi32, _mm_set1_epi32(0xff000000));
			temp_epi32 = _mm_srli_epi32(temp_epi32, 24);
			BB1_epi32 = _mm_or_si128(BB1_epi32, temp_epi32);

			inputRGB_epi32 = _mm_load_si128(inputRGB_ptr++);

			RR2_epi32 = _mm_and_si128(inputRGB_epi32, _mm_set1_epi32(0x3f));
			RR2_epi32 = _mm_slli_epi32(RR2_epi32, 4);
			temp_epi32 = _mm_and_si128(inputRGB_epi32, _mm_set1_epi32(0xf000));
			temp_epi32 = _mm_srai_epi32(temp_epi32, 12);
			RR2_epi32 = _mm_or_si128(RR2_epi32, temp_epi32);

			GG2_epi32 = _mm_and_si128(inputRGB_epi32, _mm_set1_epi32(0x0f00));
			GG2_epi32 = _mm_srai_epi32(GG2_epi32, 2);
			temp_epi32 = _mm_and_si128(inputRGB_epi32, _mm_set1_epi32(0x00fc0000));
			temp_epi32 = _mm_srai_epi32(temp_epi32, 18);
			GG2_epi32 = _mm_or_si128(GG2_epi32, temp_epi32);

			BB2_epi32 = _mm_and_si128(inputRGB_epi32, _mm_set1_epi32(0x30000));
			BB2_epi32 = _mm_srai_epi32(BB2_epi32, 8);
			temp_epi32 = _mm_and_si128(inputRGB_epi32, _mm_set1_epi32(0xff000000));
			temp_epi32 = _mm_srli_epi32(temp_epi32, 24);
			BB2_epi32 = _mm_or_si128(BB2_epi32, temp_epi32);
			break;

		case DECODED_FORMAT_DPX0:

			RR1_epi32 = _mm_and_si128(inputRGB_epi32, _mm_set1_epi32(0xff));
			RR1_epi32 = _mm_slli_epi32(RR1_epi32, 2);
			temp_epi32 = _mm_and_si128(inputRGB_epi32, _mm_set1_epi32(0xc000));
			temp_epi32 = _mm_srai_epi32(temp_epi32, 14);
			RR1_epi32 = _mm_or_si128(RR1_epi32, temp_epi32);

			GG1_epi32 = _mm_and_si128(inputRGB_epi32, _mm_set1_epi32(0x3f00));
			GG1_epi32 = _mm_srai_epi32(GG1_epi32, 4);
			temp_epi32 = _mm_and_si128(inputRGB_epi32, _mm_set1_epi32(0x00f00000));
			temp_epi32 = _mm_srai_epi32(temp_epi32, 20);
			GG1_epi32 = _mm_or_si128(GG1_epi32, temp_epi32);

			BB1_epi32 = _mm_and_si128(inputRGB_epi32, _mm_set1_epi32(0xf0000));
			BB1_epi32 = _mm_srai_epi32(BB1_epi32, 10);
			temp_epi32 = _mm_and_si128(inputRGB_epi32, _mm_set1_epi32(0xfc000000));
			temp_epi32 = _mm_srli_epi32(temp_epi32, 26);
			BB1_epi32 = _mm_or_si128(BB1_epi32, temp_epi32);

			inputRGB_epi32 = _mm_load_si128(inputRGB_ptr++);

			RR2_epi32 = _mm_and_si128(inputRGB_epi32, _mm_set1_epi32(0xff));
			RR2_epi32 = _mm_slli_epi32(RR2_epi32, 2);
			temp_epi32 = _mm_and_si128(inputRGB_epi32, _mm_set1_epi32(0xc000));
			temp_epi32 = _mm_srai_epi32(temp_epi32, 14);
			RR2_epi32 = _mm_or_si128(RR2_epi32, temp_epi32);

			GG2_epi32 = _mm_and_si128(inputRGB_epi32, _mm_set1_epi32(0x3f00));
			GG2_epi32 = _mm_srai_epi32(GG2_epi32, 4);
			temp_epi32 = _mm_and_si128(inputRGB_epi32, _mm_set1_epi32(0x00f00000));
			temp_epi32 = _mm_srai_epi32(temp_epi32, 20);
			GG2_epi32 = _mm_or_si128(GG2_epi32, temp_epi32);

			BB2_epi32 = _mm_and_si128(inputRGB_epi32, _mm_set1_epi32(0xf0000));
			BB2_epi32 = _mm_srai_epi32(BB2_epi32, 10);
			temp_epi32 = _mm_and_si128(inputRGB_epi32, _mm_set1_epi32(0xfc000000));
			temp_epi32 = _mm_srli_epi32(temp_epi32, 26);
			BB2_epi32 = _mm_or_si128(BB2_epi32, temp_epi32);
			break;
		}


		RR1_epi16 = _mm_packs_epi32(RR1_epi32, RR2_epi32);
		GG1_epi16 = _mm_packs_epi32(GG1_epi32, GG2_epi32);
		BB1_epi16 = _mm_packs_epi32(BB1_epi32, BB2_epi32);



		// Process two sets of four input pixels to get one set of four output pixels
		for (; column < post_column; column += column_step)
		{
			__m128i shiftGG_epi16;
			__m128i shiftRR_epi16;
			__m128i shiftBB_epi16;
			__m128i half_epi16;		// Half of the divisor for rounding
			__m128i sumGG1_epi16;
			__m128i sumRR1_epi16;
			__m128i sumBB1_epi16;
			__m128i sumGG2_epi16;
			__m128i sumRR2_epi16;
			__m128i sumBB2_epi16;
			__m128i lowGG1_epi16;
			__m128i lowRR1_epi16;
			__m128i lowBB1_epi16;
			__m128i lowGG2_epi16;
			__m128i lowRR2_epi16;
			__m128i lowBB2_epi16;

			__m128i sumGG1b_epi16;
			__m128i sumRR1b_epi16;
			__m128i sumBB1b_epi16;
			__m128i sumGG2b_epi16;
			__m128i sumRR2b_epi16;
			__m128i sumBB2b_epi16;

			__m128i GG2_epi16;
			__m128i BB2_epi16;


			/***** Process the first four output points *****/

			// Initialize the highpass sum
			sumGG1_epi16 = _mm_setzero_si128();
			sumRR1_epi16 = _mm_setzero_si128();
			sumBB1_epi16 = _mm_setzero_si128();

			// Apply the first filter coefficient to each pixel and sum the result
			sumGG1_epi16 = _mm_subs_epi16(sumGG1_epi16, GG1_epi16);
			sumRR1_epi16 = _mm_subs_epi16(sumRR1_epi16, RR1_epi16);
			sumBB1_epi16 = _mm_subs_epi16(sumBB1_epi16, BB1_epi16);


			// Load the next eight pixels
			inputRGB_epi32 = _mm_load_si128(inputRGB_ptr++);

			switch(format)
			{
			case DECODED_FORMAT_AB10:
			case DECODED_FORMAT_RG30:
				RR1_epi32 = _mm_and_si128(inputRGB_epi32, mask10bit_epi32);
				inputRGB_epi32 = _mm_srai_epi32(inputRGB_epi32, 10);
				GG1_epi32 = _mm_and_si128(inputRGB_epi32, mask10bit_epi32);
				inputRGB_epi32 = _mm_srai_epi32(inputRGB_epi32, 10);
				BB1_epi32 = _mm_and_si128(inputRGB_epi32, mask10bit_epi32);

				inputRGB_epi32 = _mm_load_si128(inputRGB_ptr++);

				RR2_epi32 = _mm_and_si128(inputRGB_epi32, mask10bit_epi32);
				inputRGB_epi32 = _mm_srai_epi32(inputRGB_epi32, 10);
				GG2_epi32 = _mm_and_si128(inputRGB_epi32, mask10bit_epi32);
				inputRGB_epi32 = _mm_srai_epi32(inputRGB_epi32, 10);
				BB2_epi32 = _mm_and_si128(inputRGB_epi32, mask10bit_epi32);
				break;

			case DECODED_FORMAT_AR10:
				BB1_epi32 = _mm_and_si128(inputRGB_epi32, mask10bit_epi32);
				inputRGB_epi32 = _mm_srai_epi32(inputRGB_epi32, 10);
				GG1_epi32 = _mm_and_si128(inputRGB_epi32, mask10bit_epi32);
				inputRGB_epi32 = _mm_srai_epi32(inputRGB_epi32, 10);
				RR1_epi32 = _mm_and_si128(inputRGB_epi32, mask10bit_epi32);

				inputRGB_epi32 = _mm_load_si128(inputRGB_ptr++);

				BB2_epi32 = _mm_and_si128(inputRGB_epi32, mask10bit_epi32);
				inputRGB_epi32 = _mm_srai_epi32(inputRGB_epi32, 10);
				GG2_epi32 = _mm_and_si128(inputRGB_epi32, mask10bit_epi32);
				inputRGB_epi32 = _mm_srai_epi32(inputRGB_epi32, 10);
				RR2_epi32 = _mm_and_si128(inputRGB_epi32, mask10bit_epi32);
				break;


			case DECODED_FORMAT_R210:
				RR1_epi32 = _mm_and_si128(inputRGB_epi32, _mm_set1_epi32(0x3f));
				RR1_epi32 = _mm_slli_epi32(RR1_epi32, 4);
				temp_epi32 = _mm_and_si128(inputRGB_epi32, _mm_set1_epi32(0xf000));
				temp_epi32 = _mm_srai_epi32(temp_epi32, 12);
				RR1_epi32 = _mm_or_si128(RR1_epi32, temp_epi32);

				GG1_epi32 = _mm_and_si128(inputRGB_epi32, _mm_set1_epi32(0x0f00));
				GG1_epi32 = _mm_srai_epi32(GG1_epi32, 2);
				temp_epi32 = _mm_and_si128(inputRGB_epi32, _mm_set1_epi32(0x00fc0000));
				temp_epi32 = _mm_srai_epi32(temp_epi32, 18);
				GG1_epi32 = _mm_or_si128(GG1_epi32, temp_epi32);

				BB1_epi32 = _mm_and_si128(inputRGB_epi32, _mm_set1_epi32(0x30000));
				BB1_epi32 = _mm_srai_epi32(BB1_epi32, 8);
				temp_epi32 = _mm_and_si128(inputRGB_epi32, _mm_set1_epi32(0xff000000));
				temp_epi32 = _mm_srli_epi32(temp_epi32, 24);
				BB1_epi32 = _mm_or_si128(BB1_epi32, temp_epi32);

				inputRGB_epi32 = _mm_load_si128(inputRGB_ptr++);

				RR2_epi32 = _mm_and_si128(inputRGB_epi32, _mm_set1_epi32(0x3f));
				RR2_epi32 = _mm_slli_epi32(RR2_epi32, 4);
				temp_epi32 = _mm_and_si128(inputRGB_epi32, _mm_set1_epi32(0xf000));
				temp_epi32 = _mm_srai_epi32(temp_epi32, 12);
				RR2_epi32 = _mm_or_si128(RR2_epi32, temp_epi32);

				GG2_epi32 = _mm_and_si128(inputRGB_epi32, _mm_set1_epi32(0x0f00));
				GG2_epi32 = _mm_srai_epi32(GG2_epi32, 2);
				temp_epi32 = _mm_and_si128(inputRGB_epi32, _mm_set1_epi32(0x00fc0000));
				temp_epi32 = _mm_srai_epi32(temp_epi32, 18);
				GG2_epi32 = _mm_or_si128(GG2_epi32, temp_epi32);

				BB2_epi32 = _mm_and_si128(inputRGB_epi32, _mm_set1_epi32(0x30000));
				BB2_epi32 = _mm_srai_epi32(BB2_epi32, 8);
				temp_epi32 = _mm_and_si128(inputRGB_epi32, _mm_set1_epi32(0xff000000));
				temp_epi32 = _mm_srli_epi32(temp_epi32, 24);
				BB2_epi32 = _mm_or_si128(BB2_epi32, temp_epi32);
				break;

			case DECODED_FORMAT_DPX0:

				RR1_epi32 = _mm_and_si128(inputRGB_epi32, _mm_set1_epi32(0xff));
				RR1_epi32 = _mm_slli_epi32(RR1_epi32, 2);
				temp_epi32 = _mm_and_si128(inputRGB_epi32, _mm_set1_epi32(0xc000));
				temp_epi32 = _mm_srai_epi32(temp_epi32, 14);
				RR1_epi32 = _mm_or_si128(RR1_epi32, temp_epi32);

				GG1_epi32 = _mm_and_si128(inputRGB_epi32, _mm_set1_epi32(0x3f00));
				GG1_epi32 = _mm_srai_epi32(GG1_epi32, 4);
				temp_epi32 = _mm_and_si128(inputRGB_epi32, _mm_set1_epi32(0x00f00000));
				temp_epi32 = _mm_srai_epi32(temp_epi32, 20);
				GG1_epi32 = _mm_or_si128(GG1_epi32, temp_epi32);

				BB1_epi32 = _mm_and_si128(inputRGB_epi32, _mm_set1_epi32(0xf0000));
				BB1_epi32 = _mm_srai_epi32(BB1_epi32, 10);
				temp_epi32 = _mm_and_si128(inputRGB_epi32, _mm_set1_epi32(0xfc000000));
				temp_epi32 = _mm_srli_epi32(temp_epi32, 26);
				BB1_epi32 = _mm_or_si128(BB1_epi32, temp_epi32);

				inputRGB_epi32 = _mm_load_si128(inputRGB_ptr++);

				RR2_epi32 = _mm_and_si128(inputRGB_epi32, _mm_set1_epi32(0xff));
				RR2_epi32 = _mm_slli_epi32(RR2_epi32, 2);
				temp_epi32 = _mm_and_si128(inputRGB_epi32, _mm_set1_epi32(0xc000));
				temp_epi32 = _mm_srai_epi32(temp_epi32, 14);
				RR2_epi32 = _mm_or_si128(RR2_epi32, temp_epi32);

				GG2_epi32 = _mm_and_si128(inputRGB_epi32, _mm_set1_epi32(0x3f00));
				GG2_epi32 = _mm_srai_epi32(GG2_epi32, 4);
				temp_epi32 = _mm_and_si128(inputRGB_epi32, _mm_set1_epi32(0x00f00000));
				temp_epi32 = _mm_srai_epi32(temp_epi32, 20);
				GG2_epi32 = _mm_or_si128(GG2_epi32, temp_epi32);

				BB2_epi32 = _mm_and_si128(inputRGB_epi32, _mm_set1_epi32(0xf0000));
				BB2_epi32 = _mm_srai_epi32(BB2_epi32, 10);
				temp_epi32 = _mm_and_si128(inputRGB_epi32, _mm_set1_epi32(0xfc000000));
				temp_epi32 = _mm_srli_epi32(temp_epi32, 26);
				BB2_epi32 = _mm_or_si128(BB2_epi32, temp_epi32);
				break;
			}

			RR2_epi16 = _mm_packs_epi32(RR1_epi32, RR2_epi32);
			GG2_epi16 = _mm_packs_epi32(GG1_epi32, GG2_epi32);
			BB2_epi16 = _mm_packs_epi32(BB1_epi32, BB2_epi32);





			// Initialize the lowpass sum
			lowGG1_epi16 = GG1_epi16;
			lowRR1_epi16 = RR1_epi16;
			lowBB1_epi16 = BB1_epi16;

			// Shift the first pixel from the second set into the working set
			shiftGG_epi16 = _mm_slli_si128(GG2_epi16, 7*2);
			shiftRR_epi16 = _mm_slli_si128(RR2_epi16, 7*2);
			shiftBB_epi16 = _mm_slli_si128(BB2_epi16, 7*2);
			GG1_epi16 = _mm_srli_si128(GG1_epi16, 1*2);
			RR1_epi16 = _mm_srli_si128(RR1_epi16, 1*2);
			BB1_epi16 = _mm_srli_si128(BB1_epi16, 1*2);
			GG1_epi16 = _mm_or_si128(GG1_epi16, shiftGG_epi16);
			RR1_epi16 = _mm_or_si128(RR1_epi16, shiftRR_epi16);
			BB1_epi16 = _mm_or_si128(BB1_epi16, shiftBB_epi16);

			// Apply the second filter coefficient to each pixel and sum the result
			sumGG1_epi16 = _mm_subs_epi16(sumGG1_epi16, GG1_epi16);
			sumRR1_epi16 = _mm_subs_epi16(sumRR1_epi16, RR1_epi16);
			sumBB1_epi16 = _mm_subs_epi16(sumBB1_epi16, BB1_epi16);

			// Add adjacent points to compute the lowpass sum
			lowGG1_epi16 = _mm_adds_epi16(lowGG1_epi16, GG1_epi16);
			lowRR1_epi16 = _mm_adds_epi16(lowRR1_epi16, RR1_epi16);
			lowBB1_epi16 = _mm_adds_epi16(lowBB1_epi16, BB1_epi16);

			// shift for precision
			lowGG1_epi16 = _mm_slli_epi16(lowGG1_epi16, shift);
			lowRR1_epi16 = _mm_slli_epi16(lowRR1_epi16, shift);
			lowBB1_epi16 = _mm_slli_epi16(lowBB1_epi16, shift);

			// Expand the lowpass output points to a full doubleword
			lowGG1_epi16 = _mm_slli_epi32(lowGG1_epi16, 16);
			lowRR1_epi16 = _mm_slli_epi32(lowRR1_epi16, 16);
			lowBB1_epi16 = _mm_slli_epi32(lowBB1_epi16, 16);
			lowGG1_epi16 = _mm_srai_epi32(lowGG1_epi16, 16);
			lowRR1_epi16 = _mm_srai_epi32(lowRR1_epi16, 16);
			lowBB1_epi16 = _mm_srai_epi32(lowBB1_epi16, 16);

			// Shift the second pixel from the second set into the working set
			shiftGG_epi16 = _mm_slli_si128(GG2_epi16, 6*2);
			shiftRR_epi16 = _mm_slli_si128(RR2_epi16, 6*2);
			shiftBB_epi16 = _mm_slli_si128(BB2_epi16, 6*2);
			GG1_epi16 = _mm_srli_si128(GG1_epi16, 1*2);
			RR1_epi16 = _mm_srli_si128(RR1_epi16, 1*2);
			BB1_epi16 = _mm_srli_si128(BB1_epi16, 1*2);
			GG1_epi16 = _mm_or_si128(GG1_epi16, shiftGG_epi16);
			RR1_epi16 = _mm_or_si128(RR1_epi16, shiftRR_epi16);
			BB1_epi16 = _mm_or_si128(BB1_epi16, shiftBB_epi16);

			// Apply the third filter coefficient to each pixel and sum the result
			sumGG1b_epi16 = GG1_epi16;
			sumRR1b_epi16 = RR1_epi16;
			sumBB1b_epi16 = BB1_epi16;

			// Shift the third pixel from the second set into the working set
			shiftGG_epi16 = _mm_slli_si128(GG2_epi16, 5*2);
			shiftRR_epi16 = _mm_slli_si128(RR2_epi16, 5*2);
			shiftBB_epi16 = _mm_slli_si128(BB2_epi16, 5*2);
			GG1_epi16 = _mm_srli_si128(GG1_epi16, 1*2);
			RR1_epi16 = _mm_srli_si128(RR1_epi16, 1*2);
			BB1_epi16 = _mm_srli_si128(BB1_epi16, 1*2);
			GG1_epi16 = _mm_or_si128(GG1_epi16, shiftGG_epi16);
			RR1_epi16 = _mm_or_si128(RR1_epi16, shiftRR_epi16);
			BB1_epi16 = _mm_or_si128(BB1_epi16, shiftBB_epi16);

			// Apply the fourth filter coefficient to each pixel and sum the result
			sumGG1b_epi16 = _mm_subs_epi16(sumGG1b_epi16, GG1_epi16);
			sumRR1b_epi16 = _mm_subs_epi16(sumRR1b_epi16, RR1_epi16);
			sumBB1b_epi16 = _mm_subs_epi16(sumBB1b_epi16, BB1_epi16);

			// Shift the fourth pixel from the second set into the working set
			shiftGG_epi16 = _mm_slli_si128(GG2_epi16, 4*2);
			shiftRR_epi16 = _mm_slli_si128(RR2_epi16, 4*2);
			shiftBB_epi16 = _mm_slli_si128(BB2_epi16, 4*2);
			GG1_epi16 = _mm_srli_si128(GG1_epi16, 1*2);
			RR1_epi16 = _mm_srli_si128(RR1_epi16, 1*2);
			BB1_epi16 = _mm_srli_si128(BB1_epi16, 1*2);
			GG1_epi16 = _mm_or_si128(GG1_epi16, shiftGG_epi16);
			RR1_epi16 = _mm_or_si128(RR1_epi16, shiftRR_epi16);
			BB1_epi16 = _mm_or_si128(BB1_epi16, shiftBB_epi16);

			// Apply the fifth filter coefficient to each pixel and sum the result
			sumGG1_epi16 = _mm_adds_epi16(sumGG1_epi16, GG1_epi16);
			sumRR1_epi16 = _mm_adds_epi16(sumRR1_epi16, RR1_epi16);
			sumBB1_epi16 = _mm_adds_epi16(sumBB1_epi16, BB1_epi16);

			// Shift the fifth pixel from the second set into the working set
			shiftGG_epi16 = _mm_slli_si128(GG2_epi16, 3*2);
			shiftRR_epi16 = _mm_slli_si128(RR2_epi16, 3*2);
			shiftBB_epi16 = _mm_slli_si128(BB2_epi16, 3*2);
			GG1_epi16 = _mm_srli_si128(GG1_epi16, 1*2);
			RR1_epi16 = _mm_srli_si128(RR1_epi16, 1*2);
			BB1_epi16 = _mm_srli_si128(BB1_epi16, 1*2);
			GG1_epi16 = _mm_or_si128(GG1_epi16, shiftGG_epi16);
			RR1_epi16 = _mm_or_si128(RR1_epi16, shiftRR_epi16);
			BB1_epi16 = _mm_or_si128(BB1_epi16, shiftBB_epi16);

			// Apply the sixth (last) filter coefficient to each pixel and sum the result
			sumGG1_epi16 = _mm_adds_epi16(sumGG1_epi16, GG1_epi16);
			sumRR1_epi16 = _mm_adds_epi16(sumRR1_epi16, RR1_epi16);
			sumBB1_epi16 = _mm_adds_epi16(sumBB1_epi16, BB1_epi16);

			// shift for precision
			sumGG1_epi16 = _mm_slli_epi16(sumGG1_epi16, shift);
			sumRR1_epi16 = _mm_slli_epi16(sumRR1_epi16, shift);
			sumBB1_epi16 = _mm_slli_epi16(sumBB1_epi16, shift);
			sumGG1b_epi16 = _mm_slli_epi16(sumGG1b_epi16, shift);
			sumRR1b_epi16 = _mm_slli_epi16(sumRR1b_epi16, shift);
			sumBB1b_epi16 = _mm_slli_epi16(sumBB1b_epi16, shift);


			//DAN20050915 -- reversibility
			half_epi16 = _mm_set1_epi16(4);
			sumGG1_epi16 = _mm_adds_epi16(sumGG1_epi16, half_epi16);
			sumRR1_epi16 = _mm_adds_epi16(sumRR1_epi16, half_epi16);
			sumBB1_epi16 = _mm_adds_epi16(sumBB1_epi16, half_epi16);
			sumGG1_epi16 = _mm_srai_epi16(sumGG1_epi16, 3);
			sumRR1_epi16 = _mm_srai_epi16(sumRR1_epi16, 3);
			sumBB1_epi16 = _mm_srai_epi16(sumBB1_epi16, 3);

			sumGG1_epi16 = _mm_adds_epi16(sumGG1_epi16, sumGG1b_epi16);
			sumRR1_epi16 = _mm_adds_epi16(sumRR1_epi16, sumRR1b_epi16);
			sumBB1_epi16 = _mm_adds_epi16(sumBB1_epi16, sumBB1b_epi16);

			// Expand the even output points to a full doubleword
			sumGG1_epi16 = _mm_slli_epi32(sumGG1_epi16, 16);
			sumRR1_epi16 = _mm_slli_epi32(sumRR1_epi16, 16);
			sumBB1_epi16 = _mm_slli_epi32(sumBB1_epi16, 16);
			sumGG1_epi16 = _mm_srai_epi32(sumGG1_epi16, 16);
			sumRR1_epi16 = _mm_srai_epi32(sumRR1_epi16, 16);
			sumBB1_epi16 = _mm_srai_epi32(sumBB1_epi16, 16);

			// The second eight input points become the current input points
			GG1_epi16 = GG2_epi16;
			RR1_epi16 = RR2_epi16;
			BB1_epi16 = BB2_epi16;








			/***** Process the second four output points *****/

			// Initialize the highpass sum
			sumGG2_epi16 = _mm_setzero_si128();
			sumRR2_epi16 = _mm_setzero_si128();
			sumBB2_epi16 = _mm_setzero_si128();

			// Apply the first filter coefficient to each pixel and sum the result
			sumGG2_epi16 = _mm_subs_epi16(sumGG2_epi16, GG1_epi16);
			sumRR2_epi16 = _mm_subs_epi16(sumRR2_epi16, RR1_epi16);
			sumBB2_epi16 = _mm_subs_epi16(sumBB2_epi16, BB1_epi16);


			// Load the next eight pixels
			inputRGB_epi32 = _mm_load_si128(inputRGB_ptr++);

			switch(format)
			{
			case DECODED_FORMAT_AB10:
			case DECODED_FORMAT_RG30:
				RR1_epi32 = _mm_and_si128(inputRGB_epi32, mask10bit_epi32);
				inputRGB_epi32 = _mm_srai_epi32(inputRGB_epi32, 10);
				GG1_epi32 = _mm_and_si128(inputRGB_epi32, mask10bit_epi32);
				inputRGB_epi32 = _mm_srai_epi32(inputRGB_epi32, 10);
				BB1_epi32 = _mm_and_si128(inputRGB_epi32, mask10bit_epi32);

				inputRGB_epi32 = _mm_load_si128(inputRGB_ptr++);

				RR2_epi32 = _mm_and_si128(inputRGB_epi32, mask10bit_epi32);
				inputRGB_epi32 = _mm_srai_epi32(inputRGB_epi32, 10);
				GG2_epi32 = _mm_and_si128(inputRGB_epi32, mask10bit_epi32);
				inputRGB_epi32 = _mm_srai_epi32(inputRGB_epi32, 10);
				BB2_epi32 = _mm_and_si128(inputRGB_epi32, mask10bit_epi32);
				break;

			case DECODED_FORMAT_AR10:
				BB1_epi32 = _mm_and_si128(inputRGB_epi32, mask10bit_epi32);
				inputRGB_epi32 = _mm_srai_epi32(inputRGB_epi32, 10);
				GG1_epi32 = _mm_and_si128(inputRGB_epi32, mask10bit_epi32);
				inputRGB_epi32 = _mm_srai_epi32(inputRGB_epi32, 10);
				RR1_epi32 = _mm_and_si128(inputRGB_epi32, mask10bit_epi32);

				inputRGB_epi32 = _mm_load_si128(inputRGB_ptr++);

				BB2_epi32 = _mm_and_si128(inputRGB_epi32, mask10bit_epi32);
				inputRGB_epi32 = _mm_srai_epi32(inputRGB_epi32, 10);
				GG2_epi32 = _mm_and_si128(inputRGB_epi32, mask10bit_epi32);
				inputRGB_epi32 = _mm_srai_epi32(inputRGB_epi32, 10);
				RR2_epi32 = _mm_and_si128(inputRGB_epi32, mask10bit_epi32);
				break;

			case DECODED_FORMAT_R210:
				RR1_epi32 = _mm_and_si128(inputRGB_epi32, _mm_set1_epi32(0x3f));
				RR1_epi32 = _mm_slli_epi32(RR1_epi32, 4);
				temp_epi32 = _mm_and_si128(inputRGB_epi32, _mm_set1_epi32(0xf000));
				temp_epi32 = _mm_srai_epi32(temp_epi32, 12);
				RR1_epi32 = _mm_or_si128(RR1_epi32, temp_epi32);

				GG1_epi32 = _mm_and_si128(inputRGB_epi32, _mm_set1_epi32(0x0f00));
				GG1_epi32 = _mm_srai_epi32(GG1_epi32, 2);
				temp_epi32 = _mm_and_si128(inputRGB_epi32, _mm_set1_epi32(0x00fc0000));
				temp_epi32 = _mm_srai_epi32(temp_epi32, 18);
				GG1_epi32 = _mm_or_si128(GG1_epi32, temp_epi32);

				BB1_epi32 = _mm_and_si128(inputRGB_epi32, _mm_set1_epi32(0x30000));
				BB1_epi32 = _mm_srai_epi32(BB1_epi32, 8);
				temp_epi32 = _mm_and_si128(inputRGB_epi32, _mm_set1_epi32(0xff000000));
				temp_epi32 = _mm_srli_epi32(temp_epi32, 24);
				BB1_epi32 = _mm_or_si128(BB1_epi32, temp_epi32);

				inputRGB_epi32 = _mm_load_si128(inputRGB_ptr++);

				RR2_epi32 = _mm_and_si128(inputRGB_epi32, _mm_set1_epi32(0x3f));
				RR2_epi32 = _mm_slli_epi32(RR2_epi32, 4);
				temp_epi32 = _mm_and_si128(inputRGB_epi32, _mm_set1_epi32(0xf000));
				temp_epi32 = _mm_srai_epi32(temp_epi32, 12);
				RR2_epi32 = _mm_or_si128(RR2_epi32, temp_epi32);

				GG2_epi32 = _mm_and_si128(inputRGB_epi32, _mm_set1_epi32(0x0f00));
				GG2_epi32 = _mm_srai_epi32(GG2_epi32, 2);
				temp_epi32 = _mm_and_si128(inputRGB_epi32, _mm_set1_epi32(0x00fc0000));
				temp_epi32 = _mm_srai_epi32(temp_epi32, 18);
				GG2_epi32 = _mm_or_si128(GG2_epi32, temp_epi32);

				BB2_epi32 = _mm_and_si128(inputRGB_epi32, _mm_set1_epi32(0x30000));
				BB2_epi32 = _mm_srai_epi32(BB2_epi32, 8);
				temp_epi32 = _mm_and_si128(inputRGB_epi32, _mm_set1_epi32(0xff000000));
				temp_epi32 = _mm_srli_epi32(temp_epi32, 24);
				BB2_epi32 = _mm_or_si128(BB2_epi32, temp_epi32);
				break;


			case DECODED_FORMAT_DPX0:

				RR1_epi32 = _mm_and_si128(inputRGB_epi32, _mm_set1_epi32(0xff));
				RR1_epi32 = _mm_slli_epi32(RR1_epi32, 2);
				temp_epi32 = _mm_and_si128(inputRGB_epi32, _mm_set1_epi32(0xc000));
				temp_epi32 = _mm_srai_epi32(temp_epi32, 14);
				RR1_epi32 = _mm_or_si128(RR1_epi32, temp_epi32);

				GG1_epi32 = _mm_and_si128(inputRGB_epi32, _mm_set1_epi32(0x3f00));
				GG1_epi32 = _mm_srai_epi32(GG1_epi32, 4);
				temp_epi32 = _mm_and_si128(inputRGB_epi32, _mm_set1_epi32(0x00f00000));
				temp_epi32 = _mm_srai_epi32(temp_epi32, 20);
				GG1_epi32 = _mm_or_si128(GG1_epi32, temp_epi32);

				BB1_epi32 = _mm_and_si128(inputRGB_epi32, _mm_set1_epi32(0xf0000));
				BB1_epi32 = _mm_srai_epi32(BB1_epi32, 10);
				temp_epi32 = _mm_and_si128(inputRGB_epi32, _mm_set1_epi32(0xfc000000));
				temp_epi32 = _mm_srli_epi32(temp_epi32, 26);
				BB1_epi32 = _mm_or_si128(BB1_epi32, temp_epi32);

				inputRGB_epi32 = _mm_load_si128(inputRGB_ptr++);

				RR2_epi32 = _mm_and_si128(inputRGB_epi32, _mm_set1_epi32(0xff));
				RR2_epi32 = _mm_slli_epi32(RR2_epi32, 2);
				temp_epi32 = _mm_and_si128(inputRGB_epi32, _mm_set1_epi32(0xc000));
				temp_epi32 = _mm_srai_epi32(temp_epi32, 14);
				RR2_epi32 = _mm_or_si128(RR2_epi32, temp_epi32);

				GG2_epi32 = _mm_and_si128(inputRGB_epi32, _mm_set1_epi32(0x3f00));
				GG2_epi32 = _mm_srai_epi32(GG2_epi32, 4);
				temp_epi32 = _mm_and_si128(inputRGB_epi32, _mm_set1_epi32(0x00f00000));
				temp_epi32 = _mm_srai_epi32(temp_epi32, 20);
				GG2_epi32 = _mm_or_si128(GG2_epi32, temp_epi32);

				BB2_epi32 = _mm_and_si128(inputRGB_epi32, _mm_set1_epi32(0xf0000));
				BB2_epi32 = _mm_srai_epi32(BB2_epi32, 10);
				temp_epi32 = _mm_and_si128(inputRGB_epi32, _mm_set1_epi32(0xfc000000));
				temp_epi32 = _mm_srli_epi32(temp_epi32, 26);
				BB2_epi32 = _mm_or_si128(BB2_epi32, temp_epi32);
				break;
			}


			RR2_epi16 = _mm_packs_epi32(RR1_epi32, RR2_epi32);
			GG2_epi16 = _mm_packs_epi32(GG1_epi32, GG2_epi32);
			BB2_epi16 = _mm_packs_epi32(BB1_epi32, BB2_epi32);



			// Initialize the lowpass sum
			lowGG2_epi16 = GG1_epi16;
			lowRR2_epi16 = RR1_epi16;
			lowBB2_epi16 = BB1_epi16;

			// Shift the first pixel from the second set into the working set
			shiftGG_epi16 = _mm_slli_si128(GG2_epi16, 7*2);
			shiftRR_epi16 = _mm_slli_si128(RR2_epi16, 7*2);
			shiftBB_epi16 = _mm_slli_si128(BB2_epi16, 7*2);
			GG1_epi16 = _mm_srli_si128(GG1_epi16, 1*2);
			RR1_epi16 = _mm_srli_si128(RR1_epi16, 1*2);
			BB1_epi16 = _mm_srli_si128(BB1_epi16, 1*2);
			GG1_epi16 = _mm_or_si128(GG1_epi16, shiftGG_epi16);
			RR1_epi16 = _mm_or_si128(RR1_epi16, shiftRR_epi16);
			BB1_epi16 = _mm_or_si128(BB1_epi16, shiftBB_epi16);

			// Apply the second filter coefficient to each pixel and sum the result
			sumGG2_epi16 = _mm_subs_epi16(sumGG2_epi16, GG1_epi16);
			sumRR2_epi16 = _mm_subs_epi16(sumRR2_epi16, RR1_epi16);
			sumBB2_epi16 = _mm_subs_epi16(sumBB2_epi16, BB1_epi16);

			// Add adjacent points to compute the lowpass sum
			lowGG2_epi16 = _mm_adds_epi16(lowGG2_epi16, GG1_epi16);
			lowRR2_epi16 = _mm_adds_epi16(lowRR2_epi16, RR1_epi16);
			lowBB2_epi16 = _mm_adds_epi16(lowBB2_epi16, BB1_epi16);

			// shift for precision
			lowGG2_epi16 = _mm_slli_epi16(lowGG2_epi16, shift);
			lowRR2_epi16 = _mm_slli_epi16(lowRR2_epi16, shift);
			lowBB2_epi16 = _mm_slli_epi16(lowBB2_epi16, shift);

			// Expand the lowpass output points to a full doubleword
			lowGG2_epi16 = _mm_slli_epi32(lowGG2_epi16, 16);
			lowRR2_epi16 = _mm_slli_epi32(lowRR2_epi16, 16);
			lowBB2_epi16 = _mm_slli_epi32(lowBB2_epi16, 16);
			lowGG2_epi16 = _mm_srai_epi32(lowGG2_epi16, 16);
			lowRR2_epi16 = _mm_srai_epi32(lowRR2_epi16, 16);
			lowBB2_epi16 = _mm_srai_epi32(lowBB2_epi16, 16);

			// Shift the second pixel from the second set into the working set
			shiftGG_epi16 = _mm_slli_si128(GG2_epi16, 6*2);
			shiftRR_epi16 = _mm_slli_si128(RR2_epi16, 6*2);
			shiftBB_epi16 = _mm_slli_si128(BB2_epi16, 6*2);
			GG1_epi16 = _mm_srli_si128(GG1_epi16, 1*2);
			RR1_epi16 = _mm_srli_si128(RR1_epi16, 1*2);
			BB1_epi16 = _mm_srli_si128(BB1_epi16, 1*2);
			GG1_epi16 = _mm_or_si128(GG1_epi16, shiftGG_epi16);
			RR1_epi16 = _mm_or_si128(RR1_epi16, shiftRR_epi16);
			BB1_epi16 = _mm_or_si128(BB1_epi16, shiftBB_epi16);

			// Apply the third filter coefficient to each pixel and sum the result
			sumGG2b_epi16 = GG1_epi16;
			sumRR2b_epi16 = RR1_epi16;
			sumBB2b_epi16 = BB1_epi16;

			// Shift the third pixel from the second set into the working set
			shiftGG_epi16 = _mm_slli_si128(GG2_epi16, 5*2);
			shiftRR_epi16 = _mm_slli_si128(RR2_epi16, 5*2);
			shiftBB_epi16 = _mm_slli_si128(BB2_epi16, 5*2);
			GG1_epi16 = _mm_srli_si128(GG1_epi16, 1*2);
			RR1_epi16 = _mm_srli_si128(RR1_epi16, 1*2);
			BB1_epi16 = _mm_srli_si128(BB1_epi16, 1*2);
			GG1_epi16 = _mm_or_si128(GG1_epi16, shiftGG_epi16);
			RR1_epi16 = _mm_or_si128(RR1_epi16, shiftRR_epi16);
			BB1_epi16 = _mm_or_si128(BB1_epi16, shiftBB_epi16);

			// Apply the fourth filter coefficient to each pixel and sum the result
			sumGG2b_epi16 = _mm_subs_epi16(sumGG2b_epi16, GG1_epi16);
			sumRR2b_epi16 = _mm_subs_epi16(sumRR2b_epi16, RR1_epi16);
			sumBB2b_epi16 = _mm_subs_epi16(sumBB2b_epi16, BB1_epi16);

			// Shift the fourth pixel from the second set into the working set
			shiftGG_epi16 = _mm_slli_si128(GG2_epi16, 4*2);
			shiftRR_epi16 = _mm_slli_si128(RR2_epi16, 4*2);
			shiftBB_epi16 = _mm_slli_si128(BB2_epi16, 4*2);
			GG1_epi16 = _mm_srli_si128(GG1_epi16, 1*2);
			RR1_epi16 = _mm_srli_si128(RR1_epi16, 1*2);
			BB1_epi16 = _mm_srli_si128(BB1_epi16, 1*2);
			GG1_epi16 = _mm_or_si128(GG1_epi16, shiftGG_epi16);
			RR1_epi16 = _mm_or_si128(RR1_epi16, shiftRR_epi16);
			BB1_epi16 = _mm_or_si128(BB1_epi16, shiftBB_epi16);

			// Apply the fifth filter coefficient to each pixel and sum the result
			sumGG2_epi16 = _mm_adds_epi16(sumGG2_epi16, GG1_epi16);
			sumRR2_epi16 = _mm_adds_epi16(sumRR2_epi16, RR1_epi16);
			sumBB2_epi16 = _mm_adds_epi16(sumBB2_epi16, BB1_epi16);

			// Shift the fifth pixel from the second set into the working set
			shiftGG_epi16 = _mm_slli_si128(GG2_epi16, 3*2);
			shiftRR_epi16 = _mm_slli_si128(RR2_epi16, 3*2);
			shiftBB_epi16 = _mm_slli_si128(BB2_epi16, 3*2);
			GG1_epi16 = _mm_srli_si128(GG1_epi16, 1*2);
			RR1_epi16 = _mm_srli_si128(RR1_epi16, 1*2);
			BB1_epi16 = _mm_srli_si128(BB1_epi16, 1*2);
			GG1_epi16 = _mm_or_si128(GG1_epi16, shiftGG_epi16);
			RR1_epi16 = _mm_or_si128(RR1_epi16, shiftRR_epi16);
			BB1_epi16 = _mm_or_si128(BB1_epi16, shiftBB_epi16);

			// Apply the sixth (last) filter coefficient to each pixel and sum the result
			sumGG2_epi16 = _mm_adds_epi16(sumGG2_epi16, GG1_epi16);
			sumRR2_epi16 = _mm_adds_epi16(sumRR2_epi16, RR1_epi16);
			sumBB2_epi16 = _mm_adds_epi16(sumBB2_epi16, BB1_epi16);


			// shift for precision
			sumGG2_epi16 = _mm_slli_epi16(sumGG2_epi16, shift);
			sumRR2_epi16 = _mm_slli_epi16(sumRR2_epi16, shift);
			sumBB2_epi16 = _mm_slli_epi16(sumBB2_epi16, shift);
			sumGG2b_epi16 = _mm_slli_epi16(sumGG2b_epi16, shift);
			sumRR2b_epi16 = _mm_slli_epi16(sumRR2b_epi16, shift);
			sumBB2b_epi16 = _mm_slli_epi16(sumBB2b_epi16, shift);

			//DAN20050915 -- reversibility
			half_epi16 = _mm_set1_epi16(4);
			sumGG2_epi16 = _mm_adds_epi16(sumGG2_epi16, half_epi16);
			sumRR2_epi16 = _mm_adds_epi16(sumRR2_epi16, half_epi16);
			sumBB2_epi16 = _mm_adds_epi16(sumBB2_epi16, half_epi16);
			sumGG2_epi16 = _mm_srai_epi16(sumGG2_epi16, 3);
			sumRR2_epi16 = _mm_srai_epi16(sumRR2_epi16, 3);
			sumBB2_epi16 = _mm_srai_epi16(sumBB2_epi16, 3);

			sumGG2_epi16 = _mm_adds_epi16(sumGG2_epi16, sumGG2b_epi16);
			sumRR2_epi16 = _mm_adds_epi16(sumRR2_epi16, sumRR2b_epi16);
			sumBB2_epi16 = _mm_adds_epi16(sumBB2_epi16, sumBB2b_epi16);


			// Expand the even output points to a full doubleword
			sumGG2_epi16 = _mm_slli_epi32(sumGG2_epi16, 16);
			sumRR2_epi16 = _mm_slli_epi32(sumRR2_epi16, 16);
			sumBB2_epi16 = _mm_slli_epi32(sumBB2_epi16, 16);
			sumGG2_epi16 = _mm_srai_epi32(sumGG2_epi16, 16);
			sumRR2_epi16 = _mm_srai_epi32(sumRR2_epi16, 16);
			sumBB2_epi16 = _mm_srai_epi32(sumBB2_epi16, 16);


			/***** Combine the output points *****/

			lowGG1_epi16 = _mm_packs_epi32(lowGG1_epi16, lowGG2_epi16);
			lowRR1_epi16 = _mm_packs_epi32(lowRR1_epi16, lowRR2_epi16);
			lowBB1_epi16 = _mm_packs_epi32(lowBB1_epi16, lowBB2_epi16);
			sumGG1_epi16 = _mm_packs_epi32(sumGG1_epi16, sumGG2_epi16);
			sumRR1_epi16 = _mm_packs_epi32(sumRR1_epi16, sumRR2_epi16);
			sumBB1_epi16 = _mm_packs_epi32(sumBB1_epi16, sumBB2_epi16);


			// Store the four lowpass output points
			_mm_store_si128(lowpassGG_ptr++, lowGG1_epi16);
			_mm_store_si128(lowpassRR_ptr++, lowRR1_epi16);
			_mm_store_si128(lowpassBB_ptr++, lowBB1_epi16);

			// Get the last highpass coefficient in the group
			sumGG2_epi16 = _mm_srli_si128(sumGG1_epi16, 7*2);
			sumRR2_epi16 = _mm_srli_si128(sumRR1_epi16, 7*2);
			sumBB2_epi16 = _mm_srli_si128(sumBB1_epi16, 7*2);

			// Shift the extra highpass coefficient into the output
			sumGG1_epi16 = _mm_slli_si128(sumGG1_epi16, 1*2);
			sumRR1_epi16 = _mm_slli_si128(sumRR1_epi16, 1*2);
			sumBB1_epi16 = _mm_slli_si128(sumBB1_epi16, 1*2);
			sumGG1_epi16 = _mm_insert_epi16(sumGG1_epi16, highpass_valueGG, 0);
			sumRR1_epi16 = _mm_insert_epi16(sumRR1_epi16, highpass_valueRR, 0);
			sumBB1_epi16 = _mm_insert_epi16(sumBB1_epi16, highpass_valueBB, 0);

			// Save the last highpass coefficient for the next loop iteration
			highpass_valueGG = _mm_cvtsi128_si32(sumGG2_epi16);
			highpass_valueRR = _mm_cvtsi128_si32(sumRR2_epi16);
			highpass_valueBB = _mm_cvtsi128_si32(sumBB2_epi16);

			// Store the four highpass output points
			_mm_store_si128(highpassGG_ptr++, sumGG1_epi16);
			_mm_store_si128(highpassRR_ptr++, sumRR1_epi16);
			_mm_store_si128(highpassBB_ptr++, sumBB1_epi16);

			// The second set of eight input pixels becomes the working set
			GG1_epi16 = GG2_epi16;
			RR1_epi16 = RR2_epi16;
			BB1_epi16 = BB2_epi16;
		}
	}
	// Should have exited the loop at the post processing column
	assert(column == post_column);

	lowptrGG = (PIXEL *)lowpassGG_ptr;
	lowptrRR = (PIXEL *)lowpassRR_ptr;
	lowptrBB = (PIXEL *)lowpassBB_ptr;
	highptrGG = (PIXEL *)highpassGG_ptr;
	highptrRR = (PIXEL *)highpassRR_ptr;
	highptrBB = (PIXEL *)highpassBB_ptr;
#else


	switch(format)
	{
	case DECODED_FORMAT_AB10:
	case DECODED_FORMAT_RG30:
		sumRR = ((((pixelptr[column + 0]) & 0x3ff) + ((pixelptr[column + 1]) & 0x3ff))<<shift);
		sumGG = ((((pixelptr[column + 0]>>10) & 0x3ff) + ((pixelptr[column + 1]>>10) & 0x3ff))<<shift);
		sumBB = ((((pixelptr[column + 0]>>20) & 0x3ff) + ((pixelptr[column + 1]>>20) & 0x3ff))<<shift);
		break;

	case DECODED_FORMAT_AR10:
		sumRR = ((((pixelptr[column + 0]>>20) & 0x3ff) + ((pixelptr[column + 1]>>20) & 0x3ff))<<shift);
		sumGG = ((((pixelptr[column + 0]>>10) & 0x3ff) + ((pixelptr[column + 1]>>10) & 0x3ff))<<shift);
		sumBB = ((((pixelptr[column + 0]) & 0x3ff) + ((pixelptr[column + 1]) & 0x3ff))<<shift);
		break;

	case DECODED_FORMAT_R210:
		{
		unsigned int swap = _bswap(pixelptr[column + 0]);
		unsigned int swap1 = _bswap(pixelptr[column + 1]);

		sumRR = ((((swap>>20) & 0x3ff) + ((swap1>>20) & 0x3ff))<<shift);
		sumGG = ((((swap>>10) & 0x3ff) + ((swap1>>10) & 0x3ff))<<shift);
		sumBB = ((((swap>>0 ) & 0x3ff) + ((swap1>> 0) & 0x3ff))<<shift);
		}
		break;

	case DECODED_FORMAT_DPX0:
		{
		unsigned int swap = _bswap(pixelptr[column + 0]);
		unsigned int swap1 = _bswap(pixelptr[column + 1]);

		sumRR = ((((swap>>22) & 0x3ff) + ((swap1>>22) & 0x3ff))<<shift);
		sumGG = ((((swap>>12) & 0x3ff) + ((swap1>>12) & 0x3ff))<<shift);
		sumBB = ((((swap>>2) & 0x3ff) + ((swap1>>2) & 0x3ff))<<shift);
		}
		break;
	}


	// Store the lowpass sum
	*(lowptrGG++) = SATURATE(sumGG);
	*(lowptrRR++) = SATURATE(sumRR);
	*(lowptrBB++) = SATURATE(sumBB);

	//*(highptr++) = SATURATE(sum);
	*(highptrGG++) = highpass_valueGG;
	*(highptrRR++) = highpass_valueRR;
	*(highptrBB++) = highpass_valueBB;

	column += 2;

#endif
	// Process the last group of columns as a special case to handle the border
	for (; column < last_column; column += 2)
	{
		// Compute the lowpass sum
		//sum = input[column] + input[column + 1];

		switch(format)
		{
		case DECODED_FORMAT_AB10:
		case DECODED_FORMAT_RG30:
			sumRR = ((((pixelptr[column + 0]) & 0x3ff) + ((pixelptr[column + 1]) & 0x3ff))<<shift);
			sumGG = ((((pixelptr[column + 0]>>10) & 0x3ff) + ((pixelptr[column + 1]>>10) & 0x3ff))<<shift);
			sumBB = ((((pixelptr[column + 0]>>20) & 0x3ff) + ((pixelptr[column + 1]>>20) & 0x3ff))<<shift);

			// Store the lowpass sum
			*(lowptrGG++) = SATURATE(sumGG);
			*(lowptrRR++) = SATURATE(sumRR);
			*(lowptrBB++) = SATURATE(sumBB);

			// Compute the highpass sum
			//sum = 0;
			sumGG=sumRR=sumBB = 0;

			//sum -= input[column - 2];
			sumRR -= ((pixelptr[column - 2]) & 0x3ff);
			sumGG -= ((pixelptr[column - 2]>>10) & 0x3ff);
			sumBB -= ((pixelptr[column - 2]>>20) & 0x3ff);

			//sum -= input[column - 1];
			sumRR -= ((pixelptr[column - 1]) & 0x3ff);
			sumGG -= ((pixelptr[column - 1]>>10) & 0x3ff);
			sumBB -= ((pixelptr[column - 1]>>20) & 0x3ff);

			//sum += input[column + 2];
			sumRR += ((pixelptr[column + 2]) & 0x3ff);
			sumGG += ((pixelptr[column + 2]>>10) & 0x3ff);
			sumBB += ((pixelptr[column + 2]>>20) & 0x3ff);

			//sum += input[column + 3];
			sumRR += ((pixelptr[column + 3]) & 0x3ff);
			sumGG += ((pixelptr[column + 3]>>10) & 0x3ff);
			sumBB += ((pixelptr[column + 3]>>20) & 0x3ff);

			sumRR <<= shift;
			sumGG <<= shift;
			sumBB <<= shift;

			//sum += ROUNDING(sum,8);
			sumRR += ROUNDING(sumRR,8);
			sumGG += ROUNDING(sumGG,8);
			sumBB += ROUNDING(sumBB,8);

			//sum = DivideByShift(sum, 3);
			sumRR = DivideByShift(sumRR,3);
			sumGG = DivideByShift(sumGG,3);
			sumBB = DivideByShift(sumBB,3);

			//sum += input[column + 0];
			sumRR += ((pixelptr[column + 0]) & 0x3ff)<<shift;
			sumGG += ((pixelptr[column + 0]>>10) & 0x3ff)<<shift;
			sumBB += ((pixelptr[column + 0]>>20) & 0x3ff)<<shift;

			//sum -= input[column + 1];
			sumRR -= ((pixelptr[column + 1]) & 0x3ff)<<shift;
			sumGG -= ((pixelptr[column + 1]>>10) & 0x3ff)<<shift;
			sumBB -= ((pixelptr[column + 1]>>20) & 0x3ff)<<shift;
			break;

		case DECODED_FORMAT_AR10:
			sumBB = ((((pixelptr[column + 0]) & 0x3ff) + ((pixelptr[column + 1]) & 0x3ff))<<shift);
			sumGG = ((((pixelptr[column + 0]>>10) & 0x3ff) + ((pixelptr[column + 1]>>10) & 0x3ff))<<shift);
			sumRR = ((((pixelptr[column + 0]>>20) & 0x3ff) + ((pixelptr[column + 1]>>20) & 0x3ff))<<shift);

			// Store the lowpass sum
			*(lowptrGG++) = SATURATE(sumGG);
			*(lowptrRR++) = SATURATE(sumRR);
			*(lowptrBB++) = SATURATE(sumBB);

			// Compute the highpass sum
			//sum = 0;
			sumGG=sumRR=sumBB = 0;

			//sum -= input[column - 2];
			sumBB -= ((pixelptr[column - 2]) & 0x3ff);
			sumGG -= ((pixelptr[column - 2]>>10) & 0x3ff);
			sumRR -= ((pixelptr[column - 2]>>20) & 0x3ff);

			//sum -= input[column - 1];
			sumBB -= ((pixelptr[column - 1]) & 0x3ff);
			sumGG -= ((pixelptr[column - 1]>>10) & 0x3ff);
			sumRR -= ((pixelptr[column - 1]>>20) & 0x3ff);

			//sum += input[column + 2];
			sumBB += ((pixelptr[column + 2]) & 0x3ff);
			sumGG += ((pixelptr[column + 2]>>10) & 0x3ff);
			sumRR += ((pixelptr[column + 2]>>20) & 0x3ff);

			//sum += input[column + 3];
			sumBB += ((pixelptr[column + 3]) & 0x3ff);
			sumGG += ((pixelptr[column + 3]>>10) & 0x3ff);
			sumRR += ((pixelptr[column + 3]>>20) & 0x3ff);

			sumRR <<= shift;
			sumGG <<= shift;
			sumBB <<= shift;

			//sum += ROUNDING(sum,8);
			sumRR += ROUNDING(sumRR,8);
			sumGG += ROUNDING(sumGG,8);
			sumBB += ROUNDING(sumBB,8);

			//sum = DivideByShift(sum, 3);
			sumRR = DivideByShift(sumRR,3);
			sumGG = DivideByShift(sumGG,3);
			sumBB = DivideByShift(sumBB,3);

			//sum += input[column + 0];
			sumBB += ((pixelptr[column + 0]) & 0x3ff)<<shift;
			sumGG += ((pixelptr[column + 0]>>10) & 0x3ff)<<shift;
			sumRR += ((pixelptr[column + 0]>>20) & 0x3ff)<<shift;

			//sum -= input[column + 1];
			sumBB -= ((pixelptr[column + 1]) & 0x3ff)<<shift;
			sumGG -= ((pixelptr[column + 1]>>10) & 0x3ff)<<shift;
			sumRR -= ((pixelptr[column + 1]>>20) & 0x3ff)<<shift;
			break;

		case DECODED_FORMAT_R210:
			{
			unsigned int swap = _bswap(pixelptr[column + 0]);
			unsigned int swap1 = _bswap(pixelptr[column + 1]);
			unsigned int swap2 = _bswap(pixelptr[column + 2]);
			unsigned int swap3 = _bswap(pixelptr[column + 3]);
			unsigned int swap1n = _bswap(pixelptr[column - 1]);
			unsigned int swap2n = _bswap(pixelptr[column - 2]);
			sumRR = ((((swap>>20) & 0x3ff) + ((swap1>>20) & 0x3ff))<<shift);
			sumGG = ((((swap>>10) & 0x3ff) + ((swap1>>10) & 0x3ff))<<shift);
			sumBB = ((((swap>>0) & 0x3ff) + ((swap1>>0) & 0x3ff))<<shift);

			// Store the lowpass sum
			*(lowptrGG++) = SATURATE(sumGG);
			*(lowptrRR++) = SATURATE(sumRR);
			*(lowptrBB++) = SATURATE(sumBB);

			// Compute the highpass sum
			//sum = 0;
			sumGG=sumRR=sumBB = 0;

			//sum -= input[column - 2];
			sumRR -= ((swap2n>>20) & 0x3ff);
			sumGG -= ((swap2n>>10) & 0x3ff);
			sumBB -= ((swap2n>>0 ) & 0x3ff);

			//sum -= input[column - 1];
			sumRR -= ((swap1n>>20) & 0x3ff);
			sumGG -= ((swap1n>>10) & 0x3ff);
			sumBB -= ((swap1n>>0 ) & 0x3ff);

			//sum += input[column + 2];
			sumRR += ((swap2>>20) & 0x3ff);
			sumGG += ((swap2>>10) & 0x3ff);
			sumBB += ((swap2>>0 ) & 0x3ff);

			//sum += input[column + 3];
			sumRR += ((swap3>>20) & 0x3ff);
			sumGG += ((swap3>>10) & 0x3ff);
			sumBB += ((swap3>>0 ) & 0x3ff);

			sumRR <<= shift;
			sumGG <<= shift;
			sumBB <<= shift;

			//sum += ROUNDING(sum,8);
			sumRR += ROUNDING(sumRR,8);
			sumGG += ROUNDING(sumGG,8);
			sumBB += ROUNDING(sumBB,8);

			//sum = DivideByShift(sum, 3);
			sumRR = DivideByShift(sumRR,3);
			sumGG = DivideByShift(sumGG,3);
			sumBB = DivideByShift(sumBB,3);

			//sum += input[column + 0];
			sumRR += ((swap>>20) & 0x3ff)<<shift;
			sumGG += ((swap>>10) & 0x3ff)<<shift;
			sumBB += ((swap>>0 ) & 0x3ff)<<shift;

			//sum -= input[column + 1];
			sumRR -= ((swap1>>20) & 0x3ff)<<shift;
			sumGG -= ((swap1>>10) & 0x3ff)<<shift;
			sumBB -= ((swap1>>0 ) & 0x3ff)<<shift;

			}
			break;

		case DECODED_FORMAT_DPX0:
			{
			unsigned int swap = _bswap(pixelptr[column + 0]);
			unsigned int swap1 = _bswap(pixelptr[column + 1]);
			unsigned int swap2 = _bswap(pixelptr[column + 2]);
			unsigned int swap3 = _bswap(pixelptr[column + 3]);
			unsigned int swap1n = _bswap(pixelptr[column - 1]);
			unsigned int swap2n = _bswap(pixelptr[column - 2]);
			sumRR = ((((swap>>22) & 0x3ff) + ((swap1>>22) & 0x3ff))<<shift);
			sumGG = ((((swap>>12) & 0x3ff) + ((swap1>>12) & 0x3ff))<<shift);
			sumBB = ((((swap>>2) & 0x3ff) + ((swap1>>2) & 0x3ff))<<shift);

			// Store the lowpass sum
			*(lowptrGG++) = SATURATE(sumGG);
			*(lowptrRR++) = SATURATE(sumRR);
			*(lowptrBB++) = SATURATE(sumBB);

			// Compute the highpass sum
			//sum = 0;
			sumGG=sumRR=sumBB = 0;

			//sum -= input[column - 2];
			sumRR -= ((swap2n>>22) & 0x3ff);
			sumGG -= ((swap2n>>12) & 0x3ff);
			sumBB -= ((swap2n>>2 ) & 0x3ff);

			//sum -= input[column - 1];
			sumRR -= ((swap1n>>22) & 0x3ff);
			sumGG -= ((swap1n>>12) & 0x3ff);
			sumBB -= ((swap1n>>2 ) & 0x3ff);

			//sum += input[column + 2];
			sumRR += ((swap2>>22) & 0x3ff);
			sumGG += ((swap2>>12) & 0x3ff);
			sumBB += ((swap2>>2 ) & 0x3ff);

			//sum += input[column + 3];
			sumRR += ((swap3>>22) & 0x3ff);
			sumGG += ((swap3>>12) & 0x3ff);
			sumBB += ((swap3>>2 ) & 0x3ff);

			sumRR <<= shift;
			sumGG <<= shift;
			sumBB <<= shift;

			//sum += ROUNDING(sum,8);
			sumRR += ROUNDING(sumRR,8);
			sumGG += ROUNDING(sumGG,8);
			sumBB += ROUNDING(sumBB,8);

			//sum = DivideByShift(sum, 3);
			sumRR = DivideByShift(sumRR,3);
			sumGG = DivideByShift(sumGG,3);
			sumBB = DivideByShift(sumBB,3);

			//sum += input[column + 0];
			sumRR += ((swap>>22) & 0x3ff)<<shift;
			sumGG += ((swap>>12) & 0x3ff)<<shift;
			sumBB += ((swap>>2 ) & 0x3ff)<<shift;

			//sum -= input[column + 1];
			sumRR -= ((swap1>>22) & 0x3ff)<<shift;
			sumGG -= ((swap1>>12) & 0x3ff)<<shift;
			sumBB -= ((swap1>>2 ) & 0x3ff)<<shift;

			}
			break;
		}

		// Store the highpass sum
		//*(highptr++) = SATURATE(sum);
		*(highptrGG++) = SATURATE(sumGG);
		*(highptrRR++) = SATURATE(sumRR);
		*(highptrBB++) = SATURATE(sumBB);
	}

	// Should be at the last column
	assert(column == last_column);


	switch(format)
	{
	case DECODED_FORMAT_AB10:
	case DECODED_FORMAT_RG30:
		// Compute the last lowpass value
		//sum = input[column] + input[column + 1];
		sumRR = ((((pixelptr[column + 0]) & 0x3ff) + ((pixelptr[column + 1]) & 0x3ff))<<shift);
		sumGG = ((((pixelptr[column + 0]>>10) & 0x3ff) + ((pixelptr[column + 1]>>10) & 0x3ff))<<shift);
		sumBB = ((((pixelptr[column + 0]>>20) & 0x3ff) + ((pixelptr[column + 1]>>20) & 0x3ff))<<shift);

		// Store the lowpass sum
		*(lowptrGG++) = SATURATE(sumGG);
		*(lowptrRR++) = SATURATE(sumRR);
		*(lowptrBB++) = SATURATE(sumBB);

		// Compute the last highpass value using the special border coefficients
		//sum = 0;
		sumGG=sumRR=sumBB = 0;

		//sum += 11 * input[column + 0];
		sumRR += 11 * ((pixelptr[column + 0]) & 0x3ff);
		sumGG += 11 * ((pixelptr[column + 0]>>10) & 0x3ff);
		sumBB += 11 * ((pixelptr[column + 0]>>20) & 0x3ff);

		//sum -=  5 * input[column + 1];
		sumRR -= 5 * ((pixelptr[column + 1]) & 0x3ff);
		sumGG -= 5 * ((pixelptr[column + 1]>>10) & 0x3ff);
		sumBB -= 5 * ((pixelptr[column + 1]>>20) & 0x3ff);

		//sum -=  4 * input[column - 1];
		sumRR -= 4 * ((pixelptr[column - 1]) & 0x3ff);
		sumGG -= 4 * ((pixelptr[column - 1]>>10) & 0x3ff);
		sumBB -= 4 * ((pixelptr[column - 1]>>20) & 0x3ff);

		//sum -=  4 * input[column - 2];
		sumRR -= 4 * ((pixelptr[column - 2]) & 0x3ff);
		sumGG -= 4 * ((pixelptr[column - 2]>>10) & 0x3ff);
		sumBB -= 4 * ((pixelptr[column - 2]>>20) & 0x3ff);

		//sum +=  1 * input[column - 3];
		sumRR += 1 * ((pixelptr[column - 3]) & 0x3ff);
		sumGG += 1 * ((pixelptr[column - 3]>>10) & 0x3ff);
		sumBB += 1 * ((pixelptr[column - 3]>>20) & 0x3ff);

		//sum +=  1 * input[column - 4];
		sumRR += 1 * ((pixelptr[column - 4]) & 0x3ff);
		sumGG += 1 * ((pixelptr[column - 4]>>10) & 0x3ff);
		sumBB += 1 * ((pixelptr[column - 4]>>20) & 0x3ff);
		break;

	case DECODED_FORMAT_AR10:
		// Compute the last lowpass value
		//sum = input[column] + input[column + 1];
		sumBB = ((((pixelptr[column + 0]) & 0x3ff) + ((pixelptr[column + 1]) & 0x3ff))<<shift);
		sumGG = ((((pixelptr[column + 0]>>10) & 0x3ff) + ((pixelptr[column + 1]>>10) & 0x3ff))<<shift);
		sumRR = ((((pixelptr[column + 0]>>20) & 0x3ff) + ((pixelptr[column + 1]>>20) & 0x3ff))<<shift);

		// Store the lowpass sum
		*(lowptrGG++) = SATURATE(sumGG);
		*(lowptrRR++) = SATURATE(sumRR);
		*(lowptrBB++) = SATURATE(sumBB);

		// Compute the last highpass value using the special border coefficients
		//sum = 0;
		sumGG=sumRR=sumBB = 0;

		//sum += 11 * input[column + 0];
		sumBB += 11 * ((pixelptr[column + 0]) & 0x3ff);
		sumGG += 11 * ((pixelptr[column + 0]>>10) & 0x3ff);
		sumRR += 11 * ((pixelptr[column + 0]>>20) & 0x3ff);

		//sum -=  5 * input[column + 1];
		sumBB -= 5 * ((pixelptr[column + 1]) & 0x3ff);
		sumGG -= 5 * ((pixelptr[column + 1]>>10) & 0x3ff);
		sumRR -= 5 * ((pixelptr[column + 1]>>20) & 0x3ff);

		//sum -=  4 * input[column - 1];
		sumBB -= 4 * ((pixelptr[column - 1]) & 0x3ff);
		sumGG -= 4 * ((pixelptr[column - 1]>>10) & 0x3ff);
		sumRR -= 4 * ((pixelptr[column - 1]>>20) & 0x3ff);

		//sum -=  4 * input[column - 2];
		sumBB -= 4 * ((pixelptr[column - 2]) & 0x3ff);
		sumGG -= 4 * ((pixelptr[column - 2]>>10) & 0x3ff);
		sumRR -= 4 * ((pixelptr[column - 2]>>20) & 0x3ff);

		//sum +=  1 * input[column - 3];
		sumBB += 1 * ((pixelptr[column - 3]) & 0x3ff);
		sumGG += 1 * ((pixelptr[column - 3]>>10) & 0x3ff);
		sumRR += 1 * ((pixelptr[column - 3]>>20) & 0x3ff);

		//sum +=  1 * input[column - 4];
		sumBB += 1 * ((pixelptr[column - 4]) & 0x3ff);
		sumGG += 1 * ((pixelptr[column - 4]>>10) & 0x3ff);
		sumRR += 1 * ((pixelptr[column - 4]>>20) & 0x3ff);
		break;

	case DECODED_FORMAT_R210:
		{
		unsigned int swap = _bswap(pixelptr[column + 0]);
		unsigned int swap1 = _bswap(pixelptr[column + 1]);
		unsigned int swap1n = _bswap(pixelptr[column - 1]);
		unsigned int swap2n = _bswap(pixelptr[column - 2]);
		unsigned int swap3n = _bswap(pixelptr[column - 3]);
		unsigned int swap4n = _bswap(pixelptr[column - 4]);

		// Compute the last lowpass value
		//sum = input[column] + input[column + 1];
		sumRR = ((((swap>>20) & 0x3ff) + ((swap1>>20) & 0x3ff))<<shift);
		sumGG = ((((swap>>10) & 0x3ff) + ((swap1>>10) & 0x3ff))<<shift);
		sumBB = ((((swap>>0 ) & 0x3ff) + ((swap1>>0 ) & 0x3ff))<<shift);

		// Store the lowpass sum
		*(lowptrGG++) = SATURATE(sumGG);
		*(lowptrRR++) = SATURATE(sumRR);
		*(lowptrBB++) = SATURATE(sumBB);

		// Compute the last highpass value using the special border coefficients
		//sum = 0;
		sumGG=sumRR=sumBB = 0;

		//sum += 11 * input[column + 0];
		sumRR += 11 * ((swap>>20) & 0x3ff);
		sumGG += 11 * ((swap>>10) & 0x3ff);
		sumBB += 11 * ((swap>>0 ) & 0x3ff);

		//sum -=  5 * input[column + 1];
		sumRR -= 5 * ((swap1>>20) & 0x3ff);
		sumGG -= 5 * ((swap1>>10) & 0x3ff);
		sumBB -= 5 * ((swap1>>0 ) & 0x3ff);

		//sum -=  4 * input[column - 1];
		sumRR -= 4 * ((swap1n>>20) & 0x3ff);
		sumGG -= 4 * ((swap1n>>10) & 0x3ff);
		sumBB -= 4 * ((swap1n>>0 ) & 0x3ff);

		//sum -=  4 * input[column - 2];
		sumRR -= 4 * ((swap2n>>20) & 0x3ff);
		sumGG -= 4 * ((swap2n>>10) & 0x3ff);
		sumBB -= 4 * ((swap2n>>0 ) & 0x3ff);

		//sum +=  1 * input[column - 3];
		sumRR += 1 * ((swap3n>>20) & 0x3ff);
		sumGG += 1 * ((swap3n>>10) & 0x3ff);
		sumBB += 1 * ((swap3n>>0 ) & 0x3ff);

		//sum +=  1 * input[column - 4];
		sumRR += 1 * ((swap4n>>20) & 0x3ff);
		sumGG += 1 * ((swap4n>>10) & 0x3ff);
		sumBB += 1 * ((swap4n>>0 ) & 0x3ff);
		}
		break;
	case DECODED_FORMAT_DPX0:
		{
		unsigned int swap = _bswap(pixelptr[column + 0]);
		unsigned int swap1 = _bswap(pixelptr[column + 1]);
		unsigned int swap1n = _bswap(pixelptr[column - 1]);
		unsigned int swap2n = _bswap(pixelptr[column - 2]);
		unsigned int swap3n = _bswap(pixelptr[column - 3]);
		unsigned int swap4n = _bswap(pixelptr[column - 4]);

		// Compute the last lowpass value
		//sum = input[column] + input[column + 1];
		sumRR = ((((swap>>22) & 0x3ff) + ((swap1>>22) & 0x3ff))<<shift);
		sumGG = ((((swap>>12) & 0x3ff) + ((swap1>>12) & 0x3ff))<<shift);
		sumBB = ((((swap>>2 ) & 0x3ff) + ((swap1>>2 ) & 0x3ff))<<shift);

		// Store the lowpass sum
		*(lowptrGG++) = SATURATE(sumGG);
		*(lowptrRR++) = SATURATE(sumRR);
		*(lowptrBB++) = SATURATE(sumBB);

		// Compute the last highpass value using the special border coefficients
		//sum = 0;
		sumGG=sumRR=sumBB = 0;

		//sum += 11 * input[column + 0];
		sumRR += 11 * ((swap>>22) & 0x3ff);
		sumGG += 11 * ((swap>>12) & 0x3ff);
		sumBB += 11 * ((swap>>2 ) & 0x3ff);

		//sum -=  5 * input[column + 1];
		sumRR -= 5 * ((swap1>>22) & 0x3ff);
		sumGG -= 5 * ((swap1>>12) & 0x3ff);
		sumBB -= 5 * ((swap1>>2 ) & 0x3ff);

		//sum -=  4 * input[column - 1];
		sumRR -= 4 * ((swap1n>>22) & 0x3ff);
		sumGG -= 4 * ((swap1n>>12) & 0x3ff);
		sumBB -= 4 * ((swap1n>>2 ) & 0x3ff);

		//sum -=  4 * input[column - 2];
		sumRR -= 4 * ((swap2n>>22) & 0x3ff);
		sumGG -= 4 * ((swap2n>>12) & 0x3ff);
		sumBB -= 4 * ((swap2n>>2 ) & 0x3ff);

		//sum +=  1 * input[column - 3];
		sumRR += 1 * ((swap3n>>22) & 0x3ff);
		sumGG += 1 * ((swap3n>>12) & 0x3ff);
		sumBB += 1 * ((swap3n>>2 ) & 0x3ff);

		//sum +=  1 * input[column - 4];
		sumRR += 1 * ((swap4n>>22) & 0x3ff);
		sumGG += 1 * ((swap4n>>12) & 0x3ff);
		sumBB += 1 * ((swap4n>>2 ) & 0x3ff);
		}
		break;
	}

	sumRR <<= shift;
	sumGG <<= shift;
	sumBB <<= shift;

	//sum +=  ROUNDING(sum,8);
	sumGG += ROUNDING(sumGG,8);
	sumRR += ROUNDING(sumRR,8);
	sumBB += ROUNDING(sumBB,8);

	//sum = DivideByShift(sum, 3);
	sumGG = DivideByShift(sumGG,3);
	sumRR = DivideByShift(sumRR,3);
	sumBB = DivideByShift(sumBB,3);

	//*(highptr++) = SATURATE(sum);
	*(highptrGG++) = SATURATE(sumGG);
	*(highptrRR++) = SATURATE(sumRR);
	*(highptrBB++) = SATURATE(sumBB);
}






#define CONVOLVE_SHIFT	1


void FilterHorizontalRow10bit16s(PIXEL *input, PIXEL *lowpass, PIXEL *highpass, int width, PIXEL *buffer)
{
	int column_step = 16;				// Number of input pixels processed per loop iteration
	int last_column = width - 2;		// Column at which right border processing is done

	// The post column is the column at which end of column processing must begin
	int post_column = last_column - (last_column % column_step);

	int32_t sum;

	// Start at the left end of the row
	PIXEL *lowptr = lowpass;
	PIXEL *highptr = highpass;
	int column = 0;

	__m128i *input_ptr = (__m128i *)input;
	__m128i *lowpass_ptr;
	__m128i *highpass_ptr;
	__m128i input1_epi16;
	__m128i mask_epi16;
	__m128i three = _mm_set1_epi16(3);

	int highpass_value;

	// The highpass filter on the left border uses different coefficients
	sum = 0;
	sum +=  5 * ((input[column + 0]+3)>>V210_HORIZONTAL_SHIFT);
	sum -= 11 * ((input[column + 1]+3)>>V210_HORIZONTAL_SHIFT);
	sum +=  4 * ((input[column + 2]+3)>>V210_HORIZONTAL_SHIFT);
	sum +=  4 * ((input[column + 3]+3)>>V210_HORIZONTAL_SHIFT);
	sum -=  1 * ((input[column + 4]+3)>>V210_HORIZONTAL_SHIFT);
	sum -=  1 * ((input[column + 5]+3)>>V210_HORIZONTAL_SHIFT);
	sum += ROUNDING(sum,8);
	sum = DivideByShift(sum, 3);
	highpass_value = SATURATE(sum);

	// Set the input pointer for the fast loop
	input_ptr = (__m128i *)&input[column];

	// Check that the pointer to the next group of pixels is properly aligned
	assert(ISALIGNED16(input_ptr));

	// Preload the first set of four pixels for fast processing
	input1_epi16 = _mm_load_si128(input_ptr++);
	input1_epi16 = _mm_adds_epi16(input1_epi16, three);

	// Initialize the output pointers
	lowpass_ptr = (__m128i *)lowptr;
	highpass_ptr = (__m128i *)highptr;

	// Check that the output pointers are properly aligned
	assert(ISALIGNED16(lowpass_ptr));
	assert(ISALIGNED16(highpass_ptr));

	// Intialize the mask used for downsampling the convolution results
	mask_epi16 = _mm_set1_epi32(0x0000FFFF);

#if (1 && XMMOPT)
	// Process two sets of four input pixels to get one set of four output pixels
	for (; column < post_column; column += column_step)
	{
		__m128i input2_epi16;
		__m128i shift2_epi16;
		__m128i half_epi16;		// Half of the divisor for rounding
		__m128i sum1_epi16;
		__m128i sum2_epi16;
		__m128i sum1b_epi16;
		__m128i sum2b_epi16;
		__m128i low1_epi16;
		__m128i low2_epi16;
		__m128i tmp_epi16;


		/***** Process the first four output points *****/

		// Initialize the highpass sum
		sum1_epi16 = _mm_setzero_si128();

		

		// Apply the first filter coefficient to each pixel and sum the result
		
		tmp_epi16 = _mm_srai_epi16(input1_epi16, V210_HORIZONTAL_SHIFT);
		sum1_epi16 = _mm_subs_epi16(sum1_epi16, tmp_epi16);

		// Check that the pointer to the next group of pixels is properly aligned
		assert(ISALIGNED16(input_ptr));

		// Load the next eight pixels
		input2_epi16 = _mm_load_si128(input_ptr++);
		input2_epi16 = _mm_adds_epi16(input2_epi16, three);

		// Initialize the lowpass sum
		low1_epi16 = input1_epi16;

		// Shift the first pixel from the second set into the working set
		shift2_epi16 = _mm_slli_si128(input2_epi16, 7*2);
		input1_epi16 = _mm_srli_si128(input1_epi16, 1*2);
		input1_epi16 = _mm_or_si128(input1_epi16, shift2_epi16);

		// Apply the second filter coefficient to each pixel and sum the result
		tmp_epi16 = _mm_srai_epi16(input1_epi16, V210_HORIZONTAL_SHIFT);
		sum1_epi16 = _mm_subs_epi16(sum1_epi16, tmp_epi16);

		// Add adjacent points to compute the lowpass sum
		low1_epi16 = _mm_adds_epi16(low1_epi16, input1_epi16);
		low1_epi16 = _mm_subs_epi16(low1_epi16, three);
		low1_epi16 = _mm_srai_epi16(low1_epi16, V210_HORIZONTAL_SHIFT);

		// Expand the lowpass output points to a full doubleword
		low1_epi16 = _mm_slli_epi32(low1_epi16, 16);
		low1_epi16 = _mm_srai_epi32(low1_epi16, 16);

		// Shift the second pixel from the second set into the working set
		shift2_epi16 = _mm_slli_si128(input2_epi16, 6*2);
		input1_epi16 = _mm_srli_si128(input1_epi16, 1*2);
		input1_epi16 = _mm_or_si128(input1_epi16, shift2_epi16);

		// Apply the third filter coefficient to each pixel and sum the result
		tmp_epi16 = _mm_srai_epi16(input1_epi16, V210_HORIZONTAL_SHIFT);
		sum1b_epi16 = tmp_epi16;

		// Shift the third pixel from the second set into the working set
		shift2_epi16 = _mm_slli_si128(input2_epi16, 5*2);
		input1_epi16 = _mm_srli_si128(input1_epi16, 1*2);
		input1_epi16 = _mm_or_si128(input1_epi16, shift2_epi16);

		// Apply the fourth filter coefficient to each pixel and sum the result
		tmp_epi16 = _mm_srai_epi16(input1_epi16, V210_HORIZONTAL_SHIFT);
		sum1b_epi16 = _mm_subs_epi16(sum1b_epi16, tmp_epi16);

		// Shift the fourth pixel from the second set into the working set
		shift2_epi16 = _mm_slli_si128(input2_epi16, 4*2);
		input1_epi16 = _mm_srli_si128(input1_epi16, 1*2);
		input1_epi16 = _mm_or_si128(input1_epi16, shift2_epi16);

		// Apply the fifth filter coefficient to each pixel and sum the result
		tmp_epi16 = _mm_srai_epi16(input1_epi16, V210_HORIZONTAL_SHIFT);
		sum1_epi16 = _mm_adds_epi16(sum1_epi16, tmp_epi16);

		// Shift the fifth pixel from the second set into the working set
		shift2_epi16 = _mm_slli_si128(input2_epi16, 3*2);
		input1_epi16 = _mm_srli_si128(input1_epi16, 1*2);
		input1_epi16 = _mm_or_si128(input1_epi16, shift2_epi16);

		// Apply the sixth (last) filter coefficient to each pixel and sum the result
		tmp_epi16 = _mm_srai_epi16(input1_epi16, V210_HORIZONTAL_SHIFT);
		sum1_epi16 = _mm_adds_epi16(sum1_epi16, tmp_epi16);

		//DAN20050915 -- reversibility
		half_epi16 = _mm_set1_epi16(4);
		sum1_epi16 = _mm_adds_epi16(sum1_epi16, half_epi16);
		sum1_epi16 = _mm_srai_epi16(sum1_epi16, 3);

		sum1_epi16 = _mm_adds_epi16(sum1_epi16, sum1b_epi16);

		// Expand the even output points to a full doubleword
		sum1_epi16 = _mm_slli_epi32(sum1_epi16, 16);
		sum1_epi16 = _mm_srai_epi32(sum1_epi16, 16);

		// The second eight input points become the current input points
		input1_epi16 = input2_epi16;


		/***** Process the second four output points *****/

		// Initialize the highpass sum
		sum2_epi16 = _mm_setzero_si128();

		// Apply the first filter coefficient to each pixel and sum the result
		tmp_epi16 = _mm_srai_epi16(input1_epi16, V210_HORIZONTAL_SHIFT);
		sum2_epi16 = _mm_subs_epi16(sum2_epi16, tmp_epi16);

		// Check that the pointer to the next group of pixels is properly aligned
		assert(ISALIGNED16(input_ptr));

		// Load the next eight pixels
		input2_epi16 = _mm_load_si128(input_ptr++);
		input2_epi16 = _mm_adds_epi16(input2_epi16, three);

		// Initialize the lowpass sum
		low2_epi16 = input1_epi16;

		// Shift the first pixel from the second set into the working set
		shift2_epi16 = _mm_slli_si128(input2_epi16, 7*2);
		input1_epi16 = _mm_srli_si128(input1_epi16, 1*2);
		input1_epi16 = _mm_or_si128(input1_epi16, shift2_epi16);

		// Apply the second filter coefficient to each pixel and sum the result
		tmp_epi16 = _mm_srai_epi16(input1_epi16, V210_HORIZONTAL_SHIFT);
		sum2_epi16 = _mm_subs_epi16(sum2_epi16, tmp_epi16);

		// Add adjacent points to compute the lowpass sum
		low2_epi16 = _mm_adds_epi16(low2_epi16, input1_epi16);
		low2_epi16 = _mm_subs_epi16(low2_epi16, three);
		low2_epi16 = _mm_srai_epi16(low2_epi16, V210_HORIZONTAL_SHIFT);

		// Expand the lowpass output points to a full doubleword
		low2_epi16 = _mm_slli_epi32(low2_epi16, 16);
		low2_epi16 = _mm_srai_epi32(low2_epi16, 16);

		// Shift the second pixel from the second set into the working set
		shift2_epi16 = _mm_slli_si128(input2_epi16, 6*2);
		input1_epi16 = _mm_srli_si128(input1_epi16, 1*2);
		input1_epi16 = _mm_or_si128(input1_epi16, shift2_epi16);

		// Apply the third filter coefficient to each pixel and sum the result
		tmp_epi16 = _mm_srai_epi16(input1_epi16, V210_HORIZONTAL_SHIFT);
		sum2b_epi16 = tmp_epi16;

		// Shift the third pixel from the second set into the working set
		shift2_epi16 = _mm_slli_si128(input2_epi16, 5*2);
		input1_epi16 = _mm_srli_si128(input1_epi16, 1*2);
		input1_epi16 = _mm_or_si128(input1_epi16, shift2_epi16);

		// Apply the fourth filter coefficient to each pixel and sum the result
		tmp_epi16 = _mm_srai_epi16(input1_epi16, V210_HORIZONTAL_SHIFT);
		sum2b_epi16 = _mm_subs_epi16(sum2b_epi16, tmp_epi16);

		// Shift the fourth pixel from the second set into the working set
		shift2_epi16 = _mm_slli_si128(input2_epi16, 4*2);
		input1_epi16 = _mm_srli_si128(input1_epi16, 1*2);
		input1_epi16 = _mm_or_si128(input1_epi16, shift2_epi16);

		// Apply the fifth filter coefficient to each pixel and sum the result
		tmp_epi16 = _mm_srai_epi16(input1_epi16, V210_HORIZONTAL_SHIFT);
		sum2_epi16 = _mm_adds_epi16(sum2_epi16, tmp_epi16);

		// Shift the fifth pixel from the second set into the working set
		shift2_epi16 = _mm_slli_si128(input2_epi16, 3*2);
		input1_epi16 = _mm_srli_si128(input1_epi16, 1*2);
		input1_epi16 = _mm_or_si128(input1_epi16, shift2_epi16);

		// Apply the sixth (last) filter coefficient to each pixel and sum the result
		tmp_epi16 = _mm_srai_epi16(input1_epi16, V210_HORIZONTAL_SHIFT);
		sum2_epi16 = _mm_adds_epi16(sum2_epi16, tmp_epi16);

		//DAN20050915 -- reversibility
		sum2_epi16 = _mm_adds_epi16(sum2_epi16, half_epi16);
		sum2_epi16 = _mm_srai_epi16(sum2_epi16, 3);

		sum2_epi16 = _mm_adds_epi16(sum2_epi16, sum2b_epi16);

		// Expand the even output points to a full doubleword
		sum2_epi16 = _mm_slli_epi32(sum2_epi16, 16);
		sum2_epi16 = _mm_srai_epi32(sum2_epi16, 16);


		/***** Combine the output points *****/

		low1_epi16 = _mm_packs_epi32(low1_epi16, low2_epi16);
		sum1_epi16 = _mm_packs_epi32(sum1_epi16, sum2_epi16);


		// Store the four lowpass output points
		_mm_store_si128(lowpass_ptr++, low1_epi16);

		// Get the last highpass coefficient in the group
		sum2_epi16 = _mm_srli_si128(sum1_epi16, 7*2);

		// Shift the extra highpass coefficient into the output
		sum1_epi16 = _mm_slli_si128(sum1_epi16, 1*2);
		sum1_epi16 = _mm_insert_epi16(sum1_epi16, highpass_value, 0);

		// Save the last highpass coefficient for the next loop iteration
		highpass_value = _mm_cvtsi128_si32(sum2_epi16);

		// Store the four highpass output points
		_mm_store_si128(highpass_ptr++, sum1_epi16);

		// The second set of eight input pixels becomes the working set
		input1_epi16 = input2_epi16;
	}

	// Should have exited the loop at the post processing column
	assert(column == post_column);

	lowptr = (PIXEL *)lowpass_ptr;
	highptr = (PIXEL *)highpass_ptr;

#else
	sum = input[column] + input[column + 1];
	*(lowptr++) = SATURATE(sum);
	*(highptr++) = SATURATE(highpass_value);
	column+=2;
#endif

	// Process the last group of columns as a special case to handle the border
	for (; column < last_column; column += 2)
	{
		// Compute the lowpass sum
		sum = (input[column] + input[column + 1] + 3) >> V210_HORIZONTAL_SHIFT;

		// Store the lowpass sum
		*(lowptr++) = SATURATE(sum);

		// Compute the highpass sum
		sum = 0;
		sum -= (input[column - 2]+3) >> V210_HORIZONTAL_SHIFT;
		sum -= (input[column - 1]+3) >> V210_HORIZONTAL_SHIFT;
		sum += (input[column + 2]+3) >> V210_HORIZONTAL_SHIFT;
		sum += (input[column + 3]+3) >> V210_HORIZONTAL_SHIFT;
		sum += 4;
		sum >>= 3;
		sum += (input[column + 0]+3) >> V210_HORIZONTAL_SHIFT;
		sum -= (input[column + 1]+3) >> V210_HORIZONTAL_SHIFT;

		// Store the highpass sum
		*(highptr++) = SATURATE(sum);
	}

	// Should be at the last column
	assert(column == last_column);

	// Compute the last lowpass value
	sum = (input[column] + input[column + 1] + 3) >> V210_HORIZONTAL_SHIFT;

	*(lowptr++) = SATURATE(sum);

	// Compute the last highpass value using the special border coefficients
	sum = 0;
	sum += 11 * ((input[column + 0]+3) >> V210_HORIZONTAL_SHIFT);
	sum -=  5 * ((input[column + 1]+3) >> V210_HORIZONTAL_SHIFT);
	sum -=  4 * ((input[column - 1]+3) >> V210_HORIZONTAL_SHIFT);
	sum -=  4 * ((input[column - 2]+3) >> V210_HORIZONTAL_SHIFT);
	sum +=  1 * ((input[column - 3]+3) >> V210_HORIZONTAL_SHIFT);
	sum +=  1 * ((input[column - 4]+3) >> V210_HORIZONTAL_SHIFT);
	sum +=  ROUNDING(sum,8);
	sum = DivideByShift(sum, 3);

	*(highptr++) = SATURATE(sum);
}



// Apply the lowpass and highpass horizontal filters to one row of packed data
void FilterHorizontalRowYUV16s(uint8_t *input, PIXEL *lowpass, PIXEL *highpass,
							   int width, int channel, PIXEL *buffer, size_t buffer_size,
							   FRAME_INFO *frame, int precision, int limit_yuv, int conv_601_709)
{
	size_t row_size = width * sizeof(PIXEL);
	PIXEL *unpacking_buffer;
	//PIXEL *prescaling_buffer;
	int shift = precision - 8;

//	assert(shift == 0 || shift == 2);

	// Round up the row size to an integral number of cache lines
	row_size = ALIGN(row_size, _CACHE_LINE_SIZE);

	// Check that the buffer is large enough to unpack and prescale the pixels
	//assert(2 * row_size <= buffer_size);
	assert(row_size <= buffer_size);

	//buffer_width = row_size/sizeof(PIXEL);

	// Allocate buffer space for unpacking and prescaling
	unpacking_buffer = buffer;
	//prescaling_buffer = &buffer[buffer_width];
	//prescaling_buffer = NULL;

	//unpacking_buffer = (PIXEL *)ALIGN16(unpacking_buffer);

	// Unpack the row of pixel values for the specified channel
	UnpackRowYUV16s(input, unpacking_buffer, width, channel, frame->format, shift, limit_yuv, conv_601_709);

	// Apply the horizontal wavelet filter to the row
	//FilterHorizontalRowPrescaled16s(unpacking_buffer, lowpass, highpass, width, prescaling_buffer);
	FilterHorizontalRow16s(unpacking_buffer, lowpass, highpass, width);
}


#if PREFETCH
volatile uint32_t dummy1 = 0;
#endif


#if _PROCESSOR_DISPATCH

__declspec(cpu_dispatch(Pentium_4,Generic))


//
//
//   WARNING-- maybe not revisible
//
//
void FilterHorizontalRowScaled16s(PIXEL *input, PIXEL *lowpass, PIXEL *highpass,
								  int width, int lowpass_scale, int highpass_scale)
{
	// Stub routine for processor specific dispatch
}
#endif


#if _PROCESSOR_GENERIC

#if _PROCESSOR_DISPATCH
__declspec(cpu_specific(Generic))
#endif

//
//
//   WARNING-- maybe not revisible
//
//
// Apply the lowpass and highpass horizontal filters to one row and scale the results
void FilterHorizontalRowScaled16s(PIXEL *input, PIXEL *lowpass, PIXEL *highpass,
								  int width, int lowpass_scale, int highpass_scale)
{
	int column_step = 8;				// Number of input pixels processed per loop iteration
	int last_column = width - 2;		// Column at which right border processing is done

	// The post column is the column at which end of column processing must begin
	int post_column = last_column - (last_column % column_step);

	int32_t sum;

	// Start at the left end of the row
	PIXEL *lowptr = lowpass;
	PIXEL *highptr = highpass;
	int column = 0;

	__m64 *input_ptr = (__m64 *)input;
	__m64 *lowpass_ptr;
	__m64 *highpass_ptr;
	__m64 input1_pi16;

	// Process the first highpass column as a special case
	sum = 0;
	sum +=  5 * input[column + 0];
	sum -= 11 * input[column + 1];
	sum +=  4 * input[column + 2];
	sum +=  4 * input[column + 3];
	sum -=  1 * input[column + 4];
	sum -=  1 * input[column + 5];
	sum += ROUNDING(sum,8);
	sum = DivideByShift(sum, 3);
	*(highptr++) = SATURATE(sum);

	// Check that the pointer to the next group of pixels is properly aligned
	//assert(ISALIGNED16(input_ptr));

	// Preload the first set of four pixels for fast processing
	input1_pi16 = *(input_ptr++);

	// Initialize the output pointers
	lowpass_ptr = (__m64 *)lowpass;
	highpass_ptr = (__m64 *)highptr;

	// Process two sets of four input pixels to get one set of four output pixels
	for (; column < post_column; column += column_step)
	{
		__m64 input2_pi16;
		__m64 shift2_pi16;
		__m64 mask_pi16;
		__m64 sign_pi16;
		__m64 half_pi16;		// Half of the divisor for rounding
		//__m64 lsb_pi16;		// Least significant bit for rounding
		__m64 sum1_pi16;
		__m64 sum2_pi16;
		__m64 sum1b_pi16;
		__m64 sum2b_pi16;
		__m64 low1_pi16;
		__m64 low2_pi16;


		// First two output points //

		// Initialize the highpass sum
		sum1_pi16 = _mm_setzero_si64();

		// Apply the first filter coefficient to each pixel and sum the result
		sum1_pi16 = _mm_subs_pi16(sum1_pi16, input1_pi16);

		// Load the next four pixels
		input2_pi16 = *(input_ptr++);

		// Initialize the lowpass sum
		low1_pi16 = input1_pi16;

		// Shift the first pixel from the second set into the working set
		shift2_pi16 = _mm_slli_si64(input2_pi16, 3*16);
		input1_pi16 = _mm_srli_si64(input1_pi16, 1*16);
		input1_pi16 = _mm_or_si64(input1_pi16, shift2_pi16);

		// Apply the second filter coefficient to each pixel and sum the result
		sum1_pi16 = _mm_subs_pi16(sum1_pi16, input1_pi16);

		// Add adjacent points to compute the lowpass sum
		low1_pi16 = _mm_adds_pi16(low1_pi16, input1_pi16);

		// Expand the lowpass output points to a full doubleword
		low1_pi16 = _mm_slli_pi32(low1_pi16, 16);
		low1_pi16 = _mm_srai_pi32(low1_pi16, 16);

		// Shift the next pixel from the second set into the working set
		shift2_pi16 = _mm_slli_si64(input2_pi16, 2*16);
		input1_pi16 = _mm_srli_si64(input1_pi16, 1*16);
		input1_pi16 = _mm_or_si64(input1_pi16, shift2_pi16);

		// Apply the third filter coefficient to each pixel and sum the result
		sum1b_pi16 = input1_pi16;

		// Shift the next pixel from the second set into the working set
		shift2_pi16 = _mm_slli_si64(input2_pi16, 1*16);
		input1_pi16 = _mm_srli_si64(input1_pi16, 1*16);
		input1_pi16 = _mm_or_si64(input1_pi16, shift2_pi16);

		// Apply the fourth filter coefficient to each pixel and sum the result
		sum1b_pi16 = _mm_subs_pi16(sum1b_pi16, input1_pi16);

		// Shift the next pixel from the second set into the working set
		input1_pi16 = input2_pi16;

		// Apply the fifth filter coefficient to each pixel and sum the result
		sum1_pi16 = _mm_adds_pi16(sum1_pi16, input1_pi16);

		// Shift the next pixel from the second set into the working set
		input1_pi16 = _mm_srli_si64(input1_pi16, 1*16);

		// Apply the sixth (last) filter coefficient to each pixel and sum the result
		sum1_pi16 = _mm_adds_pi16(sum1_pi16, input1_pi16);

		//DAN20050915 -- reversibility
		half_pi16 = _mm_set1_pi16(4);
		sum1_pi16 = _mm_adds_pi16(sum1_pi16, half_pi16);
		sum1_pi16 = _mm_srai_pi16(sum1_pi16, 3);

		sum1_pi16 = _mm_adds_pi16(sum1_pi16, sum1b_pi16);


		// Expand the even output points to a full doubleword
		sum1_pi16 = _mm_slli_pi32(sum1_pi16, 16);
		sum1_pi16 = _mm_srai_pi32(sum1_pi16, 16);

		// The second four input points become the first four input points
		input1_pi16 = input2_pi16;


		// Second two output points //

		// Initialize the highpass sum
		sum2_pi16 = _mm_setzero_si64();

		// Apply the first filter coefficient to each pixel and sum the result
		sum2_pi16 = _mm_subs_pi16(sum2_pi16, input1_pi16);

		// Load the next four pixels
		input2_pi16 = *(input_ptr++);

		// Initialize the lowpass sum
		low2_pi16 = input1_pi16;

		// Shift the first pixel from the second set into the working set
		shift2_pi16 = _mm_slli_si64(input2_pi16, 3*16);
		input1_pi16 = _mm_srli_si64(input1_pi16, 1*16);
		input1_pi16 = _mm_or_si64(input1_pi16, shift2_pi16);

		// Apply the second filter coefficient to each pixel and sum the result
		sum2_pi16 = _mm_subs_pi16(sum2_pi16, input1_pi16);

		// Add adjacent points to compute the lowpass sum
		low2_pi16 = _mm_adds_pi16(low2_pi16, input1_pi16);

		// Expand the lowpass output points to a full doubleword
		low2_pi16 = _mm_slli_pi32(low2_pi16, 16);
		low2_pi16 = _mm_srai_pi32(low2_pi16, 16);

		// Shift the next pixel from the second set into the working set
		shift2_pi16 = _mm_slli_si64(input2_pi16, 2*16);
		input1_pi16 = _mm_srli_si64(input1_pi16, 1*16);
		input1_pi16 = _mm_or_si64(input1_pi16, shift2_pi16);

		// Apply the third filter coefficient to each pixel and sum the result
		sum2b_pi16 = input1_pi16;

		// Shift the next pixel from the second set into the working set
		shift2_pi16 = _mm_slli_si64(input2_pi16, 1*16);
		input1_pi16 = _mm_srli_si64(input1_pi16, 1*16);
		input1_pi16 = _mm_or_si64(input1_pi16, shift2_pi16);

		// Apply the fourth filter coefficient to each pixel and sum the result
		sum2b_pi16 = _mm_subs_pi16(sum2b_pi16, input1_pi16);

		// Shift the next pixel from the second set into the working set
		input1_pi16 = input2_pi16;

		// Apply the fifth filter coefficient to each pixel and sum the result
		sum2_pi16 = _mm_adds_pi16(sum2_pi16, input1_pi16);

		// Shift the next pixel from the second set into the working set
		input1_pi16 = _mm_srli_si64(input1_pi16, 1*16);

		// Apply the sixth (last) filter coefficient to each pixel and sum the result
		sum2_pi16 = _mm_adds_pi16(sum2_pi16, input1_pi16);

		//DAN20050915 -- reversibility
		half_pi16 = _mm_set1_pi16(4);
		sum2_pi16 = _mm_adds_pi16(sum2_pi16, half_pi16);
		sum2_pi16 = _mm_srai_pi16(sum2_pi16, 3);

		sum2_pi16 = _mm_adds_pi16(sum2_pi16, sum2b_pi16);


		// Expand the even output points to a full doubleword
		sum2_pi16 = _mm_slli_pi32(sum2_pi16, 16);
		sum2_pi16 = _mm_srai_pi32(sum2_pi16, 16);


		// Combine the output points //

		low1_pi16 = _mm_packs_pi32(low1_pi16, low2_pi16);
		sum1_pi16 = _mm_packs_pi32(sum1_pi16, sum2_pi16);


		half_pi16 = _mm_set1_pi16(4);
		sum1_pi16 = _mm_adds_pi16(sum1_pi16, half_pi16);
		sum1_pi16 = _mm_srai_pi16(sum1_pi16, 3);

	/*	if (lowpass_scale > 0)
		{
			// Scale the lowpass results
			half_pi16 = _mm_set1_pi16(1 << (lowpass_scale - 1));
			low1_pi16 = _mm_adds_pi16(low1_pi16, half_pi16);
			low1_pi16 = _mm_sra_pi16(low1_pi16, _mm_cvtsi32_si64(lowpass_scale));
		}*/

		// Store the four lowpass output points
		*(lowpass_ptr++) = low1_pi16;

	/*	if (highpass_scale > 0)
		{
			// Scale the highpass results
			half_pi16 = _mm_set1_pi16(1 << (highpass_scale - 1));
			sum1_pi16 = _mm_adds_pi16(sum1_pi16, half_pi16);
			sum1_pi16 = _mm_sra_pi16(sum1_pi16, _mm_cvtsi32_si64(highpass_scale));
		}*/

		// Store the four highpass output points
		*(highpass_ptr++) = sum1_pi16;

		// The second set of eight input pixels becomes the working set
		input1_pi16 = input2_pi16;
	}

	// Should have exited the loop at the post processing column
	assert(column == post_column);

	lowptr = (PIXEL *)lowpass_ptr;
	highptr = (PIXEL *)highpass_ptr;

	// The lowpass results are behind by one column
	sum = input[column] + input[column + 1];

/*	if (lowpass_scale > 0)
	{
		// Scale the lowpass results
		sum += (1 << (lowpass_scale - 1));
		sum >>= lowpass_scale;
	}*/

	*(lowptr++) = SATURATE(sum);

	// The fast processing loop is out of phase by two columns
	if (column < last_column) column += 2;
	else highptr--;

	// Process the last group of columns as a special case to handle the border
	for (; column < last_column; column += 2)
	{
		// Compute the lowpass sum
		sum = input[column] + input[column + 1];

	/*	if (lowpass_scale > 0)
		{
			// Scale the lowpass results
			sum += (1 << (lowpass_scale - 1));
			sum >>= lowpass_scale;
		}*/

		// Store the lowpass sum
		*(lowptr++) = SATURATE(sum);

		// Compute the highpass sum
		sum = 0;
		sum -= input[column - 2];
		sum -= input[column - 1];
		sum += input[column + 2];
		sum += input[column + 3];
		sum += ROUNDING(sum,8);
		sum = DivideByShift(sum, 3);
		sum += input[column + 0];
		sum -= input[column + 1];

	/*	if (highpass_scale > 0)
		{
			// Scale the highpass results
			sum += (1 << (highpass_scale - 1));
			sum >>= highpass_scale;
		}*/

		// Store the highpass sum
		*(highptr++) = SATURATE(sum);
	}

	// Should be at the last column
	assert(column == last_column);

	// Compute the last lowpass value
	sum = input[column] + input[column + 1];

/*	if (lowpass_scale > 0)
	{
		// Scale the lowpass results
		sum += (1 << (lowpass_scale - 1));
		sum >>= lowpass_scale;
	}*/

	*(lowptr++) = SATURATE(sum);

	// Compute the last highpass value using the special border coefficients
	sum = 0;
	sum += 11 * input[column + 0];
	sum -=  5 * input[column + 1];
	sum -=  4 * input[column - 1];
	sum -=  4 * input[column - 2];
	sum +=  1 * input[column - 3];
	sum +=  1 * input[column - 4];
	sum +=  ROUNDING(sum,8);
	sum = DivideByShift(sum, 3);

/*	if (highpass_scale > 0)
	{
		// Scale the highpass results
		sum += (1 << (highpass_scale - 1));
		sum >>= highpass_scale;
	}*/

	*(highptr++) = SATURATE(sum);

	//_mm_empty();	// Clear the mmx register state
}

#endif


#if _PROCESSOR_PENTIUM_4

#if _PROCESSOR_DISPATCH
__declspec(cpu_specific(Pentium_4))
#endif

//
//
//   WARNING-- maybe not revisible
//
//
// Apply the lowpass and highpass horizontal filters to one row and scale the results.
// The lowpass and highpass scale factors are either zero or the frame prescale and
// are not used if the compile-time constant for the frame prescale is zero.
void FilterHorizontalRowScaled16s(PIXEL *input, PIXEL *lowpass, PIXEL *highpass,
								  int width, int lowpass_scale, int highpass_scale)
{
	int column_step = 16;				// Number of input pixels processed per loop iteration
	int last_column = width - 2;		// Column at which right border processing is done

	// The post column is the column at which end of column processing must begin
	int post_column = last_column - (last_column % column_step);

	int32_t sum;
	//int32_t lsb;

	// Start at the left end of the row
	PIXEL *lowptr = lowpass;
	PIXEL *highptr = highpass;
	int column = 0;

	__m128i *input_ptr = (__m128i *)input;
	__m128i *lowpass_ptr;
	__m128i *highpass_ptr;
	__m128i input1_epi16;

	int highpass_value;

	// Prescaling is performed by quantization
	assert(lowpass_scale == 0 && highpass_scale == 0);

#if _PREROLL

	// Preprocess the first lowpass and highpass columns for memory alignment

#if 0
	sum = input[column] + input[column + 1];
	*(lowptr++) = SATURATE(sum);
#endif

	// The first highpass column is a special case
	sum = 0;
	sum +=  5 * input[column + 0];
	sum -= 11 * input[column + 1];
	sum +=  4 * input[column + 2];
	sum +=  4 * input[column + 3];
	sum -=  1 * input[column + 4];
	sum -=  1 * input[column + 5];
	sum += ROUNDING(sum,8);
	sum = DivideByShift(sum, 3);
	//*(highptr++) = SATURATE(sum);
	highpass_value = SATURATE(sum);

#if 0
	column += 2;

	while (!ISALIGNED16(highptr))
	{
		sum = input[column] + input[column + 1];
		*(lowptr++) = SATURATE(sum);

		sum = 0;
		sum -= input[column - 2];
		sum -= input[column - 1];
		sum += input[column + 2];
		sum += input[column + 3];
		sum += ROUNDING(sum,8);
		sum = DivideByShift(sum, 3);
		sum += input[column + 0];
		sum -= input[column + 1];

		*(highptr++) = SATURATE(sum);

		column += 2;
	}
#endif

	// Set the input pointer for the fast loop
	input_ptr = (__m128i *)&input[column];

	// Check that the pointer to the next group of pixels is properly aligned
	assert(ISALIGNED16(input_ptr));

	// Preload the first set of four pixels for fast processing
	input1_epi16 = _mm_load_si128(input_ptr++);

	// Initialize the output pointers
	lowpass_ptr = (__m128i *)lowptr;
	highpass_ptr = (__m128i *)highptr;

	// Check that the output pointers are properly aligned
	assert(ISALIGNED16(lowpass_ptr));
	assert(ISALIGNED16(highpass_ptr));

#else

	// Process the first highpass column as a special case
	sum = 0;
	sum +=  5 * input[column + 0];
	sum -= 11 * input[column + 1];
	sum +=  4 * input[column + 2];
	sum +=  4 * input[column + 3];
	sum -=  1 * input[column + 4];
	sum -=  1 * input[column + 5];
	sum += ROUNDING(sum,8);
	sum = DivideByShift(sum, 3);
	*(highptr++) = SATURATE(sum);

	// Check that the pointer to the next group of pixels is properly aligned
	assert(ISALIGNED16(input_ptr));

	// Preload the first set of four pixels for fast processing
	input1_epi16 = _mm_load_si128(input_ptr++);

	// Initialize the output pointers
	lowpass_ptr = (__m128i *)lowpass;
	highpass_ptr = (__m128i *)highptr;

#endif


	// Process two sets of four input pixels to get one set of four output pixels
	for (; column < post_column; column += column_step)
	{
		__m128i input2_epi16;
		__m128i shift2_epi16;
		//__m128i mask_epi16;
		//__m128i sign_epi16;
		__m128i half_epi16;		// Half of the divisor for rounding
		//__m128i lsb_epi16;		// Least significant bit for rounding
		__m128i sum1_epi16;
		__m128i sum2_epi16;
		__m128i sum1b_epi16;
		__m128i sum2b_epi16;
		__m128i low1_epi16;
		__m128i low2_epi16;

		/***** Process the first four output points *****/

		// Initialize the highpass sum
		sum1_epi16 = _mm_setzero_si128();

		// Apply the first filter coefficient to each pixel and sum the result
		sum1_epi16 = _mm_subs_epi16(sum1_epi16, input1_epi16);

		// Check that the pointer to the next group of pixels is properly aligned
		assert(ISALIGNED16(input_ptr));

		// Load the next eight pixels
		input2_epi16 = _mm_load_si128(input_ptr++);

		// Initialize the lowpass sum
		low1_epi16 = input1_epi16;

		// Shift the first pixel from the second set into the working set
		shift2_epi16 = _mm_slli_si128(input2_epi16, 7*2);
		input1_epi16 = _mm_srli_si128(input1_epi16, 1*2);
		input1_epi16 = _mm_or_si128(input1_epi16, shift2_epi16);

		// Apply the second filter coefficient to each pixel and sum the result
		sum1_epi16 = _mm_subs_epi16(sum1_epi16, input1_epi16);

		// Add adjacent points to compute the lowpass sum
		low1_epi16 = _mm_adds_epi16(low1_epi16, input1_epi16);

		// Expand the lowpass output points to a full doubleword
		low1_epi16 = _mm_slli_epi32(low1_epi16, 16);
		low1_epi16 = _mm_srai_epi32(low1_epi16, 16);

		// Shift the second pixel from the second set into the working set
		shift2_epi16 = _mm_slli_si128(input2_epi16, 6*2);
		input1_epi16 = _mm_srli_si128(input1_epi16, 1*2);
		input1_epi16 = _mm_or_si128(input1_epi16, shift2_epi16);

		// Apply the third filter coefficient to each pixel and sum the result
		sum1b_epi16 = input1_epi16;

		// Shift the third pixel from the second set into the working set
		shift2_epi16 = _mm_slli_si128(input2_epi16, 5*2);
		input1_epi16 = _mm_srli_si128(input1_epi16, 1*2);
		input1_epi16 = _mm_or_si128(input1_epi16, shift2_epi16);

		// Apply the fourth filter coefficient to each pixel and sum the result
		sum1b_epi16 = _mm_subs_epi16(sum1b_epi16, input1_epi16);

		// Shift the fourth pixel from the second set into the working set
		shift2_epi16 = _mm_slli_si128(input2_epi16, 4*2);
		input1_epi16 = _mm_srli_si128(input1_epi16, 1*2);
		input1_epi16 = _mm_or_si128(input1_epi16, shift2_epi16);

		// Apply the fifth filter coefficient to each pixel and sum the result
		sum1_epi16 = _mm_adds_epi16(sum1_epi16, input1_epi16);

		// Shift the fifth pixel from the second set into the working set
		shift2_epi16 = _mm_slli_si128(input2_epi16, 3*2);
		input1_epi16 = _mm_srli_si128(input1_epi16, 1*2);
		input1_epi16 = _mm_or_si128(input1_epi16, shift2_epi16);

		// Apply the sixth (last) filter coefficient to each pixel and sum the result
		sum1_epi16 = _mm_adds_epi16(sum1_epi16, input1_epi16);


		//DAN20050915 -- reversibility
		half_epi16 = _mm_set1_epi16(4);
		sum1_epi16 = _mm_adds_epi16(sum1_epi16, half_epi16);
		sum1_epi16 = _mm_srai_epi16(sum1_epi16, 3);

		sum1_epi16 = _mm_adds_epi16(sum1_epi16, sum1b_epi16);


		// Expand the even output points to a full doubleword
		sum1_epi16 = _mm_slli_epi32(sum1_epi16, 16);
		sum1_epi16 = _mm_srai_epi32(sum1_epi16, 16);

		// The second eight input points become the current input points
		input1_epi16 = input2_epi16;


		/***** Process the second four output points *****/

		// Initialize the highpass sum
		sum2_epi16 = _mm_setzero_si128();

		// Apply the first filter coefficient to each pixel and sum the result
		sum2_epi16 = _mm_subs_epi16(sum2_epi16, input1_epi16);

		// Check that the pointer to the next group of pixels is properly aligned
		assert(ISALIGNED16(input_ptr));

		// Load the next eight pixels
		input2_epi16 = _mm_load_si128(input_ptr++);

		// Initialize the lowpass sum
		low2_epi16 = input1_epi16;

		// Shift the first pixel from the second set into the working set
		shift2_epi16 = _mm_slli_si128(input2_epi16, 7*2);
		input1_epi16 = _mm_srli_si128(input1_epi16, 1*2);
		input1_epi16 = _mm_or_si128(input1_epi16, shift2_epi16);

		// Apply the second filter coefficient to each pixel and sum the result
		sum2_epi16 = _mm_subs_epi16(sum2_epi16, input1_epi16);

		// Add adjacent points to compute the lowpass sum
		low2_epi16 = _mm_adds_epi16(low2_epi16, input1_epi16);

		// Expand the lowpass output points to a full doubleword
		low2_epi16 = _mm_slli_epi32(low2_epi16, 16);
		low2_epi16 = _mm_srai_epi32(low2_epi16, 16);

		// Shift the second pixel from the second set into the working set
		shift2_epi16 = _mm_slli_si128(input2_epi16, 6*2);
		input1_epi16 = _mm_srli_si128(input1_epi16, 1*2);
		input1_epi16 = _mm_or_si128(input1_epi16, shift2_epi16);

		// Apply the third filter coefficient to each pixel and sum the result
		sum2b_epi16 = input1_epi16;

		// Shift the third pixel from the second set into the working set
		shift2_epi16 = _mm_slli_si128(input2_epi16, 5*2);
		input1_epi16 = _mm_srli_si128(input1_epi16, 1*2);
		input1_epi16 = _mm_or_si128(input1_epi16, shift2_epi16);

		// Apply the fourth filter coefficient to each pixel and sum the result
		sum2b_epi16 = _mm_subs_epi16(sum2b_epi16, input1_epi16);

		// Shift the fourth pixel from the second set into the working set
		shift2_epi16 = _mm_slli_si128(input2_epi16, 4*2);
		input1_epi16 = _mm_srli_si128(input1_epi16, 1*2);
		input1_epi16 = _mm_or_si128(input1_epi16, shift2_epi16);

		// Apply the fifth filter coefficient to each pixel and sum the result
		sum2_epi16 = _mm_adds_epi16(sum2_epi16, input1_epi16);

		// Shift the fifth pixel from the second set into the working set
		shift2_epi16 = _mm_slli_si128(input2_epi16, 3*2);
		input1_epi16 = _mm_srli_si128(input1_epi16, 1*2);
		input1_epi16 = _mm_or_si128(input1_epi16, shift2_epi16);

		// Apply the sixth (last) filter coefficient to each pixel and sum the result
		sum2_epi16 = _mm_adds_epi16(sum2_epi16, input1_epi16);

		//DAN20050915 -- reversibility
		half_epi16 = _mm_set1_epi16(4);
		sum2_epi16 = _mm_adds_epi16(sum2_epi16, half_epi16);
		sum2_epi16 = _mm_srai_epi16(sum2_epi16, 3);

		sum2_epi16 = _mm_adds_epi16(sum2_epi16, sum2b_epi16);

		// Expand the even output points to a full doubleword
		sum2_epi16 = _mm_slli_epi32(sum2_epi16, 16);
		sum2_epi16 = _mm_srai_epi32(sum2_epi16, 16);


		/***** Combine the output points *****/

		low1_epi16 = _mm_packs_epi32(low1_epi16, low2_epi16);
		sum1_epi16 = _mm_packs_epi32(sum1_epi16, sum2_epi16);


		// Store the four lowpass output points
		_mm_store_si128(lowpass_ptr++, low1_epi16);

#if _PREROLL
		// Get the last highpass coefficient in the group
		sum2_epi16 = _mm_srli_si128(sum1_epi16, 7*2);

		// Shift the extra highpass coefficient into the output
		sum1_epi16 = _mm_slli_si128(sum1_epi16, 1*2);
		sum1_epi16 = _mm_insert_epi16(sum1_epi16, highpass_value, 0);

		// Save the last highpass coefficient for the next loop iteration
		highpass_value = _mm_cvtsi128_si32(sum2_epi16);

		// Store the four highpass output points
		_mm_store_si128(highpass_ptr++, sum1_epi16);
#else
		// Store the four highpass output points (may be unaligned without preroll)
		_mm_storeu_si128(highpass_ptr++, sum1_epi16);
#endif

		// The second set of eight input pixels becomes the working set
		input1_epi16 = input2_epi16;
	}

	// Should have exited the loop at the post processing column
	assert(column == post_column);

	lowptr = (PIXEL *)lowpass_ptr;
	highptr = (PIXEL *)highpass_ptr;

#if !_PREROLL
	// The lowpass results are behind by one column
	sum = input[column] + input[column + 1];

#if 0
	if (lowpass_scale > 0)
	{
		// Scale the lowpass results
		sum += (1 << (lowpass_scale - 1));
		sum >>= lowpass_scale;
	}
#endif

	*(lowptr++) = SATURATE(sum);

	// The fast processing loop is out of phase by two columns
	if (column < last_column) column += 2;
	else highptr--;

#endif

	// Process the last group of columns as a special case to handle the border
	for (; column < last_column; column += 2)
	{
		// Compute the lowpass sum
		sum = input[column] + input[column + 1];

#if 0
		if (lowpass_scale > 0)
		{
			// Scale the lowpass results
			sum += (1 << (lowpass_scale - 1));
			sum >>= lowpass_scale;
		}
#endif
		// Store the lowpass sum
		*(lowptr++) = SATURATE(sum);

		// Compute the highpass sum
		sum = 0;
		sum -= input[column - 2];
		sum -= input[column - 1];
		sum += input[column + 2];
		sum += input[column + 3];
		sum += ROUNDING(sum,8);
		sum = DivideByShift(sum, 3);
		sum += input[column + 0];
		sum -= input[column + 1];
#if 0
		if (highpass_scale > 0)
		{
			// Scale the highpass results
			sum += (1 << (highpass_scale - 1));
			sum >>= highpass_scale;
		}
#endif
		// Store the highpass sum
		*(highptr++) = SATURATE(sum);
	}

	// Should be at the last column
	assert(column == last_column);

	// Compute the last lowpass value
	sum = input[column] + input[column + 1];

#if 0
	if (lowpass_scale > 0)
	{
		// Scale the lowpass results
		sum += (1 << (lowpass_scale - 1));
		sum >>= lowpass_scale;
	}
#endif

	*(lowptr++) = SATURATE(sum);

	// Compute the last highpass value using the special border coefficients
	sum = 0;
	sum += 11 * input[column + 0];
	sum -=  5 * input[column + 1];
	sum -=  4 * input[column - 1];
	sum -=  4 * input[column - 2];
	sum +=  1 * input[column - 3];
	sum +=  1 * input[column - 4];
	sum +=  ROUNDING(sum,8);
	sum = DivideByShift(sum, 3);

#if 0
	if (highpass_scale > 0)
	{
		// Scale the highpass results
		sum += (1 << (highpass_scale - 1));
		sum >>= highpass_scale;
	}
#endif

	*(highptr++) = SATURATE(sum);
}

#endif  //P4





//TODO:  get rid of the global.
extern int g_midpoint_prequant; //HACK


#if _PROCESSOR_DISPATCH

__declspec(cpu_dispatch(Pentium_4,Generic))
//
//
//   WARNING-- maybe not revisible
//
//
void FilterHorizontalRowScaled16sDifferenceFiltered(PIXEL *input, PIXEL *lowpass, PIXEL *highpass,
								  int width, int lowpass_scale, int highpass_scale, int lp_divisor)
{
	// Stub routine for processor specific dispatch
}
#endif


#if _PROCESSOR_GENERIC

#if _PROCESSOR_DISPATCH
__declspec(cpu_specific(Generic))
#endif
//
//
//   WARNING-- maybe not revisible
//
//
// Apply the lowpass and highpass horizontal filters to one row and scale the results
void FilterHorizontalRowScaled16sDifferenceFiltered(PIXEL *input, PIXEL *lowpass, PIXEL *highpass,
													int width, int lowpass_scale, int highpass_scale,
													int lowpass_divisor)
{
	int column_step = 8;				// Number of input pixels processed per loop iteration
	int last_column = width - 2;		// Column at which right border processing is done

	// The post column is the column at which end of column processing must begin
	int post_column = last_column - (last_column % column_step);

	int32_t sum,lastsum;

	// Start at the left end of the row
	PIXEL *lowptr = lowpass;
	PIXEL *highptr = highpass;
	int column = 0;

	__m64 *input_ptr = (__m64 *)input;
	__m64 *lowpass_ptr;
	__m64 *highpass_ptr;
	__m64 input1_pi16;

	int lastsumvalue = 0;
	int delta;
	int highpass_value;

	// Change division to multiplication by a fraction
	int multiplier = (uint32_t)(1 << 16) / lowpass_divisor;
	__m64 quant_pi16 = _mm_set1_pi16(multiplier);
	__m64 sign_pi16;
	__m64 offset_pi16 = _mm_set1_pi16(0);

#if MIDPOINT_PREQUANT
	int prequant_midpoint = 0;// divisor/2;
	if(g_midpoint_prequant >= 2 && g_midpoint_prequant < 9)
		prequant_midpoint = lowpass_divisor / g_midpoint_prequant;

	offset_pi16 = _mm_set1_pi16(prequant_midpoint);
#endif

	// Process the first highpass column as a special case
	sum = 0;
	sum +=  5 * input[column + 0];
	sum -= 11 * input[column + 1];
	sum +=  4 * input[column + 2];
	sum +=  4 * input[column + 3];
	sum -=  1 * input[column + 4];
	sum -=  1 * input[column + 5];
	sum += ROUNDING(sum,8);
	sum = DivideByShift(sum, 3);
	*(highptr++) = SATURATE(sum);

	// Check that the pointer to the next group of pixels is properly aligned
	//assert(ISALIGNED16(input_ptr));

	// Preload the first set of four pixels for fast processing
	input1_pi16 = *(input_ptr++);

	// Initialize the output pointers
	lowpass_ptr = (__m64 *)lowpass;
	highpass_ptr = (__m64 *)highptr;

	// Process two sets of four input pixels to get one set of four output pixels
	for (; column < post_column; column += column_step)
	{
		__m64 input2_pi16;
		__m64 shift2_pi16;
		__m64 mask_pi16;
		__m64 sign_pi16;
		__m64 half_pi16;		// Half of the divisor for rounding
		__m64 sum1_pi16;
		__m64 sum2_pi16;
		__m64 low1_pi16;
		__m64 low2_pi16;
		__m64 temp_pi16;
		__m64 sum1b_pi16;
		__m64 sum2b_pi16;


		/***** First two output points *****/

		// Initialize the highpass sum
		sum1_pi16 = _mm_setzero_si64();

		// Apply the first filter coefficient to each pixel and sum the result
		sum1_pi16 = _mm_subs_pi16(sum1_pi16, input1_pi16);

		// Load the next four pixels
		input2_pi16 = *(input_ptr++);

		// Initialize the lowpass sum
		low1_pi16 = input1_pi16;

		// Shift the first pixel from the second set into the working set
		shift2_pi16 = _mm_slli_si64(input2_pi16, 3*16);
		input1_pi16 = _mm_srli_si64(input1_pi16, 1*16);
		input1_pi16 = _mm_or_si64(input1_pi16, shift2_pi16);

		// Apply the second filter coefficient to each pixel and sum the result
		//sum -= input[column - 1];
		sum1_pi16 = _mm_subs_pi16(sum1_pi16, input1_pi16);

		// Add adjacent points to compute the lowpass sum
		low1_pi16 = _mm_adds_pi16(low1_pi16, input1_pi16);

		// Expand the lowpass output points to a full doubleword
		low1_pi16 = _mm_slli_pi32(low1_pi16, 16);
		low1_pi16 = _mm_srai_pi32(low1_pi16, 16);

		// Shift the next pixel from the second set into the working set
		shift2_pi16 = _mm_slli_si64(input2_pi16, 2*16);
		input1_pi16 = _mm_srli_si64(input1_pi16, 1*16);
		input1_pi16 = _mm_or_si64(input1_pi16, shift2_pi16);

		// Apply the third filter coefficient to each pixel and sum the result
		sum1b_pi16 = input1_pi16;

		// Shift the next pixel from the second set into the working set
		shift2_pi16 = _mm_slli_si64(input2_pi16, 1*16);
		input1_pi16 = _mm_srli_si64(input1_pi16, 1*16);
		input1_pi16 = _mm_or_si64(input1_pi16, shift2_pi16);

		// Apply the fourth filter coefficient to each pixel and sum the result
		sum1b_pi16 = _mm_subs_pi16(sum1b_pi16, input1_pi16);

		// Shift the next pixel from the second set into the working set
		input1_pi16 = input2_pi16;

		// Apply the fifth filter coefficient to each pixel and sum the result
		sum1_pi16 = _mm_adds_pi16(sum1_pi16, input1_pi16);

		// Shift the next pixel from the second set into the working set
		input1_pi16 = _mm_srli_si64(input1_pi16, 1*16);

		// Apply the sixth (last) filter coefficient to each pixel and sum the result
		sum1_pi16 = _mm_adds_pi16(sum1_pi16, input1_pi16);

		//DAN20050915 -- reversibility
		half_pi16 = _mm_set1_pi16(4);
		sum1_pi16 = _mm_adds_pi16(sum1_pi16, half_pi16);
		sum1_pi16 = _mm_srai_pi16(sum1_pi16, 3);

		sum1_pi16 = _mm_adds_pi16(sum1_pi16, sum1b_pi16);

		// Expand the even output points to a full doubleword
		sum1_pi16 = _mm_slli_pi32(sum1_pi16, 16);
		sum1_pi16 = _mm_srai_pi32(sum1_pi16, 16);

		// The second four input points become the first four input points
		input1_pi16 = input2_pi16;


		/***** Second two output points *****/

		// Initialize the highpass sum
		sum2_pi16 = _mm_setzero_si64();

		// Apply the first filter coefficient to each pixel and sum the result
		sum2_pi16 = _mm_subs_pi16(sum2_pi16, input1_pi16);

		// Load the next four pixels
		input2_pi16 = *(input_ptr++);

		// Initialize the lowpass sum
		low2_pi16 = input1_pi16;

		// Shift the first pixel from the second set into the working set
		shift2_pi16 = _mm_slli_si64(input2_pi16, 3*16);
		input1_pi16 = _mm_srli_si64(input1_pi16, 1*16);
		input1_pi16 = _mm_or_si64(input1_pi16, shift2_pi16);

		// Apply the second filter coefficient to each pixel and sum the result
		sum2_pi16 = _mm_subs_pi16(sum2_pi16, input1_pi16);

		// Add adjacent points to compute the lowpass sum
		low2_pi16 = _mm_adds_pi16(low2_pi16, input1_pi16);

		// Expand the lowpass output points to a full doubleword
		low2_pi16 = _mm_slli_pi32(low2_pi16, 16);
		low2_pi16 = _mm_srai_pi32(low2_pi16, 16);

		// Shift the next pixel from the second set into the working set
		shift2_pi16 = _mm_slli_si64(input2_pi16, 2*16);
		input1_pi16 = _mm_srli_si64(input1_pi16, 1*16);
		input1_pi16 = _mm_or_si64(input1_pi16, shift2_pi16);

		// Apply the third filter coefficient to each pixel and sum the result
		sum2b_pi16 = input1_pi16;

		// Shift the next pixel from the second set into the working set
		shift2_pi16 = _mm_slli_si64(input2_pi16, 1*16);
		input1_pi16 = _mm_srli_si64(input1_pi16, 1*16);
		input1_pi16 = _mm_or_si64(input1_pi16, shift2_pi16);

		// Apply the fourth filter coefficient to each pixel and sum the result
		sum2b_pi16 = _mm_subs_pi16(sum2b_pi16, input1_pi16);

		// Shift the next pixel from the second set into the working set
		input1_pi16 = input2_pi16;

		// Apply the fifth filter coefficient to each pixel and sum the result
		sum2_pi16 = _mm_adds_pi16(sum2_pi16, input1_pi16);

		// Shift the next pixel from the second set into the working set
		input1_pi16 = _mm_srli_si64(input1_pi16, 1*16);

		// Apply the sixth (last) filter coefficient to each pixel and sum the result
		sum2_pi16 = _mm_adds_pi16(sum2_pi16, input1_pi16);

		//DAN20050915 -- reversibility
		sum2_pi16 = _mm_adds_pi16(sum2_pi16, half_pi16);
		sum2_pi16 = _mm_srai_pi16(sum2_pi16, 3);

		sum2_pi16 = _mm_adds_pi16(sum2_pi16, sum2b_pi16);

		// Expand the even output points to a full doubleword
		sum2_pi16 = _mm_slli_pi32(sum2_pi16, 16);
		sum2_pi16 = _mm_srai_pi32(sum2_pi16, 16);


		/***** Combine the output points *****/

		low1_pi16 = _mm_packs_pi32(low1_pi16, low2_pi16);
		sum1_pi16 = _mm_packs_pi32(sum1_pi16, sum2_pi16);

		if(lowpass_divisor > 1)
		{
			///////////////////////////////////////////////////
			// Quantize the passlow BEFORE it is differenced.//
			///////////////////////////////////////////////////

			// Compute the absolute value
			sign_pi16 = _mm_cmpgt_pi16(_mm_setzero_si64(), low1_pi16);
			low1_pi16 = _mm_xor_si64(low1_pi16, sign_pi16);
			low1_pi16 = _mm_sub_pi16(low1_pi16, sign_pi16);

	#if MIDPOINT_PREQUANT
			// Add the prequant_midpoint for quantization rounding
			low1_pi16 = _mm_add_pi16(low1_pi16, offset_pi16);
	#endif
			// Multiply by the quantization factor
			low1_pi16 = _mm_mulhi_pu16(low1_pi16, quant_pi16);

			// Restore the sign
			low1_pi16 = _mm_xor_si64(low1_pi16, sign_pi16);
			low1_pi16 = _mm_sub_pi16(low1_pi16, sign_pi16);
		}

		///////////////////////////////////////////////////
		// New differencing engine                       //
		// this code makes the low-pass difference data. //
		///////////////////////////////////////////////////
		temp_pi16 = _mm_slli_si64(low1_pi16, 16);
		temp_pi16 = _mm_insert_pi16(temp_pi16, lastsumvalue, 0);
		lastsumvalue = _mm_extract_pi16(low1_pi16, 3);
		low1_pi16 = _mm_sub_pi16(low1_pi16, temp_pi16);

		// Store the four lowpass output points
		*(lowpass_ptr++) = low1_pi16;

#if 0
		if (highpass_scale > 0)
		{
			// Scale the highpass results
			half_pi16 = _mm_set1_pi16(1 << (highpass_scale - 1));
			sum1_pi16 = _mm_adds_pi16(sum1_pi16, half_pi16);
			sum1_pi16 = _mm_sra_pi16(sum1_pi16, _mm_cvtsi32_si64(highpass_scale));
		}
#endif

		// Store the four highpass output points
		*(highpass_ptr++) = sum1_pi16;

		// The second set of eight input pixels becomes the working set
		input1_pi16 = input2_pi16;
	}

	// Should have exited the loop at the post processing column
	assert(column == post_column);

	lowptr = (PIXEL *)lowpass_ptr;
	highptr = (PIXEL *)highpass_ptr;


	if (column < last_column)
	{
		int sign,tmp,lastsum = 0;

		if(column > 0)
		{
			lastsum = input[column-2] + input[column-1];// previous sum
			if(lastsum < 0)
			{
				lastsum = -lastsum;
				#if MIDPOINT_PREQUANT
				lastsum += prequant_midpoint;
				#endif
				lastsum *= multiplier; // quantize
				lastsum >>= 16;
				lastsum = -lastsum;
			}
			else
			{
				#if MIDPOINT_PREQUANT
				lastsum += prequant_midpoint;
				#endif
				lastsum *= multiplier; // quantize
				lastsum >>= 16;
			}
		}

		// Process the last group of columns as a special case to handle the border
		for (; column < last_column; column += 2)
		{
			// Compute the lowpass sum
			sum = input[column] + input[column + 1];

			if(sum < 0)
			{
				sum = -sum;
				#if MIDPOINT_PREQUANT
				sum += prequant_midpoint;
				#endif
				sum *= multiplier; // quantize
				sum >>= 16;
				sum = -sum;
			}
			else
			{
				#if MIDPOINT_PREQUANT
				sum += prequant_midpoint;
				#endif
				sum *= multiplier; // quantize
				sum >>= 16;
			}

			tmp = sum;
			sum -= lastsum;
			lastsum = tmp;

			// Store the lowpass sum
			*(lowptr++) = SATURATE(sum);

			// Compute the highpass sum
			sum = 0;
			sum -= input[column - 2];
			sum -= input[column - 1];
			sum += input[column + 2];
			sum += input[column + 3];
			sum += 4;
			sum >>= 3;
			sum += input[column + 0];
			sum -= input[column + 1];

			// Store the highpass sum
			*(highptr++) = SATURATE(sum);
		}
	}

	// Should be at the last column
	assert(column == last_column);

	// Compute the last lowpass value
	lastsum = (input[column-2] + input[column + 1-2]);
	if(lastsum < 0)
	{
		lastsum = -lastsum;
		#if MIDPOINT_PREQUANT
		lastsum += prequant_midpoint;
		#endif
		lastsum *= multiplier; // quantize
		lastsum >>= 16;
		lastsum = -lastsum;
	}
	else
	{
		#if MIDPOINT_PREQUANT
		lastsum += prequant_midpoint;
		#endif
		lastsum *= multiplier; // quantize
		lastsum >>= 16;
	}


	sum = (input[column] + input[column + 1]);
	if(sum < 0)
	{
		sum = -sum;
		#if MIDPOINT_PREQUANT
		sum += prequant_midpoint;
		#endif
		sum *= multiplier; // quantize
		sum >>= 16;
		sum = -sum;
	}
	else
	{
		#if MIDPOINT_PREQUANT
		sum += prequant_midpoint;
		#endif
		sum *= multiplier; // quantize
		sum >>= 16;
	}

	sum -= lastsum;

	*(lowptr++) = SATURATE(sum);

	// Compute the last highpass value using the special border coefficients
	sum = 0;
	sum += 11 * input[column + 0];
	sum -=  5 * input[column + 1];
	sum -=  4 * input[column - 1];
	sum -=  4 * input[column - 2];
	sum +=  1 * input[column - 3];
	sum +=  1 * input[column - 4];
	sum +=  ROUNDING(sum,8);
	sum = DivideByShift(sum, 3);

	*(highptr++) = SATURATE(sum);

	//_mm_empty();	// Clear the mmx register state
}

#endif


#if _PROCESSOR_PENTIUM_4

#if _PROCESSOR_DISPATCH
__declspec(cpu_specific(Pentium_4))
#endif

void FilterHorizontalRowScaled16sDifferenceFiltered(PIXEL *input, PIXEL *lowpass, PIXEL *highpass,
								  int width, int lowpass_scale, int highpass_scale, int lp_divisor)
{
	int column_step = 16;				// Number of input pixels processed per loop iteration
	int last_column = width;			// Column at which right border processing is done

	// The post column is the column at which end of column processing must begin
	int post_column = last_column - (last_column % column_step);

	int32_t sum,lastsum;
	//int32_t lsb;

	// Start at the left end of the row
	PIXEL *lowptr = lowpass;
	PIXEL *highptr = highpass;
	int column = 0;

	__m128i *input_ptr = (__m128i *)input;
	__m128i *lowpass_ptr;
	__m128i *highpass_ptr;
	__m128i input1_epi16;
	int lastsumvalue = 0;

	int highpass_value;

	__m128i quant_epi16;
	__m128i offset_epi16;
	__m128i zero_epi16;
	//__m128i sign_epi16;

	int multiplier;

#if MIDPOINT_PREQUANT
	int prequant_midpoint = 0;// divisor/2;
	if(g_midpoint_prequant >= 2 && g_midpoint_prequant < 9)
		prequant_midpoint = lp_divisor / g_midpoint_prequant;
#endif

	// Change division to multiplication by a fraction
	multiplier = (uint32_t)(1 << 16) / lp_divisor;
	quant_epi16 = _mm_set1_epi16(multiplier);
	zero_epi16 = _mm_set1_epi16(0);

#if MIDPOINT_PREQUANT
	offset_epi16 = _mm_set1_epi16(prequant_midpoint);
#endif


	// Prescaling is performed by quantization
	assert(lowpass_scale == 0 && highpass_scale == 0);

	// Preprocess the first lowpass and highpass columns for memory alignment

	// The first highpass column is a special case
	sum = 0;
	sum +=  5 * input[column + 0];
	sum -= 11 * input[column + 1];
	sum +=  4 * input[column + 2];
	sum +=  4 * input[column + 3];
	sum -=  1 * input[column + 4];
	sum -=  1 * input[column + 5];
	sum += ROUNDING(sum,8);
	sum = DivideByShift(sum, 3);
	//*(highptr++) = SATURATE(sum);
	highpass_value = SATURATE(sum);


	// Set the input pointer for the fast loop
	input_ptr = (__m128i *)&input[column];

	// Check that the pointer to the next group of pixels is properly aligned
	assert(ISALIGNED16(input_ptr));

	// Preload the first set of four pixels for fast processing
	input1_epi16 = _mm_load_si128(input_ptr++);

	// Initialize the output pointers
	lowpass_ptr = (__m128i *)lowptr;
	highpass_ptr = (__m128i *)highptr;

	// Check that the output pointers are properly aligned
	assert(ISALIGNED16(lowpass_ptr));
	assert(ISALIGNED16(highpass_ptr));


#if (1 && XMMOPT) // SSE2
	// Process two sets of four input pixels to get one set of four output pixels
	for (; column < post_column; column += column_step)
	{
		__m128i input2_epi16;
		__m128i shift2_epi16;
		__m128i sign_epi16;
		__m128i half_epi16;		// Half of the divisor for rounding
		__m128i sum1_epi16;
		__m128i sum2_epi16;
		__m128i sum1b_epi16;
		__m128i sum2b_epi16;
		__m128i low1_epi16;
		__m128i low2_epi16;
		__m128i tmp_epi16;


		/***** Process the first four output points *****/

		// Initialize the highpass sum
		sum1_epi16 = _mm_setzero_si128();

		// Apply the first filter coefficient to each pixel and sum the result
		sum1_epi16 = _mm_subs_epi16(sum1_epi16, input1_epi16);

		// Check that the pointer to the next group of pixels is properly aligned
		assert(ISALIGNED16(input_ptr));

		// Load the next eight pixels
		input2_epi16 = _mm_load_si128(input_ptr++);

		// Initialize the lowpass sum
		low1_epi16 = input1_epi16;

		// Shift the first pixel from the second set into the working set
		shift2_epi16 = _mm_slli_si128(input2_epi16, 7*2);
		input1_epi16 = _mm_srli_si128(input1_epi16, 1*2);
		input1_epi16 = _mm_or_si128(input1_epi16, shift2_epi16);

		// Apply the second filter coefficient to each pixel and sum the result
		sum1_epi16 = _mm_subs_epi16(sum1_epi16, input1_epi16);

		// Add adjacent points to compute the lowpass sum
		low1_epi16 = _mm_adds_epi16(low1_epi16, input1_epi16);

		// Expand the lowpass output points to a full doubleword
		low1_epi16 = _mm_slli_epi32(low1_epi16, 16);
		low1_epi16 = _mm_srai_epi32(low1_epi16, 16);

		// Shift the second pixel from the second set into the working set
		shift2_epi16 = _mm_slli_si128(input2_epi16, 6*2);
		input1_epi16 = _mm_srli_si128(input1_epi16, 1*2);
		input1_epi16 = _mm_or_si128(input1_epi16, shift2_epi16);

		// Apply the third filter coefficient to each pixel and sum the result
		//sum1_epi16 = _mm_adds_epi16(sum1_epi16, _mm_slli_epi16(input1_epi16, 3));
		sum1b_epi16 = input1_epi16;

		// Shift the third pixel from the second set into the working set
		shift2_epi16 = _mm_slli_si128(input2_epi16, 5*2);
		input1_epi16 = _mm_srli_si128(input1_epi16, 1*2);
		input1_epi16 = _mm_or_si128(input1_epi16, shift2_epi16);

		// Apply the fourth filter coefficient to each pixel and sum the result
		//sum1_epi16 = _mm_subs_epi16(sum1_epi16, _mm_slli_epi16(input1_epi16, 3));
		sum1b_epi16 = _mm_subs_epi16(sum1b_epi16, input1_epi16);

		// Shift the fourth pixel from the second set into the working set
		shift2_epi16 = _mm_slli_si128(input2_epi16, 4*2);
		input1_epi16 = _mm_srli_si128(input1_epi16, 1*2);
		input1_epi16 = _mm_or_si128(input1_epi16, shift2_epi16);

		// Apply the fifth filter coefficient to each pixel and sum the result
		sum1_epi16 = _mm_adds_epi16(sum1_epi16, input1_epi16);

		// Shift the fifth pixel from the second set into the working set
		shift2_epi16 = _mm_slli_si128(input2_epi16, 3*2);
		input1_epi16 = _mm_srli_si128(input1_epi16, 1*2);
		input1_epi16 = _mm_or_si128(input1_epi16, shift2_epi16);

		// Apply the sixth (last) filter coefficient to each pixel and sum the result
		sum1_epi16 = _mm_adds_epi16(sum1_epi16, input1_epi16);

		//DAN20050915 -- reversibility
		half_epi16 = _mm_set1_epi16(4);
		sum1_epi16 = _mm_adds_epi16(sum1_epi16, half_epi16);
		sum1_epi16 = _mm_srai_epi16(sum1_epi16, 3);

		sum1_epi16 = _mm_adds_epi16(sum1_epi16, sum1b_epi16);

		// Expand the even output points to a full doubleword
		sum1_epi16 = _mm_slli_epi32(sum1_epi16, 16);
		sum1_epi16 = _mm_srai_epi32(sum1_epi16, 16);

		// The second eight input points become the current input points
		input1_epi16 = input2_epi16;


		/***** Process the second four output points *****/

		// Initialize the highpass sum
		sum2_epi16 = _mm_setzero_si128();

		// Apply the first filter coefficient to each pixel and sum the result
		sum2_epi16 = _mm_subs_epi16(sum2_epi16, input1_epi16);

		// Check that the pointer to the next group of pixels is properly aligned
		assert(ISALIGNED16(input_ptr));

		// Load the next eight pixels
		input2_epi16 = _mm_load_si128(input_ptr++);

		// Initialize the lowpass sum
		low2_epi16 = input1_epi16;

		// Shift the first pixel from the second set into the working set
		shift2_epi16 = _mm_slli_si128(input2_epi16, 7*2);
		input1_epi16 = _mm_srli_si128(input1_epi16, 1*2);
		input1_epi16 = _mm_or_si128(input1_epi16, shift2_epi16);

		// Apply the second filter coefficient to each pixel and sum the result
		sum2_epi16 = _mm_subs_epi16(sum2_epi16, input1_epi16);

		// Add adjacent points to compute the lowpass sum
		low2_epi16 = _mm_adds_epi16(low2_epi16, input1_epi16);

		// Expand the lowpass output points to a full doubleword
		low2_epi16 = _mm_slli_epi32(low2_epi16, 16);
		low2_epi16 = _mm_srai_epi32(low2_epi16, 16);

		// Shift the second pixel from the second set into the working set
		shift2_epi16 = _mm_slli_si128(input2_epi16, 6*2);
		input1_epi16 = _mm_srli_si128(input1_epi16, 1*2);
		input1_epi16 = _mm_or_si128(input1_epi16, shift2_epi16);

		// Apply the third filter coefficient to each pixel and sum the result
		//sum2_epi16 = _mm_adds_epi16(sum2_epi16, _mm_slli_epi16(input1_epi16, 3));
		sum2b_epi16 = input1_epi16;

		// Shift the third pixel from the second set into the working set
		shift2_epi16 = _mm_slli_si128(input2_epi16, 5*2);
		input1_epi16 = _mm_srli_si128(input1_epi16, 1*2);
		input1_epi16 = _mm_or_si128(input1_epi16, shift2_epi16);

		// Apply the fourth filter coefficient to each pixel and sum the result
		//sum2_epi16 = _mm_subs_epi16(sum2_epi16, _mm_slli_epi16(input1_epi16, 3));
		sum2b_epi16 = _mm_subs_epi16(sum2b_epi16, input1_epi16);

		// Shift the fourth pixel from the second set into the working set
		shift2_epi16 = _mm_slli_si128(input2_epi16, 4*2);
		input1_epi16 = _mm_srli_si128(input1_epi16, 1*2);
		input1_epi16 = _mm_or_si128(input1_epi16, shift2_epi16);

		// Apply the fifth filter coefficient to each pixel and sum the result
		sum2_epi16 = _mm_adds_epi16(sum2_epi16, input1_epi16);

		// Shift the fifth pixel from the second set into the working set
		shift2_epi16 = _mm_slli_si128(input2_epi16, 3*2);
		input1_epi16 = _mm_srli_si128(input1_epi16, 1*2);
		input1_epi16 = _mm_or_si128(input1_epi16, shift2_epi16);

		// Apply the sixth (last) filter coefficient to each pixel and sum the result
		sum2_epi16 = _mm_adds_epi16(sum2_epi16, input1_epi16);

		//DAN20050915 -- reversibility
		sum2_epi16 = _mm_adds_epi16(sum2_epi16, half_epi16);
		sum2_epi16 = _mm_srai_epi16(sum2_epi16, 3);

		sum2_epi16 = _mm_adds_epi16(sum2_epi16, sum2b_epi16);


		// Expand the even output points to a full doubleword
		sum2_epi16 = _mm_slli_epi32(sum2_epi16, 16);
		sum2_epi16 = _mm_srai_epi32(sum2_epi16, 16);


		/***** Combine the output points *****/

		low1_epi16 = _mm_packs_epi32(low1_epi16, low2_epi16);
		sum1_epi16 = _mm_packs_epi32(sum1_epi16, sum2_epi16);


		///////////////////////////////////////////////////
		// Quantize the passlow BEFORE it is differenced.//
		///////////////////////////////////////////////////

		if(lp_divisor > 1) // Fix for LOSSLESS
		{
			// Compute the absolute value
			sign_epi16 = _mm_cmpgt_epi16(zero_epi16, low1_epi16);
			low1_epi16 = _mm_xor_si128(low1_epi16, sign_epi16);
			low1_epi16 = _mm_sub_epi16(low1_epi16, sign_epi16);

	#if MIDPOINT_PREQUANT
			// Add the prequant_midpoint for quantization rounding
			low1_epi16 = _mm_add_epi16(low1_epi16, offset_epi16);
	#endif
			// Multiply by the quantization factor
			low1_epi16 = _mm_mulhi_epu16(low1_epi16, quant_epi16);

			// Restore the sign
			low1_epi16 = _mm_xor_si128(low1_epi16, sign_epi16);
			low1_epi16 = _mm_sub_epi16(low1_epi16, sign_epi16);
		}

		///////////////////////////////////////////////////
		// New differencing engine                       //
		// this code makes the low-pass difference data. //
		///////////////////////////////////////////////////
		tmp_epi16 = _mm_slli_si128(low1_epi16, 1*2);
		tmp_epi16 = _mm_insert_epi16(tmp_epi16, lastsumvalue, 0);
		lastsumvalue = _mm_extract_epi16(low1_epi16, 7);
		low1_epi16 = _mm_sub_epi16(low1_epi16, tmp_epi16);

		// Store the four lowpass output points
		_mm_store_si128(lowpass_ptr++, low1_epi16);

		// Get the last highpass coefficient in the group
		sum2_epi16 = _mm_srli_si128(sum1_epi16, 7*2);

		// Shift the extra highpass coefficient into the output
		sum1_epi16 = _mm_slli_si128(sum1_epi16, 1*2);
		sum1_epi16 = _mm_insert_epi16(sum1_epi16, highpass_value, 0);

		// Save the last highpass coefficient for the next loop iteration
		highpass_value = _mm_cvtsi128_si32(sum2_epi16);

		// Store the four highpass output points
		_mm_store_si128(highpass_ptr++, sum1_epi16);

		// The second set of eight input pixels becomes the working set
		input1_epi16 = input2_epi16;
	}

	// Should have exited the loop at the post processing column
	assert(column == post_column);

	lowptr = (PIXEL *)lowpass_ptr;
	highptr = (PIXEL *)highpass_ptr;
#endif

#if !_PREROLL
	// The lowpass results are behind by one column
	sum = input[column] + input[column + 1];

	*(lowptr++) = SATURATE(sum);

	// The fast processing loop is out of phase by two columns
	if (column < last_column)
		column += 2;
	else
		highptr--;
#endif

/* // used for test non-MMX
	if(column == 0)
	{
		sum = input[column] + input[column + 1];

		*(lowptr++) = SATURATE(sum);
		*(highptr++) = SATURATE(highpass_value);

		column += 2;
	}
*/

	if (column < last_column)
	{
		int tmp,lastsum = 0;

		if(column > 0)
		{
			lastsum = input[column-2] + input[column-1];// previous sum
			if(lastsum < 0)
			{
				lastsum = -lastsum;
				#if MIDPOINT_PREQUANT
				lastsum += prequant_midpoint;
				#endif
				lastsum *= multiplier; // quantize
				lastsum >>= 16;
				lastsum = -lastsum;
			}
			else
			{
				#if MIDPOINT_PREQUANT
				lastsum += prequant_midpoint;
				#endif
				lastsum *= multiplier; // quantize
				lastsum >>= 16;
			}
		}

		// Process the last group of columns as a special case to handle the border
		for (; column < last_column; column += 2)
		{
			// Compute the lowpass sum
			sum = input[column] + input[column + 1];

			if(sum < 0)
			{
				sum = -sum;
				#if MIDPOINT_PREQUANT
				sum += prequant_midpoint;
				#endif
				sum *= multiplier; // quantize
				sum >>= 16;
				sum = -sum;
			}
			else
			{
				#if MIDPOINT_PREQUANT
				sum += prequant_midpoint;
				#endif
				sum *= multiplier; // quantize
				sum >>= 16;
			}

			tmp = sum;
			sum -= lastsum;
			lastsum = tmp;

			// Store the lowpass sum
			*(lowptr++) = SATURATE(sum);

			// Compute the highpass sum
			sum = 0;
			sum -= input[column - 2];
			sum -= input[column - 1];
			sum += input[column + 2];
			sum += input[column + 3];
			sum += 4;
			sum >>= 3;
			sum += input[column + 0];
			sum -= input[column + 1];

			// Store the highpass sum
			*(highptr++) = SATURATE(sum);
		}
	}

	// Should be at the last column
	assert(column == last_column);

	//DAN20050503 this the point should was missing for for fix the end condition so that is would over right other buffer data.
	// if is only require when push the SSE/MMX to process the very last pixel in the row (like this version.)
	column = last_column - 2; // Redo the last two pixels for the edge
	highptr--;
	lowptr--;

	// Compute the last lowpass value
	lastsum = (input[column-2] + input[column + 1-2]);
	if(lastsum < 0)
	{
		lastsum = -lastsum;
		#if MIDPOINT_PREQUANT
		lastsum += prequant_midpoint;
		#endif
		lastsum *= multiplier; // quantize
		lastsum >>= 16;
		lastsum = -lastsum;
	}
	else
	{
		#if MIDPOINT_PREQUANT
		lastsum += prequant_midpoint;
		#endif
		lastsum *= multiplier; // quantize
		lastsum >>= 16;
	}


	sum = (input[column] + input[column + 1]);
	if(sum < 0)
	{
		sum = -sum;
		#if MIDPOINT_PREQUANT
		sum += prequant_midpoint;
		#endif
		sum *= multiplier; // quantize
		sum >>= 16;
		sum = -sum;
	}
	else
	{
		#if MIDPOINT_PREQUANT
		sum += prequant_midpoint;
		#endif
		sum *= multiplier; // quantize
		sum >>= 16;
	}

	sum -= lastsum;

	*(lowptr++) = SATURATE(sum);

	// Compute the last highpass value using the special border coefficients
	sum = 0;
	sum += 11 * input[column + 0];
	sum -=  5 * input[column + 1];
	sum -=  4 * input[column - 1];
	sum -=  4 * input[column - 2];
	sum +=  1 * input[column - 3];
	sum +=  1 * input[column - 4];
	sum +=  ROUNDING(sum,8);
	sum = DivideByShift(sum, 3);

	*(highptr++) = SATURATE(sum);
}


#endif // _PROCESSOR_PENTIUM_4


void FilterHorizontalRowQuant16s(PIXEL *input, PIXEL *lowpass, PIXEL *highpass,
								  int width, int lp_div, int hp_div)
{
	int column_step = 16;				// Number of input pixels processed per loop iteration
	int last_column = width;//DAN08092004  - 2;		// Column at which right border processing is done
	int sign = 1;

	// The post column is the column at which end of column processing must begin
	int post_column = last_column - (last_column % column_step);

	int32_t sum;
	//int32_t lsb;

	// Start at the left end of the row
	PIXEL *lowptr = lowpass;
	PIXEL *highptr = highpass;
	int column = 0;

	__m128i *input_ptr = (__m128i *)input;
	__m128i *lowpass_ptr;
	__m128i *highpass_ptr;
	__m128i input1_epi16;

	int highpass_value;

	// Prescaling is performed by quantization

	uint32_t lp_multiplier = (uint32_t)(1 << 16) / lp_div;
	uint32_t hp_multiplier = (uint32_t)(1 << 16) / hp_div;

	int lp_prequant_midpoint = lp_div/2;
	int hp_prequant_midpoint = hp_div/2;

	__m128i lp_quant_epi16 = _mm_set1_epi16(lp_multiplier);
	__m128i hp_quant_epi16 = _mm_set1_epi16(hp_multiplier);

	__m128i lp_offset_epi16 = _mm_set1_epi16(lp_prequant_midpoint);
	__m128i hp_offset_epi16 = _mm_set1_epi16(hp_prequant_midpoint);
	__m128i zero_si128 = _mm_setzero_si128();


	// Preprocess the first lowpass and highpass columns for memory alignment

	// The first highpass column is a special case
	sum = 0;
	sum +=  5 * input[column + 0];
	sum -= 11 * input[column + 1];
	sum +=  4 * input[column + 2];
	sum +=  4 * input[column + 3];
	sum -=  1 * input[column + 4];
	sum -=  1 * input[column + 5];
	sum += ROUNDING(sum,8);
	sum = DivideByShift(sum, 3);
	//*(highptr++) = SATURATE(sum);
	highpass_value = SATURATE(sum);


	// Set the input pointer for the fast loop
	input_ptr = (__m128i *)&input[column];

	// Check that the pointer to the next group of pixels is properly aligned
	assert(ISALIGNED16(input_ptr));

	// Preload the first set of four pixels for fast processing
	input1_epi16 = _mm_load_si128(input_ptr++);

	// Initialize the output pointers
	lowpass_ptr = (__m128i *)lowptr;
	highpass_ptr = (__m128i *)highptr;

	// Check that the output pointers are properly aligned
	assert(ISALIGNED16(lowpass_ptr));
	assert(ISALIGNED16(highpass_ptr));


	// Process two sets of four input pixels to get one set of four output pixels
	for (; column < post_column; column += column_step)
	{
		__m128i input2_epi16;
		__m128i shift2_epi16;
		__m128i half_epi16;		// Half of the divisor for rounding
		//__m128i lsb_epi16;		// Least significant bit for rounding
		__m128i sum1_epi16;
		__m128i sum2_epi16;
		__m128i low1_epi16;
		__m128i low2_epi16;
		__m128i sign1_epi16;

		__m128i sum1b_epi16;
		__m128i sum2b_epi16;


		/***** Process the first four output points *****/

		// Initialize the highpass sum
		sum1_epi16 = _mm_setzero_si128();

		// Apply the first filter coefficient to each pixel and sum the result
		sum1_epi16 = _mm_subs_epi16(sum1_epi16, input1_epi16);

		// Check that the pointer to the next group of pixels is properly aligned
		assert(ISALIGNED16(input_ptr));

		// Load the next eight pixels
		input2_epi16 = _mm_load_si128(input_ptr++);

		// Initialize the lowpass sum
		low1_epi16 = input1_epi16;

		// Shift the first pixel from the second set into the working set
		shift2_epi16 = _mm_slli_si128(input2_epi16, 7*2);
		input1_epi16 = _mm_srli_si128(input1_epi16, 1*2);
		input1_epi16 = _mm_or_si128(input1_epi16, shift2_epi16);

		// Apply the second filter coefficient to each pixel and sum the result
		sum1_epi16 = _mm_subs_epi16(sum1_epi16, input1_epi16);

		// Add adjacent points to compute the lowpass sum
		low1_epi16 = _mm_adds_epi16(low1_epi16, input1_epi16);

		// Expand the lowpass output points to a full doubleword
		low1_epi16 = _mm_slli_epi32(low1_epi16, 16);
		low1_epi16 = _mm_srai_epi32(low1_epi16, 16);

		// Shift the second pixel from the second set into the working set
		shift2_epi16 = _mm_slli_si128(input2_epi16, 6*2);
		input1_epi16 = _mm_srli_si128(input1_epi16, 1*2);
		input1_epi16 = _mm_or_si128(input1_epi16, shift2_epi16);

		// Apply the third filter coefficient to each pixel and sum the result
		sum1b_epi16 = input1_epi16;

		// Shift the third pixel from the second set into the working set
		shift2_epi16 = _mm_slli_si128(input2_epi16, 5*2);
		input1_epi16 = _mm_srli_si128(input1_epi16, 1*2);
		input1_epi16 = _mm_or_si128(input1_epi16, shift2_epi16);

		// Apply the fourth filter coefficient to each pixel and sum the result
		sum1b_epi16 = _mm_subs_epi16(sum1b_epi16, input1_epi16);

		// Shift the fourth pixel from the second set into the working set
		shift2_epi16 = _mm_slli_si128(input2_epi16, 4*2);
		input1_epi16 = _mm_srli_si128(input1_epi16, 1*2);
		input1_epi16 = _mm_or_si128(input1_epi16, shift2_epi16);

		// Apply the fifth filter coefficient to each pixel and sum the result
		sum1_epi16 = _mm_adds_epi16(sum1_epi16, input1_epi16);

		// Shift the fifth pixel from the second set into the working set
		shift2_epi16 = _mm_slli_si128(input2_epi16, 3*2);
		input1_epi16 = _mm_srli_si128(input1_epi16, 1*2);
		input1_epi16 = _mm_or_si128(input1_epi16, shift2_epi16);

		// Apply the sixth (last) filter coefficient to each pixel and sum the result
		sum1_epi16 = _mm_adds_epi16(sum1_epi16, input1_epi16);

		//DAN20050915 -- reversibility
		half_epi16 = _mm_set1_epi16(4);
		sum1_epi16 = _mm_adds_epi16(sum1_epi16, half_epi16);
		sum1_epi16 = _mm_srai_epi16(sum1_epi16, 3);

		sum1_epi16 = _mm_adds_epi16(sum1_epi16, sum1b_epi16);

		// Expand the even output points to a full doubleword
		sum1_epi16 = _mm_slli_epi32(sum1_epi16, 16);
		sum1_epi16 = _mm_srai_epi32(sum1_epi16, 16);

		// The second eight input points become the current input points
		input1_epi16 = input2_epi16;


		/***** Process the second four output points *****/

		// Initialize the highpass sum
		sum2_epi16 = _mm_setzero_si128();

		// Apply the first filter coefficient to each pixel and sum the result
		sum2_epi16 = _mm_subs_epi16(sum2_epi16, input1_epi16);

		// Check that the pointer to the next group of pixels is properly aligned
		assert(ISALIGNED16(input_ptr));

		// Load the next eight pixels
		input2_epi16 = _mm_load_si128(input_ptr++);

		// Initialize the lowpass sum
		low2_epi16 = input1_epi16;

		// Shift the first pixel from the second set into the working set
		shift2_epi16 = _mm_slli_si128(input2_epi16, 7*2);
		input1_epi16 = _mm_srli_si128(input1_epi16, 1*2);
		input1_epi16 = _mm_or_si128(input1_epi16, shift2_epi16);

		// Apply the second filter coefficient to each pixel and sum the result
		sum2_epi16 = _mm_subs_epi16(sum2_epi16, input1_epi16);

		// Add adjacent points to compute the lowpass sum
		low2_epi16 = _mm_adds_epi16(low2_epi16, input1_epi16);

		// Expand the lowpass output points to a full doubleword
		low2_epi16 = _mm_slli_epi32(low2_epi16, 16);
		low2_epi16 = _mm_srai_epi32(low2_epi16, 16);

		// Shift the second pixel from the second set into the working set
		shift2_epi16 = _mm_slli_si128(input2_epi16, 6*2);
		input1_epi16 = _mm_srli_si128(input1_epi16, 1*2);
		input1_epi16 = _mm_or_si128(input1_epi16, shift2_epi16);

		// Apply the third filter coefficient to each pixel and sum the result
		sum2b_epi16 = input1_epi16;

		// Shift the third pixel from the second set into the working set
		shift2_epi16 = _mm_slli_si128(input2_epi16, 5*2);
		input1_epi16 = _mm_srli_si128(input1_epi16, 1*2);
		input1_epi16 = _mm_or_si128(input1_epi16, shift2_epi16);

		// Apply the fourth filter coefficient to each pixel and sum the result
		sum2b_epi16 = _mm_subs_epi16(sum2b_epi16, input1_epi16);

		// Shift the fourth pixel from the second set into the working set
		shift2_epi16 = _mm_slli_si128(input2_epi16, 4*2);
		input1_epi16 = _mm_srli_si128(input1_epi16, 1*2);
		input1_epi16 = _mm_or_si128(input1_epi16, shift2_epi16);

		// Apply the fifth filter coefficient to each pixel and sum the result
		sum2_epi16 = _mm_adds_epi16(sum2_epi16, input1_epi16);

		// Shift the fifth pixel from the second set into the working set
		shift2_epi16 = _mm_slli_si128(input2_epi16, 3*2);
		input1_epi16 = _mm_srli_si128(input1_epi16, 1*2);
		input1_epi16 = _mm_or_si128(input1_epi16, shift2_epi16);

		// Apply the sixth (last) filter coefficient to each pixel and sum the result
		sum2_epi16 = _mm_adds_epi16(sum2_epi16, input1_epi16);

		//DAN20050915 -- reversibility
		half_epi16 = _mm_set1_epi16(4);
		sum2_epi16 = _mm_adds_epi16(sum2_epi16, half_epi16);
		sum2_epi16 = _mm_srai_epi16(sum2_epi16, 3);

		sum2_epi16 = _mm_adds_epi16(sum2_epi16, sum2b_epi16);


		// Expand the even output points to a full doubleword
		sum2_epi16 = _mm_slli_epi32(sum2_epi16, 16);
		sum2_epi16 = _mm_srai_epi32(sum2_epi16, 16);


		/***** Combine the output points *****/

		low1_epi16 = _mm_packs_epi32(low1_epi16, low2_epi16);
		sum1_epi16 = _mm_packs_epi32(sum1_epi16, sum2_epi16);

		// Do the quantization
		if(lp_div > 1)
		{
			sign1_epi16 = _mm_cmpgt_epi16(zero_si128, low1_epi16);

			// Compute the absolute value
			low1_epi16 = _mm_xor_si128(low1_epi16, sign1_epi16);
			low1_epi16 = _mm_sub_epi16(low1_epi16, sign1_epi16);

			// Add the prequant_midpoint for quantization rounding
			low1_epi16 = _mm_add_epi16(low1_epi16, lp_offset_epi16);

			// Multiply by the quantization factor
			low1_epi16 = _mm_mulhi_epu16(low1_epi16, lp_quant_epi16);

			// Restore the sign
			low1_epi16 = _mm_xor_si128(low1_epi16, sign1_epi16);
			low1_epi16 = _mm_sub_epi16(low1_epi16, sign1_epi16);

		}



		// Store the four lowpass output points
		_mm_store_si128(lowpass_ptr++, low1_epi16);

#if _PREROLL
		// Get the last highpass coefficient in the group
		sum2_epi16 = _mm_srli_si128(sum1_epi16, 7*2);

		// Shift the extra highpass coefficient into the output
		sum1_epi16 = _mm_slli_si128(sum1_epi16, 1*2);
		sum1_epi16 = _mm_insert_epi16(sum1_epi16, highpass_value, 0);

		// Save the last highpass coefficient for the next loop iteration
		highpass_value = _mm_cvtsi128_si32(sum2_epi16);



		// Do the quantization
		sign1_epi16 = _mm_cmpgt_epi16(zero_si128, sum1_epi16);

		// Compute the absolute value
		sum1_epi16 = _mm_xor_si128(sum1_epi16, sign1_epi16);
		sum1_epi16 = _mm_sub_epi16(sum1_epi16, sign1_epi16);

		// Add the prequant_midpoint for quantization rounding
		sum1_epi16 = _mm_add_epi16(sum1_epi16, hp_offset_epi16);

		// Multiply by the quantization factor
		sum1_epi16 = _mm_mulhi_epu16(sum1_epi16, hp_quant_epi16);

		// Restore the sign
		sum1_epi16 = _mm_xor_si128(sum1_epi16, sign1_epi16);
		sum1_epi16 = _mm_sub_epi16(sum1_epi16, sign1_epi16);




		// Store the four highpass output points
		_mm_store_si128(highpass_ptr++, sum1_epi16);
#else


		// Do the quantization
		sign1_epi16 = _mm_cmpgt_epi16(zero_si128, sum1_epi16);

		// Compute the absolute value
		sum1_epi16 = _mm_xor_si128(sum1_epi16, sign1_epi16);
		sum1_epi16 = _mm_sub_epi16(sum1_epi16, sign1_epi16);

		// Add the prequant_midpoint for quantization rounding
		sum1_epi16 = _mm_add_epi16(sum1_epi16, hp_offset_epi16);

		// Multiply by the quantization factor
		sum1_epi16 = _mm_mulhi_epu16(sum1_epi16, hp_quant_epi16);

		// Restore the sign
		sum1_epi16 = _mm_xor_si128(sum1_epi16, sign1_epi16);
		sum1_epi16 = _mm_sub_epi16(sum1_epi16, sign1_epi16);




		// Store the four highpass output points (may be unaligned without preroll)
		_mm_storeu_si128(highpass_ptr++, sum1_epi16);
#endif

		// The second set of eight input pixels becomes the working set
		input1_epi16 = input2_epi16;
	}

	// Should have exited the loop at the post processing column
	assert(column == post_column);

	lowptr = (PIXEL *)lowpass_ptr;
	highptr = (PIXEL *)highpass_ptr;

#if !_PREROLL
	// The lowpass results are behind by one column
	sum = input[column] + input[column + 1];

	sum *= lp_multiplier;
	sum >>= 16;
	*(lowptr++) = SATURATE(sum);

	// The fast processing loop is out of phase by two columns
	if (column < last_column) column += 2;
	else highptr--;

#endif

	// Process the last group of columns as a special case to handle the border
	for (; column < last_column; column += 2)
	{
		// Compute the lowpass sum
		sum = input[column] + input[column + 1];

		sum *= lp_multiplier;
		sum >>= 16;
		// Store the lowpass sum
		*(lowptr++) = SATURATE(sum);

		// Compute the highpass sum
		sum = 0;
		sum -= input[column - 2];
		sum -= input[column - 1];
		sum += input[column + 2];
		sum += input[column + 3];
		sum += ROUNDING(sum,8);
		sum = DivideByShift(sum, 3);
		sum += input[column + 0];
		sum -= input[column + 1];

		sign = 1;
		if(sum < 0)
		{
			sign = -1;
			sum = -sum;
		}

		sum *= hp_multiplier;
		sum >>= 16;

		sum *= sign;

		// Store the highpass sum
		*(highptr++) = SATURATE(sum);
	}

	// Should be at the last column
	assert(column == last_column);


	//DAN20050503 this the point should was missing for for fix the end condition so that is would over right other buffer data.
	// if is only require when push the SSE/MMX to process the very last pixel in the row (like this version.)
	column = last_column - 2; // Redo the last two pixels for the edge
	highptr--;
	lowptr--;


	// Compute the last lowpass value
	sum = input[column] + input[column + 1];

	sum *= lp_multiplier;
	sum >>= 16;
	*(lowptr++) = SATURATE(sum);

	// Compute the last highpass value using the special border coefficients
	sum = 0;
	sum += 11 * input[column + 0];
	sum -=  5 * input[column + 1];
	sum -=  4 * input[column - 1];
	sum -=  4 * input[column - 2];
	sum +=  1 * input[column - 3];
	sum +=  1 * input[column - 4];
	sum +=  ROUNDING(sum,8);
	sum = DivideByShift(sum, 3);

	sign = 1;
	if(sum < 0)
	{
		sign = -1;
		sum = -sum;
	}

	sum *= hp_multiplier;
	sum >>= 16;

	sum *= sign;

	*(highptr++) = SATURATE(sum);
}







#if 0
// Apply the lowpass and highpass horizontal filters to the input image
void FilterHorizontal(PIXEL *input, int input_pitch,
					  PIXEL *lowpass, int lowpass_pitch,
					  PIXEL *highpass, int highpass_pitch,
					  ROI roi, int input_scale)
{
	PIXEL *rowptr = input;
	PIXEL *lowrow = lowpass;
	PIXEL *highrow = highpass;
	PIXEL *lowptr;
	PIXEL *highptr;
	int column_step = 8;							// Number of pixels to process per iteration
	int post_column = roi.width - column_step;		// Last column before post processing
	int last_column = roi.width - 2;
	int row, column;

	bool fastmode = (input_scale < 16) ? true : false;

	// Convert pitch from bytes to pixels
	input_pitch /= sizeof(PIXEL);
	lowpass_pitch /= sizeof(PIXEL);
	highpass_pitch /= sizeof(PIXEL);

	for (row = 0; row < roi.height; row++)
	{
		int32_t sum;
		int32_t lsb;
		__m128i *colptr = (__m128i *)rowptr;
		__m128i input1_epi16;

		// Start at the left end of the row
		column = 0;
		lowptr = lowrow;
		highptr = highrow;

		// Process the first column as a special case to handle the highpass border

		// Apply the highpass filter to the beginning of the row
		sum = 0;
		sum +=  5 * rowptr[column + 0];
		sum -= 11 * rowptr[column + 1];
		sum +=  4 * rowptr[column + 2];
		sum +=  4 * rowptr[column + 3];
		sum -=  1 * rowptr[column + 4];
		sum -=  1 * rowptr[column + 5];
		sum += ROUNDING(sum,8);
		sum = DivideByShift(sum, 3);
		*(highptr++) = SATURATE(sum);

		// Skip a column to downsample the filter output
		column += 2;

		// Does the input data require full range arithmetic?
		if (!fastmode)
		{
			// Perform the lowpass and highpass convolutions using full precision arithmetic
			for (; column < last_column; column += 2) {
				int32_t sum;
				//int32_t lsb;

				// Apply the lowpass filter
				sum = 0;
				sum += rowptr[column + 0];
				sum += rowptr[column + 1];
				*(lowptr++) = SATURATE(sum);

				// Apply the highpass filter
				sum = 0;
				sum -= rowptr[column - 2];
				sum -= rowptr[column - 1];
				sum += rowptr[column + 2];
				sum += rowptr[column + 3];
				sum += ROUNDING(sum,8);
				sum = DivideByShift(sum, 3);
				sum += rowptr[column + 0];
				sum -= rowptr[column + 1];

				*(highptr++) = SATURATE(sum);
			}
		}
		else
		{
			// Check that the pointer to the next group of pixels is properly aligned
			assert(ISALIGNED16(colptr));

			// Preload the first set of eight pixels for fast processing
			//input1_epi16 = *(colptr++);
			input1_epi16 = _mm_load_si128(colptr++);

			// Process two sets of eight input pixels to get one set of four output pixels
			for (; column < post_column; column += column_step)
			{
				__m128i input2_epi16;
				__m128i shift2_epi16;
				__m128i mask_epi16;
				__m128i half_epi16;		// Half of the divisor for rounding
				__m128i lsb_epi16;		// Least significant bit for rounding
				__m128i sum_epi16;
				__m128i low_epi16;

				// Load input eight pixels
				//input1_epi16 = *(colptr++);

				// Compute four lowpass results
				low_epi16 = _mm_srli_epi32(input1_epi16, 16);
				low_epi16 = _mm_adds_epi16(input1_epi16, low_epi16);

				// Combine and store the eight lowpass results
				low_epi16 = _mm_shufflehi_epi16(low_epi16, _MM_SHUFFLE(3, 1, 2, 0));
				low_epi16 = _mm_shufflelo_epi16(low_epi16, _MM_SHUFFLE(3, 1, 2, 0));
				low_epi16 = _mm_shuffle_epi32(low_epi16, _MM_SHUFFLE(3, 1, 2, 0));
				_mm_storel_epi64((__m128i *)lowptr, low_epi16);
				lowptr += 4;

				// Initialize the sum for the highpass filter
				sum_epi16 = _mm_setzero_si128();

				// Apply the first filter coefficient to each pixel and sum the result
				sum_epi16 = _mm_subs_epi16(sum_epi16, input1_epi16);

				// Load the next eight pixels
				//input2_epi16 = *(colptr++);
				input2_epi16 = _mm_load_si128(colptr++);

				// Shift the first pixel from the second set into the working set
				shift2_epi16 = _mm_slli_si128(input2_epi16, 7*2);
				input1_epi16 = _mm_srli_si128(input1_epi16, 1*2);
				input1_epi16 = _mm_or_si128(input1_epi16, shift2_epi16);

				// Apply the second filter coefficient to each pixel and sum the result
				sum_epi16 = _mm_subs_epi16(sum_epi16, input1_epi16);

				// Shift the next pixel from the second set into the working set
				shift2_epi16 = _mm_slli_si128(input2_epi16, 6*2);
				input1_epi16 = _mm_srli_si128(input1_epi16, 1*2);
				input1_epi16 = _mm_or_si128(input1_epi16, shift2_epi16);

				// Apply the third filter coefficient to each pixel and sum the result
				sumb_epi16 = input1_epi16;

				// Shift the next pixel from the second set into the working set
				shift2_epi16 = _mm_slli_si128(input2_epi16, 5*2);
				input1_epi16 = _mm_srli_si128(input1_epi16, 1*2);
				input1_epi16 = _mm_or_si128(input1_epi16, shift2_epi16);

				// Apply the fourth filter coefficient to each pixel and sum the result
				sumb_epi16 = _mm_subs_epi16(sumb_epi16, input1_epi16);

				// Shift the next pixel from the second set into the working set
				shift2_epi16 = _mm_slli_si128(input2_epi16, 4*2);
				input1_epi16 = _mm_srli_si128(input1_epi16, 1*2);
				input1_epi16 = _mm_or_si128(input1_epi16, shift2_epi16);

				// Apply the fifth filter coefficient to each pixel and sum the result
				sum_epi16 = _mm_adds_epi16(sum_epi16, input1_epi16);

				// Shift the next pixel from the second set into the working set
				shift2_epi16 = _mm_slli_si128(input2_epi16, 3*2);
				input1_epi16 = _mm_srli_si128(input1_epi16, 1*2);
				input1_epi16 = _mm_or_si128(input1_epi16, shift2_epi16);

				// Apply the sixth (last) filter coefficient to each pixel and sum the result
				sum_epi16 = _mm_adds_epi16(sum_epi16, input1_epi16);

				//  Divide the result by eight
				half_epi16 = _mm_set1_epi16(4);
				sum_epi16 = _mm_adds_epi16(sum_epi16, half_epi16);
				sum_epi16 = _mm_srai_epi16(sum_epi16, 3);

				sum_epi16 = _mm_adds_epi16(sum_epi16, sumb_epi16);


				// Downsample and store the results
				sum_epi16 = _mm_shufflehi_epi16(sum_epi16, _MM_SHUFFLE(3, 1, 2, 0));
				sum_epi16 = _mm_shufflelo_epi16(sum_epi16, _MM_SHUFFLE(3, 1, 2, 0));
				sum_epi16 = _mm_shuffle_epi32(sum_epi16, _MM_SHUFFLE(3, 1, 2, 0));
				_mm_storel_epi64((__m128i *)highptr, sum_epi16);
				highptr += 4;

				// The second set of eight input pixels becomes the working set
				input1_epi16 = input2_epi16;
			}

			// Process the last group of columns as a special case to handle the border
			for (; column < last_column; column += 2)
			{
				// Apply the lowpass filter
				sum = 0;
				sum += rowptr[column + 0];
				sum += rowptr[column + 1];
				*(lowptr++) = SATURATE(sum);

				// Apply the highpass filter
				sum = 0;
				sum -= rowptr[column - 2];
				sum -= rowptr[column - 1];
				sum += rowptr[column + 2];
				sum += rowptr[column + 3];
				sum += ROUNDING(sum,8);
				sum = DivideByShift(sum, 3);
				sum += rowptr[column + 0];
				sum -= rowptr[column + 1];

				*(highptr++) = SATURATE(sum);
			}
		}

		// Process the last column as a special case to handle the highpass border

		// Apply the lowpass filter to the beginning of the row
		sum = 0;
		sum += rowptr[column + 0];
		sum += rowptr[column + 1];
		*(lowptr++) = SATURATE(sum);

		// Apply the highpass filter to the beginning of the row
		sum = 0;
		sum += 11 * rowptr[column + 0];
		sum -=  5 * rowptr[column + 1];
		sum -=  4 * rowptr[column - 1];
		sum -=  4 * rowptr[column - 2];
		sum +=  1 * rowptr[column - 3];
		sum +=  1 * rowptr[column - 4];
		sum +=  ROUNDING(sum,8);
		sum = DivideByShift(sum, 3);
		*(highptr++) = SATURATE(sum);

		// Advance to the next row
		rowptr += input_pitch;
		lowrow += lowpass_pitch;
		highrow += highpass_pitch;
	}

	//_mm_empty();	// Clear the mmx register state
}
#endif

#if 0
// This version performs lowpass convolution and downsampling in one pass
// and is optimized for the lowpass coefficients used in the 2/6 wavelet
void FilterLowpassHorizontal(PIXEL *input, int input_pitch, PIXEL *output, int output_pitch, ROI roi, int prescale)
{
	PIXEL *rowptr = input;
	PIXEL *outrow = output;
	int row, column;

	// The input width must be an even number to allow downsampling
	assert((roi.width % 2) == 0);
	roi.width -= (roi.width % 2);

	// Convert pitch from bytes to pixels
	input_pitch /= sizeof(PIXEL);
	output_pitch /= sizeof(PIXEL);

	for (row = 0; row < roi.height; row++)
	{
		// Load eight pixels and produce four output pixels per iteration
		const int column_step = 8;

		// Column at which end of row processing must begin
		const int post_column = roi.width - (roi.width % column_step);

		__m64 *input_ptr = (__m64 *)rowptr;
		__m64 *output_ptr = (__m64 *)outrow;
		PIXEL *outptr;

		// The post processing column must correspond to an integral number of loop iterations
		assert((post_column % column_step) == 0);

		// Read eight pixels and sum adjacent values into four output pixels
		for (column = 0; column < post_column; column += column_step)
		{
			__m64 quad1_pi16;		// First set of four pixels
			__m64 quad2_pi16;		// Second set of four pixels
			__m64 sum1_pi16;		// First sum of pairs of pixels
			__m64 sum2_pi16;		// Second sum of pairs of pixels

			// Load the first four pixels
			quad1_pi16 = *(input_ptr++);

			// Sum the first two pixels and the second two pixels in the quadword
			sum1_pi16 = _mm_shuffle_pi16(quad1_pi16, _MM_SHUFFLE(2, 3, 0, 1));
			sum1_pi16 = _mm_adds_pi16(sum1_pi16, quad1_pi16);

			// Shuffle the pair of sums into adjacent words
			sum1_pi16 = _mm_shuffle_pi16(sum1_pi16, _MM_SHUFFLE(3, 1, 2, 0));

			// Load the next four pixels
			quad2_pi16 = *(input_ptr++);

			// Sum the first two pixels and the second two pixels in the quadword
			sum2_pi16 = _mm_shuffle_pi16(quad2_pi16, _MM_SHUFFLE(2, 3, 0, 1));
			sum2_pi16 = _mm_adds_pi16(sum2_pi16, quad2_pi16);

			// Shuffle the pair of sums into adjacent words
			sum2_pi16 = _mm_shuffle_pi16(sum2_pi16, _MM_SHUFFLE(3, 1, 2, 0));

			// Combine the sums into a single quadword
			sum1_pi16 = _mm_unpacklo_pi32(sum1_pi16, sum2_pi16);

			// Store the four results
			*(output_ptr++) = sum1_pi16;
		}

		// Should have exited the loop at the post processing column
		assert(column == post_column);

		// Process the rest of the row
		outptr = (PIXEL *)output_ptr;
		while (column < roi.width)
		{
			*(outptr++) = rowptr[column++] + rowptr[column++];
		}

		// Advance to the next row
		rowptr += input_pitch;
		outrow += output_pitch;
	}

	//_mm_empty();	// Clear the mmx register state

#if (0 && DEBUG && _WINDOWS)
	_CrtCheckMemory();
#endif
}
#endif


#if 0
#if _PROCESSOR_DISPATCH

__declspec(cpu_dispatch(Pentium_4,Generic))

void FilterHighpassHorizontal(PIXEL *input, int input_pitch,
							  PIXEL *output, int output_pitch,
							  ROI roi, int input_scale, int prescale)
{
	// Stub routine for processor specific dispatch
}
#endif


#if _PROCESSOR_GENERIC

#if _PROCESSOR_DISPATCH
__declspec(cpu_specific(Generic))
#endif

// This version performs highpass convolution and downsampling in one pass
// and is optimized for the highpass coefficients used in the 2/6 wavelet
void FilterHighpassHorizontal(PIXEL *input, int input_pitch,
							  PIXEL *output, int output_pitch,
							  ROI roi, int input_scale, int prescale)
{
	PIXEL *rowptr = input;
	PIXEL *outrow = output;
	PIXEL *outptr;
	int row, column;
	int column_step = 8;				// Number of input pixels processed per loop iteration
	int last_column = roi.width - 2;	// Column at which right border processing is done

	// The post column is the column at which end of column processing must begin
	int post_column = last_column - (last_column % column_step);

	// Cannot use 16-bit arithmetic if the input scale is too large
	bool fastmode = (input_scale < 16) ? true : false;

	// Convert pitch from bytes to pixels
	input_pitch /= sizeof(PIXEL);
	output_pitch /= sizeof(PIXEL);

	for (row = 0; row < roi.height; row++)
	{
		int32_t sum;
		int32_t lsb;
		__m64 *input_ptr = (__m64 *)rowptr;
		__m64 input1_pi16;

		// Start at the left end of the row
		outptr = outrow;
		column = 0;

		// Process the first column as a special case
		sum = 0;
		sum +=  5 * rowptr[column + 0];
		sum -= 11 * rowptr[column + 1];
		sum +=  4 * rowptr[column + 2];
		sum +=  4 * rowptr[column + 3];
		sum -=  1 * rowptr[column + 4];
		sum -=  1 * rowptr[column + 5];
		sum += ROUNDING(sum,8);
		sum = DivideByShift(sum, 3);
		*(outptr++) = SATURATE(sum);

		// Does the input data require full range arithmetic?
		if (!fastmode)
		{
			// Already processed the first two columns using the left border formulas
			column += 2;

			// Perform the convolution using full precision arithmetic
			for (; column < last_column; column += 2) {
				int32_t sum = 0;
				int32_t lsb;
				sum -= rowptr[column - 2];
				sum -= rowptr[column - 1];
				sum += rowptr[column + 2];
				sum += rowptr[column + 3];
				sum += ROUNDING(sum,8);
				sum = DivideByShift(sum, 3);
				sum += rowptr[column + 0];
				sum -= rowptr[column + 1];

				*(outptr++) = SATURATE(sum);
			}
		}
		else
		{
			__m64 *output_ptr = (__m64 *)outptr;

			// Check that the pointer to the next group of pixels is properly aligned
			//assert(ISALIGNED16(input_ptr));

			// Preload the first set of four pixels for fast processing
			input1_pi16 = *(input_ptr++);

			// Process two sets of four input pixels to get one set of four output pixels
			for (; column < post_column; column += column_step)
			{
				__m64 input2_pi16;
				__m64 shift2_pi16;
				__m64 mask_pi16;
				__m64 sign_pi16;
				__m64 half_pi16;		// Half of the divisor for rounding
				__m64 lsb_pi16;			// Least significant bit for rounding
				__m64 sum1_pi16;
				__m64 sum2_pi16;


				// First two output points //

				// Initialize the sum
				sum1_pi16 = _mm_setzero_si64();

				// Apply the first filter coefficient to each pixel and sum the result
				sum1_pi16 = _mm_subs_pi16(sum1_pi16, input1_pi16);

				// Load the next four pixels
				input2_pi16 = *(input_ptr++);

				// Shift the first pixel from the second set into the working set
				shift2_pi16 = _mm_slli_si64(input2_pi16, 3*16);
				input1_pi16 = _mm_srli_si64(input1_pi16, 1*16);
				input1_pi16 = _mm_or_si64(input1_pi16, shift2_pi16);

				// Apply the second filter coefficient to each pixel and sum the result
				sum1_pi16 = _mm_subs_pi16(sum1_pi16, input1_pi16);

				// Shift the next pixel from the second set into the working set
				shift2_pi16 = _mm_slli_si64(input2_pi16, 2*16);
				input1_pi16 = _mm_srli_si64(input1_pi16, 1*16);
				input1_pi16 = _mm_or_si64(input1_pi16, shift2_pi16);

				// Apply the third filter coefficient to each pixel and sum the result
				sum1_pi16 = _mm_adds_pi16(sum1_pi16, _mm_slli_pi16(input1_pi16, 3));

				// Shift the next pixel from the second set into the working set
				shift2_pi16 = _mm_slli_si64(input2_pi16, 1*16);
				input1_pi16 = _mm_srli_si64(input1_pi16, 1*16);
				input1_pi16 = _mm_or_si64(input1_pi16, shift2_pi16);

				// Apply the fourth filter coefficient to each pixel and sum the result
				sum1_pi16 = _mm_subs_pi16(sum1_pi16, _mm_slli_pi16(input1_pi16, 3));

				// Shift the next pixel from the second set into the working set
				input1_pi16 = input2_pi16;

				// Apply the fifth filter coefficient to each pixel and sum the result
				sum1_pi16 = _mm_adds_pi16(sum1_pi16, input1_pi16);

				// Shift the next pixel from the second set into the working set
				input1_pi16 = _mm_srli_si64(input1_pi16, 1*16);

				// Apply the sixth (last) filter coefficient to each pixel and sum the result
				sum1_pi16 = _mm_adds_pi16(sum1_pi16, input1_pi16);

				// Expand the even output points to a full doubleword
				sum1_pi16 = _mm_slli_pi32(sum1_pi16, 16);
				sum1_pi16 = _mm_srai_pi32(sum1_pi16, 16);

				// The second four input points become the first four input points
				input1_pi16 = input2_pi16;


				// Second two output points //

				// Initialize the sum
				sum2_pi16 = _mm_setzero_si64();

				// Apply the first filter coefficient to each pixel and sum the result
				sum2_pi16 = _mm_subs_pi16(sum2_pi16, input1_pi16);

				// Load the next four pixels
				input2_pi16 = *(input_ptr++);

				// Shift the first pixel from the second set into the working set
				shift2_pi16 = _mm_slli_si64(input2_pi16, 3*16);
				input1_pi16 = _mm_srli_si64(input1_pi16, 1*16);
				input1_pi16 = _mm_or_si64(input1_pi16, shift2_pi16);

				// Apply the second filter coefficient to each pixel and sum the result
				sum2_pi16 = _mm_subs_pi16(sum2_pi16, input1_pi16);

				// Shift the next pixel from the second set into the working set
				shift2_pi16 = _mm_slli_si64(input2_pi16, 2*16);
				input1_pi16 = _mm_srli_si64(input1_pi16, 1*16);
				input1_pi16 = _mm_or_si64(input1_pi16, shift2_pi16);

				// Apply the third filter coefficient to each pixel and sum the result
				sum2_pi16 = _mm_adds_pi16(sum2_pi16, _mm_slli_pi16(input1_pi16, 3));

				// Shift the next pixel from the second set into the working set
				shift2_pi16 = _mm_slli_si64(input2_pi16, 1*16);
				input1_pi16 = _mm_srli_si64(input1_pi16, 1*16);
				input1_pi16 = _mm_or_si64(input1_pi16, shift2_pi16);

				// Apply the fourth filter coefficient to each pixel and sum the result
				sum2_pi16 = _mm_subs_pi16(sum2_pi16, _mm_slli_pi16(input1_pi16, 3));

				// Shift the next pixel from the second set into the working set
				input1_pi16 = input2_pi16;

				// Apply the fifth filter coefficient to each pixel and sum the result
				sum2_pi16 = _mm_adds_pi16(sum2_pi16, input1_pi16);

				// Shift the next pixel from the second set into the working set
				input1_pi16 = _mm_srli_si64(input1_pi16, 1*16);

				// Apply the sixth (last) filter coefficient to each pixel and sum the result
				sum2_pi16 = _mm_adds_pi16(sum2_pi16, input1_pi16);

				// Expand the even output points to a full doubleword
				sum2_pi16 = _mm_slli_pi32(sum2_pi16, 16);
				sum2_pi16 = _mm_srai_pi32(sum2_pi16, 16);


				// Combine the output points //

				sum1_pi16 = _mm_packs_pi32(sum1_pi16, sum2_pi16);

				//	mask_pi16 = _mm_cmpgt_pi16(_mm_setzero_si64(), sum1_pi16);
				half_pi16 = _mm_set1_pi16(4);
				sum1_pi16 = _mm_srai_pi16(sum1_pi16, 3);
				sum1_pi16 = _mm_adds_pi16(sum1_pi16, half_pi16);

				// Store the four output points
				*(output_ptr++) = sum1_pi16;

				// The second set of eight input pixels becomes the working set
				input1_pi16 = input2_pi16;
			}

			// Should have exited the loop at the post processing column
			assert(column == post_column);

			outptr = (PIXEL *)output_ptr;

			// The fast processing loop is out of phase by two columns
			if (column < last_column) column += 2;
			else outptr--;

			// Process the last group of columns as a special case to handle the border
			for (; column < last_column; column += 2)
			{
				sum = 0;
				sum -= rowptr[column - 2];
				sum -= rowptr[column - 1];
				sum += rowptr[column + 2];
				sum += rowptr[column + 3];
				sum += ROUNDING(sum,8);
				sum = DivideByShift(sum, 3);
				sum += rowptr[column + 0];
				sum -= rowptr[column + 1];

				*(outptr++) = SATURATE(sum);
			}
		}

		// Should be at the last column
		assert(column == last_column);

		// Process the last column using the special border coefficients
		sum = 0;
		sum += 11 * rowptr[column + 0];
		sum -=  5 * rowptr[column + 1];
		sum -=  4 * rowptr[column - 1];
		sum -=  4 * rowptr[column - 2];
		sum +=  1 * rowptr[column - 3];
		sum +=  1 * rowptr[column - 4];
		sum +=  ROUNDING(sum,8);
		sum = DivideByShift(sum, 3);
		*(outptr++) = SATURATE(sum);

		// Advance to the next column
		rowptr += input_pitch;
		outrow += output_pitch;
	}

	//_mm_empty();	// Clear the mmx register state

#if (0 && DEBUG && _WINDOWS)
	_CrtCheckMemory();
#endif
}

#endif


#if _PROCESSOR_PENTIUM_4

#if _PROCESSOR_DISPATCH
__declspec(cpu_specific(Pentium_4))
#endif

// This version performs highpass convolution and downsampling in one pass
// and is optimized for the highpass coefficients used in the 2/6 wavelet
void FilterHighpassHorizontal(PIXEL *input, int input_pitch,
							  PIXEL *output, int output_pitch,
							  ROI roi, int input_scale, int prescale)
{
	PIXEL *rowptr = input;
	PIXEL *outrow = output;
	PIXEL *outptr;
	int row, column;
	int column_step = 8;				// Number of pixels processed per loop iteration
	int last_column = roi.width - 2;	// Column at which right border processing is done

	// The post column is the column at which end of column processing must begin
	int post_column = last_column - (last_column % column_step);

	// Cannot use 16-bit arithmetic if the input scale is too large
	bool fastmode = (input_scale < 16) ? true : FALSE;

	// Convert pitch from bytes to pixels
	input_pitch /= sizeof(PIXEL);
	output_pitch /= sizeof(PIXEL);

	for (row = 0; row < roi.height; row++)
	{
		int32_t sum;
		int32_t lsb;
		__m128i *colptr = (__m128i *)rowptr;
		__m128i input1_epi16;

		// Start at the left end of the row
		outptr = outrow;
		column = 0;

		// Process the first column as a special case
		sum = 0;
		sum +=  5 * rowptr[column + 0];
		sum -= 11 * rowptr[column + 1];
		sum +=  4 * rowptr[column + 2];
		sum +=  4 * rowptr[column + 3];
		sum -=  1 * rowptr[column + 4];
		sum -=  1 * rowptr[column + 5];
		sum += ROUNDING(sum,8);
		sum = DivideByShift(sum, 3);
		*(outptr++) = SATURATE(sum);

		// Does the input data require full range arithmetic?
		if (!fastmode)
		{
			// Already processed the first two columns using the left border formulas
			column += 2;

			// Perform the convolution using full precision arithmetic
			for (; column < last_column; column += 2) {
				int32_t sum = 0;
				int32_t lsb;
				sum -= rowptr[column - 2];
				sum -= rowptr[column - 1];
				sum += rowptr[column + 2];
				sum += rowptr[column + 3];
				sum += ROUNDING(sum,8);
				sum = DivideByShift(sum, 3);
				sum += rowptr[column + 0];
				sum -= rowptr[column + 1];

				*(outptr++) = SATURATE(sum);
			}
		}
		else
		{
			// Check that the pointer to the next group of pixels is properly aligned
			assert(ISALIGNED16(colptr));

			// Preload the first set of eight pixels for fast processing
			input1_epi16 = _mm_load_si128(colptr++);

			// Process two sets of eight input pixels to get one set of four output pixels
			for (; column < post_column; column += column_step)
			{
				__m128i input2_epi16;
				__m128i shift2_epi16;
				__m128i mask_epi16;
				__m128i sign_epi16;
				__m128i half_epi16;		// Half of the divisor for rounding
				__m128i lsb_epi16;		// Least significant bit for rounding
				__m128i sum_epi16;

				// Initialize the sum
				sum_epi16 = _mm_setzero_si128();

				// Apply the first filter coefficient to each pixel and sum the result
				sum_epi16 = _mm_subs_epi16(sum_epi16, input1_epi16);

				// Load the next eight pixels
				//input2_epi16 = *(colptr++);
				input2_epi16 = _mm_load_si128(colptr++);

				// Shift the first pixel from the second set into the working set
				shift2_epi16 = _mm_slli_si128(input2_epi16, 7*2);
				input1_epi16 = _mm_srli_si128(input1_epi16, 1*2);
				input1_epi16 = _mm_or_si128(input1_epi16, shift2_epi16);

				// Apply the second filter coefficient to each pixel and sum the result
				sum_epi16 = _mm_subs_epi16(sum_epi16, input1_epi16);

				// Shift the next pixel from the second set into the working set
				shift2_epi16 = _mm_slli_si128(input2_epi16, 6*2);
				input1_epi16 = _mm_srli_si128(input1_epi16, 1*2);
				input1_epi16 = _mm_or_si128(input1_epi16, shift2_epi16);

				// Apply the third filter coefficient to each pixel and sum the result
				sumb_epi16 = input1_epi16;

				// Shift the next pixel from the second set into the working set
				shift2_epi16 = _mm_slli_si128(input2_epi16, 5*2);
				input1_epi16 = _mm_srli_si128(input1_epi16, 1*2);
				input1_epi16 = _mm_or_si128(input1_epi16, shift2_epi16);

				// Apply the fourth filter coefficient to each pixel and sum the result
				sumb_epi16 = _mm_subs_epi16(sumb_epi16, input1_epi16);

				// Shift the next pixel from the second set into the working set
				shift2_epi16 = _mm_slli_si128(input2_epi16, 4*2);
				input1_epi16 = _mm_srli_si128(input1_epi16, 1*2);
				input1_epi16 = _mm_or_si128(input1_epi16, shift2_epi16);

				// Apply the fifth filter coefficient to each pixel and sum the result
				sum_epi16 = _mm_adds_epi16(sum_epi16, input1_epi16);

				// Shift the next pixel from the second set into the working set
				shift2_epi16 = _mm_slli_si128(input2_epi16, 3*2);
				input1_epi16 = _mm_srli_si128(input1_epi16, 1*2);
				input1_epi16 = _mm_or_si128(input1_epi16, shift2_epi16);

				// Apply the sixth (last) filter coefficient to each pixel and sum the result
				sum_epi16 = _mm_adds_epi16(sum_epi16, input1_epi16);

				half_epi16 = _mm_set1_epi16(4);
				sum_epi16 = _mm_adds_epi16(sum_epi16, half_epi16);
				sum_epi16 = _mm_srai_epi16(sum_epi16, 3);

				sum_epi16 = _mm_adds_epi16(sum_epi16, sumb_epi16);


				// Downsample and store the results
				sum_epi16 = _mm_shufflehi_epi16(sum_epi16, _MM_SHUFFLE(3, 1, 2, 0));
				sum_epi16 = _mm_shufflelo_epi16(sum_epi16, _MM_SHUFFLE(3, 1, 2, 0));
				sum_epi16 = _mm_shuffle_epi32(sum_epi16, _MM_SHUFFLE(3, 1, 2, 0));
				_mm_storel_epi64((__m128i *)outptr, sum_epi16);
				outptr += 4;

				// The second set of eight input pixels becomes the working set
				input1_epi16 = input2_epi16;
			}

			// Should have exited the loop at the post processing column
			assert(column == post_column);

			// The fast processing loop is out of phase by two columns
			if (column < last_column) column += 2;
			else outptr--;

			// Process the last group of columns as a special case to handle the border
			for (; column < last_column; column += 2)
			{
				sum = 0;
				sum -= rowptr[column - 2];
				sum -= rowptr[column - 1];
				sum += rowptr[column + 2];
				sum += rowptr[column + 3];
				sum += ROUNDING(sum,8);
				sum = DivideByShift(sum, 3);
				sum += rowptr[column + 0];
				sum -= rowptr[column + 1];

				*(outptr++) = SATURATE(sum);
			}
		}

		// Should be at the last column
		assert(column == last_column);

		// Process the last column using the special border coefficients
		sum = 0;
		sum += 11 * rowptr[column + 0];
		sum -=  5 * rowptr[column + 1];
		sum -=  4 * rowptr[column - 1];
		sum -=  4 * rowptr[column - 2];
		sum +=  1 * rowptr[column - 3];
		sum +=  1 * rowptr[column - 4];
		sum +=  ROUNDING(sum,8);
		sum = DivideByShift(sum, 3);
		*(outptr++) = SATURATE(sum);

		// Advance to the next column
		rowptr += input_pitch;
		outrow += output_pitch;
	}

	//_mm_empty();	// Clear the mmx register state

#if (0 && DEBUG && _WINDOWS)
	_CrtCheckMemory();
#endif
}

#endif //P4
#endif


#if 0
// This version performs lowpass convolution and downsampling in one pass
// and is optimized for the lowpass coefficients used in the 2/6 wavelet
void FilterLowpassHorizontal8s(PIXEL8S *input, int input_pitch, PIXEL *output, int output_pitch, ROI roi, int prescale)
{
	PIXEL8S *rowptr = input;
	PIXEL *outrow = output;
	int row, column;

	// The input width must be an even number to allow downsampling
	assert((roi.width % 2) == 0);
	roi.width -= (roi.width % 2);

	// Convert pitch from bytes to pixels
	input_pitch /= sizeof(PIXEL8S);
	output_pitch /= sizeof(PIXEL);

	for (row = 0; row < roi.height; row++) {
		// Load eight pixels and produce four output pixels per iteration
		const int column_step = 8;

		// Column at which end of row processing must begin
		const int post_column = roi.width - (roi.width % column_step);

		__m64 *input_ptr = (__m64 *)rowptr;
		__m64 *output_ptr = (__m64 *)outrow;
		PIXEL *outptr;

		// The post processing column must correspond to an integral number loop iterations
		assert((post_column % column_step) == 0);

		// Read eight pixels and sum adjacent values into four output pixels
		for (column = 0; column < post_column; column += column_step)
		{
			__m64 quad_pi8;			// Set of eight pixels
			__m64 sign_pi8;
			__m64 quad1_pi16;		// First set of four pixels
			__m64 quad2_pi16;		// Second set of four pixels
			__m64 sum1_pi16;		// First sum of pairs of pixels
			__m64 sum2_pi16;		// Second sum of pairs of pixels

			// Load eight pixels
			quad_pi8 = *(input_ptr++);

			// Unpack the first four pixels
			sign_pi8 = _mm_cmpgt_pi8(_mm_setzero_si64(), quad_pi8);
			quad1_pi16 = _mm_unpacklo_pi8(quad_pi8, sign_pi8);

			// Prescale the input
			quad1_pi16 = _mm_srai_pi16(quad1_pi16, prescale);

			// Sum the first two pixels and the second two pixels in the quadword
			sum1_pi16 = _mm_shuffle_pi16(quad1_pi16, _MM_SHUFFLE(2, 3, 0, 1));
			sum1_pi16 = _mm_adds_pi16(sum1_pi16, quad1_pi16);

			// Shuffle the pair of sums into adjacent words
			sum1_pi16 = _mm_shuffle_pi16(sum1_pi16, _MM_SHUFFLE(3, 1, 2, 0));

			// Unpack the next four pixels
			quad2_pi16 = _mm_unpackhi_pi8(quad_pi8, sign_pi8);

			// Prescale the input
			quad2_pi16 = _mm_srai_pi16(quad2_pi16, prescale);

			// Sum the first two pixels and the second two pixels in the quadword
			sum2_pi16 = _mm_shuffle_pi16(quad2_pi16, _MM_SHUFFLE(2, 3, 0, 1));
			sum2_pi16 = _mm_adds_pi16(sum2_pi16, quad2_pi16);

			// Shuffle the pair of sums into adjacent words
			sum2_pi16 = _mm_shuffle_pi16(sum2_pi16, _MM_SHUFFLE(3, 1, 2, 0));

			// Combine the sums into a single quadword
			sum1_pi16 = _mm_unpacklo_pi32(sum1_pi16, sum2_pi16);

			// Store the four results
			*(output_ptr++) = sum1_pi16;
		}

		// Should have exited the loop at the post processing column
		assert(column == post_column);

		// Process the rest of the row
		outptr = (PIXEL *)output_ptr;
		while (column < roi.width)
			*(outptr++) = (rowptr[column++] >> prescale) + (rowptr[column++] >> prescale);

		rowptr += input_pitch;
		outrow += output_pitch;
	}

	//_mm_empty();	// Clear the mmx register state
}
#endif


#if 0
#if _PROCESSOR_DISPATCH

__declspec(cpu_dispatch(Pentium_4,Generic))

void FilterHighpassHorizontal8s(PIXEL8S *input, int input_pitch,
							    PIXEL *output, int output_pitch,
							    ROI roi, int input_scale, int prescale)
{
	// Stub routine for processor specific dispatch
}
#endif


#if _PROCESSOR_GENERIC

#if _PROCESSOR_DISPATCH
__declspec(cpu_specific(Generic))
#endif

// This version performs highpass convolution and downsampling in one pass
// and is optimized for the highpass coefficients used in the 2/6 wavelet
void FilterHighpassHorizontal8s(PIXEL8S *input, int input_pitch,
							    PIXEL *output, int output_pitch,
							    ROI roi, int input_scale, int prescale)
{
	PIXEL8S *rowptr = input;
	PIXEL *outrow = output;
	PIXEL *outptr;
	int row, column;
	int column_step = 8;				// Number of pixels processed per loop iteration
	int last_column = roi.width - 2;	// Column at which right border processing is done

	// The post column is the column at which end of column processing must begin
	int post_column = last_column - (last_column % column_step);

	// Cannot use 16-bit arithmetic if the input scale is too large
	bool fastmode = (input_scale < 16) ? true : FALSE;

	// Convert pitch from bytes to pixels
	input_pitch /= sizeof(PIXEL8S);
	output_pitch /= sizeof(PIXEL);

	for (row = 0; row < roi.height; row++)
	{
		int32_t sum;
		int32_t lsb;
		__m64 *input_ptr = (__m64 *)rowptr;
		__m64 input_pi8;
		__m64 sign_pi8;
		__m64 input1_pi16;

		// Start at the left end of the row
		outptr = outrow;
		column = 0;

		// Prescale the row of input data
		PrescaleRow8s(rowptr, roi.width, prescale);

		// Process the first column as a special case
		sum = 0;
		sum +=  5 * rowptr[column + 0];
		sum -= 11 * rowptr[column + 1];
		sum +=  4 * rowptr[column + 2];
		sum +=  4 * rowptr[column + 3];
		sum -=  1 * rowptr[column + 4];
		sum -=  1 * rowptr[column + 5];
		sum += ROUNDING(sum,8);
		sum = DivideByShift(sum, 3);
		*(outptr++) = SATURATE(sum);

		// Does the input data require full range arithmetic?
		if (!fastmode)
		{
			// Already processed the first two columns using the left border formulas
			column += 2;

			// Perform the convolution using full precision arithmetic
			for (; column < last_column; column += 2) {
				int32_t sum = 0;
				int32_t lsb;
				sum -= rowptr[column - 2];
				sum -= rowptr[column - 1];
				sum += rowptr[column + 2];
				sum += rowptr[column + 3];
				sum += ROUNDING(sum,8);
				sum = DivideByShift(sum, 3);
				sum += rowptr[column + 0];
				sum -= rowptr[column + 1];

				*(outptr++) = SATURATE(sum);
			}
		}
		else
		{
			__m64 *output_ptr = (__m64 *)outptr;

			// Check that the pointer to the next group of pixels is properly aligned
			//assert(ISALIGNED16(input_ptr));

			// Preload the first set of eight pixels for fast processing
			input_pi8 = *(input_ptr++);
			sign_pi8 = _mm_cmpgt_pi8(_mm_setzero_si64(), input_pi8);

			// Unpack the first four pixels
			input1_pi16 = _mm_unpacklo_pi8(input_pi8, sign_pi8);

			// Process four sets of four input pixels to get two sets of four output pixels
			for (; column < post_column; column += column_step)
			{
				__m64 input2_pi16;
				__m64 shift2_pi16;
				__m64 mask_pi16;
				__m64 sign_pi16;
				__m64 half_pi16;	// Half of the divisor for rounding
				__m64 lsb_pi16;		// Least significant bit for rounding
				__m64 sum1_pi16;
				__m64 sum2_pi16;


				// Calculate the first set of outputs //

				// Initialize the sum
				sum1_pi16 = _mm_setzero_si64();

				// Apply the first filter coefficient to each pixel and sum the result
				sum1_pi16 = _mm_subs_pi16(sum1_pi16, input1_pi16);

				// Unpack the next four pixels
				input2_pi16 = _mm_unpackhi_pi8(input_pi8, sign_pi8);

				// Shift the first pixel from the second set into the working set
				shift2_pi16 = _mm_slli_si64(input2_pi16, 3*16);
				input1_pi16 = _mm_srli_si64(input1_pi16, 1*16);
				input1_pi16 = _mm_or_si64(input1_pi16, shift2_pi16);

				// Apply the second filter coefficient to each pixel and sum the result
				sum1_pi16 = _mm_subs_pi16(sum1_pi16, input1_pi16);

				// Shift the next pixel from the second set into the working set
				shift2_pi16 = _mm_slli_si64(input2_pi16, 2*16);
				input1_pi16 = _mm_srli_si64(input1_pi16, 1*16);
				input1_pi16 = _mm_or_si64(input1_pi16, shift2_pi16);

				// Apply the third filter coefficient to each pixel and sum the result
				sum1_pi16 = _mm_adds_pi16(sum1_pi16, _mm_slli_pi16(input1_pi16, 3));

				// Shift the next pixel from the second set into the working set
				shift2_pi16 = _mm_slli_si64(input2_pi16, 1*16);
				input1_pi16 = _mm_srli_si64(input1_pi16, 1*16);
				input1_pi16 = _mm_or_si64(input1_pi16, shift2_pi16);

				// Apply the fourth filter coefficient to each pixel and sum the result
				sum1_pi16 = _mm_subs_pi16(sum1_pi16, _mm_slli_pi16(input1_pi16, 3));

				// Shift the next pixel from the second set into the working set
				input1_pi16 = input2_pi16;

				// Apply the fifth filter coefficient to each pixel and sum the result
				sum1_pi16 = _mm_adds_pi16(sum1_pi16, input1_pi16);

				// Shift the next pixel from the second set into the working set
				input1_pi16 = _mm_srli_si64(input1_pi16, 1*16);

				// Apply the sixth (last) filter coefficient to each pixel and sum the result
				sum1_pi16 = _mm_adds_pi16(sum1_pi16, input1_pi16);

				// Expand the even output points to a full doubleword
				sum1_pi16 = _mm_slli_pi32(sum1_pi16, 16);
				sum1_pi16 = _mm_srai_pi32(sum1_pi16, 16);


				// Prepare the next set of input pixels //

				// The second four input pixels becomes the working set
				input1_pi16 = input2_pi16;

				// Load the second set of eight pixels
				input_pi8 = *(input_ptr++);
				sign_pi8 = _mm_cmpgt_pi8(_mm_setzero_si64(), input_pi8);


				// Calculate the second set of outputs //

				// Initialize the sum
				sum2_pi16 = _mm_setzero_si64();

				// Apply the first filter coefficient to each pixel and sum the result
				sum2_pi16 = _mm_subs_pi16(sum2_pi16, input1_pi16);

				// Unpack the next four pixels
				input2_pi16 = _mm_unpacklo_pi8(input_pi8, sign_pi8);

				// Shift the first pixel from the second set into the working set
				shift2_pi16 = _mm_slli_si64(input2_pi16, 3*16);
				input1_pi16 = _mm_srli_si64(input1_pi16, 1*16);
				input1_pi16 = _mm_or_si64(input1_pi16, shift2_pi16);

				// Apply the second filter coefficient to each pixel and sum the result
				sum2_pi16 = _mm_subs_pi16(sum2_pi16, input1_pi16);

				// Shift the next pixel from the second set into the working set
				shift2_pi16 = _mm_slli_si64(input2_pi16, 2*16);
				input1_pi16 = _mm_srli_si64(input1_pi16, 1*16);
				input1_pi16 = _mm_or_si64(input1_pi16, shift2_pi16);

				// Apply the third filter coefficient to each pixel and sum the result
				sum2_pi16 = _mm_adds_pi16(sum2_pi16, _mm_slli_pi16(input1_pi16, 3));

				// Shift the next pixel from the second set into the working set
				shift2_pi16 = _mm_slli_si64(input2_pi16, 1*16);
				input1_pi16 = _mm_srli_si64(input1_pi16, 1*16);
				input1_pi16 = _mm_or_si64(input1_pi16, shift2_pi16);

				// Apply the fourth filter coefficient to each pixel and sum the result
				sum2_pi16 = _mm_subs_pi16(sum2_pi16, _mm_slli_pi16(input1_pi16, 3));

				// Shift the next pixel from the second set into the working set
				input1_pi16 = input2_pi16;

				// Apply the fifth filter coefficient to each pixel and sum the result
				sum2_pi16 = _mm_adds_pi16(sum2_pi16, input1_pi16);

				// Shift the next pixel from the second set into the working set
				input1_pi16 = _mm_srli_si64(input1_pi16, 1*16);

				// Apply the sixth (last) filter coefficient to each pixel and sum the result
				sum2_pi16 = _mm_adds_pi16(sum2_pi16, input1_pi16);

				// Expand the even output points to a full doubleword
				sum2_pi16 = _mm_slli_pi32(sum2_pi16, 16);
				sum2_pi16 = _mm_srai_pi32(sum2_pi16, 16);


				// Combine the two pairs of output points //

				sum1_pi16 = _mm_packs_pi32(sum1_pi16, sum2_pi16);

				half_pi16 = _mm_set1_pi16(4);
				sum1_pi16 = _mm_adds_pi16(sum1_pi16, half_pi16);
				sum1_pi16 = _mm_srai_pi16(sum1_pi16, 3);

				// Store the four output points
				*(output_ptr++) = sum1_pi16;

				// The second set of eight input pixels becomes the working set
				input1_pi16 = input2_pi16;
			}

			// Should have exited the loop at the post processing column
			assert(column == post_column);

			outptr = (PIXEL *)output_ptr;

			// The fast processing loop is out of phase by two columns
			if (column < last_column) column += 2;
			else outptr--;

			// Process the last group of columns as a special case to handle the border
			for (; column < last_column; column += 2)
			{
				sum = 0;
				sum -= rowptr[column - 2];
				sum -= rowptr[column - 1];
				sum += rowptr[column + 2];
				sum += rowptr[column + 3];
				sum += ROUNDING(sum,8);
				sum = DivideByShift(sum, 3);
				sum += rowptr[column + 0];
				sum -= rowptr[column + 1];
				*(outptr++) = SATURATE(sum);
			}
		}

		// Should be at the last column
		assert(column == last_column);

		// Process the last column using the special border coefficients
		sum = 0;
		sum += 11 * rowptr[column + 0];
		sum -=  5 * rowptr[column + 1];
		sum -=  4 * rowptr[column - 1];
		sum -=  4 * rowptr[column - 2];
		sum +=  1 * rowptr[column - 3];
		sum +=  1 * rowptr[column - 4];
		sum +=  ROUNDING(sum,8);
		sum = DivideByShift(sum, 3);
		*(outptr++) = SATURATE(sum);

		// Advance to the next column
		rowptr += input_pitch;
		outrow += output_pitch;
	}

	//_mm_empty();	// Clear the mmx register state
}

#endif


#if _PROCESSOR_PENTIUM_4

#if _PROCESSOR_DISPATCH
__declspec(cpu_specific(Pentium_4))
#endif

// This version performs highpass convolution and downsampling in one pass
// and is optimized for the highpass coefficients used in the 2/6 wavelet
void FilterHighpassHorizontal8s(PIXEL8S *input, int input_pitch,
							    PIXEL *output, int output_pitch,
							    ROI roi, int input_scale, int prescale)
{
	PIXEL8S *rowptr = input;
	PIXEL *outrow = output;
	PIXEL *outptr;
	int row, column;
	int column_step = 16;				// Number of pixels processed per loop iteration
	int last_column = roi.width - 2;	// Column at which right border processing is done

	// The post column is the column at which end of column processing must begin
	int post_column = last_column - (last_column % column_step);

	// Cannot use 16-bit arithmetic if the input scale is too large
	bool fastmode = (input_scale < 16) ? true : FALSE;

//	post_column -= column_step;

	// Convert pitch from bytes to pixels
	input_pitch /= sizeof(PIXEL8S);
	output_pitch /= sizeof(PIXEL);

	for (row = 0; row < roi.height; row++)
	{
		int32_t sum;
		int32_t lsb;
		__m128i *colptr = (__m128i *)rowptr;
		__m128i input_epi8;
		__m128i sign_epi8;
		__m128i input1_epi16;

		// Start at the left end of the row
		outptr = outrow;
		column = 0;

		// Prescale the row of input data
		PrescaleRow8s(rowptr, roi.width, prescale);

		// Process the first column as a special case
		sum = 0;
		sum +=  5 * rowptr[column + 0];
		sum -= 11 * rowptr[column + 1];
		sum +=  4 * rowptr[column + 2];
		sum +=  4 * rowptr[column + 3];
		sum -=  1 * rowptr[column + 4];
		sum -=  1 * rowptr[column + 5];
		sum += ROUNDING(sum,8);
		sum = DivideByShift(sum, 3);
		*(outptr++) = SATURATE(sum);

		// Does the input data require full range arithmetic?
		if (!fastmode)
		{
			// Already processed the first two columns using the left border formulas
			column += 2;

			// Perform the convolution using full precision arithmetic
			for (; column < last_column; column += 2) {
				int32_t sum = 0;
				int32_t lsb;
				sum -= rowptr[column - 2];
				sum -= rowptr[column - 1];
				sum += rowptr[column + 2];
				sum += rowptr[column + 3];
				sum += ROUNDING(sum,8);
				sum = DivideByShift(sum, 3);
				sum += rowptr[column + 0];
				sum -= rowptr[column + 1];

				*(outptr++) = SATURATE(sum);
			}
		}
		else
		{
			// Check that the pointer to the next group of pixels is properly aligned
			assert(ISALIGNED16(colptr));

			// Preload the first set of sixteen pixels for fast processing
			input_epi8 = _mm_load_si128(colptr++);
			sign_epi8 = _mm_cmpgt_epi8(_mm_setzero_si128(), input_epi8);

			// Unpack the first eight pixels
			input1_epi16 = _mm_unpacklo_epi8(input_epi8, sign_epi8);

			// Process four sets of eight input pixels to get two sets of four output pixels
			for (; column < post_column; column += column_step)
			{
				__m128i input2_epi16;
				__m128i shift2_epi16;
				__m128i mask_epi16;
				__m128i sign_epi16;
				__m128i half_epi16;		// Half of the divisor for rounding
				__m128i lsb_epi16;		// Least significant bit for rounding
				__m128i sum_epi16;

				// Calculate the first set of outputs //

				// Initialize the sum
				sum_epi16 = _mm_setzero_si128();

				// Apply the first filter coefficient to each pixel and sum the result
				sum_epi16 = _mm_subs_epi16(sum_epi16, input1_epi16);

				// Unpack the next eight pixels
				//input2_epi16 = *(colptr++);
				input2_epi16 = _mm_unpackhi_epi8(input_epi8, sign_epi8);

				// Shift the first pixel from the second set into the working set
				shift2_epi16 = _mm_slli_si128(input2_epi16, 7*2);
				input1_epi16 = _mm_srli_si128(input1_epi16, 1*2);
				input1_epi16 = _mm_or_si128(input1_epi16, shift2_epi16);

				// Apply the second filter coefficient to each pixel and sum the result
				sum_epi16 = _mm_subs_epi16(sum_epi16, input1_epi16);

				// Shift the next pixel from the second set into the working set
				shift2_epi16 = _mm_slli_si128(input2_epi16, 6*2);
				input1_epi16 = _mm_srli_si128(input1_epi16, 1*2);
				input1_epi16 = _mm_or_si128(input1_epi16, shift2_epi16);

				// Apply the third filter coefficient to each pixel and sum the result
				sumb_epi16 = input1_epi16;

				// Shift the next pixel from the second set into the working set
				shift2_epi16 = _mm_slli_si128(input2_epi16, 5*2);
				input1_epi16 = _mm_srli_si128(input1_epi16, 1*2);
				input1_epi16 = _mm_or_si128(input1_epi16, shift2_epi16);

				// Apply the fourth filter coefficient to each pixel and sum the result
				sumb_epi16 = _mm_subs_epi16(sumb_epi16, input1_epi16);

				// Shift the next pixel from the second set into the working set
				shift2_epi16 = _mm_slli_si128(input2_epi16, 4*2);
				input1_epi16 = _mm_srli_si128(input1_epi16, 1*2);
				input1_epi16 = _mm_or_si128(input1_epi16, shift2_epi16);

				// Apply the fifth filter coefficient to each pixel and sum the result
				sum_epi16 = _mm_adds_epi16(sum_epi16, input1_epi16);

				// Shift the next pixel from the second set into the working set
				shift2_epi16 = _mm_slli_si128(input2_epi16, 3*2);
				input1_epi16 = _mm_srli_si128(input1_epi16, 1*2);
				input1_epi16 = _mm_or_si128(input1_epi16, shift2_epi16);

				// Apply the sixth (last) filter coefficient to each pixel and sum the result
				sum_epi16 = _mm_adds_epi16(sum_epi16, input1_epi16);

			//	mask_epi16 = _mm_cmplt_epi16(sum_epi16, _mm_setzero_si128());
				half_epi16 = _mm_set1_epi16(4);
				sum_epi16 = _mm_adds_epi16(sum_epi16, half_epi16);
				sum_epi16 = _mm_srai_epi16(sum_epi16, 3);

				sum_epi16 = _mm_adds_epi16(sum_epi16, sumb_epi16);

				// Downsample and store the results
				sum_epi16 = _mm_shufflehi_epi16(sum_epi16, _MM_SHUFFLE(3, 1, 2, 0));
				sum_epi16 = _mm_shufflelo_epi16(sum_epi16, _MM_SHUFFLE(3, 1, 2, 0));
				sum_epi16 = _mm_shuffle_epi32(sum_epi16, _MM_SHUFFLE(3, 1, 2, 0));
				_mm_storel_epi64((__m128i *)outptr, sum_epi16);
				outptr += 4;

				// The second set of eight input pixels becomes the working set
				input1_epi16 = input2_epi16;


				// Calculate the second set of outputs //


				// Preload the next set of sixteen pixels for fast processing
				input_epi8 = _mm_load_si128(colptr++);
				sign_epi8 = _mm_cmpgt_epi8(_mm_setzero_si128(), input_epi8);


				// Initialize the sum
				sum_epi16 = _mm_setzero_si128();

				// Apply the first filter coefficient to each pixel and sum the result
				sum_epi16 = _mm_subs_epi16(sum_epi16, input1_epi16);

				// Unpack the first eight pixels
				input2_epi16 = _mm_unpacklo_epi8(input_epi8, sign_epi8);

				// Shift the first pixel from the second set into the working set
				shift2_epi16 = _mm_slli_si128(input2_epi16, 7*2);
				input1_epi16 = _mm_srli_si128(input1_epi16, 1*2);
				input1_epi16 = _mm_or_si128(input1_epi16, shift2_epi16);

				// Apply the second filter coefficient to each pixel and sum the result
				sum_epi16 = _mm_subs_epi16(sum_epi16, input1_epi16);

				// Shift the next pixel from the second set into the working set
				shift2_epi16 = _mm_slli_si128(input2_epi16, 6*2);
				input1_epi16 = _mm_srli_si128(input1_epi16, 1*2);
				input1_epi16 = _mm_or_si128(input1_epi16, shift2_epi16);

				// Apply the third filter coefficient to each pixel and sum the result
				sumb_epi16 = input1_epi16;

				// Shift the next pixel from the second set into the working set
				shift2_epi16 = _mm_slli_si128(input2_epi16, 5*2);
				input1_epi16 = _mm_srli_si128(input1_epi16, 1*2);
				input1_epi16 = _mm_or_si128(input1_epi16, shift2_epi16);

				// Apply the fourth filter coefficient to each pixel and sum the result
				sumb_epi16 = _mm_subs_epi16(sumb_epi16, input1_epi16);

				// Shift the next pixel from the second set into the working set
				shift2_epi16 = _mm_slli_si128(input2_epi16, 4*2);
				input1_epi16 = _mm_srli_si128(input1_epi16, 1*2);
				input1_epi16 = _mm_or_si128(input1_epi16, shift2_epi16);

				// Apply the fifth filter coefficient to each pixel and sum the result
				sum_epi16 = _mm_adds_epi16(sum_epi16, input1_epi16);

				// Shift the next pixel from the second set into the working set
				shift2_epi16 = _mm_slli_si128(input2_epi16, 3*2);
				input1_epi16 = _mm_srli_si128(input1_epi16, 1*2);
				input1_epi16 = _mm_or_si128(input1_epi16, shift2_epi16);

				// Apply the sixth (last) filter coefficient to each pixel and sum the result
				sum_epi16 = _mm_adds_epi16(sum_epi16, input1_epi16);

			//	mask_epi16 = _mm_cmplt_epi16(sum_epi16, _mm_setzero_si128());
				half_epi16 = _mm_set1_epi16(4);
				sum_epi16 = _mm_adds_epi16(sum_epi16, half_epi16);
				sum_epi16 = _mm_srai_epi16(sum_epi16, 3);

				sum_epi16 = _mm_adds_epi16(sum_epi16, sumb_epi16);

				// Downsample and store the results
				sum_epi16 = _mm_shufflehi_epi16(sum_epi16, _MM_SHUFFLE(3, 1, 2, 0));
				sum_epi16 = _mm_shufflelo_epi16(sum_epi16, _MM_SHUFFLE(3, 1, 2, 0));
				sum_epi16 = _mm_shuffle_epi32(sum_epi16, _MM_SHUFFLE(3, 1, 2, 0));
				_mm_storel_epi64((__m128i *)outptr, sum_epi16);
				outptr += 4;

				// The second set of eight input pixels becomes the working set
				input1_epi16 = input2_epi16;
			}

			// Should have exited the loop at the post processing column
			assert(column == post_column);

			// The fast processing loop is out of phase by two columns
			if (column < last_column) column += 2;
			else outptr--;

			// Process the last group of columns as a special case to handle the border
			for (; column < last_column; column += 2)
			{
				sum = 0;
				sum -= rowptr[column - 2];
				sum -= rowptr[column - 1];
				sum += rowptr[column + 2];
				sum += rowptr[column + 3];
				sum += ROUNDING(sum,8);
				sum = DivideByShift(sum, 3);
				sum += rowptr[column + 0];
				sum -= rowptr[column + 1];

				*(outptr++) = SATURATE(sum);
			}
		}

		// Should be at the last column
		assert(column == last_column);

		// Process the last column using the special border coefficients
		sum = 0;
		sum += 11 * rowptr[column + 0];
		sum -=  5 * rowptr[column + 1];
		sum -=  4 * rowptr[column - 1];
		sum -=  4 * rowptr[column - 2];
		sum +=  1 * rowptr[column - 3];
		sum +=  1 * rowptr[column - 4];
		sum +=  ROUNDING(sum,8);
		sum = DivideByShift(sum, 3);
		*(outptr++) = SATURATE(sum);

		// Advance to the next column
		rowptr += input_pitch;
		outrow += output_pitch;
	}

	//_mm_empty();	// Clear the mmx register state
}

#endif //p4
#endif


#if 0
// Apply the lowpass and highpass vertical filters in one pass
void FilterVertical(PIXEL *input, int input_pitch,
					PIXEL *lowpass, int lowpass_pitch,
					PIXEL *highpass, int highpass_pitch,
					ROI roi)
{
	PIXEL *rowptr = input;
	PIXEL *lowpass_row_ptr = lowpass;
	PIXEL *highpass_row_ptr = highpass;
	PIXEL *lowptr;
	PIXEL *highptr;
	int last_row = roi.height - 2;
	int row, column;

	// Convert pitch from bytes to pixels
	input_pitch /= sizeof(PIXEL);
	lowpass_pitch /= sizeof(PIXEL);
	highpass_pitch /= sizeof(PIXEL);

	// Must have an even number of rows
	assert((roi.height % 2) == 0);

	// Need to optimize the first and last rows //

	// Use border filters for the first row
	row = 0;
	lowptr = lowpass_row_ptr;
	highptr = highpass_row_ptr;

	for (column = 0; column < roi.width; column++)
	{
		int32_t sum;

		// Apply the lowpass filter
		sum  = rowptr[column + 0 * input_pitch];
		sum += rowptr[column + 1 * input_pitch];
		*(lowptr++) = SATURATE(sum);

		// Apply the highpass filter
		sum  =  5 * rowptr[column + 0 * input_pitch];
		sum -= 11 * rowptr[column + 1 * input_pitch];
		sum +=  4 * rowptr[column + 2 * input_pitch];
		sum +=  4 * rowptr[column + 3 * input_pitch];
		sum -=  1 * rowptr[column + 4 * input_pitch];
		sum -=  1 * rowptr[column + 5 * input_pitch];
		sum += ROUNDING(sum,8);
		sum = DivideByShift(sum, 3);
		*(highptr++) = SATURATE(sum);
	}

	lowpass_row_ptr += lowpass_pitch;		// Advance to the next lowpass row
	highpass_row_ptr += highpass_pitch;		// Advance to the next highpass row
	row += 2;								// Advance the row being processed

	for (; row < last_row; row += 2)
	{
#if (1 && XMMOPT)
		int column_step = 4;
		int post_column = roi.width - (roi.width % column_step);
		int quad_pitch = (input_pitch * sizeof(PIXEL))/sizeof(__m64);
		__m64 *lowpass_ptr = (__m64 *)lowpass_row_ptr;
		__m64 *highpass_ptr = (__m64 *)highpass_row_ptr;
#endif
		// Start at the first column
		column = 0;

#if (1 && XMMOPT)

		// Process a group of four pixels at a time
		for (; column < post_column; column += column_step) {
			__m64 *quad_ptr = (__m64 *)&rowptr[column];
			__m64 low_pi16;
			__m64 sum_pi16 = _mm_setzero_si64();
			__m64 quad_pi16;
			__m64 mask_pi16;
			__m64 half_pi16;
			//__m64 lsb_pi16;

			// Load first row of four pixels
			quad_pi16 = *quad_ptr;
			quad_ptr += quad_pitch;

			// Multiply each pixel by the first filter coefficient and sum the result
			sum_pi16 = _mm_subs_pi16(sum_pi16, quad_pi16);

			// Load the second row of four pixels
			quad_pi16 = *quad_ptr;
			quad_ptr += quad_pitch;

			// Multiply each pixel by the second filter coefficient and sum the result
			sum_pi16 = _mm_subs_pi16(sum_pi16, quad_pi16);

			// Load the third row of four pixels
			quad_pi16 = *quad_ptr;
			quad_ptr += quad_pitch;

			// Initialize the lowpass sum
			low_pi16 = quad_pi16;

			// Multiply each pixel by the third filter coefficient and sum the result
			quad_pi16 = _mm_slli_pi16(quad_pi16, 3);
			sum_pi16 = _mm_adds_pi16(sum_pi16, quad_pi16);

			// Load the fourth row of four pixels
			quad_pi16 = *quad_ptr;
			quad_ptr += quad_pitch;

			// Compute and store the four lowpass results
			low_pi16 = _mm_adds_pi16(low_pi16, quad_pi16);
			*(lowpass_ptr++) = low_pi16;

			// Multiply each pixel by the fourth filter coefficient and sum the result
			quad_pi16 = _mm_slli_pi16(quad_pi16, 3);
			sum_pi16 = _mm_subs_pi16(sum_pi16, quad_pi16);

			// Load the fifth row of four pixels
			quad_pi16 = *quad_ptr;
			quad_ptr += quad_pitch;

			// Multiply each pixel by the fifth filter coefficient and sum the result
			sum_pi16 = _mm_adds_pi16(sum_pi16, quad_pi16);

			// Load the sixth (last) row of four pixels
			quad_pi16 = *quad_ptr;

			// Multiply each pixel by the sixth filter coefficient and sum the result
			sum_pi16 = _mm_adds_pi16(sum_pi16, quad_pi16);

			// Approximate division by eight
			half_pi16 = _mm_set1_pi16(4);
			sum_pi16 = _mm_srai_pi16(sum_pi16, 3);
			sum_pi16 = _mm_adds_pi16(sum_pi16, half_pi16);

			// Store the four highpass results
			*(highpass_ptr++) = sum_pi16;
		}

		// Should have terminated the fast loop at the post processing column
		assert(column == post_column);
#endif

		// Process the remaining pixels to the end of the column
		lowptr = &lowpass_row_ptr[column];
		highptr = &highpass_row_ptr[column];

		for (; column < roi.width; column++)
		{
			int32_t sum;

			// Compute the lowpass result
			sum  = rowptr[column + 0 * input_pitch];
			sum += rowptr[column + 1 * input_pitch];
			*(lowptr++) = SATURATE(sum);

			// Compute the highpass result
			sum  = rowptr[column + 0 * input_pitch];
			sum -= rowptr[column + 1 * input_pitch];
			sum += rowptr[column + 4 * input_pitch];
			sum += rowptr[column + 5 * input_pitch];
			sum += ROUNDING(sum,8);
			sum = DivideByShift(sum, 3);
			sum += rowptr[column + 2 * input_pitch];
			sum -= rowptr[column + 3 * input_pitch];
			*(highptr++) = SATURATE(sum);
		}

		// Advance to the next input and output row
		rowptr += 2 * input_pitch;
		lowpass_row_ptr += lowpass_pitch;
		highpass_row_ptr += highpass_pitch;
	}

	// Should have left the loop at the last row
	assert(row == last_row);

#if (1 && XMMOPT)
	// Need to advance the row pointer if using SIMD instructions
	rowptr += 2 * input_pitch;
#endif

	// Use the border filters for the last row
	lowptr = lowpass_row_ptr;
	highptr = highpass_row_ptr;

	for (column = 0; column < roi.width; column++)
	{
		int32_t sum;

		// Compute the lowpass result
		sum  = rowptr[column + 0 * input_pitch];
		sum += rowptr[column + 1 * input_pitch];
		*(lowptr++) = SATURATE(sum);

		// Compute the highpass result
		sum  = 11 * rowptr[column + 0 * input_pitch];
		sum -=  5 * rowptr[column + 1 * input_pitch];
		sum -=  4 * rowptr[column - 1 * input_pitch];
		sum -=  4 * rowptr[column - 2 * input_pitch];
		sum +=  1 * rowptr[column - 3 * input_pitch];
		sum +=  1 * rowptr[column - 4 * input_pitch];
		sum +=  ROUNDING(sum,8);
		sum = DivideByShift(sum, 3);
		*(highptr++) = SATURATE(sum);
	}

	//_mm_empty();	// Clear the mmx register state
}
#endif


#if 0

// This version performs lowpass convolution and downsampling in one pass
// and is optimized for the lowpass coefficients used in the 2/6 wavelet
void FilterLowpassVertical(PIXEL *input, int input_pitch, PIXEL *output, int output_pitch, ROI roi)
{
	PIXEL *rowptr = input;
	PIXEL *outrow = output;
	int row, column;

	// Convert pitch from bytes to pixels
	input_pitch /= sizeof(PIXEL);
	output_pitch /= sizeof(PIXEL);

	for (row = 0; row < roi.height; row += 2)
	{
#if (1 && XMMOPT)
		__m64 *quad1_ptr = (__m64 *)rowptr;
		__m64 *quad2_ptr = (__m64 *)&rowptr[input_pitch];
		__m64 *outptr = (__m64 *)outrow;

		// Process four pixels per iteration
		int column_step = 4;

		// Read four pixels from two rows and sum into four output pixels
		for (column = 0; column < roi.width; column += column_step)
		{
			__m64 quad_pi16;		// Quadword of four pixels
			__m64 sum_pi16;			// Sum of four of pixels

			// Load four pixels and advance to the next four pixels in the row
			sum_pi16 = *(quad1_ptr++);

			// Load four pixels from the next row and advance along that row
			quad_pi16 = *(quad2_ptr++);

			// Sum the two sets of four pixels
			sum_pi16 = _mm_adds_pi16(sum_pi16, quad_pi16);

			// Store the four sums
			*(outptr++) = sum_pi16;
		}
#else
		PIXEL *outptr = outrow;
		for (column = 0; column < roi.width; column++)
			*(outptr++) = rowptr[column] + rowptr[column + input_pitch];
#endif
		rowptr += 2 * input_pitch;		// Skip the next row of input pixels
		outrow += output_pitch;			// Advance to the next output row
	}

	//_mm_empty();	// Clear the mmx register state
}
#endif

#if 0

// Apply the lowpass vertical filter and quantize the results to eight bit pixels
void FilterLowpassVerticalQuant(PIXEL *input, int input_pitch, PIXEL8S *output, int output_pitch,
								ROI roi, int quantization)
{
	PIXEL *rowptr = input;
	PIXEL8S *outrow = output;
	int row;

	// Convert pitch from bytes to pixels
	input_pitch /= sizeof(PIXEL);
	output_pitch /= sizeof(PIXEL8S);

	for (row = 0; row < roi.height; row += 2)
	{
		int column = 0;

#if (1 && XMMOPT)

		__m64 *quad1_ptr = (__m64 *)rowptr;
		__m64 *quad2_ptr = (__m64 *)&rowptr[input_pitch];
		__m64 *outptr = (__m64 *)outrow;

		// Process eight pixels per loop iteration
		int column_step = 8;
		int post_column = roi.width - (roi.width % column_step);

		// Read four pixels from two rows and sum into four output pixels
		for (; column < post_column; column += column_step)
		{
			__m64 quad_pi16;		// Quadword of four pixels
			__m64 sum1_pi16;		// Sum of four of pixels
			__m64 sum2_pi16;		// Sum of four of pixels
			__m64 sum_pi8;			// Packed sum of eight pixels

			// Load four pixels and advance to the next four pixels in the row
			sum1_pi16 = *(quad1_ptr++);

			// Load four pixels from the next row and advance along that row
			quad_pi16 = *(quad2_ptr++);

			// Sum the two sets of four pixels
			sum1_pi16 = _mm_adds_pi16(sum1_pi16, quad_pi16);

			// Load four pixels and advance to the next four pixels in the row
			sum2_pi16 = *(quad1_ptr++);

			// Load four pixels from the next row and advance along that row
			quad_pi16 = *(quad2_ptr++);

			// Sum the two sets of four pixels
			sum2_pi16 = _mm_adds_pi16(sum2_pi16, quad_pi16);

			// Pack the two vectors of four sums
			sum_pi8 = _mm_packs_pi16(sum1_pi16, sum2_pi16);

			// Need to perform quantization //

			// Store the eight packed sums
			*(outptr++) = sum_pi8;
		}

		//_mm_empty();	// Clear the mmx register state

		// Check that the loop terminated at the post processing column
		assert(column == post_column);
#endif

		// Process the rest of the output row
		for (; column < roi.width; column++)
		{
			outrow[column] = rowptr[column] + rowptr[column + input_pitch];
		}

		rowptr += 2 * input_pitch;		// Skip the next row of input pixels
		outrow += output_pitch;			// Advance to the next output row
	}
}
#endif


#if 0
#if _PROCESSOR_DISPATCH

__declspec(cpu_dispatch(Pentium_4,Generic))

void FilterHighpassVertical(PIXEL *input, int input_pitch, PIXEL *output, int output_pitch, ROI roi)
{
	// Stub routine for processor specific dispatch
}
#endif


#if _PROCESSOR_GENERIC

#if _PROCESSOR_DISPATCH
__declspec(cpu_specific(Generic))
#endif

// This version performs highpass convolution and downsampling in one pass
// and is optimized for the highpass coefficients used in the 2/6 wavelet
void FilterHighpassVertical(PIXEL *input, int input_pitch, PIXEL *output, int output_pitch, ROI roi)
{
	PIXEL *rowptr = input;
	PIXEL *outrow = output;
	PIXEL *outptr;
	int last_row = roi.height - 2;
	int row, column;

	// Convert pitch from bytes to pixels
	input_pitch /= sizeof(PIXEL);
	output_pitch /= sizeof(PIXEL);

	// Must have an even number of rows
	assert((roi.height % 2) == 0);

	// Use border filters for the first row
	row = 0;
	outptr = outrow;
	for (column = 0; column < roi.width; column++) {
		int32_t sum = 0;
		sum +=  5 * rowptr[column + 0 * input_pitch];
		sum -= 11 * rowptr[column + 1 * input_pitch];
		sum +=  4 * rowptr[column + 2 * input_pitch];
		sum +=  4 * rowptr[column + 3 * input_pitch];
		sum -=  1 * rowptr[column + 4 * input_pitch];
		sum -=  1 * rowptr[column + 5 * input_pitch];
		sum += ROUNDING(sum,8);
		sum = DivideByShift(sum, 3);
		*(outptr++) = SATURATE(sum);
	}

#if 0
	// Advance to the second input row if not using the SIMD version below since
	// the SIMD version reads the previous (in this case the first) row again
	rowptr += 2 * input_pitch;
#endif
	outrow += output_pitch;		// Advance to the next output row
	row += 2;					// Advance the row being processed

	for (; row < last_row; row += 2)
	{
#if (1 && XMMOPT)
		int column_step = 4;
		int post_column = roi.width - (roi.width % column_step);
		int quad_pitch = (input_pitch * sizeof(PIXEL))/sizeof(__m64);
		__m64 *output_ptr = (__m64 *)outrow;
#endif
		// Start at the first column
		column = 0;

#if (1 && XMMOPT)

		// Process a group of four pixels at a time
		for (; column < post_column; column += column_step) {
			__m64 *quad_ptr = (__m64 *)&rowptr[column];
			__m64 sum_pi16 = _mm_setzero_si64();
			__m64 quad_pi16;
			__m64 mask_pi16;
			__m64 half_pi16;
			__m64 lsb_pi16;

			// Load first row of four pixels
			quad_pi16 = *quad_ptr;
			quad_ptr += quad_pitch;

			// Multiply each pixel by the first filter coefficient and sum the result
			sum_pi16 = _mm_subs_pi16(sum_pi16, quad_pi16);

			// Load the second row of four pixels
			quad_pi16 = *quad_ptr;
			quad_ptr += quad_pitch;

			// Multiply each pixel by the second filter coefficient and sum the result
			sum_pi16 = _mm_subs_pi16(sum_pi16, quad_pi16);

			// Load the third row of four pixels
			quad_pi16 = *quad_ptr;
			quad_ptr += quad_pitch;

			// Multiply each pixel by the third filter coefficient and sum the result
			quad_pi16 = _mm_slli_pi16(quad_pi16, 3);
			sum_pi16 = _mm_adds_pi16(sum_pi16, quad_pi16);

			// Load the fourth row of four pixels
			quad_pi16 = *quad_ptr;
			quad_ptr += quad_pitch;

			// Multiply each pixel by the fourth filter coefficient and sum the result
			quad_pi16 = _mm_slli_pi16(quad_pi16, 3);
			sum_pi16 = _mm_subs_pi16(sum_pi16, quad_pi16);

			// Load the fifth row of four pixels
			quad_pi16 = *quad_ptr;
			quad_ptr += quad_pitch;

			// Multiply each pixel by the fifth filter coefficient and sum the result
			sum_pi16 = _mm_adds_pi16(sum_pi16, quad_pi16);

			// Load the sixth (last) row of four pixels
			quad_pi16 = *quad_ptr;

			// Multiply each pixel by the sixth filter coefficient and sum the result
			sum_pi16 = _mm_adds_pi16(sum_pi16, quad_pi16);

			// Approximate division by eight
			half_pi16 = _mm_set1_pi16(4);
			sum_pi16 = _mm_srai_pi16(sum_pi16, 3);
			sum_pi16 = _mm_adds_pi16(sum_pi16, half_pi16);

			// Store the four results
			*(output_ptr++) = sum_pi16;
		}

		// Should have terminated the fast loop at the post processing column
		assert(column == post_column);
#endif

		// Process the remaining pixels to the end of the column
		outptr = &outrow[column];
		for (; column < roi.width; column++)
		{
			int32_t sum = 0;
			sum -= rowptr[column + 0 * input_pitch];
			sum -= rowptr[column + 1 * input_pitch];
			sum += rowptr[column + 4 * input_pitch];
			sum += rowptr[column + 5 * input_pitch];
			sum += ROUNDING(sum,8);
			sum = DivideByShift(sum, 3);
			sum += rowptr[column + 2 * input_pitch];
			sum -= rowptr[column + 3 * input_pitch];
			*(outptr++) = SATURATE(sum);
		}

		// Advance to the next input and output row
		rowptr += 2 * input_pitch;
		outrow += output_pitch;
	}

	// Should have left the loop at the last row
	assert(row == last_row);

#if (1 && XMMOPT)
	// Need to advance the row pointer if using SIMD instructions
	rowptr += 2 * input_pitch;
#endif

	// Use the border filters for the last row
	outptr = outrow;
	for (column = 0; column < roi.width; column++) {
		int32_t sum = 0;
		sum += 11 * rowptr[column + 0 * input_pitch];
		sum -=  5 * rowptr[column + 1 * input_pitch];
		sum -=  4 * rowptr[column - 1 * input_pitch];
		sum -=  4 * rowptr[column - 2 * input_pitch];
		sum +=  1 * rowptr[column - 3 * input_pitch];
		sum +=  1 * rowptr[column - 4 * input_pitch];
		sum +=  ROUNDING(sum,8);
		sum = DivideByShift(sum, 3);
		*(outptr++) = SATURATE(sum);
	}

	//_mm_empty();	// Clear the mmx register state
}

#endif


#if _PROCESSOR_PENTIUM_4

#if _PROCESSOR_DISPATCH
__declspec(cpu_specific(Pentium_4))
#endif

// This version performs highpass convolution and downsampling in one pass
// and is optimized for the highpass coefficients used in the 2/6 wavelet
void FilterHighpassVertical(PIXEL *input, int input_pitch, PIXEL *output, int output_pitch, ROI roi)
{
	PIXEL *rowptr = input;
	PIXEL *outrow = output;
	PIXEL *outptr;
	int last_row = roi.height - 2;
	int row, column;

	// Convert pitch from bytes to pixels
	input_pitch /= sizeof(PIXEL);
	output_pitch /= sizeof(PIXEL);

	// Must have an even number of rows
	assert((roi.height % 2) == 0);

	// Use border filters for the first row
	row = 0;
	outptr = outrow;
	for (column = 0; column < roi.width; column++) {
		int32_t sum = 0;
		sum +=  5 * rowptr[column + 0 * input_pitch];
		sum -= 11 * rowptr[column + 1 * input_pitch];
		sum +=  4 * rowptr[column + 2 * input_pitch];
		sum +=  4 * rowptr[column + 3 * input_pitch];
		sum -=  1 * rowptr[column + 4 * input_pitch];
		sum -=  1 * rowptr[column + 5 * input_pitch];
		sum += ROUNDING(sum,8);
		sum = DivideByShift(sum, 3);
		*(outptr++) = SATURATE(sum);
	}

#if 0
	// Advance to the second input row if not using the SIMD version below since
	// the SIMD version reads the previous (in this case the first) row again
	rowptr += 2 * input_pitch;
#endif
	outrow += output_pitch;		// Advance to the next output row
	row += 2;					// Advance the row being processed

	for (; row < last_row; row += 2)
	{
#if (1 && XMMOPT)
		const int column_step = 8;
		const int post_column = roi.width - (roi.width % column_step);
		int group_pitch = (input_pitch * sizeof(PIXEL))/sizeof(__m128i);
		__m128i *output_ptr = (__m128i *)outrow;

		// Can handle a row length that is not a multiple of the column step
		//assert((roi.width % column_step) == 0);
#endif
		// Start at the first column
		column = 0;

#if (1 && XMMOPT)
		// Process a group of eight pixels at a time
		for (; column < post_column; column += column_step)
		{
			__m128i *group_ptr = (__m128i *)&rowptr[column];
			__m128i sum_epi16 = _mm_setzero_si128();
			__m128i group_epi16;
			__m128i mask_epi16;
			__m128i half_epi16;
			__m128i sign_epi16;
			__m128i lsb_epi16;

			// Check that the pointer to the next group of pixels is properly aligned
			assert(ISALIGNED16(group_ptr));

			// Check that the output pointer is properly aligned
			assert(ISALIGNED16(output_ptr));

			// Load the first row of eight pixels
			group_epi16 = _mm_load_si128(group_ptr);
			group_ptr += group_pitch;

			// Multiply each pixel by the first filter coefficient and sum the result
			sum_epi16 = _mm_subs_epi16(sum_epi16, group_epi16);

			// Load the second row of eight pixels
			group_epi16 = _mm_load_si128(group_ptr);
			group_ptr += group_pitch;

			// Multiply each pixel by the second filter coefficient and sum the result
			sum_epi16 = _mm_subs_epi16(sum_epi16, group_epi16);

			// Load the third row of four pixels
			group_epi16 = _mm_load_si128(group_ptr);
			group_ptr += group_pitch;

			// Multiply each pixel by the third filter coefficient and sum the result
			group_epi16 = _mm_slli_epi16(group_epi16, 3);
			sum_epi16 = _mm_adds_epi16(sum_epi16, group_epi16);

			// Load the fourth row of four pixels
			group_epi16 = _mm_load_si128(group_ptr);
			group_ptr += group_pitch;

			// Multiply each pixel by the fourth filter coefficient and sum the result
			group_epi16 = _mm_slli_epi16(group_epi16, 3);
			sum_epi16 = _mm_subs_epi16(sum_epi16, group_epi16);

			// Load the fifth row of four pixels
			group_epi16 = _mm_load_si128(group_ptr);
			group_ptr += group_pitch;

			// Multiply each pixel by the fifth filter coefficient and sum the result
			sum_epi16 = _mm_adds_epi16(sum_epi16, group_epi16);

			// Load the sixth (last) row of four pixels
			group_epi16 = _mm_load_si128(group_ptr);

			// Multiply each pixel by the sixth filter coefficient and sum the result
			sum_epi16 = _mm_adds_epi16(sum_epi16, group_epi16);

			// Divide  by eight
			half_epi16 = _mm_set1_epi16(4);
			sum_epi16 = _mm_adds_epi16(sum_epi16, half_epi16);
			sum_epi16 = _mm_srai_epi16(sum_epi16, 3);

			// Store the eight results
			_mm_store_si128(output_ptr++, sum_epi16);
		}

		// Should have terminated the fast loop at the post processing column
		assert(column == post_column);
#endif
		// Process the remaining pixels to the end of the column
		outptr = (PIXEL *)output_ptr;
		for (; column < roi.width; column++)
		{
			int32_t sum = 0;
			//int32_t lsb;
			sum -= rowptr[column + 0 * input_pitch];
			sum -= rowptr[column + 1 * input_pitch];
			sum += rowptr[column + 4 * input_pitch];
			sum += rowptr[column + 5 * input_pitch];
			sum += ROUNDING(sum,8);
			sum = DivideByShift(sum, 3);
			sum += rowptr[column + 2 * input_pitch];
			sum -= rowptr[column + 3 * input_pitch];

			*(outptr++) = SATURATE(sum);
		}

		rowptr += 2 * input_pitch;
		outrow += output_pitch;
	}

	// Should have left the loop at the last row
	assert(row == last_row);

#if 1
	// Need to advance the row pointer if using SIMD instructions
	rowptr += 2 * input_pitch;
#endif

	// Use the border filters for the last row
	outptr = outrow;
	for (column = 0; column < roi.width; column++) {
		int32_t sum = 0;
		sum += 11 * rowptr[column + 0 * input_pitch];
		sum -=  5 * rowptr[column + 1 * input_pitch];
		sum -=  4 * rowptr[column - 1 * input_pitch];
		sum -=  4 * rowptr[column - 2 * input_pitch];
		sum +=  1 * rowptr[column - 3 * input_pitch];
		sum +=  1 * rowptr[column - 4 * input_pitch];
		sum +=  ROUNDING(sum,8);
		sum = DivideByShift(sum, 3);
		*(outptr++) = SATURATE(sum);
	}

	//_mm_empty();	// Clear the mmx register state
}

#endif //P4
#endif


#if 0

// This version performs lowpass convolution and downsampling in one pass
// and is optimized for the lowpass coefficients used in the 2/6 wavelet
void FilterLowpassVerticalScaled(PIXEL *input, int input_pitch, PIXEL *output, int output_pitch, ROI roi)
{
//	Ipp32s kernel[2] = {1, 1};
	int kernel_length = 2;
	int scale = 1;
	PIXEL *rowptr = input;
	PIXEL *outrow = output;
	int anchor = kernel_length - 1;
	int row, column;
	int half = scale/2;

	// Convert pitch from bytes to pixels
	input_pitch /= sizeof(PIXEL);
	output_pitch /= sizeof(PIXEL);

	for (row = 0; row < roi.height; row += 2) {
		__m64 *quad1_ptr = (__m64 *)rowptr;
		__m64 *quad2_ptr = (__m64 *)&rowptr[input_pitch];
		__m64 *outptr = (__m64 *)outrow;

		// Process four pixels per iteration
		int column_step = 4;

		// Read four pixels from two rows and sum into four output pixels
		for (column = 0; column < roi.width; column += column_step)
		{
			__m64 quad_pi16;		// Quadword of four pixels
			__m64 sum_pi16;			// Sum of four of pixels

			// Load four pixels and advance to the next four pixels in the row
			sum_pi16 = *(quad1_ptr++);

			// Load four pixels from the next row and advance along that row
			quad_pi16 = *(quad2_ptr++);

			// Sum the two sets of four pixels
			sum_pi16 = _mm_adds_pi16(sum_pi16, quad_pi16);

			// Store the four sums
			*(outptr++) = sum_pi16;
		}
		rowptr += 2 * input_pitch;		// Skip the next row of input pixels
		outrow += output_pitch;			// Advance to the next output row
	}

	//_mm_empty();	// Clear the mmx register state
}
#endif

#if 0

// Apply the highpass vertical filter and quantize the results to eight bit pixels
void FilterHighpassVerticalQuant(PIXEL *input, int input_pitch, PIXEL8S *output, int output_pitch,
								 ROI roi, int quantization)
{
	PIXEL *rowptr = input;
	PIXEL8S *outrow = output;
	PIXEL8S *outptr;
	int last_row = roi.height - 2;
	int row, column;

	// Convert pitch from bytes to pixels
	input_pitch /= sizeof(PIXEL);
	output_pitch /= sizeof(PIXEL8S);

	// Must have an even number of rows
	assert((roi.height % 2) == 0);

	// Use border filters for the first row
	row = 0;
	outptr = outrow;
	for (column = 0; column < roi.width; column++) {
		int32_t sum = 0;
		sum +=  5 * rowptr[column + 0 * input_pitch];
		sum -= 11 * rowptr[column + 1 * input_pitch];
		sum +=  4 * rowptr[column + 2 * input_pitch];
		sum +=  4 * rowptr[column + 3 * input_pitch];
		sum -=  1 * rowptr[column + 4 * input_pitch];
		sum -=  1 * rowptr[column + 5 * input_pitch];
		sum += ROUNDING(sum,8);
		sum = DivideByShift(sum, 3);
		sum /= quantization;
		*(outptr++) = HIGHPASS(sum);
	}

#if 0
	// Advance to the second input row if not using the SIMD version below since
	// the SIMD version reads the previous (in this case the first) row again
	rowptr += 2 * input_pitch;
#endif
	outrow += output_pitch;		// Advance to the next output row
	row += 2;					// Advance the row being processed

	for (; row < last_row; row += 2)
	{
#if (1 && XMMOPT)
		int column_step = 8;
		int post_column = roi.width - (roi.width % column_step);
		int quad_pitch = (input_pitch * sizeof(PIXEL))/sizeof(__m64);
		__m64 *output_ptr = (__m64 *)outrow;
#endif
		// Start at the first column
		column = 0;

#if (1 && XMMOPT)
		// Process a group of four pixels at a time
		for (; column < post_column; column += column_step)
		{
			__m64 *quad_ptr = (__m64 *)&rowptr[column];
			__m64 sum1_pi16 = _mm_setzero_si64();
			__m64 sum2_pi16 = _mm_setzero_si64();
			__m64 quad1_pi16;
			__m64 quad2_pi16;
			__m64 mask_pi16;
			__m64 half_pi16;
			//__m64 lsb_pi16;
			__m64 sum_pi8;

			// Load first row of eight pixels
			quad1_pi16 = *quad_ptr;
			quad2_pi16 = *(quad_ptr + 1);
			quad_ptr += quad_pitch;

			// Multiply each pixel by the first filter coefficient and sum the result
			sum1_pi16 = _mm_subs_pi16(sum1_pi16, quad1_pi16);
			sum2_pi16 = _mm_subs_pi16(sum2_pi16, quad2_pi16);

			// Load the second row of four pixels
			quad1_pi16 = *quad_ptr;
			quad2_pi16 = *(quad_ptr + 1);
			quad_ptr += quad_pitch;

			// Multiply each pixel by the second filter coefficient and sum the result
			sum1_pi16 = _mm_subs_pi16(sum1_pi16, quad1_pi16);
			sum2_pi16 = _mm_subs_pi16(sum2_pi16, quad2_pi16);

			// Load the third row of four pixels
			quad1_pi16 = *quad_ptr;
			quad2_pi16 = *(quad_ptr + 1);
			quad_ptr += quad_pitch;

			// Multiply each pixel by the third filter coefficient and sum the result
			quad1_pi16 = _mm_slli_pi16(quad1_pi16, 3);
			quad2_pi16 = _mm_slli_pi16(quad2_pi16, 3);
			sum1_pi16 = _mm_adds_pi16(sum1_pi16, quad1_pi16);
			sum2_pi16 = _mm_adds_pi16(sum2_pi16, quad2_pi16);

			// Load the fourth row of four pixels
			quad1_pi16 = *quad_ptr;
			quad2_pi16 = *(quad_ptr + 1);
			quad_ptr += quad_pitch;

			// Multiply each pixel by the fourth filter coefficient and sum the result
			quad1_pi16 = _mm_slli_pi16(quad1_pi16, 3);
			quad2_pi16 = _mm_slli_pi16(quad2_pi16, 3);
			sum1_pi16 = _mm_subs_pi16(sum1_pi16, quad1_pi16);
			sum2_pi16 = _mm_subs_pi16(sum2_pi16, quad2_pi16);

			// Load the fifth row of four pixels
			quad1_pi16 = *quad_ptr;
			quad2_pi16 = *(quad_ptr + 1);
			quad_ptr += quad_pitch;

			// Multiply each pixel by the fifth filter coefficient and sum the result
			sum1_pi16 = _mm_adds_pi16(sum1_pi16, quad1_pi16);
			sum2_pi16 = _mm_adds_pi16(sum2_pi16, quad2_pi16);

			// Load the sixth (last) row of four pixels
			quad1_pi16 = *quad_ptr;
			quad2_pi16 = *(quad_ptr + 1);

			// Multiply each pixel by the sixth filter coefficient and sum the result
			sum1_pi16 = _mm_adds_pi16(sum1_pi16, quad1_pi16);
			sum2_pi16 = _mm_adds_pi16(sum2_pi16, quad2_pi16);

			// Approximate division of first four sums by eight
			half_pi16 = _mm_set1_pi16(4);
			sum1_pi16 = _mm_srai_pi16(sum1_pi16, 3);
			sum1_pi16 = _mm_adds_pi16(sum1_pi16, half_pi16);

			// Approximate division of second four sums by eight
			sum2_pi16 = _mm_srai_pi16(sum2_pi16, 3);
			sum2_pi16 = _mm_adds_pi16(sum1_pi16, half_pi16);

			// Need to perform quantization //

			// Pack and store the eight results
			sum_pi8 = _mm_packs_pi16(sum1_pi16, sum2_pi16);
			*(output_ptr++) = sum_pi8;
		}

		// Should have terminated the fast loop at the post processing column
		assert(column == post_column);
#endif

		// Process the remaining pixels to the end of the column
		outptr = &outrow[column];
		for (; column < roi.width; column++)
		{
			int32_t sum = 0;
			sum -= rowptr[column + 0 * input_pitch];
			sum -= rowptr[column + 1 * input_pitch];
			sum += rowptr[column + 4 * input_pitch];
			sum += rowptr[column + 5 * input_pitch];
			sum += ROUNDING(sum,8);
			sum = DivideByShift(sum, 3);
			sum += rowptr[column + 2 * input_pitch];
			sum -= rowptr[column + 3 * input_pitch];
			*(outptr++) = SATURATE(sum);
		}

		// Add call to row quantization here //

		// Advance to the next input and output row
		rowptr += 2 * input_pitch;
		outrow += output_pitch;
	}

	// Should have left the loop at the last row
	assert(row == last_row);

#if (1 && XMMOPT)
	// Need to advance the row pointer if using SIMD instructions
	rowptr += 2 * input_pitch;
#endif

	// Use the border filters for the last row
	outptr = outrow;
	for (column = 0; column < roi.width; column++) {
		int32_t sum = 0;
		sum += 11 * rowptr[column + 0 * input_pitch];
		sum -=  5 * rowptr[column + 1 * input_pitch];
		sum -=  4 * rowptr[column - 1 * input_pitch];
		sum -=  4 * rowptr[column - 2 * input_pitch];
		sum +=  1 * rowptr[column - 3 * input_pitch];
		sum +=  1 * rowptr[column - 4 * input_pitch];
		sum +=  ROUNDING(sum,8);
		sum = DivideByShift(sum, 3);
		*(outptr++) = SATURATE(sum);
	}

	//_mm_empty();	// Clear the mmx register state
}
#endif



// Apply the horizontal inverse wavelet filter to 8-bit signed coefficients
void InvertHorizontal8s(PIXEL *lowpass, int lowpass_pitch,
						PIXEL *highpass, int highpass_pitch,
						PIXEL *output, int output_pitch,
						ROI roi, bool fastmode)
{
	// Need to implement this routine for 8-bit decoding

#if _DECODE_LOWPASS_16S

	// Call the routine: InvertHorizontalRow8s()

#else
#error Have not implemented 8-bit lowpass coefficients
#endif
}

#if 0
// Optimized even reconstruction filter
void FilterEvenHorizontal(PIXEL *input, int input_pitch, PIXEL *output, int output_pitch, ROI roi)
{
	PIXEL *rowptr = input;
	PIXEL *outrow = output;
	PIXEL *outptr;
	//int half = scale/2;
	int row, column;

	// Convert pitch from bytes to pixels
	input_pitch /= sizeof(PIXEL);
	output_pitch /= sizeof(PIXEL);

	for (row = 0; row < roi.height; row++) {
		outptr = outrow;

		for (column = 0; column < roi.width; column++) {
			int32_t sum = 0;
			sum += rowptr[column + 0];
			sum -= rowptr[column + 2];
			sum += 4;
			sum >>= 3;
			sum += rowptr[column + 1];

			*(outptr++) = SATURATE(sum);
		}
		rowptr += input_pitch;
		outrow += output_pitch;
	}
}
#endif

#if 0
// Optimized odd reconstruction filter
void FilterOddHorizontal(PIXEL *input, int input_pitch, PIXEL *output, int output_pitch, ROI roi)
{
	PIXEL *rowptr = input;
	PIXEL *outrow = output;
	PIXEL *outptr;
	//int half = scale/2;
	int row, column;

	// Convert pitch from bytes to pixels
	input_pitch /= sizeof(PIXEL);
	output_pitch /= sizeof(PIXEL);

	for (row = 0; row < roi.height; row++) {
		outptr = outrow;

		for (column = 0; column < roi.width; column++) {
			int32_t sum = 0;
			sum -= rowptr[column + 0];
			sum += rowptr[column + 2];
			sum += 4;
			sum >>= 3;
			sum += rowptr[column + 1];
			*(outptr++) = SATURATE(sum);
		}
		rowptr += input_pitch;
		outrow += output_pitch;
	}
}
#endif

#if 0
void FilterEvenLowHigh(PIXEL *lowpass, int lowpass_pitch,
					   PIXEL *highpass, int highpass_pitch, int highpass_border,
					   PIXEL *output, int output_pitch, ROI roi)
{
	int row, column;

	// Convert pitch from bytes to pixels
	lowpass_pitch /= sizeof(PIXEL);
	highpass_pitch /= sizeof(PIXEL);
	output_pitch /= sizeof(PIXEL);

	for (row = 0; row < roi.height; row++)
	{
		for (column = 0; column < roi.width; column++)
		{
			// Apply the even reconstruction filter to the lowpass band
			int32_t sum = 0;
			sum += lowpass[column + 0];
			sum -= lowpass[column + 2];
			sum += 4;
			sum >>= 3;
			sum += lowpass[column + 1];

			// Add the highpass correction
			sum += highpass[column];
			sum /= 2;

			// Place the result in an even column
			output[2 * column] = SATURATE(sum);
		}
		lowpass += lowpass_pitch;
		highpass += highpass_pitch;
		output += output_pitch;
	}
}
#endif

#if 0
void FilterOddLowHigh(PIXEL *lowpass, int lowpass_pitch,
					  PIXEL *highpass, int highpass_pitch, int highpass_border,
					  PIXEL *output, int output_pitch, ROI roi)
{
	int row, column;

	// Convert pitch from bytes to pixels
	lowpass_pitch /= sizeof(PIXEL);
	highpass_pitch /= sizeof(PIXEL);
	output_pitch /= sizeof(PIXEL);

	for (row = 0; row < roi.height; row++)
	{
		for (column = 0; column < roi.width; column++)
		{
			// Apply the odd reconstruction filter to the lowpass band
			int32_t sum = 0;
			sum -= lowpass[column + 0];
			sum += lowpass[column + 2];
			sum += ROUNDING(sum,8);
			sum >>= 3;
			sum += lowpass[column + 1];

			// Subtract the highpass correction
			sum -= highpass[column];
			sum /= 2;

			// Place the result in an odd column
			output[2 * column + 1] = SATURATE(sum);
		}
		lowpass += lowpass_pitch;
		highpass += highpass_pitch;
		output += output_pitch;
	}
}
#endif

#if 0
#if 1

// Optimized version using MMX instructions

// Apply the vertical inverse wavelet filter
void InvertVertical16s(PIXEL *lowpass, int lowpass_pitch,
					   PIXEL *highpass, int highpass_pitch,
					   PIXEL *output, int output_pitch,
					   ROI roi)
{
	int cache_width = _CACHE_LINE_SIZE/sizeof(PIXEL);
	int last_row = roi.height - 1;
	int row, column;

	// Convert pitch from bytes to pixels
	lowpass_pitch /= sizeof(PIXEL);
	highpass_pitch /= sizeof(PIXEL);
	output_pitch /= sizeof(PIXEL);

	// Apply the border filter to the first row
	row = 0;

	for (column = 0; column < roi.width; column++)
	{
		int32_t even = 0;		// Result of convolution with even filter
		int32_t odd = 0;		// Result of convolution with odd filter

		// Apply the even reconstruction filter to the lowpass band
		even += 11 * lowpass[column + 0 * lowpass_pitch];
		even -=  4 * lowpass[column + 1 * lowpass_pitch];
		even +=  1 * lowpass[column + 2 * lowpass_pitch];
		even += ROUNDING(even,8);
		even = DivideByShift(even, 3);

		// Add the highpass correction
		even += highpass[column];
		even = DivideByShift(even, 1);

		// Place the even result in the even row
		output[column] = SATURATE(even);

		// Apply the odd reconstruction filter to the lowpass band
		odd += 5 * lowpass[column + 0 * lowpass_pitch];
		odd += 4 * lowpass[column + 1 * lowpass_pitch];
		odd -= 1 * lowpass[column + 2 * lowpass_pitch];
		odd += ROUNDING(odd,8);
		odd = DivideByShift(odd, 3);

		// Subtract the highpass correction
		odd -= highpass[column];
		odd = DivideByShift(odd, 1);

		// Place the odd result in the odd row
		output[column + output_pitch] = SATURATE(odd);
	}

#if 0
	// Advance to the next input row if not using SIMD
	lowpass += lowpass_pitch;
#endif
	highpass += highpass_pitch;

	// Skip two output rows
	output += 2 * output_pitch;

	// Advance the row index
	row++;

	// Process the middle rows using the ordinary reconstruction filters
	for (; row < last_row; row++)
	{
#if (1 && XMMOPT)

		int column_step = 4;
		int post_column = roi.width - (roi.width % column_step);
		int quad_pitch = (lowpass_pitch * sizeof(PIXEL))/sizeof(__m64);
		__m64 *even_ptr = (__m64 *)&output[0];
		__m64 *odd_ptr = (__m64 *)&output[output_pitch];

#endif

		column = 0;

#if (1 && XMMOPT)

		// Process groups of four coefficients along the row
		for (; column < post_column; column += column_step)
		{
			__m64 *quad_ptr = (__m64 *)&lowpass[column];
			__m64 *high_ptr = (__m64 *)&highpass[column];
			__m64 quad_pi16;
			__m64 even_pi16;
			__m64 odd_pi16;

			// Accumulate parallel sums for the even and odd filters

			quad_pi16 = *quad_ptr;		// Get four lowpass coefficients
			quad_ptr += quad_pitch;		// Advance to the next row

			even_pi16 = quad_pi16;
			odd_pi16 = _mm_subs_pi16(_mm_setzero_si64(), quad_pi16);

			quad_pi16 = *quad_ptr;		// Get four lowpass coefficients
			quad_ptr += quad_pitch;		// Advance to the next row

			// Multiply the lowpass coefficients by eight
//DAN031304 -- wrong inverse filter
			assert(0); //fix filter
			quad_pi16 = _mm_slli_pi16(quad_pi16, 3);

			even_pi16 = _mm_adds_pi16(even_pi16, quad_pi16);
			odd_pi16 = _mm_adds_pi16(odd_pi16, quad_pi16);

			quad_pi16 = *quad_ptr;		// Get four lowpass coefficients

			even_pi16 = _mm_subs_pi16(even_pi16, quad_pi16);
			odd_pi16 = _mm_adds_pi16(odd_pi16, quad_pi16);

			// Apply the rounding adjustment
			even_pi16 = _mm_adds_pi16(even_pi16, _mm_set1_pi16(4));
			// Divide by eight
			even_pi16 = _mm_srai_pi16(even_pi16, 3);

			// Apply the rounding adjustment
			odd_pi16 = _mm_adds_pi16(odd_pi16, _mm_set1_pi16(4));
			// Divide by eight
			odd_pi16 = _mm_srai_pi16(odd_pi16, 3);

			// Add the highpass correction to the even result and divide by two
			quad_pi16 = *high_ptr;
			even_pi16 = _mm_adds_pi16(even_pi16, quad_pi16);
			even_pi16 = _mm_srai_pi16(even_pi16, 1);

			// Subtract the highpass correction from the odd result and divide by two
			odd_pi16 = _mm_subs_pi16(odd_pi16, quad_pi16);
			odd_pi16 = _mm_srai_pi16(odd_pi16, 1);

			// Place the even result in the even row and the odd result in the odd row
			*(even_ptr++) = even_pi16;
			*(odd_ptr++) = odd_pi16;
		}

		// Should have finished the fast loop at the post processing column
		assert(column == post_column);
#endif

		// Process the rest of the row
		for (; column < roi.width; column++)
		{
			int32_t even = 0;		// Result of convolution with even filter
			int32_t odd = 0;		// Result of convolution with odd filter

			// Apply the even reconstruction filter to the lowpass band
			even += lowpass[column - 1 * lowpass_pitch];
			even -= lowpass[column + 1 * lowpass_pitch];
			even += ROUNDING(even,8);
			even = DivideByShift(even, 3);
			even += lowpass[column + 0 * lowpass_pitch];

			// Add the highpass correction
			even += highpass[column];
			even = DivideByShift(even, 1);

			// Place the even result in the even row
			output[column] = SATURATE(even);

			// Apply the odd reconstruction filter to the lowpass band
			odd -= lowpass[column - 1 * lowpass_pitch];
			odd += lowpass[column + 1 * lowpass_pitch];
			odd += ROUNDING(odd,8);
			odd = DivideByShift(odd, 3);
			odd += lowpass[column + 0 * lowpass_pitch];

			// Subtract the highpass correction
			odd -= highpass[column];
			odd = DivideByShift(odd, 1);

			// Place the odd result in the odd row
			output[column + output_pitch] = SATURATE(odd);
		}

		// Advance to the next input rows and skip the next output row
		lowpass += lowpass_pitch;
		highpass += highpass_pitch;
		output += 2 * output_pitch;
	}

	//_mm_empty();	// Clear the mmx register state

#if 1
	// Need to advance the lowpass pointer if using SIMD instructions
	lowpass += lowpass_pitch;
#endif

	// Should have exited the loop at the last row
	assert(row == (roi.height - 1));

	// Apply the border filter to the last row
	for (column = 0; column < roi.width; column++)
	{
		int32_t even = 0;		// Result of convolution with even filter
		int32_t odd = 0;		// Result of convolution with odd filter

		// Apply the even reconstruction filter to the lowpass band
		even += 5 * lowpass[column + 0 * lowpass_pitch];
		even += 4 * lowpass[column - 1 * lowpass_pitch];
		even -= 1 * lowpass[column - 2 * lowpass_pitch];
		even += ROUNDING(even,8);
		even = DivideByShift(even, 3);

		// Add the highpass correction
		even += highpass[column];
		even = DivideByShift(even, 1);

		// Place the even result in the even row
		output[column] = SATURATE(even);

		// Apply the odd reconstruction filter to the lowpass band
		odd += 11 * lowpass[column + 0 * lowpass_pitch];
		odd -=  4 * lowpass[column - 1 * lowpass_pitch];
		odd +=  1 * lowpass[column - 2 * lowpass_pitch];
		odd += ROUNDING(odd,8);
		odd = DivideByShift(odd, 3);

		// Subtract the highpass correction
		odd -= highpass[column];
		odd = DivideByShift(odd, 1);

		// Place the odd result in the odd row
		output[column + output_pitch] = SATURATE(odd);
	}
}

#else

// Optimized version that processes the image by columns of cache lines

// Apply the vertical inverse wavelet filter
void InvertVertical16s(PIXEL *lowpass_array, int lowpass_pitch,
					   PIXEL *highpass_array, int highpass_pitch,
					   PIXEL *output_array, int output_pitch,
					   ROI roi)
{
	int cache_line_width = _CACHE_LINE_SIZE/sizeof(PIXEL);
	int last_row = roi.height - 1;
	int last_column = roi.width - 1;
	int start_column;
	int row, column;

	// Convert pitch from bytes to pixels
	lowpass_pitch /= sizeof(PIXEL);
	highpass_pitch /= sizeof(PIXEL);
	output_pitch /= sizeof(PIXEL);

	// Process the image by columns of cache lines
	for (start_column = 0; start_column < roi.width; start_column += cache_line_width)
	{
		// Compute pointers to the start of the cache line of coefficients
		PIXEL *lowpass = &lowpass_array[0];
		PIXEL *highpass = &highpass_array[0];
		PIXEL *output = &output_array[0];

		// Compute the last column in the current cache line
		int end_column = start_column + cache_line_width - 1;

		// May process fewer columns in last cache line
		if (end_column > last_column) end_column = last_column;

		// Apply the border filter to the first row
		row = 0;

		for (column = start_column; column <= end_column; column++)
		{
			int32_t even = 0;		// Result of convolution with even filter
			int32_t odd = 0;		// Result of convolution with odd filter

			// Apply the even reconstruction filter to the lowpass band
			even += 11 * lowpass[column + 0 * lowpass_pitch];
			even -=  4 * lowpass[column + 1 * lowpass_pitch];
			even +=  1 * lowpass[column + 2 * lowpass_pitch];
			even += ROUNDING(even,8);
			even = DivideByShift(even, 3);

			// Add the highpass correction
			even += highpass[column];
			even = DivideByShift(even, 1);

			// Place the even result in the even row
			output[column] = SATURATE(even);

			// Apply the odd reconstruction filter to the lowpass band
			odd += 5 * lowpass[column + 0 * lowpass_pitch];
			odd += 4 * lowpass[column + 1 * lowpass_pitch];
			odd -= 1 * lowpass[column + 2 * lowpass_pitch];
			odd += ROUNDING(odd,8);
			odd = DivideByShift(odd, 3);

			// Subtract the highpass correction
			odd -= highpass[column];
			odd = DivideByShift(odd, 1);

			// Place the odd result in the odd row
			output[column + output_pitch] = SATURATE(odd);
		}

#if 0
		// Advance to the next input row if not using SIMD
		lowpass += lowpass_pitch;
#endif
		highpass += highpass_pitch;

		// Skip two output rows
		output += 2 * output_pitch;

		// Advance the row index
		row++;

		// Process the middle rows using the ordinary reconstruction filters
		for (; row < last_row; row++)
		{
#if 0
			// Use the unoptimized version of the inverse vertical filter code
			for (column = start_column; column <= end_column; column++)
			{
				int32_t even = 0;		// Result of convolution with even filter
				int32_t odd = 0;		// Result of convolution with odd filter

				// Apply the even reconstruction filter to the lowpass band
				even += lowpass[column - 1 * lowpass_pitch];
				even -= lowpass[column + 1 * lowpass_pitch];
				even += ROUNDING(even,8);
				even = DivideByShift(even, 3);
				even += lowpass[column + 0 * lowpass_pitch];

				// Add the highpass correction
				even += highpass[column];
				even = DivideByShift(even, 1);

				// Place the even result in the even row
				output[column] = SATURATE(even);

				// Apply the odd reconstruction filter to the lowpass band
				odd -= lowpass[column - 1 * lowpass_pitch];
				odd += lowpass[column + 1 * lowpass_pitch];
				odd += ROUNDING(odd,8);
				odd = DivideByShift(odd, 3);
				odd += lowpass[column + 0 * lowpass_pitch];

				// Subtract the highpass correction
				odd -= highpass[column];
				odd = DivideByShift(odd, 1);

				// Place the odd result in the odd row
				output[column + output_pitch] = SATURATE(odd);
			}
#else
			// Use the optimized version of the inverse vertical filter code

			int column_step = 4;
			int quad_pitch = (lowpass_pitch * sizeof(PIXEL))/sizeof(__m64);
			__m64 *even_ptr = (__m64 *)&output[start_column];
			__m64 *odd_ptr = (__m64 *)&output[start_column + output_pitch];

			// Check that the cache line can be processed in an integral number of iterations
			assert((cache_line_width % column_step) == 0);

			// Process groups of four coefficients along the row
			for (column = start_column; column <= end_column; column += column_step)
			{
				__m64 *quad_ptr = (__m64 *)&lowpass[column];
				__m64 *high_ptr = (__m64 *)&highpass[column];
				__m64 quad_pi16;
				__m64 even_pi16;
				__m64 odd_pi16;

				// Accumulate parallel sums for the even and odd filters

				quad_pi16 = *quad_ptr;		// Get four lowpass coefficients
				quad_ptr += quad_pitch;		// Advance to the next row

				even_pi16 = quad_pi16;
				odd_pi16 = _mm_subs_pi16(_mm_setzero_si64(), quad_pi16);

				quad_pi16 = *quad_ptr;		// Get four lowpass coefficients
				quad_ptr += quad_pitch;		// Advance to the next row

				// Multiply the lowpass coefficients by eight
//DAN031304 -- wrong inverse filter
				assert(0); //fix filter
				quad_pi16 = _mm_slli_pi16(quad_pi16, 3);

				even_pi16 = _mm_adds_pi16(even_pi16, quad_pi16);
				odd_pi16 = _mm_adds_pi16(odd_pi16, quad_pi16);

				quad_pi16 = *quad_ptr;		// Get four lowpass coefficients

				even_pi16 = _mm_subs_pi16(even_pi16, quad_pi16);
				odd_pi16 = _mm_adds_pi16(odd_pi16, quad_pi16);

				// Apply the rounding adjustment
				even_pi16 = _mm_adds_pi16(even_pi16, _mm_set1_pi16(4));
				// Divide by eight
				even_pi16 = _mm_srai_pi16(even_pi16, 3);

				// Apply the rounding adjustment
				odd_pi16 = _mm_adds_pi16(odd_pi16, _mm_set1_pi16(4));
				// Divide by eight
				odd_pi16 = _mm_srai_pi16(odd_pi16, 3);

				// Add the highpass correction to the even result and divide by two
				quad_pi16 = *high_ptr;
				even_pi16 = _mm_adds_pi16(even_pi16, quad_pi16);
				even_pi16 = _mm_srai_pi16(even_pi16, 1);

				// Subtract the highpass correction from the odd result and divide by two
				odd_pi16 = _mm_subs_pi16(odd_pi16, quad_pi16);
				odd_pi16 = _mm_srai_pi16(odd_pi16, 1);

				// Place the even result in the even row and the odd result in the odd row
				*(even_ptr++) = even_pi16;
				*(odd_ptr++) = odd_pi16;
			}
#endif
			// Advance to the next input rows and skip the next output row
			lowpass += lowpass_pitch;
			highpass += highpass_pitch;
			output += 2 * output_pitch;
		}

#if 1
		// Need to advance the lowpass pointer if using SIMD instructions
		lowpass += lowpass_pitch;
#endif

		// Should have exited the loop at the last row
		assert(row == (roi.height - 1));

		// Apply the border filter to the last row
		for (column = start_column; column <= end_column; column++)
		{
			int32_t even = 0;		// Result of convolution with even filter
			int32_t odd = 0;		// Result of convolution with odd filter

			// Apply the even reconstruction filter to the lowpass band
			even += 5 * lowpass[column + 0 * lowpass_pitch];
			even += 4 * lowpass[column - 1 * lowpass_pitch];
			even -= 1 * lowpass[column - 2 * lowpass_pitch];
			even += ROUNDING(even,8);
			even = DivideByShift(even, 3);

			// Add the highpass correction
			even += highpass[column];
			even = DivideByShift(even, 1);

			// Place the even result in the even row
			output[column] = SATURATE(even);

			// Apply the odd reconstruction filter to the lowpass band
			odd += 11 * lowpass[column + 0 * lowpass_pitch];
			odd -=  4 * lowpass[column - 1 * lowpass_pitch];
			odd +=  1 * lowpass[column - 2 * lowpass_pitch];
			odd += ROUNDING(odd,8);
			odd = DivideByShift(odd, 3);

			// Subtract the highpass correction
			odd -= highpass[column];
			odd = DivideByShift(odd, 1);

			// Place the odd result in the odd row
			output[column + output_pitch] = SATURATE(odd);
		}
	}

	//_mm_empty();	// Clear the mmx register state
}

#endif
#endif


#if _PROCESSOR_DISPATCH

__declspec(cpu_dispatch(Pentium_4,Generic))

// Apply the frame (temporal and horizontal) transform to unsigned byte data
void FilterSpatialQuant16s(PIXEL *input_image, int input_pitch,
						   PIXEL *lowlow_band, int lowlow_pitch,
						   PIXEL *lowhigh_band, int lowhigh_pitch,
						   PIXEL *highlow_band, int highlow_pitch,
						   PIXEL *highhigh_band, int highhigh_pitch,
						   PIXEL *buffer, size_t buffer_size,
						   ROI roi, int quantization[4])
{
	// Stub routine for processor specific dispatch
}

#endif


#if _PROCESSOR_GENERIC

#if _PROCESSOR_DISPATCH
__declspec(cpu_specific(Generic))
#endif

// Apply the forward spatial (horizontal and vertical) transform with quantization
void FilterSpatialQuant16s(PIXEL *input_image, int input_pitch,
						   PIXEL *lowlow_band, int lowlow_pitch,
						   PIXEL *lowhigh_band, int lowhigh_pitch,
						   PIXEL *highlow_band, int highlow_pitch,
						   PIXEL *highhigh_band, int highhigh_pitch,
						   PIXEL *buffer, size_t buffer_size,
						   ROI roi, int quantization[4])
{
	PIXEL *rowptr = input_image;

	// Six rows of lowpass and highpass horizontal results
	PIXEL *lowpass[6];
	PIXEL *highpass[6];

	PIXEL *lowlow_buffer;
	PIXEL *lowhigh_buffer;
	PIXEL *highlow_buffer;
	PIXEL *highhigh_buffer;

	int lowlow_quantization;
	int lowhigh_quantization;
	int highlow_quantization;
	int highhigh_quantization;

	// Change the highpass output bands to be 8-bit pixels //

#if _HIGHPASS_8S
	PIXEL16S *lowlow_row_ptr = lowlow_band;
	PIXEL8S *lowhigh_row_ptr = (PIXEL8S *)lowhigh_band;
	PIXEL8S *highlow_row_ptr = (PIXEL8S *)highlow_band;
	PIXEL8S *highhigh_row_ptr = (PIXEL8S *)highhigh_band;
#else
	PIXEL *lowlow_row_ptr = lowlow_band;
	PIXEL *lowhigh_row_ptr = lowhigh_band;
	PIXEL *highlow_row_ptr = highlow_band;
	PIXEL *highhigh_row_ptr = highhigh_band;
#endif

	int last_row = roi.height - 2;
	int output_width;
	size_t output_buffer_size;
	int output_buffer_width;
	int row, column;
	PIXEL *bufptr;
	const int buffer_row_count = sizeof(lowpass)/sizeof(lowpass[0]);
	//const int prescale = 2;
#if _TRANSFORM_PRESCALE
	int lowround = (lowscale > 0) ? (1 << (lowscale - 1)) : 0;
#endif
	int k;

	// Convert pitch from bytes to pixels
	input_pitch /= sizeof(PIXEL);
	lowlow_pitch /= sizeof(PIXEL);
#if _HIGHPASS_8S
	lowhigh_pitch /= sizeof(PIXEL8S);
	highlow_pitch /= sizeof(PIXEL8S);
	highhigh_pitch /= sizeof(PIXEL8S);
#else
	lowhigh_pitch /= sizeof(PIXEL);
	highlow_pitch /= sizeof(PIXEL);
	highhigh_pitch /= sizeof(PIXEL);
#endif

	if (quantization != NULL)
	{
		lowlow_quantization = quantization[0];
		lowhigh_quantization = quantization[1];
		highlow_quantization = quantization[2];
		highhigh_quantization = quantization[3];
	}
	else
	{
		lowlow_quantization = 1;
		lowhigh_quantization = 1;
		highlow_quantization = 1;
		highhigh_quantization = 1;
	}

	// Must have an even number of rows
	assert((roi.height % 2) == 0);

	// Must have an even number of columns
	assert((roi.width % 2) == 0);

	// Compute the width of each row of horizontal filter output
	output_width = roi.width/2;

	// Compute the size of each row of horizontal filter output in bytes
	output_buffer_size = output_width * sizeof(PIXEL);

	// Round up the buffer size to an integer number of cache lines
	output_buffer_size = ALIGN(output_buffer_size, _CACHE_LINE_SIZE);

	if (lowlow_quantization > 1) {
		// The buffer must be large enough for twelve rows
		assert(buffer_size >= (12 * output_buffer_size));
	}
	else {
		// The buffer must be large enough for eleven rows
		assert(buffer_size >= (11 * output_buffer_size));
	}

	// Compute the allocated width of each buffer
	output_buffer_width = output_buffer_size / sizeof(PIXEL);

	// Allocate space in the buffer for the horizontal filter results
	bufptr = buffer;
	for (k = 0; k < buffer_row_count; k++) {
		lowpass[k] = bufptr;	bufptr += output_buffer_width;
		highpass[k] = bufptr;	bufptr += output_buffer_width;
	}

	// Allocate space in the buffer for the pre-quantized coefficients
	if (lowlow_quantization > 1) {
		lowlow_buffer = bufptr;		bufptr += output_buffer_width;
	}
	lowhigh_buffer = bufptr;		bufptr += output_buffer_width;
	highlow_buffer = bufptr;		bufptr += output_buffer_width;
	highhigh_buffer = bufptr;		bufptr += output_buffer_width;

	// Compute the first six rows of horizontal filter output
	for (k = 0; k < buffer_row_count; k++) {
		//SplitRow16s(rowptr, roi.width, lowpass[k], highpass[k]);
		//FilterHorizontalRow16s(rowptr, lowpass[k], highpass[k], roi.width, input_scale, prescale);
		//assert(prescale == 0 && input_scale == 0);
		FilterHorizontalRow16s(rowptr, lowpass[k], highpass[k], roi.width);
		rowptr += input_pitch;
	}


	/***** Need to optimize the first and last row calculations *****/

	// Use border filters for the first row
	row = 0;

	for (column = 0; column < output_width; column++)
	{
		int32_t sum;

		// Apply the lowpass vertical filter to the lowpass horizontal results
		sum  = lowpass[0][column];
		sum += lowpass[1][column];

		// The lowpass prescale should be zero
		//assert(lowscale == 0);

		if (lowlow_quantization > 1) {
			lowlow_buffer[column] = SATURATE(sum);
		}
		else {
			lowlow_row_ptr[column] = SATURATE(sum);
		}

		// Apply the highpass vertical filter to the lowpass horizontal results
		sum  =  5 * lowpass[0][column];
		sum -= 11 * lowpass[1][column];
		sum +=  4 * lowpass[2][column];
		sum +=  4 * lowpass[3][column];
		sum -=  1 * lowpass[4][column];
		sum -=  1 * lowpass[5][column];
		sum += ROUNDING(sum,8);
		sum = DivideByShift(sum, 3);
		highlow_buffer[column] = SATURATE(sum);

		// Apply the lowpass vertical filter to the highpass horizontal results
		sum  = highpass[0][column];
		sum += highpass[1][column];
		lowhigh_buffer[column] = SATURATE(sum);

		// Apply the highpass vertical filter to the highpass horizontal results
		sum  =  5 * highpass[0][column];
		sum -= 11 * highpass[1][column];
		sum +=  4 * highpass[2][column];
		sum +=  4 * highpass[3][column];
		sum -=  1 * highpass[4][column];
		sum -=  1 * highpass[5][column];
		sum += ROUNDING(sum,8);
		sum = DivideByShift(sum, 3);
		highhigh_buffer[column] = SATURATE(sum);
	}

#if _HIGHPASS_8S
	if (lowlow_quantization > 1) {
		// Quantize the first row of 16-bit lowpass coefficients
		QuantizeRow16sTo16s(lowlow_buffer, lowlow_row_ptr, output_width, lowlow_quantization);
	}
	// Quantize the first row of 8-bit highpass coefficients
	QuantizeRow16sTo8s(lowhigh_buffer, lowhigh_row_ptr, output_width, lowhigh_quantization);
	QuantizeRow16sTo8s(highlow_buffer, highlow_row_ptr, output_width, highlow_quantization);
	QuantizeRow16sTo8s(highhigh_buffer, highhigh_row_ptr, output_width, highhigh_quantization);
#else
	// Quantize the first row of results for each 16-bit output band
	if (lowlow_quantization > 1)
		QuantizeRow16sTo16s(lowlow_buffer, lowlow_row_ptr, output_width, lowlow_quantization);
	QuantizeRow16sTo16s(lowhigh_buffer, lowhigh_row_ptr, output_width, lowhigh_quantization);
	QuantizeRow16sTo16s(highlow_buffer, highlow_row_ptr, output_width, highlow_quantization);
	QuantizeRow16sTo16s(highhigh_buffer, highhigh_row_ptr, output_width, highhigh_quantization);
#endif

#if 0
	// Advance to the next pair of input rows if not using the SIMD code since the
	// SIMD version uses the first two rows again to compute the second output row

	{
		// Rotate the horizontal filter results by two rows
		PIXEL *temp0 = lowpass[0];
		PIXEL *temp1 = lowpass[1];
		PIXEL *high0 = highpass[0];
		PIXEL *high1 = highpass[1];

		for (k = 0; k < buffer_row_count - 2; k++) {
			lowpass[k] = lowpass[k+2];
			highpass[k] = highpass[k+2];
		}

		lowpass[buffer_row_count - 2] = temp0;
		lowpass[buffer_row_count - 1] = temp1;
		highpass[buffer_row_count - 2] = high0;
		highpass[buffer_row_count - 1] = high1;

		// Compute the next two rows of horizontal filter results
		for (; k < buffer_row_count; k++) {
			//SplitRow16s(rowptr, roi.width, lowpass[k], highpass[k]);
			//FilterHorizontalRow16s(rowptr, lowpass[k], highpass[k], roi.width, input_scale, prescale);
			assert(prescale == 0 && input_scale == 0);
			FilterHorizontalRow16s(rowptr, lowpass[k], highpass[k], roi.width);
			rowptr += input_pitch;
		}
	}
#endif

	// Advance to the next output rows
	lowlow_row_ptr += lowlow_pitch;
	highlow_row_ptr += highlow_pitch;
	lowhigh_row_ptr += lowhigh_pitch;
	highhigh_row_ptr += highhigh_pitch;

	row += 2;								// Advance the row being processed

	for (; row < last_row; row += 2)
	{
#if (1 && XMMOPT)
		__m64 *lowlow_ptr;
		__m64 *highlow_ptr = (__m64 *)highlow_buffer;
		__m64 *lowhigh_ptr = (__m64 *)lowhigh_buffer;
		__m64 *highhigh_ptr = (__m64 *)highhigh_buffer;

		int column_step = 4;
		int post_column = output_width - (output_width % column_step);
#endif
		// Start at the first column
		column = 0;

#if (1 && XMMOPT)

		if (lowlow_quantization > 1) {
			lowlow_ptr = (__m64 *)lowlow_buffer;
		}
		else {
			lowlow_ptr = (__m64 *)lowlow_row_ptr;
		}

		// Process a group of four pixels at a time
		for (; column < post_column; column += column_step)
		{
			__m64 low_pi16;
			__m64 sum_pi16;
			__m64 sum8_pi16;
			__m64 quad_pi16;
			__m64 mask_pi16;
			__m64 half_pi16;


			// Apply the vertical filters to the horizontal lowpass results //

			// Load the first row of four pixels
			quad_pi16 = *((__m64 *)&lowpass[0][column]);

			// Initialize the highpass filter sum
			sum_pi16 = _mm_setzero_si64();

			// Multiply each pixel by the first filter coefficient and sum the result
			sum_pi16 = _mm_subs_pi16(sum_pi16, quad_pi16);

			// Load the second row of four pixels
			quad_pi16 = *((__m64 *)&lowpass[1][column]);

			// Multiply each pixel by the second filter coefficient and sum the result
			sum_pi16 = _mm_subs_pi16(sum_pi16, quad_pi16);

			// Load the third row of four pixels
			quad_pi16 = *((__m64 *)&lowpass[2][column]);

			// Initialize the lowpass sum
			low_pi16 = quad_pi16;

			// Multiply each pixel by the third filter coefficient and sum the result
			 sum8_pi16 = _mm_setzero_si64();
			 sum8_pi16 = _mm_adds_pi16(sum8_pi16, quad_pi16);

			// Load the fourth row of four pixels
			quad_pi16 = *((__m64 *)&lowpass[3][column]);

			// Compute the four lowpass results
			low_pi16 = _mm_adds_pi16(low_pi16, quad_pi16);

			// Store the lowpass results
			*(lowlow_ptr++) = low_pi16;

			// Multiply each pixel by the fourth filter coefficient and sum the result
			 sum8_pi16 = _mm_subs_pi16(sum8_pi16, quad_pi16);

			// Load the fifth row of four pixels
			quad_pi16 = *((__m64 *)&lowpass[4][column]);

			// Multiply each pixel by the fifth filter coefficient and sum the result
			sum_pi16 = _mm_adds_pi16(sum_pi16, quad_pi16);

			// Load the sixth (last) row of four pixels
			quad_pi16 = *((__m64 *)&lowpass[5][column]);

			// Multiply each pixel by the sixth filter coefficient and sum the result
			sum_pi16 = _mm_adds_pi16(sum_pi16, quad_pi16);

			// Approximate division by eight
			half_pi16 = _mm_set1_pi16(4);
			sum_pi16 = _mm_adds_pi16(sum_pi16, half_pi16);
			sum_pi16 = _mm_srai_pi16(sum_pi16, 3);

			 sum_pi16 = _mm_adds_pi16(sum_pi16, sum8_pi16);

			// Store the four highpass results
			*(highlow_ptr++) = sum_pi16;


			// Apply the vertical filters to the horizontal highpass results //

			sum_pi16 = _mm_setzero_si64();

			// Load the first row of four pixels
			quad_pi16 = *((__m64 *)&highpass[0][column]);

			// Multiply each pixel by the first filter coefficient and sum the result
			sum_pi16 = _mm_subs_pi16(sum_pi16, quad_pi16);

			// Load the second row of four pixels
			quad_pi16 = *((__m64 *)&highpass[1][column]);

			// Multiply each pixel by the second filter coefficient and sum the result
			sum_pi16 = _mm_subs_pi16(sum_pi16, quad_pi16);

			// Load the third row of four pixels
			quad_pi16 = *((__m64 *)&highpass[2][column]);

			// Initialize the lowpass sum
			low_pi16 = quad_pi16;

			// Multiply each pixel by the third filter coefficient and sum the result
			 sum8_pi16 = _mm_setzero_si64();
			 sum8_pi16 = _mm_adds_pi16(sum8_pi16, quad_pi16);

			// Load the fourth row of four pixels
			quad_pi16 = *((__m64 *)&highpass[3][column]);

			// Compute and store the four lowpass results
			low_pi16 = _mm_adds_pi16(low_pi16, quad_pi16);
			*(lowhigh_ptr++) = low_pi16;

			// Multiply each pixel by the fourth filter coefficient and sum the result
			 sum8_pi16 = _mm_subs_pi16(sum8_pi16, quad_pi16);

			// Load the fifth row of four pixels
			quad_pi16 = *((__m64 *)&highpass[4][column]);

			// Multiply each pixel by the fifth filter coefficient and sum the result
			sum_pi16 = _mm_adds_pi16(sum_pi16, quad_pi16);

			// Load the sixth (last) row of four pixels
			quad_pi16 = *((__m64 *)&highpass[5][column]);

			// Multiply each pixel by the sixth filter coefficient and sum the result
			sum_pi16 = _mm_adds_pi16(sum_pi16, quad_pi16);

			// Approximate division by eight
			half_pi16 = _mm_set1_pi16(4);
			sum_pi16 = _mm_adds_pi16(sum_pi16, half_pi16);
			sum_pi16 = _mm_srai_pi16(sum_pi16, 3);

			 sum_pi16 = _mm_adds_pi16(sum_pi16, sum8_pi16);

			// Store the four highpass results
			*(highhigh_ptr++) = sum_pi16;
		}

		// Should have terminated the fast loop at the post processing column
		assert(column == post_column);
#endif

		// Process the remaining pixels to the end of the row
		for (; column < output_width; column++)
		{
			int32_t sum;

			// Apply the lowpass vertical filter to the lowpass horizontal results
			sum  = lowpass[2][column];
			sum += lowpass[3][column];

			// The lowpass prescale should be zero
			//assert(lowscale == 0);

			if (lowlow_quantization > 1) {
				lowlow_buffer[column] = SATURATE(sum);
			}
			else {
				lowlow_row_ptr[column] = SATURATE(sum);
			}

			// Apply the highpass vertical filter to the lowpass horizontal results
			sum  = -1 * lowpass[0][column];
			sum += -1 * lowpass[1][column];
			sum +=  1 * lowpass[4][column];
			sum +=  1 * lowpass[5][column];
			sum += ROUNDING(sum,8);
			sum = DivideByShift(sum, 3);
			sum +=  lowpass[2][column];
			sum += -lowpass[3][column];
			highlow_buffer[column] = SATURATE(sum);

			// Apply the lowpass vertical filter to the highpass horizontal results
			sum  = highpass[2][column];
			sum += highpass[3][column];
			lowhigh_buffer[column] = SATURATE(sum);

			// Apply the highpass vertical filter to the highpass horizontal results
			sum  = -1 * highpass[0][column];
			sum += -1 * highpass[1][column];
			sum +=  1 * highpass[4][column];
			sum +=  1 * highpass[5][column];
			sum += ROUNDING(sum,8);
			sum = DivideByShift(sum, 3);
			sum +=  highpass[2][column];
			sum += -highpass[3][column];
			highhigh_buffer[column] = SATURATE(sum);
		}

		if (row < (last_row - 2))
		{
			// Rotate the horizontal filter results by two rows
			PIXEL *temp0 = lowpass[0];
			PIXEL *temp1 = lowpass[1];
			PIXEL *high0 = highpass[0];
			PIXEL *high1 = highpass[1];

			for (k = 0; k < buffer_row_count - 2; k++) {
				lowpass[k] = lowpass[k+2];
				highpass[k] = highpass[k+2];
			}

			lowpass[buffer_row_count - 2] = temp0;
			lowpass[buffer_row_count - 1] = temp1;
			highpass[buffer_row_count - 2] = high0;
			highpass[buffer_row_count - 1] = high1;

			// Compute the next two rows of horizontal filter results
			for (; k < buffer_row_count; k++) {
				//SplitRow16s(rowptr, roi.width, lowpass[k], highpass[k]);
				//FilterHorizontalRow16s(rowptr, lowpass[k], highpass[k], roi.width, input_scale, prescale);
				//assert(prescale == 0 && input_scale == 0);
				FilterHorizontalRow16s(rowptr, lowpass[k], highpass[k], roi.width);
				rowptr += input_pitch;
			}
		}

#if _HIGHPASS_8S
		if (lowlow_quantization > 1) {
			// Quantize the current row of 16-bit lowpass coefficients
			QuantizeRow16sTo16s(lowlow_buffer, lowlow_row_ptr, output_width, lowlow_quantization);
		}
		// Quantize the current row of 8-bit highpass coefficients
		QuantizeRow16sTo8s(lowhigh_buffer, lowhigh_row_ptr, output_width, lowhigh_quantization);
		QuantizeRow16sTo8s(highlow_buffer, highlow_row_ptr, output_width, highlow_quantization);
		QuantizeRow16sTo8s(highhigh_buffer, highhigh_row_ptr, output_width, highhigh_quantization);
#else
		// Quantize the current row of results for each 16-bit output band
		if (lowlow_quantization > 1)
			QuantizeRow16sTo16s(lowlow_buffer, lowlow_row_ptr, output_width, lowlow_quantization);
		QuantizeRow16sTo16s(lowhigh_buffer, lowhigh_row_ptr, output_width, lowhigh_quantization);
		QuantizeRow16sTo16s(highlow_buffer, highlow_row_ptr, output_width, highlow_quantization);
		QuantizeRow16sTo16s(highhigh_buffer, highhigh_row_ptr, output_width, highhigh_quantization);
#endif

		// Advance to the next output rows
		lowlow_row_ptr += lowlow_pitch;
		highlow_row_ptr += highlow_pitch;
		lowhigh_row_ptr += lowhigh_pitch;
		highhigh_row_ptr += highhigh_pitch;
	}

	// Should have left the loop at the last row
	assert(row == last_row);

	// Use the border filters for the last row
	for (column = 0; column < output_width; column++)
	{
		int32_t sum;

		// Apply the lowpass vertical filter to the lowpass horizontal results
		sum  = lowpass[4][column];
		sum += lowpass[5][column];

		// The lowpass prescale should be zero
		//assert(lowscale == 0);

		if (lowlow_quantization > 1) {
			lowlow_buffer[column] = SATURATE(sum);
		}
		else {
			lowlow_row_ptr[column] = SATURATE(sum);
		}

		// Apply the highpass vertical filter to the lowpass horizontal results
		sum  = 11 * lowpass[4][column];
		sum -=  5 * lowpass[5][column];
		sum -=  4 * lowpass[3][column];
		sum -=  4 * lowpass[2][column];
		sum +=  1 * lowpass[1][column];
		sum +=  1 * lowpass[0][column];
		sum +=  ROUNDING(sum,8);
		sum = DivideByShift(sum, 3);
		highlow_buffer[column] = SATURATE(sum);

		// Apply the lowpass vertical filter to the highpass horizontal results
		sum  = highpass[4][column];
		sum += highpass[5][column];
		lowhigh_buffer[column] = SATURATE(sum);

		// Apply the highpass vertical filter to the highpass horizontal results
		sum  = 11 * highpass[4][column];
		sum -=  5 * highpass[5][column];
		sum -=  4 * highpass[3][column];
		sum -=  4 * highpass[2][column];
		sum +=  1 * highpass[1][column];
		sum +=  1 * highpass[0][column];
		sum +=  ROUNDING(sum,8);
		sum = DivideByShift(sum, 3);
		highhigh_buffer[column] = SATURATE(sum);
	}

#if _HIGHPASS_8S
		if (lowlow_quantization > 1) {
			// Quantize the 16-bit lowpass coefficients
			QuantizeRow16sTo16s(lowlow_buffer, lowlow_row_ptr, output_width, lowlow_quantization);
		}
		// Quantize the 8-bit highpass coefficients
		QuantizeRow16sTo8s(lowhigh_buffer, lowhigh_row_ptr, output_width, lowhigh_quantization);
		QuantizeRow16sTo8s(highlow_buffer, highlow_row_ptr, output_width, highlow_quantization);
		QuantizeRow16sTo8s(highhigh_buffer, highhigh_row_ptr, output_width, highhigh_quantization);
#else
		// Quantize the first row of results for each 16-bit output band
		if (lowlow_quantization > 1)
			QuantizeRow16sTo16s(lowlow_buffer, lowlow_row_ptr, output_width, lowlow_quantization);
		QuantizeRow16sTo16s(lowhigh_buffer, lowhigh_row_ptr, output_width, lowhigh_quantization);
		QuantizeRow16sTo16s(highlow_buffer, highlow_row_ptr, output_width, highlow_quantization);
		QuantizeRow16sTo16s(highhigh_buffer, highhigh_row_ptr, output_width, highhigh_quantization);
#endif

	//_mm_empty();	// Clear the mmx register state
}

#endif


#if _PROCESSOR_PENTIUM_4

#if _PROCESSOR_DISPATCH
__declspec(cpu_specific(Pentium_4))
#endif

// Apply the forward spatial (horizontal and vertical) transform with quantization
void FilterSpatialQuant16s(PIXEL *input_image, int input_pitch,
						   PIXEL *lowlow_band, int lowlow_pitch,
						   PIXEL *lowhigh_band, int lowhigh_pitch,
						   PIXEL *highlow_band, int highlow_pitch,
						   PIXEL *highhigh_band, int highhigh_pitch,
						   PIXEL *buffer, size_t buffer_size,
						   ROI roi, int quantization[4])
{
	PIXEL *rowptr = input_image;

	// Six rows of lowpass and highpass horizontal results
	PIXEL *lowpass[6];
	PIXEL *highpass[6];

	PIXEL *lowlow_buffer;
	PIXEL *lowhigh_buffer;
	PIXEL *highlow_buffer;
	PIXEL *highhigh_buffer;

	int lowlow_quantization;
	int lowhigh_quantization;
	int highlow_quantization;
	int highhigh_quantization;

	// Change the highpass output bands to be 8-bit pixels //

#if _HIGHPASS_8S
	PIXEL16S *lowlow_row_ptr = lowlow_band;
	PIXEL8S *lowhigh_row_ptr = (PIXEL8S *)lowhigh_band;
	PIXEL8S *highlow_row_ptr = (PIXEL8S *)highlow_band;
	PIXEL8S *highhigh_row_ptr = (PIXEL8S *)highhigh_band;
#else
	PIXEL *lowlow_row_ptr = lowlow_band;
	PIXEL *lowhigh_row_ptr = lowhigh_band;
	PIXEL *highlow_row_ptr = highlow_band;
	PIXEL *highhigh_row_ptr = highhigh_band;
#endif

	int last_row = roi.height - 2;
	int output_width;
	size_t output_buffer_size;
	int output_buffer_width;
	int row, column;
	PIXEL *bufptr;
	const int buffer_row_count = sizeof(lowpass)/sizeof(lowpass[0]);
	//const int prescale = 2;
	int k;

	// Convert pitch from bytes to pixels
	input_pitch /= sizeof(PIXEL);
	lowlow_pitch /= sizeof(PIXEL);
#if _HIGHPASS_8S
	lowhigh_pitch /= sizeof(PIXEL8S);
	highlow_pitch /= sizeof(PIXEL8S);
	highhigh_pitch /= sizeof(PIXEL8S);
#else
	lowhigh_pitch /= sizeof(PIXEL);
	highlow_pitch /= sizeof(PIXEL);
	highhigh_pitch /= sizeof(PIXEL);
#endif

	if (quantization != NULL)
	{
		lowlow_quantization = quantization[0];
		lowhigh_quantization = quantization[1];
		highlow_quantization = quantization[2];
		highhigh_quantization = quantization[3];
	}
	else
	{
		lowlow_quantization = 1;
		lowhigh_quantization = 1;
		highlow_quantization = 1;
		highhigh_quantization = 1;
	}

	// Must have an even number of rows
	assert((roi.height % 2) == 0);

	// Must have an even number of columns
	assert((roi.width % 2) == 0);

	// Compute the width of each row of horizontal filter output
	output_width = roi.width/2;
	//output_width = ALIGN16(output_width);

	// Compute the size of each row of horizontal filter output in bytes
	output_buffer_size = output_width * sizeof(PIXEL);

	// Round up the buffer size to an integer number of cache lines
	output_buffer_size = ALIGN(output_buffer_size, _CACHE_LINE_SIZE);

	if (lowlow_quantization > 1) {
		// The buffer must be large enough for twelve rows
		assert(buffer_size >= (12 * output_buffer_size));
	}
	else {
		// The buffer must be large enough for eleven rows
		assert(buffer_size >= (11 * output_buffer_size));
	}

	// Compute the allocated width of each buffer
	output_buffer_width = (int)output_buffer_size / sizeof(PIXEL);

	// Allocate space in the buffer for the horizontal filter results
	bufptr = buffer;
	for (k = 0; k < buffer_row_count; k++) {
		lowpass[k] = bufptr;		bufptr += output_buffer_width;
		highpass[k] = bufptr;		bufptr += output_buffer_width;
	}

	// Allocate space in the buffer for the pre-quantized coefficients
	if (lowlow_quantization > 1) {
		lowlow_buffer = bufptr;		bufptr += output_buffer_width;
	}
	lowhigh_buffer = bufptr;		bufptr += output_buffer_width;
	highlow_buffer = bufptr;		bufptr += output_buffer_width;
	highhigh_buffer = bufptr;		bufptr += output_buffer_width;

	// Compute the first six rows of horizontal filter output
	for (k = 0; k < buffer_row_count; k++) {
		//SplitRow16s(rowptr, roi.width, lowpass[k], highpass[k]);
		//FilterHorizontalRowPrescaled16s(rowptr, lowpass[k], highpass[k], roi.width, NULL);
		FilterHorizontalRow16s(rowptr, lowpass[k], highpass[k], roi.width);
		rowptr += input_pitch;
	}


	// Need to optimize the first and last row calculations //

	// Use border filters for the first row
	row = 0;

	for (column = 0; column < output_width; column++)
	{
		int32_t sum;

		// Apply the lowpass vertical filter to the lowpass horizontal results
		sum  = lowpass[0][column];
		sum += lowpass[1][column];

		// The lowpass prescale should be zero
		//assert(lowscale == 0);

		if (lowlow_quantization > 1) {
			lowlow_buffer[column] = SATURATE(sum);
		}
		else {
			lowlow_row_ptr[column] = SATURATE(sum);
		}

		// Apply the highpass vertical filter to the lowpass horizontal results
		sum  =  5 * lowpass[0][column];
		sum -= 11 * lowpass[1][column];
		sum +=  4 * lowpass[2][column];
		sum +=  4 * lowpass[3][column];
		sum -=  1 * lowpass[4][column];
		sum -=  1 * lowpass[5][column];
		sum += ROUNDING(sum,8);
		sum = DivideByShift(sum, 3);
		highlow_buffer[column] = SATURATE(sum);

		// Apply the lowpass vertical filter to the highpass horizontal results
		sum  = highpass[0][column];
		sum += highpass[1][column];
		lowhigh_buffer[column] = SATURATE(sum);

		// Apply the highpass vertical filter to the highpass horizontal results
		sum  =  5 * highpass[0][column];
		sum -= 11 * highpass[1][column];
		sum +=  4 * highpass[2][column];
		sum +=  4 * highpass[3][column];
		sum -=  1 * highpass[4][column];
		sum -=  1 * highpass[5][column];
		sum += ROUNDING(sum,8);
		sum = DivideByShift(sum, 3);
		highhigh_buffer[column] = SATURATE(sum);
	}

#if _HIGHPASS_8S
	if (lowlow_quantization > 1) {
		// Quantize the first row of 16-bit lowpass coefficients
		QuantizeRow16sTo16s(lowlow_buffer, lowlow_row_ptr, output_width, lowlow_quantization);
	}
	// Quantize the first row of 8-bit highpass coefficients
	QuantizeRow16sTo8s(lowhigh_buffer, lowhigh_row_ptr, output_width, lowhigh_quantization);
	QuantizeRow16sTo8s(highlow_buffer, highlow_row_ptr, output_width, highlow_quantization);
	QuantizeRow16sTo8s(highhigh_buffer, highhigh_row_ptr, output_width, highhigh_quantization);
#else
	// Quantize the first row of results for each 16-bit output band
	if (lowlow_quantization > 1)
		QuantizeRow16sTo16s(lowlow_buffer, lowlow_row_ptr, output_width, lowlow_quantization);
	QuantizeRow16sTo16s(lowhigh_buffer, lowhigh_row_ptr, output_width, lowhigh_quantization);
	QuantizeRow16sTo16s(highlow_buffer, highlow_row_ptr, output_width, highlow_quantization);
	QuantizeRow16sTo16s(highhigh_buffer, highhigh_row_ptr, output_width, highhigh_quantization);
#endif

#if 0
	// Advance to the next pair of input rows if not using the SIMD code since the
	// SIMD version uses the first two rows again to compute the second output row

	{
		// Rotate the horizontal filter results by two rows
		PIXEL *temp0 = lowpass[0];
		PIXEL *temp1 = lowpass[1];
		PIXEL *high0 = highpass[0];
		PIXEL *high1 = highpass[1];

		for (k = 0; k < buffer_row_count - 2; k++) {
			lowpass[k] = lowpass[k+2];
			highpass[k] = highpass[k+2];
		}

		lowpass[buffer_row_count - 2] = temp0;
		lowpass[buffer_row_count - 1] = temp1;
		highpass[buffer_row_count - 2] = high0;
		highpass[buffer_row_count - 1] = high1;

		// Compute the next two rows of horizontal filter results
		for (; k < buffer_row_count; k++) {
			//SplitRow16s(rowptr, roi.width, lowpass[k], highpass[k]);
			//FilterHorizontalRowPrescaled16s(rowptr, lowpass[k], highpass[k], roi.width, input_scale, NULL);
			FilterHorizontalRow16s(rowptr, lowpass[k], highpass[k], roi.width, input_scale);
			rowptr += input_pitch;
		}
	}
#endif

	// Advance to the next output rows
	lowlow_row_ptr += lowlow_pitch;
	highlow_row_ptr += highlow_pitch;
	lowhigh_row_ptr += lowhigh_pitch;
	highhigh_row_ptr += highhigh_pitch;

	row += 2;								// Advance the row being processed

	for (; row < last_row; row += 2)
	{
#if (1 && XMMOPT)
		__m128i *lowlow_ptr;
		__m128i *highlow_ptr = (__m128i *)highlow_buffer;
		__m128i *lowhigh_ptr = (__m128i *)lowhigh_buffer;
		__m128i *highhigh_ptr = (__m128i *)highhigh_buffer;

		int column_step = 8;
		int post_column = output_width - (output_width % column_step);
#endif
		// Start at the first column
		column = 0;

#if (1 && XMMOPT)

		if (lowlow_quantization > 1) {
			lowlow_ptr = (__m128i *)lowlow_buffer;
		}
		else {
			lowlow_ptr = (__m128i *)lowlow_row_ptr;
		}

		// Process a group of eight pixels at a time
		for (; column < post_column; column += column_step)
		{
			__m128i low_epi16;
			__m128i sum_epi16;
			__m128i sum8_epi16;
			__m128i quad_epi16;
			__m128i half_epi16;


			/***** Apply the vertical filters to the horizontal lowpass results *****/

			// Load the first row of four pixels
			quad_epi16 = _mm_load_si128((__m128i *)&lowpass[0][column]);

			// Initialize the highpass filter sum
			sum_epi16 = _mm_setzero_si128();

			// Multiply each pixel by the first filter coefficient and sum the result
			sum_epi16 = _mm_subs_epi16(sum_epi16, quad_epi16);

			// Load the second row of four pixels
			quad_epi16 = _mm_load_si128((__m128i *)&lowpass[1][column]);

			// Multiply each pixel by the second filter coefficient and sum the result
			sum_epi16 = _mm_subs_epi16(sum_epi16, quad_epi16);

			// Load the third row of four pixels
			quad_epi16 = _mm_load_si128((__m128i *)&lowpass[2][column]);

			// Initialize the lowpass sum
			low_epi16 = quad_epi16;

			// Multiply each pixel by the third filter coefficient and sum the result
			sum8_epi16 = _mm_setzero_si128();
			sum8_epi16 = _mm_adds_epi16(sum8_epi16, quad_epi16);

			// Load the fourth row of four pixels
			quad_epi16 = _mm_load_si128((__m128i *)&lowpass[3][column]);

			// Compute the four lowpass results
			low_epi16 = _mm_adds_epi16(low_epi16, quad_epi16);

			// Store the lowpass results
			_mm_store_si128(lowlow_ptr++, low_epi16);

			// Multiply each pixel by the fourth filter coefficient and sum the result
			sum8_epi16 = _mm_subs_epi16(sum8_epi16, quad_epi16);

			// Load the fifth row of four pixels
			quad_epi16 = _mm_load_si128((__m128i *)&lowpass[4][column]);

			// Multiply each pixel by the fifth filter coefficient and sum the result
			sum_epi16 = _mm_adds_epi16(sum_epi16, quad_epi16);

			// Load the sixth (last) row of four pixels
			quad_epi16 = _mm_load_si128((__m128i *)&lowpass[5][column]);

			// Multiply each pixel by the sixth filter coefficient and sum the result
			sum_epi16 = _mm_adds_epi16(sum_epi16, quad_epi16);


			half_epi16 = _mm_set1_epi16(4); //DAN031604 4 to 6
			sum_epi16 = _mm_adds_epi16(sum_epi16, half_epi16); // +7 rounding
			sum_epi16 = _mm_srai_epi16(sum_epi16, 3); // divide 8

			sum_epi16 = _mm_adds_epi16(sum_epi16, sum8_epi16);

			// Store the four highpass results
			_mm_store_si128(highlow_ptr++, sum_epi16);


			/***** Apply the vertical filters to the horizontal highpass results *****/

			sum_epi16 = _mm_setzero_si128();

			// Load the first row of four pixels
			quad_epi16 = _mm_load_si128((__m128i *)&highpass[0][column]);

			// Multiply each pixel by the first filter coefficient and sum the result
			sum_epi16 = _mm_subs_epi16(sum_epi16, quad_epi16);

			// Load the second row of four pixels
			quad_epi16 = _mm_load_si128((__m128i *)&highpass[1][column]);

			// Multiply each pixel by the second filter coefficient and sum the result
			sum_epi16 = _mm_subs_epi16(sum_epi16, quad_epi16);

			// Load the third row of four pixels
			quad_epi16 = _mm_load_si128((__m128i *)&highpass[2][column]);

			// Initialize the lowpass sum
			low_epi16 = quad_epi16;

			// Multiply each pixel by the third filter coefficient and sum the result
			sum8_epi16 = _mm_setzero_si128();
			sum8_epi16 = _mm_adds_epi16(sum8_epi16, quad_epi16);

			// Load the fourth row of four pixels
			quad_epi16 = _mm_load_si128((__m128i *)&highpass[3][column]);

			// Compute and store the four lowpass results
			low_epi16 = _mm_adds_epi16(low_epi16, quad_epi16);
			_mm_store_si128(lowhigh_ptr++, low_epi16);

			// Multiply each pixel by the fourth filter coefficient and sum the result
			sum8_epi16 = _mm_subs_epi16(sum8_epi16, quad_epi16);

			// Load the fifth row of four pixels
			quad_epi16 = _mm_load_si128((__m128i *)&highpass[4][column]);

			// Multiply each pixel by the fifth filter coefficient and sum the result
			sum_epi16 = _mm_adds_epi16(sum_epi16, quad_epi16);

			// Load the sixth (last) row of four pixels
			quad_epi16 = _mm_load_si128((__m128i *)&highpass[5][column]);

			// Multiply each pixel by the sixth filter coefficient and sum the result
			sum_epi16 = _mm_adds_epi16(sum_epi16, quad_epi16);


			sum_epi16 = _mm_adds_epi16(sum_epi16, half_epi16); // +7 rounding
			sum_epi16 = _mm_srai_epi16(sum_epi16, 3); // divide 8

			sum_epi16 = _mm_adds_epi16(sum_epi16, sum8_epi16);


			// Store the four highpass results
			_mm_store_si128(highhigh_ptr++, sum_epi16);
		}

		// Should have terminated the fast loop at the post processing column
		assert(column == post_column);
#endif

		// Process the remaining pixels to the end of the row
		for (; column < output_width; column++)
		{
			int32_t sum;

			// Apply the lowpass vertical filter to the lowpass horizontal results
			sum  = lowpass[2][column];
			sum += lowpass[3][column];

			if (lowlow_quantization > 1) {
				lowlow_buffer[column] = SATURATE(sum);
			}
			else {
				lowlow_row_ptr[column] = SATURATE(sum);
			}
			// Apply the highpass vertical filter to the lowpass horizontal results
			sum  = -1 * lowpass[0][column];
			sum += -1 * lowpass[1][column];
			sum +=  1 * lowpass[4][column];
			sum +=  1 * lowpass[5][column];
			sum +=	4;
			sum >>= 3;
			sum +=  1 * lowpass[2][column];
			sum += -1 * lowpass[3][column];

			highlow_buffer[column] = (sum);

			// Apply the lowpass vertical filter to the highpass horizontal results
			sum  = highpass[2][column];
			sum += highpass[3][column];
			lowhigh_buffer[column] = (sum);

			// Apply the highpass vertical filter to the highpass horizontal results
			sum  = -1 * highpass[0][column];
			sum += -1 * highpass[1][column];
			sum +=  1 * highpass[4][column];
			sum +=  1 * highpass[5][column];
			sum +=	4;
			sum >>= 3;
			sum +=  1 * highpass[2][column];
			sum += -1 * highpass[3][column];
			highhigh_buffer[column] = (sum);
		}

		if (row < (last_row - 2))
		{
			// Rotate the horizontal filter results by two rows
			PIXEL *temp0 = lowpass[0];
			PIXEL *temp1 = lowpass[1];
			PIXEL *high0 = highpass[0];
			PIXEL *high1 = highpass[1];

			for (k = 0; k < buffer_row_count - 2; k++) {
				lowpass[k] = lowpass[k+2];
				highpass[k] = highpass[k+2];
			}

			lowpass[buffer_row_count - 2] = temp0;
			lowpass[buffer_row_count - 1] = temp1;
			highpass[buffer_row_count - 2] = high0;
			highpass[buffer_row_count - 1] = high1;

			// Compute the next two rows of horizontal filter results
			for (; k < buffer_row_count; k++) {
				//SplitRow16s(rowptr, roi.width, lowpass[k], highpass[k]);
				//FilterHorizontalRowPrescaled16s(rowptr, lowpass[k], highpass[k], roi.width, NULL);
				FilterHorizontalRow16s(rowptr, lowpass[k], highpass[k], roi.width);
				rowptr += input_pitch;
			}
		}

#if _HIGHPASS_8S
		if (lowlow_quantization > 1) {
			// Quantize the current row of 16-bit lowpass coefficients
			QuantizeRow16sTo16s(lowlow_buffer, lowlow_row_ptr, output_width, lowlow_quantization);
		}
		// Quantize the current row of 8-bit highpass coefficients
		QuantizeRow16sTo8s(lowhigh_buffer, lowhigh_row_ptr, output_width, lowhigh_quantization);
		QuantizeRow16sTo8s(highlow_buffer, highlow_row_ptr, output_width, highlow_quantization);
		QuantizeRow16sTo8s(highhigh_buffer, highhigh_row_ptr, output_width, highhigh_quantization);
#else
		// Quantize the current row of results for each 16-bit output band
		if (lowlow_quantization > 1)
			QuantizeRow16sTo16s(lowlow_buffer, lowlow_row_ptr, output_width, lowlow_quantization);
		QuantizeRow16sTo16s(lowhigh_buffer, lowhigh_row_ptr, output_width, lowhigh_quantization);
		QuantizeRow16sTo16s(highlow_buffer, highlow_row_ptr, output_width, highlow_quantization);
		QuantizeRow16sTo16s(highhigh_buffer, highhigh_row_ptr, output_width, highhigh_quantization);
#endif

		// Advance to the next output rows
		lowlow_row_ptr += lowlow_pitch;
		highlow_row_ptr += highlow_pitch;
		lowhigh_row_ptr += lowhigh_pitch;
		highhigh_row_ptr += highhigh_pitch;
	}

	// Should have left the loop at the last row
	assert(row == last_row);

	// Use the border filters for the last row
	for (column = 0; column < output_width; column++)
	{
		int32_t sum;

		// Apply the lowpass vertical filter to the lowpass horizontal results
		sum  = lowpass[4][column];
		sum += lowpass[5][column];

		// The lowpass prescale should be zero
		//assert(lowscale == 0);

		if (lowlow_quantization > 1) {
			lowlow_buffer[column] = SATURATE(sum);
		}
		else {
			lowlow_row_ptr[column] = SATURATE(sum);
		}

		// Apply the highpass vertical filter to the lowpass horizontal results
		sum  = 11 * lowpass[4][column];
		sum -=  5 * lowpass[5][column];
		sum -=  4 * lowpass[3][column];
		sum -=  4 * lowpass[2][column];
		sum +=  1 * lowpass[1][column];
		sum +=  1 * lowpass[0][column];
		sum +=  ROUNDING(sum,8);
		sum = DivideByShift(sum, 3);
		highlow_buffer[column] = SATURATE(sum);

		// Apply the lowpass vertical filter to the highpass horizontal results
		sum  = highpass[4][column];
		sum += highpass[5][column];
		lowhigh_buffer[column] = SATURATE(sum);

		// Apply the highpass vertical filter to the highpass horizontal results
		sum  = 11 * highpass[4][column];
		sum -=  5 * highpass[5][column];
		sum -=  4 * highpass[3][column];
		sum -=  4 * highpass[2][column];
		sum +=  1 * highpass[1][column];
		sum +=  1 * highpass[0][column];
		sum +=  ROUNDING(sum,8);
		sum = DivideByShift(sum, 3);
		highhigh_buffer[column] = SATURATE(sum);
	}

#if _HIGHPASS_8S
		if (lowlow_quantization > 1) {
			// Quantize the 16-bit lowpass coefficients
			QuantizeRow16sTo16s(lowlow_buffer, lowlow_row_ptr, output_width, lowlow_quantization);
		}
		// Quantize the 8-bit highpass coefficients
		QuantizeRow16sTo8s(lowhigh_buffer, lowhigh_row_ptr, output_width, lowhigh_quantization);
		QuantizeRow16sTo8s(highlow_buffer, highlow_row_ptr, output_width, highlow_quantization);
		QuantizeRow16sTo8s(highhigh_buffer, highhigh_row_ptr, output_width, highhigh_quantization);
#else
		// Quantize the first row of results for each 16-bit output band
		if (lowlow_quantization > 1)
			QuantizeRow16sTo16s(lowlow_buffer, lowlow_row_ptr, output_width, lowlow_quantization);
		QuantizeRow16sTo16s(lowhigh_buffer, lowhigh_row_ptr, output_width, lowhigh_quantization);
		QuantizeRow16sTo16s(highlow_buffer, highlow_row_ptr, output_width, highlow_quantization);
		QuantizeRow16sTo16s(highhigh_buffer, highhigh_row_ptr, output_width, highhigh_quantization);
#endif
}

#endif




#if _PROCESSOR_DISPATCH

__declspec(cpu_dispatch(Pentium_4,Generic))

// Apply the frame (temporal and horizontal) transform to unsigned byte data
void FilterSpatialQuantDifferenceLL16s(PIXEL *input_image, int input_pitch,
						   PIXEL *lowlow_band, int lowlow_pitch,
						   PIXEL *lowhigh_band, int lowhigh_pitch,
						   PIXEL *highlow_band, int highlow_pitch,
						   PIXEL *highhigh_band, int highhigh_pitch,
						   PIXEL *buffer, size_t buffer_size,
						   ROI roi, int quantization[4])
{
	// Stub routine for processor specific dispatch
}

#endif


#if _PROCESSOR_GENERIC

#if _PROCESSOR_DISPATCH
__declspec(cpu_specific(Generic))
#endif

// Apply the forward spatial (horizontal and vertical) transform with quantization
void FilterSpatialQuantDifferenceLL16s(PIXEL *input_image, int input_pitch,
						   PIXEL *lowlow_band, int lowlow_pitch,
						   PIXEL *lowhigh_band, int lowhigh_pitch,
						   PIXEL *highlow_band, int highlow_pitch,
						   PIXEL *highhigh_band, int highhigh_pitch,
						   PIXEL *buffer, size_t buffer_size,
						   ROI roi, int quantization[4])
{
	PIXEL *rowptr = input_image;

	// Six rows of lowpass and highpass horizontal results
	PIXEL *lowpass[6];
	PIXEL *highpass[6];

	PIXEL *lowlow_buffer;
	PIXEL *lowhigh_buffer;
	PIXEL *highlow_buffer;
	PIXEL *highhigh_buffer;

	int lowlow_quantization;
	int lowhigh_quantization;
	int highlow_quantization;
	int highhigh_quantization;

	// Change the highpass output bands to be 8-bit pixels //

#if _HIGHPASS_8S
	PIXEL16S *lowlow_row_ptr = lowlow_band;
	PIXEL8S *lowhigh_row_ptr = (PIXEL8S *)lowhigh_band;
	PIXEL8S *highlow_row_ptr = (PIXEL8S *)highlow_band;
	PIXEL8S *highhigh_row_ptr = (PIXEL8S *)highhigh_band;
#else
	PIXEL *lowlow_row_ptr = lowlow_band;
	PIXEL *lowhigh_row_ptr = lowhigh_band;
	PIXEL *highlow_row_ptr = highlow_band;
	PIXEL *highhigh_row_ptr = highhigh_band;
#endif

	int last_row = roi.height - 2;
	int output_width;
	size_t output_buffer_size;
	int output_buffer_width;
	int row, column;
	PIXEL *bufptr;
	const int buffer_row_count = sizeof(lowpass)/sizeof(lowpass[0]);
	//const int prescale = 2;
#if _TRANSFORM_PRESCALE
	int lowround = (lowscale > 0) ? (1 << (lowscale - 1)) : 0;
#endif
	int k;

	int this_has_not_been_modified_for_differencing_LL_yet = 0;
	assert(this_has_not_been_modified_for_differencing_LL_yet);

	// Convert pitch from bytes to pixels
	input_pitch /= sizeof(PIXEL);
	lowlow_pitch /= sizeof(PIXEL);
#if _HIGHPASS_8S
	lowhigh_pitch /= sizeof(PIXEL8S);
	highlow_pitch /= sizeof(PIXEL8S);
	highhigh_pitch /= sizeof(PIXEL8S);
#else
	lowhigh_pitch /= sizeof(PIXEL);
	highlow_pitch /= sizeof(PIXEL);
	highhigh_pitch /= sizeof(PIXEL);
#endif

	if (quantization != NULL)
	{
		lowlow_quantization = quantization[0];
		lowhigh_quantization = quantization[1];
		highlow_quantization = quantization[2];
		highhigh_quantization = quantization[3];
	}
	else
	{
		lowlow_quantization = 1;
		lowhigh_quantization = 1;
		highlow_quantization = 1;
		highhigh_quantization = 1;
	}

	// Must have an even number of rows
	assert((roi.height % 2) == 0);

	// Must have an even number of columns
	assert((roi.width % 2) == 0);

	// Compute the width of each row of horizontal filter output
	output_width = roi.width/2;

	// Compute the size of each row of horizontal filter output in bytes
	output_buffer_size = output_width * sizeof(PIXEL);

	// Round up the buffer size to an integer number of cache lines
	output_buffer_size = ALIGN(output_buffer_size, _CACHE_LINE_SIZE);

	if (lowlow_quantization > 1) {
		// The buffer must be large enough for twelve rows
		assert(buffer_size >= (12 * output_buffer_size));
	}
	else {
		// The buffer must be large enough for eleven rows
		assert(buffer_size >= (11 * output_buffer_size));
	}

	// Compute the allocated width of each buffer
	output_buffer_width = output_buffer_size / sizeof(PIXEL);

	// Allocate space in the buffer for the horizontal filter results
	bufptr = buffer;
	for (k = 0; k < buffer_row_count; k++) {
		lowpass[k] = bufptr;	bufptr += output_buffer_width;
		highpass[k] = bufptr;	bufptr += output_buffer_width;
	}

	// Allocate space in the buffer for the pre-quantized coefficients
	if (lowlow_quantization > 1) {
		lowlow_buffer = bufptr;		bufptr += output_buffer_width;
	}
	lowhigh_buffer = bufptr;		bufptr += output_buffer_width;
	highlow_buffer = bufptr;		bufptr += output_buffer_width;
	highhigh_buffer = bufptr;		bufptr += output_buffer_width;

	// Compute the first six rows of horizontal filter output
	for (k = 0; k < buffer_row_count; k++) {
		//SplitRow16s(rowptr, roi.width, lowpass[k], highpass[k]);
		//FilterHorizontalRow16s(rowptr, lowpass[k], highpass[k], roi.width, input_scale, prescale);
		//assert(prescale == 0 && input_scale == 0);
		FilterHorizontalRow16s(rowptr, lowpass[k], highpass[k], roi.width);
		rowptr += input_pitch;
	}


	/***** Need to optimize the first and last row calculations *****/

	// Use border filters for the first row
	row = 0;

	for (column = 0; column < output_width; column++)
	{
		int32_t sum;

		// Apply the lowpass vertical filter to the lowpass horizontal results
		sum  = lowpass[0][column];
		sum += lowpass[1][column];

		// The lowpass prescale should be zero
		//assert(lowscale == 0);

		if (lowlow_quantization > 1) {
			lowlow_buffer[column] = SATURATE(sum);
		}
		else {
			lowlow_row_ptr[column] = SATURATE(sum);
		}

		// Apply the highpass vertical filter to the lowpass horizontal results
		sum  =  5 * lowpass[0][column];
		sum -= 11 * lowpass[1][column];
		sum +=  4 * lowpass[2][column];
		sum +=  4 * lowpass[3][column];
		sum -=  1 * lowpass[4][column];
		sum -=  1 * lowpass[5][column];
		sum += ROUNDING(sum,8);
		sum = DivideByShift(sum, 3);
		highlow_buffer[column] = SATURATE(sum);

		// Apply the lowpass vertical filter to the highpass horizontal results
		sum  = highpass[0][column];
		sum += highpass[1][column];
		lowhigh_buffer[column] = SATURATE(sum);

		// Apply the highpass vertical filter to the highpass horizontal results
		sum  =  5 * highpass[0][column];
		sum -= 11 * highpass[1][column];
		sum +=  4 * highpass[2][column];
		sum +=  4 * highpass[3][column];
		sum -=  1 * highpass[4][column];
		sum -=  1 * highpass[5][column];
		sum += ROUNDING(sum,8);
		sum = DivideByShift(sum, 3);
		highhigh_buffer[column] = SATURATE(sum);
	}

#if _HIGHPASS_8S
	if (lowlow_quantization > 1) {
		// Quantize the first row of 16-bit lowpass coefficients
		QuantizeRow16sTo16s(lowlow_buffer, lowlow_row_ptr, output_width, lowlow_quantization);
	}
	// Quantize the first row of 8-bit highpass coefficients
	QuantizeRow16sTo8s(lowhigh_buffer, lowhigh_row_ptr, output_width, lowhigh_quantization);
	QuantizeRow16sTo8s(highlow_buffer, highlow_row_ptr, output_width, highlow_quantization);
	QuantizeRow16sTo8s(highhigh_buffer, highhigh_row_ptr, output_width, highhigh_quantization);
#else
	// Quantize the first row of results for each 16-bit output band
	if (lowlow_quantization > 1)
		QuantizeRow16sTo16s(lowlow_buffer, lowlow_row_ptr, output_width, lowlow_quantization);
	QuantizeRow16sTo16s(lowhigh_buffer, lowhigh_row_ptr, output_width, lowhigh_quantization);
	QuantizeRow16sTo16s(highlow_buffer, highlow_row_ptr, output_width, highlow_quantization);
	QuantizeRow16sTo16s(highhigh_buffer, highhigh_row_ptr, output_width, highhigh_quantization);
#endif

#if 0
	// Advance to the next pair of input rows if not using the SIMD code since the
	// SIMD version uses the first two rows again to compute the second output row

	{
		// Rotate the horizontal filter results by two rows
		PIXEL *temp0 = lowpass[0];
		PIXEL *temp1 = lowpass[1];
		PIXEL *high0 = highpass[0];
		PIXEL *high1 = highpass[1];

		for (k = 0; k < buffer_row_count - 2; k++) {
			lowpass[k] = lowpass[k+2];
			highpass[k] = highpass[k+2];
		}

		lowpass[buffer_row_count - 2] = temp0;
		lowpass[buffer_row_count - 1] = temp1;
		highpass[buffer_row_count - 2] = high0;
		highpass[buffer_row_count - 1] = high1;

		// Compute the next two rows of horizontal filter results
		for (; k < buffer_row_count; k++) {
			//SplitRow16s(rowptr, roi.width, lowpass[k], highpass[k]);
			//FilterHorizontalRow16s(rowptr, lowpass[k], highpass[k], roi.width, input_scale, prescale);
			assert(prescale == 0 && input_scale == 0);
			FilterHorizontalRow16s(rowptr, lowpass[k], highpass[k], roi.width);
			rowptr += input_pitch;
		}
	}
#endif

	// Advance to the next output rows
	lowlow_row_ptr += lowlow_pitch;
	highlow_row_ptr += highlow_pitch;
	lowhigh_row_ptr += lowhigh_pitch;
	highhigh_row_ptr += highhigh_pitch;

	row += 2;								// Advance the row being processed

	for (; row < last_row; row += 2)
	{
#if (1 && XMMOPT)
		__m64 *lowlow_ptr;
		__m64 *highlow_ptr = (__m64 *)highlow_buffer;
		__m64 *lowhigh_ptr = (__m64 *)lowhigh_buffer;
		__m64 *highhigh_ptr = (__m64 *)highhigh_buffer;

		int column_step = 4;
		int post_column = output_width - (output_width % column_step);
#endif
		// Start at the first column
		column = 0;

#if (1 && XMMOPT)

		if (lowlow_quantization > 1) {
			lowlow_ptr = (__m64 *)lowlow_buffer;
		}
		else {
			lowlow_ptr = (__m64 *)lowlow_row_ptr;
		}

		// Process a group of four pixels at a time
		for (; column < post_column; column += column_step)
		{
			__m64 low_pi16;
			__m64 sum_pi16;
			__m64 quad_pi16;
			__m64 mask_pi16;
			__m64 half_pi16;


			// Apply the vertical filters to the horizontal lowpass results //

			// Load the first row of four pixels
			quad_pi16 = *((__m64 *)&lowpass[0][column]);

			// Initialize the highpass filter sum
			sum_pi16 = _mm_setzero_si64();

			// Multiply each pixel by the first filter coefficient and sum the result
			sum_pi16 = _mm_subs_pi16(sum_pi16, quad_pi16);

			// Load the second row of four pixels
			quad_pi16 = *((__m64 *)&lowpass[1][column]);

			// Multiply each pixel by the second filter coefficient and sum the result
			sum_pi16 = _mm_subs_pi16(sum_pi16, quad_pi16);

			// Load the third row of four pixels
			quad_pi16 = *((__m64 *)&lowpass[2][column]);

			// Initialize the lowpass sum
			low_pi16 = quad_pi16;

			// Multiply each pixel by the third filter coefficient and sum the result
			quad_pi16 = _mm_slli_pi16(quad_pi16, 3);
			sum_pi16 = _mm_adds_pi16(sum_pi16, quad_pi16);

			// Load the fourth row of four pixels
			quad_pi16 = *((__m64 *)&lowpass[3][column]);

			// Compute the four lowpass results
			low_pi16 = _mm_adds_pi16(low_pi16, quad_pi16);

			// Store the lowpass results
			*(lowlow_ptr++) = low_pi16;

			// Multiply each pixel by the fourth filter coefficient and sum the result
			quad_pi16 = _mm_slli_pi16(quad_pi16, 3);
			sum_pi16 = _mm_subs_pi16(sum_pi16, quad_pi16);

			// Load the fifth row of four pixels
			quad_pi16 = *((__m64 *)&lowpass[4][column]);

			// Multiply each pixel by the fifth filter coefficient and sum the result
			sum_pi16 = _mm_adds_pi16(sum_pi16, quad_pi16);

			// Load the sixth (last) row of four pixels
			quad_pi16 = *((__m64 *)&lowpass[5][column]);

			// Multiply each pixel by the sixth filter coefficient and sum the result
			sum_pi16 = _mm_adds_pi16(sum_pi16, quad_pi16);

			// Approximate division by eight
			half_pi16 = _mm_set1_pi16(4);
			sum_pi16 = _mm_srai_pi16(sum_pi16, 3);
			sum_pi16 = _mm_adds_pi16(sum_pi16, half_pi16);

			// Store the four highpass results
			*(highlow_ptr++) = sum_pi16;


			// Apply the vertical filters to the horizontal highpass results //

			sum_pi16 = _mm_setzero_si64();

			// Load the first row of four pixels
			quad_pi16 = *((__m64 *)&highpass[0][column]);

			// Multiply each pixel by the first filter coefficient and sum the result
			sum_pi16 = _mm_subs_pi16(sum_pi16, quad_pi16);

			// Load the second row of four pixels
			quad_pi16 = *((__m64 *)&highpass[1][column]);

			// Multiply each pixel by the second filter coefficient and sum the result
			sum_pi16 = _mm_subs_pi16(sum_pi16, quad_pi16);

			// Load the third row of four pixels
			quad_pi16 = *((__m64 *)&highpass[2][column]);

			// Initialize the lowpass sum
			low_pi16 = quad_pi16;

			// Multiply each pixel by the third filter coefficient and sum the result
			quad_pi16 = _mm_slli_pi16(quad_pi16, 3);
			sum_pi16 = _mm_adds_pi16(sum_pi16, quad_pi16);

			// Load the fourth row of four pixels
			quad_pi16 = *((__m64 *)&highpass[3][column]);

			// Compute and store the four lowpass results
			low_pi16 = _mm_adds_pi16(low_pi16, quad_pi16);
			*(lowhigh_ptr++) = low_pi16;

			// Multiply each pixel by the fourth filter coefficient and sum the result
			quad_pi16 = _mm_slli_pi16(quad_pi16, 3);
			sum_pi16 = _mm_subs_pi16(sum_pi16, quad_pi16);

			// Load the fifth row of four pixels
			quad_pi16 = *((__m64 *)&highpass[4][column]);

			// Multiply each pixel by the fifth filter coefficient and sum the result
			sum_pi16 = _mm_adds_pi16(sum_pi16, quad_pi16);

			// Load the sixth (last) row of four pixels
			quad_pi16 = *((__m64 *)&highpass[5][column]);

			// Multiply each pixel by the sixth filter coefficient and sum the result
			sum_pi16 = _mm_adds_pi16(sum_pi16, quad_pi16);

			// Approximate division by eight
			half_pi16 = _mm_set1_pi16(4);
			sum_pi16 = _mm_srai_pi16(sum_pi16, 3);
			sum_pi16 = _mm_adds_pi16(sum_pi16, half_pi16);

			// Store the four highpass results
			*(highhigh_ptr++) = sum_pi16;
		}

		// Should have terminated the fast loop at the post processing column
		assert(column == post_column);
#endif

		// Process the remaining pixels to the end of the row
		for (; column < output_width; column++)
		{
			int32_t sum;

			// Apply the lowpass vertical filter to the lowpass horizontal results
			sum  = lowpass[2][column];
			sum += lowpass[3][column];

			// The lowpass prescale should be zero
			//assert(lowscale == 0);

			if (lowlow_quantization > 1) {
				lowlow_buffer[column] = SATURATE(sum);
			}
			else {
				lowlow_row_ptr[column] = SATURATE(sum);
			}

			// Apply the highpass vertical filter to the lowpass horizontal results
			sum  = -1 * lowpass[0][column];
			sum += -1 * lowpass[1][column];
			sum +=  1 * lowpass[4][column];
			sum +=  1 * lowpass[5][column];
			sum += ROUNDING(sum,8);
			sum = DivideByShift(sum, 3);
			sum +=  lowpass[2][column];
			sum += -lowpass[3][column];
			highlow_buffer[column] = SATURATE(sum);

			// Apply the lowpass vertical filter to the highpass horizontal results
			sum  = highpass[2][column];
			sum += highpass[3][column];
			lowhigh_buffer[column] = SATURATE(sum);

			// Apply the highpass vertical filter to the highpass horizontal results
			sum  = -1 * highpass[0][column];
			sum += -1 * highpass[1][column];
			sum +=  1 * highpass[4][column];
			sum +=  1 * highpass[5][column];
			sum += ROUNDING(sum,8);
			sum = DivideByShift(sum, 3);
			sum +=  highpass[2][column];
			sum += -highpass[3][column];
			highhigh_buffer[column] = SATURATE(sum);
		}

		if (row < (last_row - 2))
		{
			// Rotate the horizontal filter results by two rows
			PIXEL *temp0 = lowpass[0];
			PIXEL *temp1 = lowpass[1];
			PIXEL *high0 = highpass[0];
			PIXEL *high1 = highpass[1];

			for (k = 0; k < buffer_row_count - 2; k++) {
				lowpass[k] = lowpass[k+2];
				highpass[k] = highpass[k+2];
			}

			lowpass[buffer_row_count - 2] = temp0;
			lowpass[buffer_row_count - 1] = temp1;
			highpass[buffer_row_count - 2] = high0;
			highpass[buffer_row_count - 1] = high1;

			// Compute the next two rows of horizontal filter results
			for (; k < buffer_row_count; k++) {
				//SplitRow16s(rowptr, roi.width, lowpass[k], highpass[k]);
				//FilterHorizontalRow16s(rowptr, lowpass[k], highpass[k], roi.width, input_scale, prescale);
				//assert(prescale == 0 && input_scale == 0);
				FilterHorizontalRow16s(rowptr, lowpass[k], highpass[k], roi.width);
				rowptr += input_pitch;
			}
		}

#if _HIGHPASS_8S
		if (lowlow_quantization > 1) {
			// Quantize the current row of 16-bit lowpass coefficients
			QuantizeRow16sTo16s(lowlow_buffer, lowlow_row_ptr, output_width, lowlow_quantization);
		}
		// Quantize the current row of 8-bit highpass coefficients
		QuantizeRow16sTo8s(lowhigh_buffer, lowhigh_row_ptr, output_width, lowhigh_quantization);
		QuantizeRow16sTo8s(highlow_buffer, highlow_row_ptr, output_width, highlow_quantization);
		QuantizeRow16sTo8s(highhigh_buffer, highhigh_row_ptr, output_width, highhigh_quantization);
#else
		// Quantize the current row of results for each 16-bit output band
		if (lowlow_quantization > 1)
			QuantizeRow16sTo16s(lowlow_buffer, lowlow_row_ptr, output_width, lowlow_quantization);
		QuantizeRow16sTo16s(lowhigh_buffer, lowhigh_row_ptr, output_width, lowhigh_quantization);
		QuantizeRow16sTo16s(highlow_buffer, highlow_row_ptr, output_width, highlow_quantization);
		QuantizeRow16sTo16s(highhigh_buffer, highhigh_row_ptr, output_width, highhigh_quantization);
#endif

		// Advance to the next output rows
		lowlow_row_ptr += lowlow_pitch;
		highlow_row_ptr += highlow_pitch;
		lowhigh_row_ptr += lowhigh_pitch;
		highhigh_row_ptr += highhigh_pitch;
	}

	// Should have left the loop at the last row
	assert(row == last_row);

	// Use the border filters for the last row
	for (column = 0; column < output_width; column++)
	{
		int32_t sum;

		// Apply the lowpass vertical filter to the lowpass horizontal results
		sum  = lowpass[4][column];
		sum += lowpass[5][column];

		// The lowpass prescale should be zero
		//assert(lowscale == 0);

		if (lowlow_quantization > 1) {
			lowlow_buffer[column] = SATURATE(sum);
		}
		else {
			lowlow_row_ptr[column] = SATURATE(sum);
		}

		// Apply the highpass vertical filter to the lowpass horizontal results
		sum  = 11 * lowpass[4][column];
		sum -=  5 * lowpass[5][column];
		sum -=  4 * lowpass[3][column];
		sum -=  4 * lowpass[2][column];
		sum +=  1 * lowpass[1][column];
		sum +=  1 * lowpass[0][column];
		sum +=  ROUNDING(sum,8);
		sum = DivideByShift(sum, 3);
		highlow_buffer[column] = SATURATE(sum);

		// Apply the lowpass vertical filter to the highpass horizontal results
		sum  = highpass[4][column];
		sum += highpass[5][column];
		lowhigh_buffer[column] = SATURATE(sum);

		// Apply the highpass vertical filter to the highpass horizontal results
		sum  = 11 * highpass[4][column];
		sum -=  5 * highpass[5][column];
		sum -=  4 * highpass[3][column];
		sum -=  4 * highpass[2][column];
		sum +=  1 * highpass[1][column];
		sum +=  1 * highpass[0][column];
		sum +=  ROUNDING(sum,8);
		sum = DivideByShift(sum, 3);
		highhigh_buffer[column] = SATURATE(sum);
	}

#if _HIGHPASS_8S
		if (lowlow_quantization > 1) {
			// Quantize the 16-bit lowpass coefficients
			QuantizeRow16sTo16s(lowlow_buffer, lowlow_row_ptr, output_width, lowlow_quantization);
		}
		// Quantize the 8-bit highpass coefficients
		QuantizeRow16sTo8s(lowhigh_buffer, lowhigh_row_ptr, output_width, lowhigh_quantization);
		QuantizeRow16sTo8s(highlow_buffer, highlow_row_ptr, output_width, highlow_quantization);
		QuantizeRow16sTo8s(highhigh_buffer, highhigh_row_ptr, output_width, highhigh_quantization);
#else
		// Quantize the first row of results for each 16-bit output band
		if (lowlow_quantization > 1)
			QuantizeRow16sTo16s(lowlow_buffer, lowlow_row_ptr, output_width, lowlow_quantization);
		QuantizeRow16sTo16s(lowhigh_buffer, lowhigh_row_ptr, output_width, lowhigh_quantization);
		QuantizeRow16sTo16s(highlow_buffer, highlow_row_ptr, output_width, highlow_quantization);
		QuantizeRow16sTo16s(highhigh_buffer, highhigh_row_ptr, output_width, highhigh_quantization);
#endif

	//_mm_empty();	// Clear the mmx register state
}

#endif


#if _PROCESSOR_PENTIUM_4

#if _PROCESSOR_DISPATCH
__declspec(cpu_specific(Pentium_4))
#endif

// Apply the forward spatial (horizontal and vertical) transform with quantization
void FilterSpatialQuantDifferenceLL16s(PIXEL *input_image, int input_pitch,
						   PIXEL *lowlow_band, int lowlow_pitch,
						   PIXEL *lowhigh_band, int lowhigh_pitch,
						   PIXEL *highlow_band, int highlow_pitch,
						   PIXEL *highhigh_band, int highhigh_pitch,
						   PIXEL *buffer, size_t buffer_size,
						   ROI roi, int quantization[4])
{
	PIXEL *rowptr = input_image;

	// Six rows of lowpass and highpass horizontal results
	PIXEL *lowpass[6];
	PIXEL *highpass[6];

	PIXEL *lowhigh_buffer;
	PIXEL *highlow_buffer;
	PIXEL *highhigh_buffer;

	int lowlow_quantization;
	int lowhigh_quantization;
	int highlow_quantization;
	int highhigh_quantization;

	// Change the highpass output bands to be 8-bit pixels //

	PIXEL *lowlow_row_ptr = lowlow_band;
	PIXEL *lowhigh_row_ptr = lowhigh_band;
	PIXEL *highlow_row_ptr = highlow_band;
	PIXEL *highhigh_row_ptr = highhigh_band;

	int last_row = roi.height - 2;
	int output_width;
	size_t output_buffer_size;
	int output_buffer_width;
	int row, column;
	PIXEL *bufptr;
	const int buffer_row_count = sizeof(lowpass)/sizeof(lowpass[0]);
	//const int prescale = 2;
	int k;


	__m128i quant_epi16;
	__m128i offset_epi16;
	__m128i zero_epi16;
	__m128i sign_epi16;
	__m128i tmp_epi16;

	int lastsum;
	int multiplier;

	// Setup for differencing pre-quantization
	int prequant_midpoint = 0;// divisor/2;

	// Convert pitch from bytes to pixels
	input_pitch /= sizeof(PIXEL);
	lowlow_pitch /= sizeof(PIXEL);
	lowhigh_pitch /= sizeof(PIXEL);
	highlow_pitch /= sizeof(PIXEL);
	highhigh_pitch /= sizeof(PIXEL);

	if (quantization != NULL)
	{
		lowlow_quantization = quantization[0];
		lowhigh_quantization = quantization[1];
		highlow_quantization = quantization[2];
		highhigh_quantization = quantization[3];
	}
	else
	{
		lowlow_quantization = 1;
		lowhigh_quantization = 1;
		highlow_quantization = 1;
		highhigh_quantization = 1;
	}

#if MIDPOINT_PREQUANT
	if(g_midpoint_prequant >= 2 && g_midpoint_prequant < 9)
		prequant_midpoint = lowlow_quantization / g_midpoint_prequant;
#endif

	// Change division to multiplication by a fraction
	multiplier = (uint32_t)(1 << 16) / lowlow_quantization;
	quant_epi16 = _mm_set1_epi16(multiplier);
	zero_epi16 = _mm_set1_epi16(0);
#if MIDPOINT_PREQUANT
	offset_epi16 = _mm_set1_epi16(prequant_midpoint);
#endif


	// Must have an even number of rows
	assert((roi.height % 2) == 0);

	// Must have an even number of columns
	assert((roi.width % 2) == 0);

	// Compute the width of each row of horizontal filter output
	output_width = roi.width/2;
	//output_width = ALIGN16(output_width);

	// Compute the size of each row of horizontal filter output in bytes
	output_buffer_size = output_width * sizeof(PIXEL);

	// Round up the buffer size to an integer number of cache lines
	output_buffer_size = ALIGN(output_buffer_size, _CACHE_LINE_SIZE);


	// The buffer must be large enough for eleven rows
	assert(buffer_size >= (11 * output_buffer_size));


	// Compute the allocated width of each buffer
	output_buffer_width = (int)output_buffer_size / sizeof(PIXEL);

	// Allocate space in the buffer for the horizontal filter results
	bufptr = buffer;
	for (k = 0; k < buffer_row_count; k++) {
		lowpass[k] = bufptr;		bufptr += output_buffer_width;
		highpass[k] = bufptr;		bufptr += output_buffer_width;
	}

	// Allocate space in the buffer for the pre-quantized coefficients
	lowhigh_buffer = bufptr;		bufptr += output_buffer_width;
	highlow_buffer = bufptr;		bufptr += output_buffer_width;
	highhigh_buffer = bufptr;		bufptr += output_buffer_width;

	// Compute the first six rows of horizontal filter output
	for (k = 0; k < buffer_row_count; k++) {
		//SplitRow16s(rowptr, roi.width, lowpass[k], highpass[k]);
		//FilterHorizontalRowPrescaled16s(rowptr, lowpass[k], highpass[k], roi.width, NULL);
		FilterHorizontalRow16s(rowptr, lowpass[k], highpass[k], roi.width);
		rowptr += input_pitch;
	}


	// Need to optimize the first and last row calculations //

	// Use border filters for the first row
	{
		int tmp;
		row = 0;
		lastsum = 0;

		for (column = 0; column < output_width; column++)
		{
			int32_t sum;

			// Apply the lowpass vertical filter to the lowpass horizontal results
			sum  = lowpass[0][column];
			sum += lowpass[1][column];

			if(sum < 0)
			{
				sum = -sum;
#if MIDPOINT_PREQUANT
				sum += prequant_midpoint;
#endif
				sum *= multiplier; // quantize
				sum >>= 16;
				sum = -sum;
			}
			else
			{
#if MIDPOINT_PREQUANT
				sum += prequant_midpoint;
#endif
				sum *= multiplier; // quantize
				sum >>= 16;
			}

			tmp = sum;
			sum -= lastsum;
			lastsum = tmp;

			// The lowpass prescale should be zero
			//assert(lowscale == 0);

			lowlow_row_ptr[column] = SATURATE(sum);

			// Apply the highpass vertical filter to the lowpass horizontal results
			sum  =  5 * lowpass[0][column];
			sum -= 11 * lowpass[1][column];
			sum +=  4 * lowpass[2][column];
			sum +=  4 * lowpass[3][column];
			sum -=  1 * lowpass[4][column];
			sum -=  1 * lowpass[5][column];
			sum += ROUNDING(sum,8);
			sum = DivideByShift(sum, 3);
			highlow_buffer[column] = SATURATE(sum);

			// Apply the lowpass vertical filter to the highpass horizontal results
			sum  = highpass[0][column];
			sum += highpass[1][column];
			lowhigh_buffer[column] = SATURATE(sum);

			// Apply the highpass vertical filter to the highpass horizontal results
			sum  =  5 * highpass[0][column];
			sum -= 11 * highpass[1][column];
			sum +=  4 * highpass[2][column];
			sum +=  4 * highpass[3][column];
			sum -=  1 * highpass[4][column];
			sum -=  1 * highpass[5][column];
			sum += ROUNDING(sum,8);
			sum = DivideByShift(sum, 3);
			highhigh_buffer[column] = SATURATE(sum);
		}
	}



	// Quantize the first row of results for each 16-bit output band
	QuantizeRow16sTo16s(lowhigh_buffer, lowhigh_row_ptr, output_width, lowhigh_quantization);
	QuantizeRow16sTo16s(highlow_buffer, highlow_row_ptr, output_width, highlow_quantization);
	QuantizeRow16sTo16s(highhigh_buffer, highhigh_row_ptr, output_width, highhigh_quantization);


	// Advance to the next output rows
	lowlow_row_ptr += lowlow_pitch;
	highlow_row_ptr += highlow_pitch;
	lowhigh_row_ptr += lowhigh_pitch;
	highhigh_row_ptr += highhigh_pitch;

	row += 2;								// Advance the row being processed

	for (; row < last_row; row += 2)
	{
		int lastsumvalue = 0;

#if (1 && XMMOPT)
		__m128i *lowlow_ptr;
		__m128i *highlow_ptr = (__m128i *)highlow_buffer;
		__m128i *lowhigh_ptr = (__m128i *)lowhigh_buffer;
		__m128i *highhigh_ptr = (__m128i *)highhigh_buffer;

		int column_step = 8;
		int post_column = output_width - (output_width % column_step);
#endif
		// Start at the first column
		column = 0;

#if (1 && XMMOPT)
		lowlow_ptr = (__m128i *)lowlow_row_ptr;

		// Process a group of eight pixels at a time
		for (; column < post_column; column += column_step)
		{
			__m128i low_epi16;
			__m128i sum_epi16;
			__m128i sum8_epi16;
			__m128i quad_epi16;
			__m128i half_epi16;


			/***** Apply the vertical filters to the horizontal lowpass results *****/

			// Load the first row of four pixels
			quad_epi16 = _mm_load_si128((__m128i *)&lowpass[0][column]);

			// Initialize the highpass filter sum
			sum_epi16 = _mm_setzero_si128();

			// Multiply each pixel by the first filter coefficient and sum the result
			sum_epi16 = _mm_subs_epi16(sum_epi16, quad_epi16);

			// Load the second row of four pixels
			quad_epi16 = _mm_load_si128((__m128i *)&lowpass[1][column]);

			// Multiply each pixel by the second filter coefficient and sum the result
			sum_epi16 = _mm_subs_epi16(sum_epi16, quad_epi16);

			// Load the third row of four pixels
			quad_epi16 = _mm_load_si128((__m128i *)&lowpass[2][column]);

			// Initialize the lowpass sum
			low_epi16 = quad_epi16;

			// Multiply each pixel by the third filter coefficient and sum the result
			sum8_epi16 = _mm_setzero_si128();
			sum8_epi16 = _mm_adds_epi16(sum8_epi16, quad_epi16);

			// Load the fourth row of four pixels
			quad_epi16 = _mm_load_si128((__m128i *)&lowpass[3][column]);

			// Compute the four lowpass results
			low_epi16 = _mm_adds_epi16(low_epi16, quad_epi16);




			///////////////////////////////////////////////////
			// Quantize the passlow BEFORE it is differenced.//
			///////////////////////////////////////////////////
			sign_epi16 = _mm_cmpgt_epi16(zero_epi16, low_epi16);
			// Compute the absolute value
			low_epi16 = _mm_xor_si128(low_epi16, sign_epi16);
			low_epi16 = _mm_sub_epi16(low_epi16, sign_epi16);
	#if MIDPOINT_PREQUANT
			// Add the prequant_midpoint for quantization rounding
			low_epi16 = _mm_add_epi16(low_epi16, offset_epi16);
	#endif
			// Multiply by the quantization factor
			low_epi16 = _mm_mulhi_epu16(low_epi16, quant_epi16);
			// Restore the sign
			low_epi16 = _mm_xor_si128(low_epi16, sign_epi16);
			low_epi16 = _mm_sub_epi16(low_epi16, sign_epi16);



			///////////////////////////////////////////////////
			// New differencing engine                       //
			// this code makes the low-pass difference data. //
			///////////////////////////////////////////////////
			tmp_epi16 = _mm_slli_si128(low_epi16, 1*2);
			tmp_epi16 = _mm_insert_epi16(tmp_epi16, lastsumvalue, 0);
			lastsumvalue = _mm_extract_epi16(low_epi16, 7);
			low_epi16 = _mm_sub_epi16(low_epi16, tmp_epi16);




			// Store the lowpass results
			_mm_store_si128(lowlow_ptr++, low_epi16);

			// Multiply each pixel by the fourth filter coefficient and sum the result
			sum8_epi16 = _mm_subs_epi16(sum8_epi16, quad_epi16);

			// Load the fifth row of four pixels
			quad_epi16 = _mm_load_si128((__m128i *)&lowpass[4][column]);

			// Multiply each pixel by the fifth filter coefficient and sum the result
			sum_epi16 = _mm_adds_epi16(sum_epi16, quad_epi16);

			// Load the sixth (last) row of four pixels
			quad_epi16 = _mm_load_si128((__m128i *)&lowpass[5][column]);

			// Multiply each pixel by the sixth filter coefficient and sum the result
			sum_epi16 = _mm_adds_epi16(sum_epi16, quad_epi16);


			half_epi16 = _mm_set1_epi16(4); //DAN031604 4 to 6
			sum_epi16 = _mm_adds_epi16(sum_epi16, half_epi16); // +7 rounding
			sum_epi16 = _mm_srai_epi16(sum_epi16, 3); // divide 8

			sum_epi16 = _mm_adds_epi16(sum_epi16, sum8_epi16);

			// Store the four highpass results
			_mm_store_si128(highlow_ptr++, sum_epi16);


			/***** Apply the vertical filters to the horizontal highpass results *****/

			sum_epi16 = _mm_setzero_si128();

			// Load the first row of four pixels
			quad_epi16 = _mm_load_si128((__m128i *)&highpass[0][column]);

			// Multiply each pixel by the first filter coefficient and sum the result
			sum_epi16 = _mm_subs_epi16(sum_epi16, quad_epi16);

			// Load the second row of four pixels
			quad_epi16 = _mm_load_si128((__m128i *)&highpass[1][column]);

			// Multiply each pixel by the second filter coefficient and sum the result
			sum_epi16 = _mm_subs_epi16(sum_epi16, quad_epi16);

			// Load the third row of four pixels
			quad_epi16 = _mm_load_si128((__m128i *)&highpass[2][column]);

			// Initialize the lowpass sum
			low_epi16 = quad_epi16;

			// Multiply each pixel by the third filter coefficient and sum the result
			sum8_epi16 = _mm_setzero_si128();
			sum8_epi16 = _mm_adds_epi16(sum8_epi16, quad_epi16);

			// Load the fourth row of four pixels
			quad_epi16 = _mm_load_si128((__m128i *)&highpass[3][column]);

			// Compute and store the four lowpass results
			low_epi16 = _mm_adds_epi16(low_epi16, quad_epi16);
			_mm_store_si128(lowhigh_ptr++, low_epi16);

			// Multiply each pixel by the fourth filter coefficient and sum the result
			sum8_epi16 = _mm_subs_epi16(sum8_epi16, quad_epi16);

			// Load the fifth row of four pixels
			quad_epi16 = _mm_load_si128((__m128i *)&highpass[4][column]);

			// Multiply each pixel by the fifth filter coefficient and sum the result
			sum_epi16 = _mm_adds_epi16(sum_epi16, quad_epi16);

			// Load the sixth (last) row of four pixels
			quad_epi16 = _mm_load_si128((__m128i *)&highpass[5][column]);

			// Multiply each pixel by the sixth filter coefficient and sum the result
			sum_epi16 = _mm_adds_epi16(sum_epi16, quad_epi16);


			sum_epi16 = _mm_adds_epi16(sum_epi16, half_epi16); // +7 rounding
			sum_epi16 = _mm_srai_epi16(sum_epi16, 3); // divide 8

			sum_epi16 = _mm_adds_epi16(sum_epi16, sum8_epi16);


			// Store the four highpass results
			_mm_store_si128(highhigh_ptr++, sum_epi16);
		}

		// Should have terminated the fast loop at the post processing column
		assert(column == post_column);
#endif

		lastsum = lowlow_row_ptr[column-1];
		// Process the remaining pixels to the end of the row
		for (; column < output_width; column++)
		{
			int32_t sum,tmp;

			// Apply the lowpass vertical filter to the lowpass horizontal results
			sum  = lowpass[2][column];
			sum += lowpass[3][column];

			if(sum < 0)
			{
				sum = -sum;
#if MIDPOINT_PREQUANT
				sum += prequant_midpoint;
#endif
				sum *= multiplier; // quantize
				sum >>= 16;
				sum = -sum;
			}
			else
			{
#if MIDPOINT_PREQUANT
				sum += prequant_midpoint;
#endif
				sum *= multiplier; // quantize
				sum >>= 16;
			}

			tmp = sum;
			sum -= lastsum;
			lastsum = tmp;

			lowlow_row_ptr[column] = SATURATE(sum);

			// Apply the highpass vertical filter to the lowpass horizontal results
			sum  = -1 * lowpass[0][column];
			sum += -1 * lowpass[1][column];
			sum +=  1 * lowpass[4][column];
			sum +=  1 * lowpass[5][column];
			sum +=	4;
			sum >>= 3;
			sum +=  1 * lowpass[2][column];
			sum += -1 * lowpass[3][column];

			highlow_buffer[column] = (sum);

			// Apply the lowpass vertical filter to the highpass horizontal results
			sum  = highpass[2][column];
			sum += highpass[3][column];
			lowhigh_buffer[column] = (sum);

			// Apply the highpass vertical filter to the highpass horizontal results
			sum  = -1 * highpass[0][column];
			sum += -1 * highpass[1][column];
			sum +=  1 * highpass[4][column];
			sum +=  1 * highpass[5][column];
			sum +=	4;
			sum >>= 3;
			sum +=  1 * highpass[2][column];
			sum += -1 * highpass[3][column];
			highhigh_buffer[column] = (sum);
		}

		if (row < (last_row - 2))
		{
			// Rotate the horizontal filter results by two rows
			PIXEL *temp0 = lowpass[0];
			PIXEL *temp1 = lowpass[1];
			PIXEL *high0 = highpass[0];
			PIXEL *high1 = highpass[1];

			for (k = 0; k < buffer_row_count - 2; k++) {
				lowpass[k] = lowpass[k+2];
				highpass[k] = highpass[k+2];
			}

			lowpass[buffer_row_count - 2] = temp0;
			lowpass[buffer_row_count - 1] = temp1;
			highpass[buffer_row_count - 2] = high0;
			highpass[buffer_row_count - 1] = high1;

			// Compute the next two rows of horizontal filter results
			for (; k < buffer_row_count; k++) {
				//SplitRow16s(rowptr, roi.width, lowpass[k], highpass[k]);
				//FilterHorizontalRowPrescaled16s(rowptr, lowpass[k], highpass[k], roi.width, NULL);
				FilterHorizontalRow16s(rowptr, lowpass[k], highpass[k], roi.width);
				rowptr += input_pitch;
			}
		}


		QuantizeRow16sTo16s(lowhigh_buffer, lowhigh_row_ptr, output_width, lowhigh_quantization);
		QuantizeRow16sTo16s(highlow_buffer, highlow_row_ptr, output_width, highlow_quantization);
		QuantizeRow16sTo16s(highhigh_buffer, highhigh_row_ptr, output_width, highhigh_quantization);

		// Advance to the next output rows
		lowlow_row_ptr += lowlow_pitch;
		highlow_row_ptr += highlow_pitch;
		lowhigh_row_ptr += lowhigh_pitch;
		highhigh_row_ptr += highhigh_pitch;
	}

	// Should have left the loop at the last row
	assert(row == last_row);

	// Use the border filters for the last row
	lastsum = 0;
	for (column = 0; column < output_width; column++)
	{
		int32_t sum,tmp;

		// Apply the lowpass vertical filter to the lowpass horizontal results
		sum  = lowpass[4][column];
		sum += lowpass[5][column];

		if(sum < 0)
		{
			sum = -sum;
#if MIDPOINT_PREQUANT
			sum += prequant_midpoint;
#endif
			sum *= multiplier; // quantize
			sum >>= 16;
			sum = -sum;
		}
		else
		{
#if MIDPOINT_PREQUANT
			sum += prequant_midpoint;
#endif
			sum *= multiplier; // quantize
			sum >>= 16;
		}

		tmp = sum;
		sum -= lastsum;
		lastsum = tmp;

		// The lowpass prescale should be zero
		//assert(lowscale == 0);

		lowlow_row_ptr[column] = SATURATE(sum);

		// Apply the highpass vertical filter to the lowpass horizontal results
		sum  = 11 * lowpass[4][column];
		sum -=  5 * lowpass[5][column];
		sum -=  4 * lowpass[3][column];
		sum -=  4 * lowpass[2][column];
		sum +=  1 * lowpass[1][column];
		sum +=  1 * lowpass[0][column];
		sum +=  ROUNDING(sum,8);
		sum = DivideByShift(sum, 3);
		highlow_buffer[column] = SATURATE(sum);

		// Apply the lowpass vertical filter to the highpass horizontal results
		sum  = highpass[4][column];
		sum += highpass[5][column];
		lowhigh_buffer[column] = SATURATE(sum);

		// Apply the highpass vertical filter to the highpass horizontal results
		sum  = 11 * highpass[4][column];
		sum -=  5 * highpass[5][column];
		sum -=  4 * highpass[3][column];
		sum -=  4 * highpass[2][column];
		sum +=  1 * highpass[1][column];
		sum +=  1 * highpass[0][column];
		sum +=  ROUNDING(sum,8);
		sum = DivideByShift(sum, 3);
		highhigh_buffer[column] = SATURATE(sum);
	}

	// Quantize the first row of results for each 16-bit output band
	QuantizeRow16sTo16s(lowhigh_buffer, lowhigh_row_ptr, output_width, lowhigh_quantization);
	QuantizeRow16sTo16s(highlow_buffer, highlow_row_ptr, output_width, highlow_quantization);
	QuantizeRow16sTo16s(highhigh_buffer, highhigh_row_ptr, output_width, highhigh_quantization);
}

#endif


#if 0 // FilterSpatialPrescaleQuant16s() removed

#if _PROCESSOR_DISPATCH

__declspec(cpu_dispatch(Pentium_4,Generic))

void FilterSpatialPrescaleQuant16s(PIXEL *input_image, int input_pitch,
								   PIXEL *lowlow_band, int lowlow_pitch,
								   PIXEL *lowhigh_band, int lowhigh_pitch,
								   PIXEL *highlow_band, int highlow_pitch,
								   PIXEL *highhigh_band, int highhigh_pitch,
								   PIXEL *buffer, size_t buffer_size, ROI roi,
								   int quantization[4])
{
	// Stub routine for processor specific dispatch
}
#endif


#if _PROCESSOR_GENERIC

#if _PROCESSOR_DISPATCH
__declspec(cpu_specific(Generic))
#endif

// Compute the forward spatial transform with prescaling and quantization
void FilterSpatialPrescaleQuant16s(PIXEL *input_image, int input_pitch,
								   PIXEL *lowlow_band, int lowlow_pitch,
								   PIXEL *lowhigh_band, int lowhigh_pitch,
								   PIXEL *highlow_band, int highlow_pitch,
								   PIXEL *highhigh_band, int highhigh_pitch,
								   PIXEL *buffer, size_t buffer_size, ROI roi,
								   int quantization[4])
{
	PIXEL *rowptr = input_image;

	// Six rows of lowpass and highpass horizontal results
	PIXEL *lowpass[6];
	PIXEL *highpass[6];

	PIXEL *lowlow_buffer;
	PIXEL *lowhigh_buffer;
	PIXEL *highlow_buffer;
	PIXEL *highhigh_buffer;

	int lowlow_quantization;
	int lowhigh_quantization;
	int highlow_quantization;
	int highhigh_quantization;

	// Change the highpass output bands to be 8-bit pixels //

#if _HIGHPASS_8S
	PIXEL16S *lowlow_row_ptr = lowlow_band;
	PIXEL8S *lowhigh_row_ptr = (PIXEL8S *)lowhigh_band;
	PIXEL8S *highlow_row_ptr = (PIXEL8S *)highlow_band;
	PIXEL8S *highhigh_row_ptr = (PIXEL8S *)highhigh_band;
#else
	PIXEL *lowlow_row_ptr = lowlow_band;
	PIXEL *lowhigh_row_ptr = lowhigh_band;
	PIXEL *highlow_row_ptr = highlow_band;
	PIXEL *highhigh_row_ptr = highhigh_band;
#endif

	int last_row = roi.height - 2;
	int output_width;
	size_t output_buffer_size;
	int output_buffer_width;
	PIXEL *bufptr;
	const int buffer_row_count = sizeof(lowpass)/sizeof(lowpass[0]);
	PIXEL *prescaling_buffer;
	size_t prescaling_buffer_size;
	int prescaling_buffer_width;
	int row, column;
	int k;

	// Convert pitch from bytes to pixels
	input_pitch /= sizeof(PIXEL);
	lowlow_pitch /= sizeof(PIXEL);
#if _HIGHPASS_8S
	lowhigh_pitch /= sizeof(PIXEL8S);
	highlow_pitch /= sizeof(PIXEL8S);
	highhigh_pitch /= sizeof(PIXEL8S);
#else
	lowhigh_pitch /= sizeof(PIXEL);
	highlow_pitch /= sizeof(PIXEL);
	highhigh_pitch /= sizeof(PIXEL);
#endif

	if (quantization != NULL)
	{
		lowlow_quantization = quantization[0];
		lowhigh_quantization = quantization[1];
		highlow_quantization = quantization[2];
		highhigh_quantization = quantization[3];
	}
	else
	{
		lowlow_quantization = 1;
		lowhigh_quantization = 1;
		highlow_quantization = 1;
		highhigh_quantization = 1;
	}

	// Must have an even number of rows
	assert((roi.height % 2) == 0);

	// Must have an even number of columns
	assert((roi.width % 2) == 0);

	// Compute the width of each row of horizontal filter output
	output_width = roi.width/2;

	// Compute the size of each row of horizontal filter output in bytes
	output_buffer_size = output_width * sizeof(PIXEL);

	// Round up the buffer size to an integer number of cache lines
	output_buffer_size = ALIGN(output_buffer_size, _CACHE_LINE_SIZE);

	// Compute the size of the buffer for prescaling the input rows to avoid overflow
	prescaling_buffer_size = roi.width * sizeof(PIXEL);

	// Round tp the buffer size to an integer number of cache lines
	prescaling_buffer_size = ALIGN(prescaling_buffer_size, _CACHE_LINE_SIZE);

#if _QUANTIZE_SPATIAL_LOWPASS
	// The buffer must be large enough for twelve rows plus the prescaling buffer
	assert(buffer_size >= ((12 * output_buffer_size) + prescaling_buffer_size));
#else
	// The buffer must be large enough for eleven rows plus the prescaling buffer
	assert(buffer_size >= ((11 * output_buffer_size) + prescaling_buffer_size));
#endif

	// Computed the allocated width of each buffer
	output_buffer_width = output_buffer_size / sizeof(PIXEL);

	// Compute the allocated width of the prescaling buffer
	prescaling_buffer_width = prescaling_buffer_size / sizeof(PIXEL);

	// Start allocating intermediate buffers at the beginning of the supplied buffer
	bufptr = buffer;

	// Allocate space in the buffer for prescaling the input coefficients
	prescaling_buffer = bufptr;		bufptr += prescaling_buffer_width;

	// Allocate space in the buffer for the horizontal filter results
	for (k = 0; k < buffer_row_count; k++) {
		lowpass[k] = bufptr;		bufptr += output_buffer_width;
		highpass[k] = bufptr;		bufptr += output_buffer_width;
	}

	// Allocate space in the buffer for the pre-quantized coefficients
#if _QUANTIZE_SPATIAL_LOWPASS
	lowlow_buffer = bufptr;			bufptr += output_buffer_width;
#endif
	lowhigh_buffer = bufptr;		bufptr += output_buffer_width;
	highlow_buffer = bufptr;		bufptr += output_buffer_width;
	highhigh_buffer = bufptr;		bufptr += output_buffer_width;

	// Compute the first six rows of horizontal filter output
	for (k = 0; k < buffer_row_count; k++) {
		//SplitRow16s(rowptr, roi.width, lowpass[k], highpass[k]);
		FilterHorizontalRowPrescaled16s(rowptr, lowpass[k], highpass[k], roi.width, prescaling_buffer);
		rowptr += input_pitch;
	}


	// Need to optimize the first and last row calculations //

	// Use border filters for the first row
	row = 0;

	for (column = 0; column < output_width; column++)
	{
		int32_t sum;

		// Apply the lowpass vertical filter to the lowpass horizontal results
		sum  = lowpass[0][column];
		sum += lowpass[1][column];
#if _QUANTIZE_SPATIAL_LOWPASS
		lowlow_buffer[column] = SATURATE(sum);
#else
		lowlow_row_ptr[column] = SATURATE(sum);
#endif
		// Apply the highpass vertical filter to the lowpass horizontal results
		sum  =  5 * lowpass[0][column];
		sum -= 11 * lowpass[1][column];
		sum +=  4 * lowpass[2][column];
		sum +=  4 * lowpass[3][column];
		sum -=  1 * lowpass[4][column];
		sum -=  1 * lowpass[5][column];
		sum += ROUNDING(sum,8);
		sum = DivideByShift(sum, 3);
		highlow_buffer[column] = SATURATE(sum);

		// Apply the lowpass vertical filter to the highpass horizontal results
		sum  = highpass[0][column];
		sum += highpass[1][column];
		lowhigh_buffer[column] = SATURATE(sum);

		// Apply the highpass vertical filter to the highpass horizontal results
		sum  =  5 * highpass[0][column];
		sum -= 11 * highpass[1][column];
		sum +=  4 * highpass[2][column];
		sum +=  4 * highpass[3][column];
		sum -=  1 * highpass[4][column];
		sum -=  1 * highpass[5][column];
		sum += ROUNDING(sum,8);
		sum = DivideByShift(sum, 3);
		highhigh_buffer[column] = SATURATE(sum);
	}

#if _HIGHPASS_8S
#if _QUANTIZE_SPATIAL_LOWPASS
	// Quantize the 16-bit lowpass coefficients
	QuantizeRow16sTo16s(lowlow_buffer, lowlow_row_ptr, output_width, lowlow_quantization);
#endif
	// Quantize the first row of results for each 8-bit output band
	QuantizeRow16sTo8s(lowhigh_buffer, lowhigh_row_ptr, output_width, lowhigh_quantization);
	QuantizeRow16sTo8s(highlow_buffer, highlow_row_ptr, output_width, highlow_quantization);
	QuantizeRow16sTo8s(highhigh_buffer, highhigh_row_ptr, output_width, highhigh_quantization);
#else
	// Quantize the first row of results for each 16-bit output band
#if _QUANTIZE_SPATIAL_LOWPASS
	QuantizeRow16sTo16s(lowlow_buffer, lowlow_row_ptr, output_width, lowlow_quantization);
#endif
	QuantizeRow16sTo16s(lowhigh_buffer, lowhigh_row_ptr, output_width, lowhigh_quantization);
	QuantizeRow16sTo16s(highlow_buffer, highlow_row_ptr, output_width, highlow_quantization);
	QuantizeRow16sTo16s(highhigh_buffer, highhigh_row_ptr, output_width, highhigh_quantization);
#endif

#if 0
	// Advance to the next pair of input rows if not using the SIMD code since the
	// SIMD version uses the first two rows again to compute the second output row

	{
		// Rotate the horizontal filter results by two rows
		PIXEL *temp0 = lowpass[0];
		PIXEL *temp1 = lowpass[1];
		PIXEL *high0 = highpass[0];
		PIXEL *high1 = highpass[1];

		for (k = 0; k < buffer_row_count - 2; k++) {
			lowpass[k] = lowpass[k+2];
			highpass[k] = highpass[k+2];
		}

		lowpass[buffer_row_count - 2] = temp0;
		lowpass[buffer_row_count - 1] = temp1;
		highpass[buffer_row_count - 2] = high0;
		highpass[buffer_row_count - 1] = high1;

		// Compute the next two rows of horizontal filter results
		for (; k < buffer_row_count; k++) {
			//SplitRow16s(rowptr, roi.width, lowpass[k], highpass[k]);
			FilterHorizontalRowPrescaled16s(rowptr, lowpass[k], highpass[k], roi.width, prescaling_buffer);
			rowptr += input_pitch;
		}
	}
#endif

	// Advance to the next output rows
	lowlow_row_ptr += lowlow_pitch;
	highlow_row_ptr += highlow_pitch;
	lowhigh_row_ptr += lowhigh_pitch;
	highhigh_row_ptr += highhigh_pitch;

	row += 2;								// Advance the row being processed

	for (; row < last_row; row += 2)
	{
#if (1 && XMMOPT)
#if _QUANTIZE_SPATIAL_LOWPASS
		__m64 *lowlow_ptr = (__m64 *)lowlow_buffer;
#else
		__m64 *lowlow_ptr = (__m64 *)lowlow_row_ptr;
#endif
		__m64 *highlow_ptr = (__m64 *)highlow_buffer;
		__m64 *lowhigh_ptr = (__m64 *)lowhigh_buffer;
		__m64 *highhigh_ptr = (__m64 *)highhigh_buffer;

		int column_step = 4;
		int post_column = output_width - (output_width % column_step);
#endif
		// Start at the first column
		column = 0;

#if (1 && XMMOPT)

		// Process a group of four pixels at a time
		for (; column < post_column; column += column_step)
		{
			__m64 low_pi16;
			__m64 sum_pi16;
			__m64 quad_pi16;
			__m64 mask_pi16;
			__m64 half_pi16;


			// Apply the vertical filters to the horizontal lowpass results //

			// Load the first row of four pixels
			quad_pi16 = *((__m64 *)&lowpass[0][column]);
			// Initialize the highpass filter sum
			sum_pi16 = _mm_setzero_si64();
			// Multiply each pixel by the first filter coefficient and sum the result
			sum_pi16 = _mm_subs_pi16(sum_pi16, quad_pi16);

			// Load the second row of four pixels
			quad_pi16 = *((__m64 *)&lowpass[1][column]);
			// Multiply each pixel by the second filter coefficient and sum the result
			sum_pi16 = _mm_subs_pi16(sum_pi16, quad_pi16);

			// Load the fifth row of four pixels
			quad_pi16 = *((__m64 *)&lowpass[4][column]);
			// Multiply each pixel by the fifth filter coefficient and sum the result
			sum_pi16 = _mm_adds_pi16(sum_pi16, quad_pi16);

			// Load the sixth (last) row of four pixels
			quad_pi16 = *((__m64 *)&lowpass[5][column]);
			// Multiply each pixel by the sixth filter coefficient and sum the result
			sum_pi16 = _mm_adds_pi16(sum_pi16, quad_pi16);

			half_pi16 = _mm_set1_pi16(4);
			sum_pi16 = _mm_adds_pi16(sum_pi16, half_pi16); // +4 rounding

			sum_pi16 = _mm_srai_pi16(sum_pi16, 3); // divided by 8 =   (-1a -1b +1e +1f) / 8



			// Load the third row of four pixels
			quad_pi16 = *((__m64 *)&lowpass[2][column]);
			// Initialize the lowpass sum
			low_pi16 = quad_pi16;

			// Multiply each pixel by the third filter coefficient and sum the result
			sum_pi16 = _mm_adds_pi16(sum_pi16, quad_pi16);

			// Load the fourth row of four pixels
			quad_pi16 = *((__m64 *)&lowpass[3][column]);
			// Compute the four lowpass results
			low_pi16 = _mm_adds_pi16(low_pi16, quad_pi16);

			// Store the lowpass results
			*(lowlow_ptr++) = low_pi16;
			// Multiply each pixel by the fourth filter coefficient and sum the result
			sum_pi16 = _mm_subs_pi16(sum_pi16, quad_pi16);


			// Store the four highpass results
			*(highlow_ptr++) = sum_pi16;


			// Apply the vertical filters to the horizontal highpass results //

			sum_pi16 = _mm_setzero_si64();

			// Load the first row of four pixels
			quad_pi16 = *((__m64 *)&highpass[0][column]);
			// Multiply each pixel by the first filter coefficient and sum the result
			sum_pi16 = _mm_subs_pi16(sum_pi16, quad_pi16);

			// Load the second row of four pixels
			quad_pi16 = *((__m64 *)&highpass[1][column]);
			// Multiply each pixel by the second filter coefficient and sum the result
			sum_pi16 = _mm_subs_pi16(sum_pi16, quad_pi16);

			// Load the fifth row of four pixels
			quad_pi16 = *((__m64 *)&highpass[4][column]);
			// Multiply each pixel by the fifth filter coefficient and sum the result
			sum_pi16 = _mm_adds_pi16(sum_pi16, quad_pi16);

			// Load the sixth (last) row of four pixels
			quad_pi16 = *((__m64 *)&highpass[5][column]);
			// Multiply each pixel by the sixth filter coefficient and sum the result
			sum_pi16 = _mm_adds_pi16(sum_pi16, quad_pi16);

			sum_pi16 = _mm_adds_pi16(sum_pi16, half_pi16); // +4 rounding

			sum_pi16 = _mm_srai_pi16(sum_pi16, 3); // divided by 8 =   (-1a -1b +1e +1f) / 8


			// Load the third row of four pixels
			quad_pi16 = *((__m64 *)&highpass[2][column]);
			// Initialize the lowpass sum
			low_pi16 = quad_pi16;

			// Multiply each pixel by the third filter coefficient and sum the result
			sum_pi16 = _mm_adds_pi16(sum_pi16, quad_pi16);

			// Load the fourth row of four pixels
			quad_pi16 = *((__m64 *)&highpass[3][column]);
			// Compute and store the four lowpass results
			low_pi16 = _mm_adds_pi16(low_pi16, quad_pi16);
			*(lowhigh_ptr++) = low_pi16;

			// Multiply each pixel by the fourth filter coefficient and sum the result
			sum_pi16 = _mm_subs_pi16(sum_pi16, quad_pi16);


			// Store the four highpass results
			*(highhigh_ptr++) = sum_pi16;
		}

		// Should have terminated the fast loop at the post processing column
		assert(column == post_column);
#endif

		// Process the remaining pixels to the end of the row
		for (; column < output_width; column++)
		{
			int32_t sum;

			// Apply the lowpass vertical filter to the lowpass horizontal results
			sum  = lowpass[2][column];
			sum += lowpass[3][column];
#if _QUANTIZE_SPATIAL_LOWPASS
			lowlow_buffer[column] = SATURATE(sum);
#else
			lowlow_row_ptr[column] = SATURATE(sum);
#endif
			// Apply the highpass vertical filter to the lowpass horizontal results
			sum  = -1 * lowpass[0][column];
			sum += -1 * lowpass[1][column];
			sum +=  1 * lowpass[4][column];
			sum +=  1 * lowpass[5][column];
			sum += ROUNDING(sum,8);
			sum = DivideByShift(sum, 3);
			sum +=  lowpass[2][column];
			sum += -lowpass[3][column];
			highlow_buffer[column] = SATURATE(sum);

			// Apply the lowpass vertical filter to the highpass horizontal results
			sum  = highpass[2][column];
			sum += highpass[3][column];
			lowhigh_buffer[column] = SATURATE(sum);

			// Apply the highpass vertical filter to the highpass horizontal results
			sum  = -1 * highpass[0][column];
			sum += -1 * highpass[1][column];
			sum +=  1 * highpass[4][column];
			sum +=  1 * highpass[5][column];
			sum += ROUNDING(sum,8);
			sum = DivideByShift(sum, 3);
			sum +=  highpass[2][column];
			sum += -highpass[3][column];
			highhigh_buffer[column] = SATURATE(sum);
		}

		if (row < (last_row - 2))
		{
			// Rotate the horizontal filter results by two rows
			PIXEL *temp0 = lowpass[0];
			PIXEL *temp1 = lowpass[1];
			PIXEL *high0 = highpass[0];
			PIXEL *high1 = highpass[1];

			for (k = 0; k < buffer_row_count - 2; k++) {
				lowpass[k] = lowpass[k+2];
				highpass[k] = highpass[k+2];
			}

			lowpass[buffer_row_count - 2] = temp0;
			lowpass[buffer_row_count - 1] = temp1;
			highpass[buffer_row_count - 2] = high0;
			highpass[buffer_row_count - 1] = high1;

			// Compute the next two rows of horizontal filter results
			for (; k < buffer_row_count; k++) {
				//SplitRow16s(rowptr, roi.width, lowpass[k], highpass[k]);
				FilterHorizontalRowPrescaled16s(rowptr, lowpass[k], highpass[k], roi.width, prescaling_buffer);
				rowptr += input_pitch;
			}
		}

#if _HIGHPASS_8S
#if _QUANTIZE_SPATIAL_LOWPASS
		// Quantize the current row 16-bit lowpass coefficients
		QuantizeRow16sTo16s(lowlow_buffer, lowlow_row_ptr, output_width, lowlow_quantization);
#endif
		// Quantize the current row of results for each 8-bit highpass band
		QuantizeRow16sTo8s(lowhigh_buffer, lowhigh_row_ptr, output_width, lowhigh_quantization);
		QuantizeRow16sTo8s(highlow_buffer, highlow_row_ptr, output_width, highlow_quantization);
		QuantizeRow16sTo8s(highhigh_buffer, highhigh_row_ptr, output_width, highhigh_quantization);
#else
		// Quantize the current row of results for each 16-bit output band
#if _QUANTIZE_SPATIAL_LOWPASS
		QuantizeRow16sTo16s(lowlow_buffer, lowlow_row_ptr, output_width, lowlow_quantization);
#endif
		QuantizeRow16sTo16s(lowhigh_buffer, lowhigh_row_ptr, output_width, lowhigh_quantization);
		QuantizeRow16sTo16s(highlow_buffer, highlow_row_ptr, output_width, highlow_quantization);
		QuantizeRow16sTo16s(highhigh_buffer, highhigh_row_ptr, output_width, highhigh_quantization);
#endif

		// Advance to the next output rows
		lowlow_row_ptr += lowlow_pitch;
		highlow_row_ptr += highlow_pitch;
		lowhigh_row_ptr += lowhigh_pitch;
		highhigh_row_ptr += highhigh_pitch;
	}

	// Should have left the loop at the last row
	assert(row == last_row);

	// Use the border filters for the last row
	for (column = 0; column < output_width; column++)
	{
		int32_t sum;

		// Apply the lowpass vertical filter to the lowpass horizontal results
		sum  = lowpass[4][column];
		sum += lowpass[5][column];
#if _QUANTIZE_SPATIAL_LOWPASS
		lowlow_buffer[column] = SATURATE(sum);
#else
		lowlow_row_ptr[column] = SATURATE(sum);
#endif
		// Apply the highpass vertical filter to the lowpass horizontal results
		sum  = 11 * lowpass[4][column];
		sum -=  5 * lowpass[5][column];
		sum -=  4 * lowpass[3][column];
		sum -=  4 * lowpass[2][column];
		sum +=  1 * lowpass[1][column];
		sum +=  1 * lowpass[0][column];
		sum +=  ROUNDING(sum,8);
		sum = DivideByShift(sum, 3);
		highlow_buffer[column] = SATURATE(sum);

		// Apply the lowpass vertical filter to the highpass horizontal results
		sum  = highpass[4][column];
		sum += highpass[5][column];
		lowhigh_buffer[column] = SATURATE(sum);

		// Apply the highpass vertical filter to the highpass horizontal results
		sum  = 11 * highpass[4][column];
		sum -=  5 * highpass[5][column];
		sum -=  4 * highpass[3][column];
		sum -=  4 * highpass[2][column];
		sum +=  1 * highpass[1][column];
		sum +=  1 * highpass[0][column];
		sum +=  ROUNDING(sum,8);
		sum = DivideByShift(sum, 3);
		highhigh_buffer[column] = SATURATE(sum);
	}

#if _HIGHPASS_8S
#if _QUANTIZE_SPATIAL_LOWPASS
		// Quantize the last row of 16-bit lowpass coefficients
		QuantizeRow16sTo16s(lowlow_buffer, lowlow_row_ptr, output_width, lowlow_quantization);
#endif
		// Quantize the last row of results for each 8-bit highpass band
		QuantizeRow16sTo8s(lowhigh_buffer, lowhigh_row_ptr, output_width, lowhigh_quantization);
		QuantizeRow16sTo8s(highlow_buffer, highlow_row_ptr, output_width, highlow_quantization);
		QuantizeRow16sTo8s(highhigh_buffer, highhigh_row_ptr, output_width, highhigh_quantization);
#else
		// Quantize the last row of results for each 16-bit output band
#if _QUANTIZE_SPATIAL_LOWPASS
		QuantizeRow16sTo16s(lowlow_buffer, lowlow_row_ptr, output_width, lowlow_quantization);
#endif
		QuantizeRow16sTo16s(lowhigh_buffer, lowhigh_row_ptr, output_width, lowhigh_quantization);
		QuantizeRow16sTo16s(highlow_buffer, highlow_row_ptr, output_width, highlow_quantization);
		QuantizeRow16sTo16s(highhigh_buffer, highhigh_row_ptr, output_width, highhigh_quantization);
#endif

	//_mm_empty();	// Clear the mmx register state
}

#endif


#if _PROCESSOR_PENTIUM_4

#if _PROCESSOR_DISPATCH
__declspec(cpu_specific(Pentium_4))
#endif

void FilterSpatialPrescaleQuant16s(PIXEL *input_image, int input_pitch,
								   PIXEL *lowlow_band, int lowlow_pitch,
								   PIXEL *lowhigh_band, int lowhigh_pitch,
								   PIXEL *highlow_band, int highlow_pitch,
								   PIXEL *highhigh_band, int highhigh_pitch,
								   PIXEL *buffer, size_t buffer_size, ROI roi,
								   int quantization[4])
{
	PIXEL *rowptr = input_image;

	// Six rows of lowpass and highpass horizontal results
	PIXEL *lowpass[6];
	PIXEL *highpass[6];

	PIXEL *lowlow_buffer;
	PIXEL *lowhigh_buffer;
	PIXEL *highlow_buffer;
	PIXEL *highhigh_buffer;

	int lowlow_quantization;
	int lowhigh_quantization;
	int highlow_quantization;
	int highhigh_quantization;

	// Change the highpass output bands to be 8-bit pixels //

#if _HIGHPASS_8S
	PIXEL16S *lowlow_row_ptr = lowlow_band;
	PIXEL8S *lowhigh_row_ptr = (PIXEL8S *)lowhigh_band;
	PIXEL8S *highlow_row_ptr = (PIXEL8S *)highlow_band;
	PIXEL8S *highhigh_row_ptr = (PIXEL8S *)highhigh_band;
#else
	PIXEL *lowlow_row_ptr = lowlow_band;
	PIXEL *lowhigh_row_ptr = lowhigh_band;
	PIXEL *highlow_row_ptr = highlow_band;
	PIXEL *highhigh_row_ptr = highhigh_band;
#endif

	int last_row = roi.height - 2;
	int output_width;
	size_t output_buffer_size;
	int output_buffer_width;
	PIXEL *bufptr;
	const int buffer_row_count = sizeof(lowpass)/sizeof(lowpass[0]);
	PIXEL *prescaling_buffer;
	size_t prescaling_buffer_size;
	int prescaling_buffer_width;
	int row, column;
	int k;

	// Convert pitch from bytes to pixels
	input_pitch /= sizeof(PIXEL);
	lowlow_pitch /= sizeof(PIXEL);
#if _HIGHPASS_8S
	lowhigh_pitch /= sizeof(PIXEL8S);
	highlow_pitch /= sizeof(PIXEL8S);
	highhigh_pitch /= sizeof(PIXEL8S);
#else
	lowhigh_pitch /= sizeof(PIXEL);
	highlow_pitch /= sizeof(PIXEL);
	highhigh_pitch /= sizeof(PIXEL);
#endif

	if (quantization != NULL)
	{
		lowlow_quantization = quantization[0];
		lowhigh_quantization = quantization[1];
		highlow_quantization = quantization[2];
		highhigh_quantization = quantization[3];
	}
	else
	{
		lowlow_quantization = 1;
		lowhigh_quantization = 1;
		highlow_quantization = 1;
		highhigh_quantization = 1;
	}

	// Must have an even number of rows
	assert((roi.height % 2) == 0);

	// Must have an even number of columns
	assert((roi.width % 2) == 0);

	// Compute the width of each row of horizontal filter output
	output_width = roi.width/2;

	// Compute the size of each row of horizontal filter output in bytes
	output_buffer_size = output_width * sizeof(PIXEL);

	// Round up the buffer size to an integer number of cache lines
	output_buffer_size = ALIGN(output_buffer_size, _CACHE_LINE_SIZE);

	// Compute the size of the buffer for prescaling the input rows to avoid overflow
	prescaling_buffer_size = roi.width * sizeof(PIXEL);

	// Round tp the buffer size to an integer number of cache lines
	prescaling_buffer_size = ALIGN(prescaling_buffer_size, _CACHE_LINE_SIZE);

#if _QUANTIZE_SPATIAL_LOWPASS
	// The buffer must be large enough for 16 output rows plus the prescaling buffer
	assert(buffer_size >= ((16 * output_buffer_size) + prescaling_buffer_size));
#else
	// The buffer must be large enough for 15 output rows plus the prescaling buffer
	assert(buffer_size >= ((15 * output_buffer_size) + prescaling_buffer_size));
#endif

	// Computed the allocated width of each buffer
	output_buffer_width = output_buffer_size / sizeof(PIXEL);

	// Compute the allocated width of the prescaling buffer
	prescaling_buffer_width = prescaling_buffer_size / sizeof(PIXEL);

	// Start allocating intermediate buffers at the beginning of the supplied buffer
	bufptr = buffer;

	// Allocate space in the buffer for prescaling the input coefficients
	prescaling_buffer = bufptr;		bufptr += prescaling_buffer_width;

	// Allocate space in the buffer for the horizontal filter results
	for (k = 0; k < buffer_row_count; k++) {
		lowpass[k] = bufptr;		bufptr += output_buffer_width;
		highpass[k] = bufptr;		bufptr += output_buffer_width;
	}

	// Allocate space in the buffer for the pre-quantized coefficients
#if _QUANTIZE_SPATIAL_LOWPASS
	lowlow_buffer = bufptr;			bufptr += output_buffer_width;
#endif
	lowhigh_buffer = bufptr;		bufptr += output_buffer_width;
	highlow_buffer = bufptr;		bufptr += output_buffer_width;
	highhigh_buffer = bufptr;		bufptr += output_buffer_width;

	// Compute the first six rows of horizontal filter output
	for (k = 0; k < buffer_row_count; k++) {
		FilterHorizontalRowPrescaled16s(rowptr, lowpass[k], highpass[k], roi.width, prescaling_buffer);
		rowptr += input_pitch;
	}


	// Need to optimize the first and last row calculations //

	// Use border filters for the first row
	row = 0;

	for (column = 0; column < output_width; column++)
	{
		int32_t sum;

		// Apply the lowpass vertical filter to the lowpass horizontal results
		sum  = lowpass[0][column];
		sum += lowpass[1][column];
#if _QUANTIZE_SPATIAL_LOWPASS
		lowlow_buffer[column] = SATURATE(sum);
#else
		lowlow_row_ptr[column] = SATURATE(sum);
#endif
		// Apply the highpass vertical filter to the lowpass horizontal results
		sum  =  5 * lowpass[0][column];
		sum -= 11 * lowpass[1][column];
		sum +=  4 * lowpass[2][column];
		sum +=  4 * lowpass[3][column];
		sum -=  1 * lowpass[4][column];
		sum -=  1 * lowpass[5][column];
		sum += ROUNDING(sum,8);
		sum = DivideByShift(sum, 3);
		highlow_buffer[column] = SATURATE(sum);

		// Apply the lowpass vertical filter to the highpass horizontal results
		sum  = highpass[0][column];
		sum += highpass[1][column];
		lowhigh_buffer[column] = SATURATE(sum);

		// Apply the highpass vertical filter to the highpass horizontal results
		sum  =  5 * highpass[0][column];
		sum -= 11 * highpass[1][column];
		sum +=  4 * highpass[2][column];
		sum +=  4 * highpass[3][column];
		sum -=  1 * highpass[4][column];
		sum -=  1 * highpass[5][column];
		sum += ROUNDING(sum,8);
		sum = DivideByShift(sum, 3);
		highhigh_buffer[column] = SATURATE(sum);
	}

#if _HIGHPASS_8S
#if _QUANTIZE_SPATIAL_LOWPASS
	// Quantize the 16-bit lowpass coefficients
	QuantizeRow16sTo16s(lowlow_buffer, lowlow_row_ptr, output_width, lowlow_quantization);
#endif
	// Quantize the first row of results for each 8-bit output band
	QuantizeRow16sTo8s(lowhigh_buffer, lowhigh_row_ptr, output_width, lowhigh_quantization);
	QuantizeRow16sTo8s(highlow_buffer, highlow_row_ptr, output_width, highlow_quantization);
	QuantizeRow16sTo8s(highhigh_buffer, highhigh_row_ptr, output_width, highhigh_quantization);
#else
	// Quantize the first row of results for each 16-bit output band
#if _QUANTIZE_SPATIAL_LOWPASS
	QuantizeRow16sTo16s(lowlow_buffer, lowlow_row_ptr, output_width, lowlow_quantization);
#endif
	QuantizeRow16sTo16s(lowhigh_buffer, lowhigh_row_ptr, output_width, lowhigh_quantization);
	QuantizeRow16sTo16s(highlow_buffer, highlow_row_ptr, output_width, highlow_quantization);
	QuantizeRow16sTo16s(highhigh_buffer, highhigh_row_ptr, output_width, highhigh_quantization);
#endif

#if 0
	// Advance to the next pair of input rows if not using the SIMD code since the
	// SIMD version uses the first two rows again to compute the second output row

	{
		// Rotate the horizontal filter results by two rows
		PIXEL *temp0 = lowpass[0];
		PIXEL *temp1 = lowpass[1];
		PIXEL *high0 = highpass[0];
		PIXEL *high1 = highpass[1];

		for (k = 0; k < buffer_row_count - 2; k++) {
			lowpass[k] = lowpass[k+2];
			highpass[k] = highpass[k+2];
		}

		lowpass[buffer_row_count - 2] = temp0;
		lowpass[buffer_row_count - 1] = temp1;
		highpass[buffer_row_count - 2] = high0;
		highpass[buffer_row_count - 1] = high1;

		// Compute the next two rows of horizontal filter results
		for (; k < buffer_row_count; k++) {
			//SplitRow16s(rowptr, roi.width, lowpass[k], highpass[k]);
			FilterHorizontalRowPrescaled16s(rowptr, lowpass[k], highpass[k], roi.width, prescaling_buffer);
			rowptr += input_pitch;
		}
	}
#endif

	// Advance to the next output rows
	lowlow_row_ptr += lowlow_pitch;
	highlow_row_ptr += highlow_pitch;
	lowhigh_row_ptr += lowhigh_pitch;
	highhigh_row_ptr += highhigh_pitch;

	row += 2;								// Advance the row being processed

	for (; row < last_row; row += 2)
	{
#if (1 && XMMOPT)
#if _QUANTIZE_SPATIAL_LOWPASS
		__m128i *lowlow_ptr = (__m128i *)lowlow_buffer;
#else
		__m128i *lowlow_ptr = (__m128i *)lowlow_row_ptr;
#endif
		__m128i *highlow_ptr = (__m128i *)highlow_buffer;
		__m128i *lowhigh_ptr = (__m128i *)lowhigh_buffer;
		__m128i *highhigh_ptr = (__m128i *)highhigh_buffer;

		int column_step = 8;
		int post_column = output_width - (output_width % column_step);
#endif
		// Start at the first column
		column = 0;

		// Check that the input and output addresses are properly aligned
		for (k = 0; k < buffer_row_count; k++) {
			assert(ISALIGNED16(lowpass[k]));
			assert(ISALIGNED16(highpass[k]));
		}
		assert(ISALIGNED16(lowlow_ptr));
		assert(ISALIGNED16(lowhigh_ptr));
		assert(ISALIGNED16(highlow_ptr));
		assert(ISALIGNED16(highhigh_ptr));

#if (1 && XMMOPT)

		// Process a group of four pixels at a time
		for (; column < post_column; column += column_step)
		{
			__m128i low_epi16;
			__m128i sum_epi16;
			__m128i sum8_epi16;
			__m128i quad_epi16;
			__m128i mask_epi16;
			__m128i half_epi16;


			/***** Apply the vertical filters to the horizontal lowpass results *****/

			// Load the first row of four pixels
			quad_epi16 = _mm_load_si128((__m128i *)&lowpass[0][column]);

			// Initialize the highpass filter sum
			sum_epi16 = _mm_setzero_si128();

			// Multiply each pixel by the first filter coefficient and sum the result
			sum_epi16 = _mm_subs_epi16(sum_epi16, quad_epi16);

			// Load the second row of four pixels
			quad_epi16 = _mm_load_si128((__m128i *)&lowpass[1][column]);

			// Multiply each pixel by the second filter coefficient and sum the result
			sum_epi16 = _mm_subs_epi16(sum_epi16, quad_epi16);

			// Load the third row of four pixels
			quad_epi16 = _mm_load_si128((__m128i *)&lowpass[2][column]);

			// Initialize the lowpass sum
			low_epi16 = quad_epi16;

			// Multiply each pixel by the third filter coefficient and sum the result
			sum8_epi16 = _mm_setzero_si128();
			sum8_epi16 = _mm_adds_epi16(sum8_epi16, quad_epi16);

			// Load the fourth row of four pixels
			quad_epi16 = _mm_load_si128((__m128i *)&lowpass[3][column]);

			// Compute the four lowpass results
			low_epi16 = _mm_adds_epi16(low_epi16, quad_epi16);

			// Store the lowpass results
			_mm_store_si128(lowlow_ptr++, low_epi16);

			// Multiply each pixel by the fourth filter coefficient and sum the result
			sum8_epi16 = _mm_subs_epi16(sum8_epi16, quad_epi16);

			// Load the fifth row of four pixels
			quad_epi16 = _mm_load_si128((__m128i *)&lowpass[4][column]);

			// Multiply each pixel by the fifth filter coefficient and sum the result
			sum_epi16 = _mm_adds_epi16(sum_epi16, quad_epi16);

			// Load the sixth (last) row of four pixels
			quad_epi16 = _mm_load_si128((__m128i *)&lowpass[5][column]);

			// Multiply each pixel by the sixth filter coefficient and sum the result
			sum_epi16 = _mm_adds_epi16(sum_epi16, quad_epi16);


			half_epi16 = _mm_set1_epi16(4); //was 4
			sum_epi16 = _mm_adds_epi16(sum_epi16, half_epi16); // +7 rounding
			sum_epi16 = _mm_srai_epi16(sum_epi16, 3); // divide 8

			sum_epi16 = _mm_adds_epi16(sum_epi16, sum8_epi16);

			// Store the four highpass results
			_mm_store_si128(highlow_ptr++, sum_epi16);


			/***** Apply the vertical filters to the horizontal highpass results *****/

			sum_epi16 = _mm_setzero_si128();

			// Load the first row of four pixels
			quad_epi16 = _mm_load_si128((__m128i *)&highpass[0][column]);

			// Multiply each pixel by the first filter coefficient and sum the result
			sum_epi16 = _mm_subs_epi16(sum_epi16, quad_epi16);

			// Load the second row of four pixels
			quad_epi16 = _mm_load_si128((__m128i *)&highpass[1][column]);

			// Multiply each pixel by the second filter coefficient and sum the result
			sum_epi16 = _mm_subs_epi16(sum_epi16, quad_epi16);

			// Load the third row of four pixels
			quad_epi16 = _mm_load_si128((__m128i *)&highpass[2][column]);

			// Initialize the lowpass sum
			low_epi16 = quad_epi16;

			// Multiply each pixel by the third filter coefficient and sum the result
			sum8_epi16 = _mm_setzero_si128();
			sum8_epi16 = _mm_adds_epi16(sum8_epi16, quad_epi16);

			// Load the fourth row of four pixels
			quad_epi16 = _mm_load_si128((__m128i *)&highpass[3][column]);

			// Compute and store the four lowpass results
			low_epi16 = _mm_adds_epi16(low_epi16, quad_epi16);
			_mm_store_si128(lowhigh_ptr++, low_epi16);

			// Multiply each pixel by the fourth filter coefficient and sum the result
			sum8_epi16 = _mm_subs_epi16(sum8_epi16, quad_epi16);

			// Load the fifth row of four pixels
			quad_epi16 = _mm_load_si128((__m128i *)&highpass[4][column]);

			// Multiply each pixel by the fifth filter coefficient and sum the result
			sum_epi16 = _mm_adds_epi16(sum_epi16, quad_epi16);

			// Load the sixth (last) row of four pixels
			quad_epi16 = _mm_load_si128((__m128i *)&highpass[5][column]);

			// Multiply each pixel by the sixth filter coefficient and sum the result
			sum_epi16 = _mm_adds_epi16(sum_epi16, quad_epi16);


			sum_epi16 = _mm_adds_epi16(sum_epi16, half_epi16); // +7 rounding
			sum_epi16 = _mm_srai_epi16(sum_epi16, 3); // divide 8

			sum_epi16 = _mm_adds_epi16(sum_epi16, sum8_epi16);


			// Store the four highpass results
			_mm_store_si128(highhigh_ptr++, sum_epi16);
		}

		// Should have terminated the fast loop at the post processing column
		assert(column == post_column);
#endif

		// Process the remaining pixels to the end of the row
		for (; column < output_width; column++)
		{
			int32_t sum;

			// Apply the lowpass vertical filter to the lowpass horizontal results
			sum  = lowpass[2][column];
			sum += lowpass[3][column];
#if _QUANTIZE_SPATIAL_LOWPASS
			lowlow_buffer[column] = SATURATE(sum);
#else
			lowlow_row_ptr[column] = SATURATE(sum);
#endif
			// Apply the highpass vertical filter to the lowpass horizontal results
			sum  = -1 * lowpass[0][column];
			sum += -1 * lowpass[1][column];
			sum +=  1 * lowpass[4][column];
			sum +=  1 * lowpass[5][column];
			sum +=	4;
			sum >>= 3;
			sum +=  1 * lowpass[2][column];
			sum += -1 * lowpass[3][column];

			highlow_buffer[column] = (sum);

			// Apply the lowpass vertical filter to the highpass horizontal results
			sum  = highpass[2][column];
			sum += highpass[3][column];
			lowhigh_buffer[column] = (sum);

			// Apply the highpass vertical filter to the highpass horizontal results
			sum  = -1 * highpass[0][column];
			sum += -1 * highpass[1][column];
			sum +=  1 * highpass[4][column];
			sum +=  1 * highpass[5][column];
			sum +=	4;
			sum >>= 3;
			sum +=  1 * highpass[2][column];
			sum += -1 * highpass[3][column];
			highhigh_buffer[column] = (sum);
		}

		if (row < (last_row - 2))
		{
			// Rotate the horizontal filter results by two rows
			PIXEL *temp0 = lowpass[0];
			PIXEL *temp1 = lowpass[1];
			PIXEL *high0 = highpass[0];
			PIXEL *high1 = highpass[1];

			for (k = 0; k < buffer_row_count - 2; k++) {
				lowpass[k] = lowpass[k+2];
				highpass[k] = highpass[k+2];
			}

			lowpass[buffer_row_count - 2] = temp0;
			lowpass[buffer_row_count - 1] = temp1;
			highpass[buffer_row_count - 2] = high0;
			highpass[buffer_row_count - 1] = high1;

			// Compute the next two rows of horizontal filter results
			for (; k < buffer_row_count; k++) {
				//SplitRow16s(rowptr, roi.width, lowpass[k], highpass[k]);
				FilterHorizontalRowPrescaled16s(rowptr, lowpass[k], highpass[k], roi.width, prescaling_buffer);
				rowptr += input_pitch;
			}
		}

#if _HIGHPASS_8S
#if _QUANTIZE_SPATIAL_LOWPASS
		// Quantize the current row 16-bit lowpass coefficients
		QuantizeRow16sTo16s(lowlow_buffer, lowlow_row_ptr, output_width, lowlow_quantization);
#endif
		// Quantize the current row of results for each 8-bit highpass band
		QuantizeRow16sTo8s(lowhigh_buffer, lowhigh_row_ptr, output_width, lowhigh_quantization);
		QuantizeRow16sTo8s(highlow_buffer, highlow_row_ptr, output_width, highlow_quantization);
		QuantizeRow16sTo8s(highhigh_buffer, highhigh_row_ptr, output_width, highhigh_quantization);
#else
		// Quantize the current row of results for each 16-bit output band
#if _QUANTIZE_SPATIAL_LOWPASS
		QuantizeRow16sTo16s(lowlow_buffer, lowlow_row_ptr, output_width, lowlow_quantization);
#endif
		QuantizeRow16sTo16s(lowhigh_buffer, lowhigh_row_ptr, output_width, lowhigh_quantization);
		QuantizeRow16sTo16s(highlow_buffer, highlow_row_ptr, output_width, highlow_quantization);
		QuantizeRow16sTo16s(highhigh_buffer, highhigh_row_ptr, output_width, highhigh_quantization);
#endif

		// Advance to the next output rows
		lowlow_row_ptr += lowlow_pitch;
		highlow_row_ptr += highlow_pitch;
		lowhigh_row_ptr += lowhigh_pitch;
		highhigh_row_ptr += highhigh_pitch;
	}

	// Should have left the loop at the last row
	assert(row == last_row);

	// Use the border filters for the last row
	for (column = 0; column < output_width; column++)
	{
		int32_t sum;

		// Apply the lowpass vertical filter to the lowpass horizontal results
		sum  = lowpass[4][column];
		sum += lowpass[5][column];
#if _QUANTIZE_SPATIAL_LOWPASS
		lowlow_buffer[column] = SATURATE(sum);
#else
		lowlow_row_ptr[column] = SATURATE(sum);
#endif
		// Apply the highpass vertical filter to the lowpass horizontal results
		sum  = 11 * lowpass[4][column];
		sum -=  5 * lowpass[5][column];
		sum -=  4 * lowpass[3][column];
		sum -=  4 * lowpass[2][column];
		sum +=  1 * lowpass[1][column];
		sum +=  1 * lowpass[0][column];
		sum +=  ROUNDING(sum,8);
		sum = DivideByShift(sum, 3);
		highlow_buffer[column] = SATURATE(sum);

		// Apply the lowpass vertical filter to the highpass horizontal results
		sum  = highpass[4][column];
		sum += highpass[5][column];
		lowhigh_buffer[column] = SATURATE(sum);

		// Apply the highpass vertical filter to the highpass horizontal results
		sum  = 11 * highpass[4][column];
		sum -=  5 * highpass[5][column];
		sum -=  4 * highpass[3][column];
		sum -=  4 * highpass[2][column];
		sum +=  1 * highpass[1][column];
		sum +=  1 * highpass[0][column];
		sum +=  ROUNDING(sum,8);
		sum = DivideByShift(sum, 3);
		highhigh_buffer[column] = SATURATE(sum);
	}

#if _HIGHPASS_8S
#if _QUANTIZE_SPATIAL_LOWPASS
		// Quantize the last row of 16-bit lowpass coefficients
		QuantizeRow16sTo16s(lowlow_buffer, lowlow_row_ptr, output_width, lowlow_quantization);
#endif
		// Quantize the last row of results for each 8-bit highpass band
		QuantizeRow16sTo8s(lowhigh_buffer, lowhigh_row_ptr, output_width, lowhigh_quantization);
		QuantizeRow16sTo8s(highlow_buffer, highlow_row_ptr, output_width, highlow_quantization);
		QuantizeRow16sTo8s(highhigh_buffer, highhigh_row_ptr, output_width, highhigh_quantization);
#else
		// Quantize the last row of results for each 16-bit output band
#if _QUANTIZE_SPATIAL_LOWPASS
		QuantizeRow16sTo16s(lowlow_buffer, lowlow_row_ptr, output_width, lowlow_quantization);
#endif
		QuantizeRow16sTo16s(lowhigh_buffer, lowhigh_row_ptr, output_width, lowhigh_quantization);
		QuantizeRow16sTo16s(highlow_buffer, highlow_row_ptr, output_width, highlow_quantization);
		QuantizeRow16sTo16s(highhigh_buffer, highhigh_row_ptr, output_width, highhigh_quantization);
#endif

	//_mm_empty();	// Clear the mmx register state
}

#endif

#endif //0  FilterSpatialPrescaleQuant16s() removed



// Forward spatial wavelet transform with prescaling for 10-bit video sources
// (Pentium 4 version only)
//#if BUILD_PROSPECT//10-bit for everyone

void FilterSpatialV210Quant16s(PIXEL *input_image, int input_pitch,
							   PIXEL *lowlow_band, int lowlow_pitch,
							   PIXEL *lowhigh_band, int lowhigh_pitch,
							   PIXEL *highlow_band, int highlow_pitch,
							   PIXEL *highhigh_band, int highhigh_pitch,
							   PIXEL *buffer, size_t buffer_size, ROI roi,
							   int quantization[4])
{
	PIXEL *rowptr = input_image;

	// Six rows of lowpass and highpass horizontal results
	PIXEL *lowpass[6];
	PIXEL *highpass[6];

	PIXEL *lowhigh_buffer;
	PIXEL *highlow_buffer;
	PIXEL *highhigh_buffer;

	int lowlow_quantization;
	int lowhigh_quantization;
	int highlow_quantization;
	int highhigh_quantization;

	// Change the highpass output bands to be 8-bit pixels //

#if _HIGHPASS_8S
	PIXEL16S *lowlow_row_ptr = lowlow_band;
	PIXEL8S *lowhigh_row_ptr = (PIXEL8S *)lowhigh_band;
	PIXEL8S *highlow_row_ptr = (PIXEL8S *)highlow_band;
	PIXEL8S *highhigh_row_ptr = (PIXEL8S *)highhigh_band;
#else
	PIXEL *lowlow_row_ptr = lowlow_band;
	PIXEL *lowhigh_row_ptr = lowhigh_band;
	PIXEL *highlow_row_ptr = highlow_band;
	PIXEL *highhigh_row_ptr = highhigh_band;
#endif

	int last_row = roi.height - 2;
	int output_width;
	size_t output_buffer_size;
	int output_buffer_width;
	PIXEL *bufptr;
	const int buffer_row_count = sizeof(lowpass)/sizeof(lowpass[0]);
	PIXEL *prescaling_buffer;
	size_t prescaling_buffer_size;
	int prescaling_buffer_width;
	int row, column;
	int k;

	// Convert pitch from bytes to pixels
	input_pitch /= sizeof(PIXEL);
	lowlow_pitch /= sizeof(PIXEL);
#if _HIGHPASS_8S
	lowhigh_pitch /= sizeof(PIXEL8S);
	highlow_pitch /= sizeof(PIXEL8S);
	highhigh_pitch /= sizeof(PIXEL8S);
#else
	lowhigh_pitch /= sizeof(PIXEL);
	highlow_pitch /= sizeof(PIXEL);
	highhigh_pitch /= sizeof(PIXEL);
#endif

	if (quantization != NULL)
	{
		lowlow_quantization = quantization[0];
		lowhigh_quantization = quantization[1];
		highlow_quantization = quantization[2];
		highhigh_quantization = quantization[3];
	}
	else
	{
		lowlow_quantization = 1;
		lowhigh_quantization = 1;
		highlow_quantization = 1;
		highhigh_quantization = 1;
	}

	// Must have an even number of rows
	assert((roi.height % 2) == 0);

	// Must have an even number of columns
	assert((roi.width % 2) == 0);

	// Compute the width of each row of horizontal filter output
	output_width = roi.width/2;

	// Compute the size of each row of horizontal filter output in bytes
	output_buffer_size = output_width * sizeof(PIXEL);

	// Round up the buffer size to an integer number of cache lines
	output_buffer_size = ALIGN(output_buffer_size, _CACHE_LINE_SIZE);

	// Compute the size of the buffer for prescaling the input rows to avoid overflow
	prescaling_buffer_size = roi.width * sizeof(PIXEL);

	// Round tp the buffer size to an integer number of cache lines
	prescaling_buffer_size = ALIGN(prescaling_buffer_size, _CACHE_LINE_SIZE);

#if _QUANTIZE_SPATIAL_LOWPASS
	// The buffer must be large enough for twelve rows plus the prescaling buffer
	assert(buffer_size >= ((12 * output_buffer_size) + prescaling_buffer_size));
#else
	// The buffer must be large enough for eleven rows plus the prescaling buffer
	assert(buffer_size >= ((11 * output_buffer_size) + prescaling_buffer_size));
#endif

	// Computed the allocated width of each buffer
	output_buffer_width = (int)output_buffer_size / sizeof(PIXEL);

	// Compute the allocated width of the prescaling buffer
	prescaling_buffer_width = (int)prescaling_buffer_size / sizeof(PIXEL);

	// Start allocating intermediate buffers at the beginning of the supplied buffer
	bufptr = buffer;

	// Allocate space in the buffer for prescaling the input coefficients
	prescaling_buffer = bufptr;		bufptr += prescaling_buffer_width;

	// Allocate space in the buffer for the horizontal filter results
	for (k = 0; k < buffer_row_count; k++) {
		lowpass[k] = bufptr;		bufptr += output_buffer_width;
		highpass[k] = bufptr;		bufptr += output_buffer_width;
	}

	// Allocate space in the buffer for the pre-quantized coefficients
#if _QUANTIZE_SPATIAL_LOWPASS
	lowlow_buffer = bufptr;			bufptr += output_buffer_width;
#endif
	lowhigh_buffer = bufptr;		bufptr += output_buffer_width;
	highlow_buffer = bufptr;		bufptr += output_buffer_width;
	highhigh_buffer = bufptr;		bufptr += output_buffer_width;

	// Compute the first six rows of horizontal filter output
	for (k = 0; k < buffer_row_count; k++) {
		FilterHorizontalRow10bit16s(rowptr, lowpass[k], highpass[k], roi.width, prescaling_buffer);
		rowptr += input_pitch;
	}


	/***** Need to optimize the first and last row calculations *****/

	// Use border filters for the first row
	row = 0;

	for (column = 0; column < output_width; column++)
	{
		int32_t sum;

		// Apply the lowpass vertical filter to the lowpass horizontal results
		sum  = lowpass[0][column];
		sum += lowpass[1][column];
#if _QUANTIZE_SPATIAL_LOWPASS
		lowlow_buffer[column] = SATURATE(sum);
#else
		lowlow_row_ptr[column] = SATURATE(sum);
#endif
		// Apply the highpass vertical filter to the lowpass horizontal results
		sum  =  5 * lowpass[0][column];
		sum -= 11 * lowpass[1][column];
		sum +=  4 * lowpass[2][column];
		sum +=  4 * lowpass[3][column];
		sum -=  1 * lowpass[4][column];
		sum -=  1 * lowpass[5][column];
		sum += ROUNDING(sum,8);
		sum = DivideByShift(sum, 3);
		highlow_buffer[column] = SATURATE(sum);

		// Apply the lowpass vertical filter to the highpass horizontal results
		sum  = highpass[0][column];
		sum += highpass[1][column];
		lowhigh_buffer[column] = SATURATE(sum);

		// Apply the highpass vertical filter to the highpass horizontal results
		sum  =  5 * highpass[0][column];
		sum -= 11 * highpass[1][column];
		sum +=  4 * highpass[2][column];
		sum +=  4 * highpass[3][column];
		sum -=  1 * highpass[4][column];
		sum -=  1 * highpass[5][column];
		sum += ROUNDING(sum,8);
		sum = DivideByShift(sum, 3);
		highhigh_buffer[column] = SATURATE(sum);
	}

#if _HIGHPASS_8S
#if _QUANTIZE_SPATIAL_LOWPASS
	// Quantize the 16-bit lowpass coefficients
	QuantizeRow16sTo16s(lowlow_buffer, lowlow_row_ptr, output_width, lowlow_quantization);
#endif
	// Quantize the first row of results for each 8-bit output band
	QuantizeRow16sTo8s(lowhigh_buffer, lowhigh_row_ptr, output_width, lowhigh_quantization);
	QuantizeRow16sTo8s(highlow_buffer, highlow_row_ptr, output_width, highlow_quantization);
	QuantizeRow16sTo8s(highhigh_buffer, highhigh_row_ptr, output_width, highhigh_quantization);
#else
	// Quantize the first row of results for each 16-bit output band
#if _QUANTIZE_SPATIAL_LOWPASS
	QuantizeRow16sTo16s(lowlow_buffer, lowlow_row_ptr, output_width, lowlow_quantization);
#endif
	QuantizeRow16sTo16s(lowhigh_buffer, lowhigh_row_ptr, output_width, lowhigh_quantization);
	QuantizeRow16sTo16s(highlow_buffer, highlow_row_ptr, output_width, highlow_quantization);
	QuantizeRow16sTo16s(highhigh_buffer, highhigh_row_ptr, output_width, highhigh_quantization);
#endif

#if 0
	// Advance to the next pair of input rows if not using the SIMD code since the
	// SIMD version uses the first two rows again to compute the second output row

	{
		// Rotate the horizontal filter results by two rows
		PIXEL *temp0 = lowpass[0];
		PIXEL *temp1 = lowpass[1];
		PIXEL *high0 = highpass[0];
		PIXEL *high1 = highpass[1];

		for (k = 0; k < buffer_row_count - 2; k++) {
			lowpass[k] = lowpass[k+2];
			highpass[k] = highpass[k+2];
		}

		lowpass[buffer_row_count - 2] = temp0;
		lowpass[buffer_row_count - 1] = temp1;
		highpass[buffer_row_count - 2] = high0;
		highpass[buffer_row_count - 1] = high1;

		// Compute the next two rows of horizontal filter results
		for (; k < buffer_row_count; k++) {
			//SplitRow16s(rowptr, roi.width, lowpass[k], highpass[k]);
			FilterHorizontalRow10bit16s(rowptr, lowpass[k], highpass[k], roi.width, prescaling_buffer);
			rowptr += input_pitch;
		}
	}
#endif

	// Advance to the next output rows
	lowlow_row_ptr += lowlow_pitch;
	highlow_row_ptr += highlow_pitch;
	lowhigh_row_ptr += lowhigh_pitch;
	highhigh_row_ptr += highhigh_pitch;

	row += 2;								// Advance the row being processed

	for (; row < last_row; row += 2)
	{
#if (1 && XMMOPT)
#if _QUANTIZE_SPATIAL_LOWPASS
		__m128i *lowlow_ptr = (__m128i *)lowlow_buffer;
#else
		__m128i *lowlow_ptr = (__m128i *)lowlow_row_ptr;
#endif
		__m128i *highlow_ptr = (__m128i *)highlow_buffer;
		__m128i *lowhigh_ptr = (__m128i *)lowhigh_buffer;
		__m128i *highhigh_ptr = (__m128i *)highhigh_buffer;

		int column_step = 8;
		int post_column = output_width - (output_width % column_step);
#endif
		// Start at the first column
		column = 0;

		// Check that the input and output addresses are properly aligned
		for (k = 0; k < buffer_row_count; k++) {
			assert(ISALIGNED16(lowpass[k]));
			assert(ISALIGNED16(highpass[k]));
		}
		assert(ISALIGNED16(lowlow_ptr));
		assert(ISALIGNED16(lowhigh_ptr));
		assert(ISALIGNED16(highlow_ptr));
		assert(ISALIGNED16(highhigh_ptr));

#if (1 && XMMOPT)

		// Process a group of four pixels at a time
		for (; column < post_column; column += column_step)
		{
			__m128i low_epi16;
			__m128i sum_epi16;
			__m128i sum8_epi16;
			__m128i quad_epi16;
			__m128i half_epi16;


			/***** Apply the vertical filters to the horizontal lowpass results *****/

			// Load the first row of four pixels
			quad_epi16 = _mm_load_si128((__m128i *)&lowpass[0][column]);

			// Initialize the highpass filter sum
			sum_epi16 = _mm_setzero_si128();

			// Multiply each pixel by the first filter coefficient and sum the result
			sum_epi16 = _mm_subs_epi16(sum_epi16, quad_epi16);

			// Load the second row of four pixels
			quad_epi16 = _mm_load_si128((__m128i *)&lowpass[1][column]);

			// Multiply each pixel by the second filter coefficient and sum the result
			sum_epi16 = _mm_subs_epi16(sum_epi16, quad_epi16);

			// Load the third row of four pixels
			quad_epi16 = _mm_load_si128((__m128i *)&lowpass[2][column]);

			// Initialize the lowpass sum
			low_epi16 = quad_epi16;

			// Multiply each pixel by the third filter coefficient and sum the result
			sum8_epi16 = _mm_setzero_si128();
			sum8_epi16 = _mm_adds_epi16(sum8_epi16, quad_epi16);

			// Load the fourth row of four pixels
			quad_epi16 = _mm_load_si128((__m128i *)&lowpass[3][column]);

			// Compute the four lowpass results
			low_epi16 = _mm_adds_epi16(low_epi16, quad_epi16);

			// Scale the lowpass result to eliminate overflows in the vertical transform
			low_epi16 = _mm_srli_epi16(low_epi16, V210_VERTICAL_SHIFT);

			// Store the lowpass results
			_mm_store_si128(lowlow_ptr++, low_epi16);

			// Multiply each pixel by the fourth filter coefficient and sum the result
			sum8_epi16 = _mm_subs_epi16(sum8_epi16, quad_epi16);

			// Load the fifth row of four pixels
			quad_epi16 = _mm_load_si128((__m128i *)&lowpass[4][column]);

			// Multiply each pixel by the fifth filter coefficient and sum the result
			sum_epi16 = _mm_adds_epi16(sum_epi16, quad_epi16);

			// Load the sixth (last) row of four pixels
			quad_epi16 = _mm_load_si128((__m128i *)&lowpass[5][column]);

			// Multiply each pixel by the sixth filter coefficient and sum the result
			sum_epi16 = _mm_adds_epi16(sum_epi16, quad_epi16);


			half_epi16 = _mm_set1_epi16(4); //was 4
			sum_epi16 = _mm_adds_epi16(sum_epi16, half_epi16); // +7 rounding
			sum_epi16 = _mm_srai_epi16(sum_epi16, 3); // divide 8

			sum_epi16 = _mm_adds_epi16(sum_epi16, sum8_epi16);

			// Store the four highpass results
			_mm_store_si128(highlow_ptr++, sum_epi16);


			/***** Apply the vertical filters to the horizontal highpass results *****/

			sum_epi16 = _mm_setzero_si128();

			// Load the first row of four pixels
			quad_epi16 = _mm_load_si128((__m128i *)&highpass[0][column]);

			// Multiply each pixel by the first filter coefficient and sum the result
			sum_epi16 = _mm_subs_epi16(sum_epi16, quad_epi16);

			// Load the second row of four pixels
			quad_epi16 = _mm_load_si128((__m128i *)&highpass[1][column]);

			// Multiply each pixel by the second filter coefficient and sum the result
			sum_epi16 = _mm_subs_epi16(sum_epi16, quad_epi16);

			// Load the third row of four pixels
			quad_epi16 = _mm_load_si128((__m128i *)&highpass[2][column]);

			// Initialize the lowpass sum
			low_epi16 = quad_epi16;

			// Multiply each pixel by the third filter coefficient and sum the result
			sum8_epi16 = _mm_setzero_si128();
			sum8_epi16 = _mm_adds_epi16(sum8_epi16, quad_epi16);

			// Load the fourth row of four pixels
			quad_epi16 = _mm_load_si128((__m128i *)&highpass[3][column]);

			// Compute and store the four lowpass results
			low_epi16 = _mm_adds_epi16(low_epi16, quad_epi16);
			_mm_store_si128(lowhigh_ptr++, low_epi16);

			// Multiply each pixel by the fourth filter coefficient and sum the result
			sum8_epi16 = _mm_subs_epi16(sum8_epi16, quad_epi16);

			// Load the fifth row of four pixels
			quad_epi16 = _mm_load_si128((__m128i *)&highpass[4][column]);

			// Multiply each pixel by the fifth filter coefficient and sum the result
			sum_epi16 = _mm_adds_epi16(sum_epi16, quad_epi16);

			// Load the sixth (last) row of four pixels
			quad_epi16 = _mm_load_si128((__m128i *)&highpass[5][column]);

			// Multiply each pixel by the sixth filter coefficient and sum the result
			sum_epi16 = _mm_adds_epi16(sum_epi16, quad_epi16);


			sum_epi16 = _mm_adds_epi16(sum_epi16, half_epi16); // +7 rounding
			sum_epi16 = _mm_srai_epi16(sum_epi16, 3); // divide 8

			sum_epi16 = _mm_adds_epi16(sum_epi16, sum8_epi16);


			// Store the four highpass results
			_mm_store_si128(highhigh_ptr++, sum_epi16);
		}

		// Should have terminated the fast loop at the post processing column
		assert(column == post_column);
#endif

		// Process the remaining pixels to the end of the row
		for (; column < output_width; column++)
		{
			int32_t sum;

			// Apply the lowpass vertical filter to the lowpass horizontal results
			sum  = lowpass[2][column];
			sum += lowpass[3][column];

			// Scale the lowpass result to eliminate overflows in the vertical transform
			sum >>= V210_VERTICAL_SHIFT;

#if _QUANTIZE_SPATIAL_LOWPASS
			lowlow_buffer[column] = SATURATE(sum);
#else
			lowlow_row_ptr[column] = SATURATE(sum);
#endif
			// Apply the highpass vertical filter to the lowpass horizontal results
			sum  = -1 * lowpass[0][column];
			sum += -1 * lowpass[1][column];
			sum +=  1 * lowpass[4][column];
			sum +=  1 * lowpass[5][column];
			sum +=	4;
			sum >>= 3;
			sum +=  1 * lowpass[2][column];
			sum += -1 * lowpass[3][column];

			highlow_buffer[column] = (sum);

			// Apply the lowpass vertical filter to the highpass horizontal results
			sum  = highpass[2][column];
			sum += highpass[3][column];
			lowhigh_buffer[column] = (sum);

			// Apply the highpass vertical filter to the highpass horizontal results
			sum  = -1 * highpass[0][column];
			sum += -1 * highpass[1][column];
			sum +=  1 * highpass[4][column];
			sum +=  1 * highpass[5][column];
			sum +=	4;
			sum >>= 3;
			sum +=  1 * highpass[2][column];
			sum += -1 * highpass[3][column];
			highhigh_buffer[column] = (sum);
		}

		if (row < (last_row - 2))
		{
			// Rotate the horizontal filter results by two rows
			PIXEL *temp0 = lowpass[0];
			PIXEL *temp1 = lowpass[1];
			PIXEL *high0 = highpass[0];
			PIXEL *high1 = highpass[1];

			for (k = 0; k < buffer_row_count - 2; k++) {
				lowpass[k] = lowpass[k+2];
				highpass[k] = highpass[k+2];
			}

			lowpass[buffer_row_count - 2] = temp0;
			lowpass[buffer_row_count - 1] = temp1;
			highpass[buffer_row_count - 2] = high0;
			highpass[buffer_row_count - 1] = high1;

			// Compute the next two rows of horizontal filter results
			for (; k < buffer_row_count; k++) {
				//SplitRow16s(rowptr, roi.width, lowpass[k], highpass[k]);
				FilterHorizontalRow10bit16s(rowptr, lowpass[k], highpass[k], roi.width, prescaling_buffer);
				rowptr += input_pitch;
			}
		}

#if _HIGHPASS_8S
#if _QUANTIZE_SPATIAL_LOWPASS
		// Quantize the current row 16-bit lowpass coefficients
		QuantizeRow16sTo16s(lowlow_buffer, lowlow_row_ptr, output_width, lowlow_quantization);
#endif
		// Quantize the current row of results for each 8-bit highpass band
		QuantizeRow16sTo8s(lowhigh_buffer, lowhigh_row_ptr, output_width, lowhigh_quantization);
		QuantizeRow16sTo8s(highlow_buffer, highlow_row_ptr, output_width, highlow_quantization);
		QuantizeRow16sTo8s(highhigh_buffer, highhigh_row_ptr, output_width, highhigh_quantization);
#else
		// Quantize the current row of results for each 16-bit output band
#if _QUANTIZE_SPATIAL_LOWPASS
		QuantizeRow16sTo16s(lowlow_buffer, lowlow_row_ptr, output_width, lowlow_quantization);
#endif
		QuantizeRow16sTo16s(lowhigh_buffer, lowhigh_row_ptr, output_width, lowhigh_quantization);
		QuantizeRow16sTo16s(highlow_buffer, highlow_row_ptr, output_width, highlow_quantization);
		QuantizeRow16sTo16s(highhigh_buffer, highhigh_row_ptr, output_width, highhigh_quantization);
#endif

		// Advance to the next output rows
		lowlow_row_ptr += lowlow_pitch;
		highlow_row_ptr += highlow_pitch;
		lowhigh_row_ptr += lowhigh_pitch;
		highhigh_row_ptr += highhigh_pitch;
	}

	// Should have left the loop at the last row
	assert(row == last_row);

	// Use the border filters for the last row
	for (column = 0; column < output_width; column++)
	{
		int32_t sum;

		// Apply the lowpass vertical filter to the lowpass horizontal results
		sum  = lowpass[4][column];
		sum += lowpass[5][column];
#if _QUANTIZE_SPATIAL_LOWPASS
		lowlow_buffer[column] = SATURATE(sum);
#else
		lowlow_row_ptr[column] = SATURATE(sum);
#endif
		// Apply the highpass vertical filter to the lowpass horizontal results
		sum  = 11 * lowpass[4][column];
		sum -=  5 * lowpass[5][column];
		sum -=  4 * lowpass[3][column];
		sum -=  4 * lowpass[2][column];
		sum +=  1 * lowpass[1][column];
		sum +=  1 * lowpass[0][column];
		sum +=  ROUNDING(sum,8);
		sum = DivideByShift(sum, 3);
		highlow_buffer[column] = SATURATE(sum);

		// Apply the lowpass vertical filter to the highpass horizontal results
		sum  = highpass[4][column];
		sum += highpass[5][column];
		lowhigh_buffer[column] = SATURATE(sum);

		// Apply the highpass vertical filter to the highpass horizontal results
		sum  = 11 * highpass[4][column];
		sum -=  5 * highpass[5][column];
		sum -=  4 * highpass[3][column];
		sum -=  4 * highpass[2][column];
		sum +=  1 * highpass[1][column];
		sum +=  1 * highpass[0][column];
		sum +=  ROUNDING(sum,8);
		sum = DivideByShift(sum, 3);
		highhigh_buffer[column] = SATURATE(sum);
	}

#if _HIGHPASS_8S
#if _QUANTIZE_SPATIAL_LOWPASS
		// Quantize the last row of 16-bit lowpass coefficients
		QuantizeRow16sTo16s(lowlow_buffer, lowlow_row_ptr, output_width, lowlow_quantization);
#endif
		// Quantize the last row of results for each 8-bit highpass band
		QuantizeRow16sTo8s(lowhigh_buffer, lowhigh_row_ptr, output_width, lowhigh_quantization);
		QuantizeRow16sTo8s(highlow_buffer, highlow_row_ptr, output_width, highlow_quantization);
		QuantizeRow16sTo8s(highhigh_buffer, highhigh_row_ptr, output_width, highhigh_quantization);
#else
		// Quantize the last row of results for each 16-bit output band
#if _QUANTIZE_SPATIAL_LOWPASS
		QuantizeRow16sTo16s(lowlow_buffer, lowlow_row_ptr, output_width, lowlow_quantization);
#endif
		QuantizeRow16sTo16s(lowhigh_buffer, lowhigh_row_ptr, output_width, lowhigh_quantization);
		QuantizeRow16sTo16s(highlow_buffer, highlow_row_ptr, output_width, highlow_quantization);
		QuantizeRow16sTo16s(highhigh_buffer, highhigh_row_ptr, output_width, highhigh_quantization);
#endif
}
//#endif //p4



#if _HIGHPASS_CODED

// Compute the forward spatial transform, quantize the coefficients, and encode
// the quantized coefficients using runs of zeros and variable length coding.
// Note that this routine is generic MMX, also need to code version for SSE2.
// The routine was adapted from FilterSpatialPrescaleQuant16s and may still include
// prescaling.

void FilterSpatialQuant16sToCoded(ENCODER *encoder,
								  PIXEL *input_image, int input_pitch,
								  PIXEL *lowlow_band, int lowlow_pitch,
								  PIXEL *lowhigh_band, int lowhigh_pitch,
								  PIXEL *highlow_band, int highlow_pitch,
								  PIXEL *highhigh_band, int highhigh_pitch,
								  PIXEL *buffer, size_t buffer_size, ROI roi,
								  int quantization[4], int coded_size[4])
{
	PIXEL *rowptr = input_image;

	// Six rows of lowpass and highpass horizontal results
	PIXEL *lowpass[6];
	PIXEL *highpass[6];

	PIXEL *lowlow_buffer;
	PIXEL *lowhigh_buffer;
	PIXEL *highlow_buffer;
	PIXEL *highhigh_buffer;

	int lowlow_quantization;
	int lowhigh_quantization;
	int highlow_quantization;
	int highhigh_quantization;

	PIXEL *lowlow_row_ptr = lowlow_band;

	BITSTREAM lowhigh_stream;
	BITSTREAM highlow_stream;
	BITSTREAM highhigh_stream;

	int lowhigh_gap;
	int highlow_gap;
	int highhigh_gap;

	int lowhigh_zero_count = 0;
	int highlow_zero_count = 0;
	int highhigh_zero_count = 0;

	int last_row = roi.height - 2;
	int output_width;
	size_t output_buffer_size;
	int output_buffer_width;
	PIXEL *bufptr;
	const int buffer_row_count = sizeof(lowpass)/sizeof(lowpass[0]);
	//PIXEL *prescaling_buffer;
	//size_t prescaling_buffer_size;
	//int prescaling_buffer_width;
	int row, column;
	int k;

	// Compute the size of the highpass bands
	int output_height = roi.height/2;
	size_t lowhigh_band_size = lowhigh_pitch * output_height;
	size_t highlow_band_size = highlow_pitch * output_height;
	size_t highhigh_band_size = highhigh_pitch * output_height;

	// Compute the width of each row of horizontal filter output
	assert((roi.width % 2) == 0);
	output_width = roi.width/2;

	// Convert pitch from bytes to pixels
	input_pitch /= sizeof(PIXEL);
	lowlow_pitch /= sizeof(PIXEL);
	lowhigh_pitch /= sizeof(PIXEL);
	highlow_pitch /= sizeof(PIXEL);
	highhigh_pitch /= sizeof(PIXEL);

	// Compute the gaps at the end of each band of highpass coefficients
	lowhigh_gap = lowhigh_pitch - output_width;
	highlow_gap = highlow_pitch - output_width;
	highhigh_gap = highhigh_pitch - output_width;

	if (quantization != NULL)
	{
		lowlow_quantization = quantization[0];
		lowhigh_quantization = quantization[1];
		highlow_quantization = quantization[2];
		highhigh_quantization = quantization[3];
	}
	else
	{
		lowlow_quantization = 1;
		lowhigh_quantization = 1;
		highlow_quantization = 1;
		highhigh_quantization = 1;
	}

	// Must have an even number of rows
	assert((roi.height % 2) == 0);

	// Must have an even number of columns
	assert((roi.width % 2) == 0);

	// Compute the size of each row of horizontal filter output in bytes
	output_buffer_size = output_width * sizeof(PIXEL);

	// Round up the buffer size to an integer number of cache lines
	output_buffer_size = ALIGN(output_buffer_size, _CACHE_LINE_SIZE);

	// Compute the size of the buffer for prescaling the input rows to avoid overflow
	prescaling_buffer_size = roi.width * sizeof(PIXEL);

	// Round tp the buffer size to an integer number of cache lines
	//prescaling_buffer_size = ALIGN(prescaling_buffer_size, _CACHE_LINE_SIZE);

#if _QUANTIZE_SPATIAL_LOWPASS
	// The buffer must be large enough for twelve rows plus the prescaling buffer
	assert(buffer_size >= ((12 * output_buffer_size) + prescaling_buffer_size));
#else
	// The buffer must be large enough for eleven rows plus the prescaling buffer
	assert(buffer_size >= ((11 * output_buffer_size) + prescaling_buffer_size));
#endif

	// Computed the allocated width of each buffer
	output_buffer_width = output_buffer_size / sizeof(PIXEL);

	// Compute the allocated width of the prescaling buffer
	//prescaling_buffer_width = prescaling_buffer_size / sizeof(PIXEL);

	// Start allocating intermediate buffers at the beginning of the supplied buffer
	bufptr = buffer;

	// Allocate space in the buffer for prescaling the input coefficients
	//prescaling_buffer = bufptr;		bufptr += prescaling_buffer_width;

	// Allocate space in the buffer for the horizontal filter results
	for (k = 0; k < buffer_row_count; k++) {
		lowpass[k] = bufptr;		bufptr += output_buffer_width;
		highpass[k] = bufptr;		bufptr += output_buffer_width;
	}

	// Allocate space in the buffer for the pre-quantized coefficients
#if _QUANTIZE_SPATIAL_LOWPASS
	lowlow_buffer = bufptr;			bufptr += output_buffer_width;
#endif
	lowhigh_buffer = bufptr;		bufptr += output_buffer_width;
	highlow_buffer = bufptr;		bufptr += output_buffer_width;
	highhigh_buffer = bufptr;		bufptr += output_buffer_width;

	// Initialize bitstream structures for the highpass bands
	InitBitstream(&lowhigh_stream);
	InitBitstream(&highlow_stream);
	InitBitstream(&highhigh_stream);

	// Bind the bitstreams to the highpass bands
	SetBitstreamBuffer(&lowhigh_stream, (uint8_t *)lowhigh_band, lowhigh_band_size, BITSTREAM_ACCESS_WRITE);
	SetBitstreamBuffer(&highlow_stream, (uint8_t *)highlow_band, highlow_band_size, BITSTREAM_ACCESS_WRITE);
	SetBitstreamBuffer(&highhigh_stream, (uint8_t *)highhigh_band, highhigh_band_size, BITSTREAM_ACCESS_WRITE);

	// Compute the first six rows of horizontal filter output
	for (k = 0; k < buffer_row_count; k++) {
		//SplitRow16s(rowptr, roi.width, lowpass[k], highpass[k]);
		//FilterHorizontalRowPrescaled16s(rowptr, lowpass[k], highpass[k], roi.width, prescaling_buffer);
		FilterHorizontalRow16s(rowptr, lowpass[k], highpass[k], roi.width);
		rowptr += input_pitch;
	}


	// Need to optimize the first and last row calculations

	// Use border filters for the first row
	row = 0;

	for (column = 0; column < output_width; column++)
	{
		int32_t sum;

		// Apply the lowpass vertical filter to the lowpass horizontal results
		sum  = lowpass[0][column];
		sum += lowpass[1][column];
#if _QUANTIZE_SPATIAL_LOWPASS
		lowlow_buffer[column] = SATURATE(sum);
#else
		lowlow_row_ptr[column] = SATURATE(sum);
#endif
		// Apply the highpass vertical filter to the lowpass horizontal results
		sum  =  5 * lowpass[0][column];
		sum -= 11 * lowpass[1][column];
		sum +=  4 * lowpass[2][column];
		sum +=  4 * lowpass[3][column];
		sum -=  1 * lowpass[4][column];
		sum -=  1 * lowpass[5][column];
		sum += ROUNDING(sum,8);
		sum = DivideByShift(sum, 3);
		highlow_buffer[column] = SATURATE(sum);

		// Apply the lowpass vertical filter to the highpass horizontal results
		sum  = highpass[0][column];
		sum += highpass[1][column];
		lowhigh_buffer[column] = SATURATE(sum);

		// Apply the highpass vertical filter to the highpass horizontal results
		sum  =  5 * highpass[0][column];
		sum -= 11 * highpass[1][column];
		sum +=  4 * highpass[2][column];
		sum +=  4 * highpass[3][column];
		sum -=  1 * highpass[4][column];
		sum -=  1 * highpass[5][column];
		sum += ROUNDING(sum,8);
		sum = DivideByShift(sum, 3);
		highhigh_buffer[column] = SATURATE(sum);
	}

	// Quantize the first row of results for each 16-bit output band

#if _QUANTIZE_SPATIAL_LOWPASS
	QuantizeRow16sTo16s(lowlow_buffer, lowlow_row_ptr, output_width, lowlow_quantization);
#endif

	QuantizeRow16sToCoded(encoder, &lowhigh_stream, lowhigh_buffer, output_width, lowhigh_gap,
						  lowhigh_quantization, &lowhigh_zero_count, FALSE);

	QuantizeRow16sToCoded(encoder, &highlow_stream, highlow_buffer, output_width, highlow_gap,
						  highlow_quantization, &highlow_zero_count, FALSE);

	QuantizeRow16sToCoded(encoder, &highhigh_stream, highhigh_buffer, output_width, highhigh_gap,
						  highhigh_quantization, &highhigh_zero_count, FALSE);

#if 0
	// Advance to the next pair of input rows if not using the SIMD code since the
	// SIMD version uses the first two rows again to compute the second output row

	{
		// Rotate the horizontal filter results by two rows
		PIXEL *temp0 = lowpass[0];
		PIXEL *temp1 = lowpass[1];
		PIXEL *high0 = highpass[0];
		PIXEL *high1 = highpass[1];

		for (k = 0; k < buffer_row_count - 2; k++) {
			lowpass[k] = lowpass[k+2];
			highpass[k] = highpass[k+2];
		}

		lowpass[buffer_row_count - 2] = temp0;
		lowpass[buffer_row_count - 1] = temp1;
		highpass[buffer_row_count - 2] = high0;
		highpass[buffer_row_count - 1] = high1;

		// Compute the next two rows of horizontal filter results
		for (; k < buffer_row_count; k++) {
			//SplitRow16s(rowptr, roi.width, lowpass[k], highpass[k]);
			//FilterHorizontalRowPrescaled16s(rowptr, lowpass[k], highpass[k], roi.width, prescaling_buffer);
			FilterHorizontalRow16s(rowptr, lowpass[k], highpass[k], roi.width);
			rowptr += input_pitch;
		}
	}
#endif

	// Advance to the next output rows
	lowlow_row_ptr += lowlow_pitch;
	//highlow_row_ptr += highlow_pitch;
	//lowhigh_row_ptr += lowhigh_pitch;
	//highhigh_row_ptr += highhigh_pitch;

	row += 2;								// Advance the row being processed

	for (; row < last_row; row += 2)
	{
#if (1 && XMMOPT)
#if _QUANTIZE_SPATIAL_LOWPASS
		__m64 *lowlow_ptr = (__m64 *)lowlow_buffer;
#else
		__m64 *lowlow_ptr = (__m64 *)lowlow_row_ptr;
#endif
		__m64 *highlow_ptr = (__m64 *)highlow_buffer;
		__m64 *lowhigh_ptr = (__m64 *)lowhigh_buffer;
		__m64 *highhigh_ptr = (__m64 *)highhigh_buffer;

		int column_step = 4;
		int post_column = output_width - (output_width % column_step);
#endif
		// Start at the first column
		column = 0;

#if (1 && XMMOPT)

		// Process a group of four pixels at a time
		for (; column < post_column; column += column_step)
		{
			__m64 low_pi16;
			__m64 sum_pi16;
			__m64 quad_pi16;
			__m64 mask_pi16;
			__m64 half_pi16;


			// Apply the vertical filters to the horizontal lowpass results //

			// Load the first row of four pixels
			quad_pi16 = *((__m64 *)&lowpass[0][column]);
			// Initialize the highpass filter sum
			sum_pi16 = _mm_setzero_si64();
			// Multiply each pixel by the first filter coefficient and sum the result
			sum_pi16 = _mm_subs_pi16(sum_pi16, quad_pi16);

			// Load the second row of four pixels
			quad_pi16 = *((__m64 *)&lowpass[1][column]);
			// Multiply each pixel by the second filter coefficient and sum the result
			sum_pi16 = _mm_subs_pi16(sum_pi16, quad_pi16);

			// Load the fifth row of four pixels
			quad_pi16 = *((__m64 *)&lowpass[4][column]);
			// Multiply each pixel by the fifth filter coefficient and sum the result
			sum_pi16 = _mm_adds_pi16(sum_pi16, quad_pi16);

			// Load the sixth (last) row of four pixels
			quad_pi16 = *((__m64 *)&lowpass[5][column]);
			// Multiply each pixel by the sixth filter coefficient and sum the result
			sum_pi16 = _mm_adds_pi16(sum_pi16, quad_pi16);

			sum_pi16 = _mm_srai_pi16(sum_pi16, 3); // divided by 8 =   (-1a -1b +1e +1f) / 8



			// Load the third row of four pixels
			quad_pi16 = *((__m64 *)&lowpass[2][column]);
			// Initialize the lowpass sum
			low_pi16 = quad_pi16;

			// Multiply each pixel by the third filter coefficient and sum the result
			sum_pi16 = _mm_adds_pi16(sum_pi16, quad_pi16);

			// Load the fourth row of four pixels
			quad_pi16 = *((__m64 *)&lowpass[3][column]);
			// Compute the four lowpass results
			low_pi16 = _mm_adds_pi16(low_pi16, quad_pi16);

			// Store the lowpass results
			*(lowlow_ptr++) = low_pi16;
			// Multiply each pixel by the fourth filter coefficient and sum the result
			sum_pi16 = _mm_subs_pi16(sum_pi16, quad_pi16);


			// Store the four highpass results
			*(highlow_ptr++) = sum_pi16;


			// Apply the vertical filters to the horizontal highpass results //

			sum_pi16 = _mm_setzero_si64();

			// Load the first row of four pixels
			quad_pi16 = *((__m64 *)&highpass[0][column]);
			// Multiply each pixel by the first filter coefficient and sum the result
			sum_pi16 = _mm_subs_pi16(sum_pi16, quad_pi16);

			// Load the second row of four pixels
			quad_pi16 = *((__m64 *)&highpass[1][column]);
			// Multiply each pixel by the second filter coefficient and sum the result
			sum_pi16 = _mm_subs_pi16(sum_pi16, quad_pi16);

			// Load the fifth row of four pixels
			quad_pi16 = *((__m64 *)&highpass[4][column]);
			// Multiply each pixel by the fifth filter coefficient and sum the result
			sum_pi16 = _mm_adds_pi16(sum_pi16, quad_pi16);

			// Load the sixth (last) row of four pixels
			quad_pi16 = *((__m64 *)&highpass[5][column]);
			// Multiply each pixel by the sixth filter coefficient and sum the result
			sum_pi16 = _mm_adds_pi16(sum_pi16, quad_pi16);

			sum_pi16 = _mm_srai_pi16(sum_pi16, 3); // divided by 8 =   (-1a -1b +1e +1f) / 8


			// Load the third row of four pixels
			quad_pi16 = *((__m64 *)&highpass[2][column]);
			// Initialize the lowpass sum
			low_pi16 = quad_pi16;

			// Multiply each pixel by the third filter coefficient and sum the result
			sum_pi16 = _mm_adds_pi16(sum_pi16, quad_pi16);

			// Load the fourth row of four pixels
			quad_pi16 = *((__m64 *)&highpass[3][column]);
			// Compute and store the four lowpass results
			low_pi16 = _mm_adds_pi16(low_pi16, quad_pi16);
			*(lowhigh_ptr++) = low_pi16;

			// Multiply each pixel by the fourth filter coefficient and sum the result
			sum_pi16 = _mm_subs_pi16(sum_pi16, quad_pi16);


			// Store the four highpass results
			*(highhigh_ptr++) = sum_pi16;
		}

		//_mm_empty();	// Clear the MMX register state

		// Should have terminated the fast loop at the post processing column
		assert(column == post_column);
#endif

		// Process the remaining pixels to the end of the row
		for (; column < output_width; column++)
		{
			int32_t sum;

			// Apply the lowpass vertical filter to the lowpass horizontal results
			sum  = lowpass[2][column];
			sum += lowpass[3][column];
#if _QUANTIZE_SPATIAL_LOWPASS
			lowlow_buffer[column] = SATURATE(sum);
#else
			lowlow_row_ptr[column] = SATURATE(sum);
#endif
			// Apply the highpass vertical filter to the lowpass horizontal results
			sum  = -1 * lowpass[0][column];
			sum += -1 * lowpass[1][column];
			sum +=  8 * lowpass[2][column];
			sum += -8 * lowpass[3][column];
			sum +=  1 * lowpass[4][column];
			sum +=  1 * lowpass[5][column];
			sum += ROUNDING(sum,8);
			sum = DivideByShift(sum, 3);
			highlow_buffer[column] = SATURATE(sum);

			// Apply the lowpass vertical filter to the highpass horizontal results
			sum  = highpass[2][column];
			sum += highpass[3][column];
			lowhigh_buffer[column] = SATURATE(sum);

			// Apply the highpass vertical filter to the highpass horizontal results
			sum  = -1 * highpass[0][column];
			sum += -1 * highpass[1][column];
			sum +=  8 * highpass[2][column];
			sum += -8 * highpass[3][column];
			sum +=  1 * highpass[4][column];
			sum +=  1 * highpass[5][column];
			sum += ROUNDING(sum,8);
			sum = DivideByShift(sum, 3);
			highhigh_buffer[column] = SATURATE(sum);
		}

		if (row < (last_row - 2))
		{
			// Rotate the horizontal filter results by two rows
			PIXEL *temp0 = lowpass[0];
			PIXEL *temp1 = lowpass[1];
			PIXEL *high0 = highpass[0];
			PIXEL *high1 = highpass[1];

			for (k = 0; k < buffer_row_count - 2; k++) {
				lowpass[k] = lowpass[k+2];
				highpass[k] = highpass[k+2];
			}

			lowpass[buffer_row_count - 2] = temp0;
			lowpass[buffer_row_count - 1] = temp1;
			highpass[buffer_row_count - 2] = high0;
			highpass[buffer_row_count - 1] = high1;

			// Compute the next two rows of horizontal filter results
			for (; k < buffer_row_count; k++) {
				//SplitRow16s(rowptr, roi.width, lowpass[k], highpass[k]);
				//FilterHorizontalRowPrescaled16s(rowptr, lowpass[k], highpass[k], roi.width, prescaling_buffer);
				FilterHorizontalRow16s(rowptr, lowpass[k], highpass[k], roi.width);
				rowptr += input_pitch;
			}
		}

#if _QUANTIZE_SPATIAL_LOWPASS
		QuantizeRow16sTo16s(lowlow_buffer, lowlow_row_ptr, output_width, lowlow_quantization);
#endif

		QuantizeRow16sToCoded(encoder, &lowhigh_stream, lowhigh_buffer, output_width, lowhigh_gap,
							  lowhigh_quantization, &lowhigh_zero_count, FALSE);

		QuantizeRow16sToCoded(encoder, &highlow_stream, highlow_buffer, output_width, highlow_gap,
							  highlow_quantization, &highlow_zero_count, FALSE);

		QuantizeRow16sToCoded(encoder, &highhigh_stream, highhigh_buffer, output_width, highhigh_gap,
							  highhigh_quantization, &highhigh_zero_count, FALSE);

		// Advance to the next output rows
		lowlow_row_ptr += lowlow_pitch;
		//highlow_row_ptr += highlow_pitch;
		//lowhigh_row_ptr += lowhigh_pitch;
		//highhigh_row_ptr += highhigh_pitch;
	}

	// Should have left the loop at the last row
	assert(row == last_row);

	// Use the border filters for the last row
	for (column = 0; column < output_width; column++)
	{
		int32_t sum;

		// Apply the lowpass vertical filter to the lowpass horizontal results
		sum  = lowpass[4][column];
		sum += lowpass[5][column];
#if _QUANTIZE_SPATIAL_LOWPASS
		lowlow_buffer[column] = SATURATE(sum);
#else
		lowlow_row_ptr[column] = SATURATE(sum);
#endif
		// Apply the highpass vertical filter to the lowpass horizontal results
		sum  = 11 * lowpass[4][column];
		sum -=  5 * lowpass[5][column];
		sum -=  4 * lowpass[3][column];
		sum -=  4 * lowpass[2][column];
		sum +=  1 * lowpass[1][column];
		sum +=  1 * lowpass[0][column];
		sum +=  ROUNDING(sum,8);
		sum = DivideByShift(sum, 3);
		highlow_buffer[column] = SATURATE(sum);

		// Apply the lowpass vertical filter to the highpass horizontal results
		sum  = highpass[4][column];
		sum += highpass[5][column];
		lowhigh_buffer[column] = SATURATE(sum);

		// Apply the highpass vertical filter to the highpass horizontal results
		sum  = 11 * highpass[4][column];
		sum -=  5 * highpass[5][column];
		sum -=  4 * highpass[3][column];
		sum -=  4 * highpass[2][column];
		sum +=  1 * highpass[1][column];
		sum +=  1 * highpass[0][column];
		sum +=  ROUNDING(sum,8);
		sum = DivideByShift(sum, 3);
		highhigh_buffer[column] = SATURATE(sum);
	}

#if _QUANTIZE_SPATIAL_LOWPASS
	QuantizeRow16sTo16s(lowlow_buffer, lowlow_row_ptr, output_width, lowlow_quantization);
#endif

	QuantizeRow16sToCoded(encoder, &lowhigh_stream, lowhigh_buffer, output_width, lowhigh_gap,
						  lowhigh_quantization, &lowhigh_zero_count, true);

	QuantizeRow16sToCoded(encoder, &highlow_stream, highlow_buffer, output_width, highlow_gap,
						  highlow_quantization, &highlow_zero_count, true);

	QuantizeRow16sToCoded(encoder, &highhigh_stream, highhigh_buffer, output_width, highhigh_gap,
						  highhigh_quantization, &highhigh_zero_count, true);

	// Check that the last runs of zeros has been placed in each stream
	assert(lowhigh_zero_count == 0);
	assert(highlow_zero_count == 0);
	assert(highhigh_zero_count == 0);

	// Append the band end codeword to the encoded coefficients
	FinishEncodeBand(&lowhigh_stream,encoder->band_end_code[encoder->active_codebook],encoder->band_end_size[encoder->active_codebook]);
	FinishEncodeBand(&highlow_stream,encoder->band_end_code[encoder->active_codebook],encoder->band_end_size[encoder->active_codebook]);
	FinishEncodeBand(&highhigh_stream,encoder->band_end_code[encoder->active_codebook],encoder->band_end_size[encoder->active_codebook]);

	// Flush the bitstreams
	FlushBitstream(&lowhigh_stream);
	FlushBitstream(&highlow_stream);
	FlushBitstream(&highhigh_stream);

	// Leave the bitstreams aligned on a tag word boundary
	AlignBitsTag(&lowhigh_stream);
	AlignBitsTag(&highlow_stream);
	AlignBitsTag(&highhigh_stream);

	// Record the size of each encoded band
	coded_size[0] = 0;
	coded_size[1] = BitstreamByteCount(&lowhigh_stream);
	coded_size[2] = BitstreamByteCount(&highlow_stream);
	coded_size[3] = BitstreamByteCount(&highhigh_stream);

	// Check that the encoded bands did not overflow the available space
	assert(coded_size[1] <= lowhigh_band_size);
	assert(coded_size[2] <= highlow_band_size);
	assert(coded_size[3] <= highhigh_band_size);
}

#endif


#if _PROCESSOR_DISPATCH

__declspec(cpu_dispatch(Pentium_4,Generic))

void FilterSpatialYUVQuant16s(uint8_t *input_data, int input_pitch,
							  PIXEL *lowlow_band, int lowlow_pitch,
							  PIXEL *lowhigh_band, int lowhigh_pitch,
							  PIXEL *highlow_band, int highlow_pitch,
							  PIXEL *highhigh_band, int highhigh_pitch,
							  PIXEL *buffer, size_t buffer_size, ROI roi,
							  int channel, int quantization[4], FRAME_INFO *frame, int precision)
{
	// Stub routine for processor specific dispatch
}
#endif


#if _PROCESSOR_GENERIC

#if _PROCESSOR_DISPATCH
__declspec(cpu_specific(Generic))
#endif

// Compute the forward spatial transform with prescaling and quantization
void FilterSpatialYUVQuant16s(uint8_t *input_data, int input_pitch,
							  PIXEL *lowlow_band, int lowlow_pitch,
							  PIXEL *lowhigh_band, int lowhigh_pitch,
							  PIXEL *highlow_band, int highlow_pitch,
							  PIXEL *highhigh_band, int highhigh_pitch,
							  PIXEL *buffer, size_t buffer_size, ROI roi,
							  int channel, int quantization[4], FRAME_INFO *frame, int precision, int limit_yuv)
{
	uint8_t *rowptr = input_data;

	// Six rows of lowpass and highpass horizontal results
	PIXEL *lowpass[6];
	PIXEL *highpass[6];

	PIXEL *lowlow_buffer;
	PIXEL *lowhigh_buffer;
	PIXEL *highlow_buffer;
	PIXEL *highhigh_buffer;

	int lowlow_quantization;
	int lowhigh_quantization;
	int highlow_quantization;
	int highhigh_quantization;

	// Change the highpass output bands to be 8-bit pixels //

#if _HIGHPASS_8S
	PIXEL16S *lowlow_row_ptr = lowlow_band;
	PIXEL8S *lowhigh_row_ptr = (PIXEL8S *)lowhigh_band;
	PIXEL8S *highlow_row_ptr = (PIXEL8S *)highlow_band;
	PIXEL8S *highhigh_row_ptr = (PIXEL8S *)highhigh_band;
#else
	PIXEL *lowlow_row_ptr = lowlow_band;
	PIXEL *lowhigh_row_ptr = lowhigh_band;
	PIXEL *highlow_row_ptr = highlow_band;
	PIXEL *highhigh_row_ptr = highhigh_band;
#endif

	int last_row = roi.height - 2;
	int output_width;
	size_t output_buffer_size;
	int output_buffer_width;
	PIXEL *bufptr;
	const int buffer_row_count = sizeof(lowpass)/sizeof(lowpass[0]);
	PIXEL *unpacking_buffer;
	size_t unpacking_buffer_size = 0;
	int unpacking_buffer_width;
	int row, column;
	int k;

	// Convert pitch from bytes to pixels
	lowlow_pitch /= sizeof(PIXEL);
#if _HIGHPASS_8S
	lowhigh_pitch /= sizeof(PIXEL8S);
	highlow_pitch /= sizeof(PIXEL8S);
	highhigh_pitch /= sizeof(PIXEL8S);
#else
	lowhigh_pitch /= sizeof(PIXEL);
	highlow_pitch /= sizeof(PIXEL);
	highhigh_pitch /= sizeof(PIXEL);
#endif

	if (quantization != NULL)
	{
		lowlow_quantization = quantization[0];
		lowhigh_quantization = quantization[1];
		highlow_quantization = quantization[2];
		highhigh_quantization = quantization[3];
	}
	else
	{
		lowlow_quantization = 1;
		lowhigh_quantization = 1;
		highlow_quantization = 1;
		highhigh_quantization = 1;
	}

	// Must have an even number of rows
	assert((roi.height % 2) == 0);

	// Must have an even number of columns
	assert((roi.width % 2) == 0);

	// Compute the width of each row of horizontal filter output
	output_width = roi.width/2;

	// Compute the size of each row of horizontal filter output in bytes
	output_buffer_size = output_width * sizeof(PIXEL);

	// Round up the buffer size to an integer number of cache lines
	output_buffer_size = ALIGN(output_buffer_size, _CACHE_LINE_SIZE);

	// Compute the size of the buffer for prescaling the input rows to avoid overflow
	unpacking_buffer_size = roi.width * sizeof(PIXEL);

	// Round tp the buffer size to an integer number of cache lines
	unpacking_buffer_size = ALIGN(unpacking_buffer_size, _CACHE_LINE_SIZE);

#if _QUANTIZE_SPATIAL_LOWPASS
	// The buffer must be large enough for sixteen rows plus the unpacking buffer
	assert(buffer_size >= ((16 * output_buffer_size) + unpacking_buffer_size));
#else
	// The buffer must be large enough for fifteen rows plus the unpacking buffer
	assert(buffer_size >= ((15 * output_buffer_size) + unpacking_buffer_size));
#endif

	// Computed the allocated width of each buffer
	output_buffer_width = output_buffer_size / sizeof(PIXEL);

	// Compute the allocated width of the prescaling buffer
	unpacking_buffer_width = unpacking_buffer_size / sizeof(PIXEL);

	// Start allocating intermediate buffers at the beginning of the supplied buffer
	bufptr = buffer;

	// Allocate space in the buffer for prescaling the input coefficients
	unpacking_buffer = bufptr;		bufptr += unpacking_buffer_width;

	// Allocate space in the buffer for the horizontal filter results
	for (k = 0; k < buffer_row_count; k++) {
		lowpass[k] = bufptr;		bufptr += output_buffer_width;
		highpass[k] = bufptr;		bufptr += output_buffer_width;
	}

	// Allocate space in the buffer for the pre-quantized coefficients
#if _QUANTIZE_SPATIAL_LOWPASS
	lowlow_buffer = bufptr;			bufptr += output_buffer_width;
#endif
	lowhigh_buffer = bufptr;		bufptr += output_buffer_width;
	highlow_buffer = bufptr;		bufptr += output_buffer_width;
	highhigh_buffer = bufptr;		bufptr += output_buffer_width;

	// Compute the first six rows of horizontal filter output
	for (k = 0; k < buffer_row_count; k++) {
		//SplitRow16s(rowptr, roi.width, lowpass[k], highpass[k]);
		FilterHorizontalRowYUV16s(rowptr, lowpass[k], highpass[k], roi.width, channel,
								  unpacking_buffer, unpacking_buffer_size, frame, precision, limit_yuv);
		rowptr += input_pitch;
	}


	/***** Need to optimize the first and last row calculations *****/

	// Use border filters for the first row
	row = 0;

	for (column = 0; column < output_width; column++)
	{
		int32_t sum;

		// Apply the lowpass vertical filter to the lowpass horizontal results
		sum  = lowpass[0][column];
		sum += lowpass[1][column];
#if _QUANTIZE_SPATIAL_LOWPASS
		lowlow_buffer[column] = SATURATE(sum);
#else
		lowlow_row_ptr[column] = SATURATE(sum);
#endif
		// Apply the highpass vertical filter to the lowpass horizontal results
		sum  =  5 * lowpass[0][column];
		sum -= 11 * lowpass[1][column];
		sum +=  4 * lowpass[2][column];
		sum +=  4 * lowpass[3][column];
		sum -=  1 * lowpass[4][column];
		sum -=  1 * lowpass[5][column];
		sum += ROUNDING(sum,8);
		sum = DivideByShift(sum, 3);
		highlow_buffer[column] = SATURATE(sum);

		// Apply the lowpass vertical filter to the highpass horizontal results
		sum  = highpass[0][column];
		sum += highpass[1][column];
		lowhigh_buffer[column] = SATURATE(sum);

		// Apply the highpass vertical filter to the highpass horizontal results
		sum  =  5 * highpass[0][column];
		sum -= 11 * highpass[1][column];
		sum +=  4 * highpass[2][column];
		sum +=  4 * highpass[3][column];
		sum -=  1 * highpass[4][column];
		sum -=  1 * highpass[5][column];
		sum += ROUNDING(sum,8);
		sum = DivideByShift(sum, 3);
		highhigh_buffer[column] = SATURATE(sum);
	}

#if _HIGHPASS_8S
#if _QUANTIZE_SPATIAL_LOWPASS
	// Quantize the 16-bit lowpass coefficients
	QuantizeRow16sTo16s(lowlow_buffer, lowlow_row_ptr, output_width, lowlow_quantization);
#endif
	// Quantize the first row of results for each 8-bit output band
	QuantizeRow16sTo8s(lowhigh_buffer, lowhigh_row_ptr, output_width, lowhigh_quantization);
	QuantizeRow16sTo8s(highlow_buffer, highlow_row_ptr, output_width, highlow_quantization);
	QuantizeRow16sTo8s(highhigh_buffer, highhigh_row_ptr, output_width, highhigh_quantization);
#else

	#if _PACK_RUNS_IN_BAND_16S
	  // Quantize the current row of results for each 16-bit output band
	  #if _QUANTIZE_SPATIAL_LOWPASS
		QuantizeRow16sTo16s(lowlow_buffer, lowlow_row_ptr, output_width, lowlow_quantization);
	  #endif

		QuantizeRow16sTo16s(lowhigh_buffer, lowhigh_row_ptr, output_width, lowhigh_quantization);
		lowhigh_row_ptr += PackRuns16s(lowhigh_row_ptr, output_width);
		QuantizeRow16sTo16s(highlow_buffer, highlow_row_ptr, output_width, highlow_quantization);
		highlow_row_ptr += PackRuns16s(highlow_row_ptr, output_width);
		QuantizeRow16sTo16s(highhigh_buffer, highhigh_row_ptr, output_width, highhigh_quantization);
		highhigh_row_ptr += PackRuns16s(highhigh_row_ptr, output_width);

		// Advance to the next output rows
		lowlow_row_ptr += lowlow_pitch;
    #else
	  // Quantize the first row of results for each 16-bit output band
	  #if _QUANTIZE_SPATIAL_LOWPASS
		QuantizeRow16sTo16s(lowlow_buffer, lowlow_row_ptr, output_width, lowlow_quantization);
	  #endif

		QuantizeRow16sTo16s(lowhigh_buffer, lowhigh_row_ptr, output_width, lowhigh_quantization);
		QuantizeRow16sTo16s(highlow_buffer, highlow_row_ptr, output_width, highlow_quantization);
		QuantizeRow16sTo16s(highhigh_buffer, highhigh_row_ptr, output_width, highhigh_quantization);

		// Advance to the next output rows
		lowlow_row_ptr += lowlow_pitch;
		highlow_row_ptr += highlow_pitch;
		lowhigh_row_ptr += lowhigh_pitch;
		highhigh_row_ptr += highhigh_pitch;
	#endif
#endif





#if 0
	// Advance to the next pair of input rows if not using the SIMD code since the
	// SIMD version uses the first two rows again to compute the second output row

	{
		// Rotate the horizontal filter results by two rows
		PIXEL *temp0 = lowpass[0];
		PIXEL *temp1 = lowpass[1];
		PIXEL *high0 = highpass[0];
		PIXEL *high1 = highpass[1];

		for (k = 0; k < buffer_row_count - 2; k++) {
			lowpass[k] = lowpass[k+2];
			highpass[k] = highpass[k+2];
		}

		lowpass[buffer_row_count - 2] = temp0;
		lowpass[buffer_row_count - 1] = temp1;
		highpass[buffer_row_count - 2] = high0;
		highpass[buffer_row_count - 1] = high1;

		// Compute the next two rows of horizontal filter results
		for (; k < buffer_row_count; k++) {
			//SplitRow16s(rowptr, roi.width, lowpass[k], highpass[k]);
			FilterHorizontalRowYUV16s(rowptr, lowpass[k], highpass[k], roi.width, channel,
									  unpacking_buffer, unpacking_buffer_size, frame, precision, limit_yuv);
			rowptr += input_pitch;
		}
	}
#endif


	row += 2;								// Advance the row being processed

	for (; row < last_row; row += 2)
	{
#if (1 && XMMOPT)
#if _QUANTIZE_SPATIAL_LOWPASS
		__m64 *lowlow_ptr = (__m64 *)lowlow_buffer;
#else
		__m64 *lowlow_ptr = (__m64 *)lowlow_row_ptr;
#endif
		__m64 *highlow_ptr = (__m64 *)highlow_buffer;
		__m64 *lowhigh_ptr = (__m64 *)lowhigh_buffer;
		__m64 *highhigh_ptr = (__m64 *)highhigh_buffer;

		int column_step = 4;
		int post_column = output_width - (output_width % column_step);
#endif
		// Start at the first column
		column = 0;

#if (1 && XMMOPT)

		// Process a group of four pixels at a time
		for (; column < post_column; column += column_step)
		{
			__m64 low_pi16;
			__m64 sum_pi16;
			__m64 quad_pi16;
			__m64 mask_pi16;
			__m64 half_pi16;


			// Apply the vertical filters to the horizontal lowpass results //

			// Load the first row of four pixels
			quad_pi16 = *((__m64 *)&lowpass[0][column]);
			// Initialize the highpass filter sum
			sum_pi16 = _mm_setzero_si64();
			// Multiply each pixel by the first filter coefficient and sum the result
			sum_pi16 = _mm_subs_pi16(sum_pi16, quad_pi16);

			// Load the second row of four pixels
			quad_pi16 = *((__m64 *)&lowpass[1][column]);
			// Multiply each pixel by the second filter coefficient and sum the result
			sum_pi16 = _mm_subs_pi16(sum_pi16, quad_pi16);

			// Load the fifth row of four pixels
			quad_pi16 = *((__m64 *)&lowpass[4][column]);
			// Multiply each pixel by the fifth filter coefficient and sum the result
			sum_pi16 = _mm_adds_pi16(sum_pi16, quad_pi16);

			// Load the sixth (last) row of four pixels
			quad_pi16 = *((__m64 *)&lowpass[5][column]);
			// Multiply each pixel by the sixth filter coefficient and sum the result
			sum_pi16 = _mm_adds_pi16(sum_pi16, quad_pi16);

			sum_pi16 = _mm_srai_pi16(sum_pi16, 3); // divided by 8 =   (-1a -1b +1e +1f) / 8



			// Load the third row of four pixels
			quad_pi16 = *((__m64 *)&lowpass[2][column]);
			// Initialize the lowpass sum
			low_pi16 = quad_pi16;

			// Multiply each pixel by the third filter coefficient and sum the result
			sum_pi16 = _mm_adds_pi16(sum_pi16, quad_pi16);

			// Load the fourth row of four pixels
			quad_pi16 = *((__m64 *)&lowpass[3][column]);
			// Compute the four lowpass results
			low_pi16 = _mm_adds_pi16(low_pi16, quad_pi16);

			// Store the lowpass results
			*(lowlow_ptr++) = low_pi16;
			// Multiply each pixel by the fourth filter coefficient and sum the result
			sum_pi16 = _mm_subs_pi16(sum_pi16, quad_pi16);


			// Store the four highpass results
			*(highlow_ptr++) = sum_pi16;


			// Apply the vertical filters to the horizontal highpass results //

			sum_pi16 = _mm_setzero_si64();

			// Load the first row of four pixels
			quad_pi16 = *((__m64 *)&highpass[0][column]);
			// Multiply each pixel by the first filter coefficient and sum the result
			sum_pi16 = _mm_subs_pi16(sum_pi16, quad_pi16);

			// Load the second row of four pixels
			quad_pi16 = *((__m64 *)&highpass[1][column]);
			// Multiply each pixel by the second filter coefficient and sum the result
			sum_pi16 = _mm_subs_pi16(sum_pi16, quad_pi16);

			// Load the fifth row of four pixels
			quad_pi16 = *((__m64 *)&highpass[4][column]);
			// Multiply each pixel by the fifth filter coefficient and sum the result
			sum_pi16 = _mm_adds_pi16(sum_pi16, quad_pi16);

			// Load the sixth (last) row of four pixels
			quad_pi16 = *((__m64 *)&highpass[5][column]);
			// Multiply each pixel by the sixth filter coefficient and sum the result
			sum_pi16 = _mm_adds_pi16(sum_pi16, quad_pi16);

			sum_pi16 = _mm_srai_pi16(sum_pi16, 3); // divided by 8 =   (-1a -1b +1e +1f) / 8


			// Load the third row of four pixels
			quad_pi16 = *((__m64 *)&highpass[2][column]);
			// Initialize the lowpass sum
			low_pi16 = quad_pi16;

			// Multiply each pixel by the third filter coefficient and sum the result
			sum_pi16 = _mm_adds_pi16(sum_pi16, quad_pi16);

			// Load the fourth row of four pixels
			quad_pi16 = *((__m64 *)&highpass[3][column]);
			// Compute and store the four lowpass results
			low_pi16 = _mm_adds_pi16(low_pi16, quad_pi16);
			*(lowhigh_ptr++) = low_pi16;

			// Multiply each pixel by the fourth filter coefficient and sum the result
			sum_pi16 = _mm_subs_pi16(sum_pi16, quad_pi16);


			// Store the four highpass results
			*(highhigh_ptr++) = sum_pi16;
		}

		// Should have terminated the fast loop at the post processing column
		assert(column == post_column);
#endif

		// Process the remaining pixels to the end of the row
		for (; column < output_width; column++)
		{
			int32_t sum;

			// Apply the lowpass vertical filter to the lowpass horizontal results
			sum  = lowpass[2][column];
			sum += lowpass[3][column];
#if _QUANTIZE_SPATIAL_LOWPASS
			lowlow_buffer[column] = SATURATE(sum);
#else
			lowlow_row_ptr[column] = SATURATE(sum);
#endif
			// Apply the highpass vertical filter to the lowpass horizontal results
			sum  = -1 * lowpass[0][column];
			sum += -1 * lowpass[1][column];
			sum +=  8 * lowpass[2][column];
			sum += -8 * lowpass[3][column];
			sum +=  1 * lowpass[4][column];
			sum +=  1 * lowpass[5][column];
			sum += ROUNDING(sum,8);
			sum = DivideByShift(sum, 3);
			highlow_buffer[column] = SATURATE(sum);

			// Apply the lowpass vertical filter to the highpass horizontal results
			sum  = highpass[2][column];
			sum += highpass[3][column];
			lowhigh_buffer[column] = SATURATE(sum);

			// Apply the highpass vertical filter to the highpass horizontal results
			sum  = -1 * highpass[0][column];
			sum += -1 * highpass[1][column];
			sum +=  8 * highpass[2][column];
			sum += -8 * highpass[3][column];
			sum +=  1 * highpass[4][column];
			sum +=  1 * highpass[5][column];
			sum += ROUNDING(sum,8);
			sum = DivideByShift(sum, 3);
			highhigh_buffer[column] = SATURATE(sum);
		}

		if (row < (last_row - 2))
		{
			// Rotate the horizontal filter results by two rows
			PIXEL *temp0 = lowpass[0];
			PIXEL *temp1 = lowpass[1];
			PIXEL *high0 = highpass[0];
			PIXEL *high1 = highpass[1];

			for (k = 0; k < buffer_row_count - 2; k++) {
				lowpass[k] = lowpass[k+2];
				highpass[k] = highpass[k+2];
			}

			lowpass[buffer_row_count - 2] = temp0;
			lowpass[buffer_row_count - 1] = temp1;
			highpass[buffer_row_count - 2] = high0;
			highpass[buffer_row_count - 1] = high1;

			// Compute the next two rows of horizontal filter results
			for (; k < buffer_row_count; k++) {
				//SplitRow16s(rowptr, roi.width, lowpass[k], highpass[k]);
				FilterHorizontalRowYUV16s(rowptr, lowpass[k], highpass[k], roi.width, channel,
										  unpacking_buffer, unpacking_buffer_size, frame, precision, limit_yuv);
				rowptr += input_pitch;
			}
		}

#if _HIGHPASS_8S
#if _QUANTIZE_SPATIAL_LOWPASS
		// Quantize the current row 16-bit lowpass coefficients
		QuantizeRow16sTo16s(lowlow_buffer, lowlow_row_ptr, output_width, lowlow_quantization);
#endif
		// Quantize the current row of results for each 8-bit highpass band
		QuantizeRow16sTo8s(lowhigh_buffer, lowhigh_row_ptr, output_width, lowhigh_quantization);
		QuantizeRow16sTo8s(highlow_buffer, highlow_row_ptr, output_width, highlow_quantization);
		QuantizeRow16sTo8s(highhigh_buffer, highhigh_row_ptr, output_width, highhigh_quantization);
#else
	#if _PACK_RUNS_IN_BAND_16S
		// Quantize the current row of results for each 16-bit output band
	    #if _QUANTIZE_SPATIAL_LOWPASS
		QuantizeRow16sTo16s(lowlow_buffer, lowlow_row_ptr, output_width, lowlow_quantization);
	    #endif

		QuantizeRow16sTo16s(lowhigh_buffer, lowhigh_row_ptr, output_width, lowhigh_quantization);
		lowhigh_row_ptr += PackRuns16s(lowhigh_row_ptr, output_width);
		QuantizeRow16sTo16s(highlow_buffer, highlow_row_ptr, output_width, highlow_quantization);
		highlow_row_ptr += PackRuns16s(highlow_row_ptr, output_width);
		QuantizeRow16sTo16s(highhigh_buffer, highhigh_row_ptr, output_width, highhigh_quantization);
		highhigh_row_ptr += PackRuns16s(highhigh_row_ptr, output_width);

		// Advance to the next output rows
		lowlow_row_ptr += lowlow_pitch;
    #else
		// Quantize the current row of results for each 16-bit output band
		#if _QUANTIZE_SPATIAL_LOWPASS
		QuantizeRow16sTo16s(lowlow_buffer, lowlow_row_ptr, output_width, lowlow_quantization);
		#endif
		QuantizeRow16sTo16s(lowhigh_buffer, lowhigh_row_ptr, output_width, lowhigh_quantization);
		QuantizeRow16sTo16s(highlow_buffer, highlow_row_ptr, output_width, highlow_quantization);
		QuantizeRow16sTo16s(highhigh_buffer, highhigh_row_ptr, output_width, highhigh_quantization);

		// Advance to the next output rows
		lowlow_row_ptr += lowlow_pitch;
		highlow_row_ptr += highlow_pitch;
		lowhigh_row_ptr += lowhigh_pitch;
		highhigh_row_ptr += highhigh_pitch;
	#endif
#endif

	}

	// Should have left the loop at the last row
	assert(row == last_row);

	// Use the border filters for the last row
	for (column = 0; column < output_width; column++)
	{
		int32_t sum;

		// Apply the lowpass vertical filter to the lowpass horizontal results
		sum  = lowpass[4][column];
		sum += lowpass[5][column];
#if _QUANTIZE_SPATIAL_LOWPASS
		lowlow_buffer[column] = SATURATE(sum);
#else
		lowlow_row_ptr[column] = SATURATE(sum);
#endif
		// Apply the highpass vertical filter to the lowpass horizontal results
		sum  = 11 * lowpass[4][column];
		sum -=  5 * lowpass[5][column];
		sum -=  4 * lowpass[3][column];
		sum -=  4 * lowpass[2][column];
		sum +=  1 * lowpass[1][column];
		sum +=  1 * lowpass[0][column];
		sum +=  ROUNDING(sum,8);
		sum = DivideByShift(sum, 3);
		highlow_buffer[column] = SATURATE(sum);

		// Apply the lowpass vertical filter to the highpass horizontal results
		sum  = highpass[4][column];
		sum += highpass[5][column];
		lowhigh_buffer[column] = SATURATE(sum);

		// Apply the highpass vertical filter to the highpass horizontal results
		sum  = 11 * highpass[4][column];
		sum -=  5 * highpass[5][column];
		sum -=  4 * highpass[3][column];
		sum -=  4 * highpass[2][column];
		sum +=  1 * highpass[1][column];
		sum +=  1 * highpass[0][column];
		sum +=  ROUNDING(sum,8);
		sum = DivideByShift(sum, 3);
		highhigh_buffer[column] = SATURATE(sum);
	}

#if _HIGHPASS_8S
#if _QUANTIZE_SPATIAL_LOWPASS
		// Quantize the last row of 16-bit lowpass coefficients
		QuantizeRow16sTo16s(lowlow_buffer, lowlow_row_ptr, output_width, lowlow_quantization);
#endif
		// Quantize the last row of results for each 8-bit highpass band
		QuantizeRow16sTo8s(lowhigh_buffer, lowhigh_row_ptr, output_width, lowhigh_quantization);
		QuantizeRow16sTo8s(highlow_buffer, highlow_row_ptr, output_width, highlow_quantization);
		QuantizeRow16sTo8s(highhigh_buffer, highhigh_row_ptr, output_width, highhigh_quantization);
#else
	#if _PACK_RUNS_IN_BAND_16S
		// Quantize the current row of results for each 16-bit output band
		#if _QUANTIZE_SPATIAL_LOWPASS
		QuantizeRow16sTo16s(lowlow_buffer, lowlow_row_ptr, output_width, lowlow_quantization);
		#endif

		QuantizeRow16sTo16s(lowhigh_buffer, lowhigh_row_ptr, output_width, lowhigh_quantization);
		lowhigh_row_ptr += PackRuns16s(lowhigh_row_ptr, output_width);
		QuantizeRow16sTo16s(highlow_buffer, highlow_row_ptr, output_width, highlow_quantization);
		highlow_row_ptr += PackRuns16s(highlow_row_ptr, output_width);
		QuantizeRow16sTo16s(highhigh_buffer, highhigh_row_ptr, output_width, highhigh_quantization);
		highhigh_row_ptr += PackRuns16s(highhigh_row_ptr, output_width);
	#else
		// Quantize the last row of results for each 16-bit output band
		#if _QUANTIZE_SPATIAL_LOWPASS
		QuantizeRow16sTo16s(lowlow_buffer, lowlow_row_ptr, output_width, lowlow_quantization);
		#endif

		QuantizeRow16sTo16s(lowhigh_buffer, lowhigh_row_ptr, output_width, lowhigh_quantization);
		QuantizeRow16sTo16s(highlow_buffer, highlow_row_ptr, output_width, highlow_quantization);
		QuantizeRow16sTo16s(highhigh_buffer, highhigh_row_ptr, output_width, highhigh_quantization);
	#endif
#endif

	//_mm_empty();	// Clear the mmx register state
}

#endif


#if _PROCESSOR_PENTIUM_4

#if _PROCESSOR_DISPATCH
__declspec(cpu_specific(Pentium_4))
#endif

void FilterSpatialYUVQuant16s(uint8_t *input_data, int input_pitch,
							  PIXEL *lowlow_band, int lowlow_pitch,
							  PIXEL *lowhigh_band, int lowhigh_pitch,
							  PIXEL *highlow_band, int highlow_pitch,
							  PIXEL *highhigh_band, int highhigh_pitch,
							  PIXEL *buffer, size_t buffer_size, ROI roi,
							  int channel, int quantization[4], FRAME_INFO *frame, 
							  int precision, int limit_yuv, int conv_601_709)
{
	uint8_t *rowptr = input_data;

	// Six rows of lowpass and highpass horizontal results
	PIXEL *lowpass[6];
	PIXEL *highpass[6];

	//PIXEL *lowlow_buffer;
	PIXEL *lowhigh_buffer;
	PIXEL *highlow_buffer;
	PIXEL *highhigh_buffer;

	int lowlow_quantization;
	int lowhigh_quantization;
	int highlow_quantization;
	int highhigh_quantization;

	// Pointers to the rows of coefficients in the wavelet bands
	PIXEL *lowlow_row_ptr = lowlow_band;
	PIXEL *lowhigh_row_ptr = lowhigh_band;
	PIXEL *highlow_row_ptr = highlow_band;
	PIXEL *highhigh_row_ptr = highhigh_band;

	int last_row = roi.height - 2;
	int output_width;
	size_t output_buffer_size;
	int output_buffer_width;
	PIXEL *bufptr;
	const int buffer_row_count = sizeof(lowpass)/sizeof(lowpass[0]);
	PIXEL *unpacking_buffer;
	size_t unpacking_buffer_size;
	int unpacking_buffer_width;
	int row, column;
	int k;

	// Convert pitch from bytes to pixels
	lowlow_pitch /= sizeof(PIXEL);
	lowhigh_pitch /= sizeof(PIXEL);
	highlow_pitch /= sizeof(PIXEL);
	highhigh_pitch /= sizeof(PIXEL);

	if (quantization != NULL)
	{
		lowlow_quantization = quantization[0];
		lowhigh_quantization = quantization[1];
		highlow_quantization = quantization[2];
		highhigh_quantization = quantization[3];
	}
	else
	{
		lowlow_quantization = 1;
		lowhigh_quantization = 1;
		highlow_quantization = 1;
		highhigh_quantization = 1;
	}

	// Must have an even number of rows
	assert((roi.height % 2) == 0);

	// Must have an even number of columns
	assert((roi.width % 2) == 0);

	// Compute the width of each row of horizontal filter output
	output_width = roi.width/2;

	// Compute the size of each row of horizontal filter output in bytes
	output_buffer_size = output_width * sizeof(PIXEL);

	// Round up the buffer size to an integer number of cache lines
	output_buffer_size = ALIGN(output_buffer_size, _CACHE_LINE_SIZE);

	// Compute the size of the buffer for unpacking the input rows
	unpacking_buffer_size = roi.width * sizeof(PIXEL);

	// Round up the buffer size to an integer number of cache lines
	unpacking_buffer_size = ALIGN(unpacking_buffer_size, _CACHE_LINE_SIZE);

	// The buffer must be large enough for fifteen rows plus the unpacking buffer
	assert(buffer_size >= ((15 * output_buffer_size) + unpacking_buffer_size));

	// Compute the allocated width of each wavelet band buffer
	output_buffer_width = (int)output_buffer_size / sizeof(PIXEL);

	// Compute the allocated width of the unpacking buffer
	unpacking_buffer_width = (int)unpacking_buffer_size / sizeof(PIXEL);

	// Start allocating intermediate buffers at the beginning of the supplied buffer
	bufptr = buffer;

	// Allocate space in the buffer for the horizontal filter results
	for (k = 0; k < buffer_row_count; k++) {
		lowpass[k] = bufptr;		bufptr += output_buffer_width;
		highpass[k] = bufptr;		bufptr += output_buffer_width;
	}

	// Allocate space in the buffer for the pre-quantized coefficients
	lowhigh_buffer = bufptr;		bufptr += output_buffer_width;
	highlow_buffer = bufptr;		bufptr += output_buffer_width;
	highhigh_buffer = bufptr;		bufptr += output_buffer_width;

	// Allocate space in the buffer for unpacking the input coefficients
	unpacking_buffer = bufptr;		bufptr += unpacking_buffer_width;

	// Compute the first six rows of horizontal filter output
	for (k = 0; k < buffer_row_count; k++) {
		FilterHorizontalRowYUV16s(rowptr, lowpass[k], highpass[k], roi.width, channel,
								  unpacking_buffer, unpacking_buffer_size, frame, 
								  precision, limit_yuv, conv_601_709);
		rowptr += input_pitch;
	}

#if (0 && PREFETCH)
	// Prefetch the next two rows from the input image
	{
		const int cache_line_size = 64;
		size_t input_row_size = ALIGN(input_pitch, _CACHE_LINE_SIZE);
		int num_cache_lines = 2 * input_row_size / cache_line_size;
		uint8_t *prefetch = rowptr;
		DWORD dummy2 = 0;
		num_cache_lines--;
		for (; num_cache_lines > 0; --num_cache_lines)
		{
			dummy2 += prefetch[num_cache_lines * cache_line_size];
		}
		dummy1 += dummy2;
	}
#endif

	/***** Need to optimize the first and last row calculations *****/

	// Use border filters for the first row
	row = 0;

	for (column = 0; column < output_width; column++)
	{
		int32_t sum;

		// Apply the lowpass vertical filter to the lowpass horizontal results
		sum  = lowpass[0][column];
		sum += lowpass[1][column];
		lowlow_row_ptr[column] = SATURATE(sum);

		// Apply the highpass vertical filter to the lowpass horizontal results
		sum  =  5 * lowpass[0][column];
		sum -= 11 * lowpass[1][column];
		sum +=  4 * lowpass[2][column];
		sum +=  4 * lowpass[3][column];
		sum -=  1 * lowpass[4][column];
		sum -=  1 * lowpass[5][column];
		sum += ROUNDING(sum,8);
		sum = DivideByShift(sum, 3);
		highlow_buffer[column] = SATURATE(sum);

		// Apply the lowpass vertical filter to the highpass horizontal results
		sum  = highpass[0][column];
		sum += highpass[1][column];
		lowhigh_buffer[column] = SATURATE(sum);

		// Apply the highpass vertical filter to the highpass horizontal results
		sum  =  5 * highpass[0][column];
		sum -= 11 * highpass[1][column];
		sum +=  4 * highpass[2][column];
		sum +=  4 * highpass[3][column];
		sum -=  1 * highpass[4][column];
		sum -=  1 * highpass[5][column];
		sum += ROUNDING(sum,8);
		sum = DivideByShift(sum, 3);
		highhigh_buffer[column] = SATURATE(sum);
	}

#if _PACK_RUNS_IN_BAND_16S
	// Quantize the current row of results for each 16-bit output band
	QuantizeRow16sTo16s(lowhigh_buffer, lowhigh_row_ptr, output_width, lowhigh_quantization);
	lowhigh_row_ptr += PackRuns16s(lowhigh_row_ptr, output_width);
	QuantizeRow16sTo16s(highlow_buffer, highlow_row_ptr, output_width, highlow_quantization);
	highlow_row_ptr += PackRuns16s(highlow_row_ptr, output_width);
	QuantizeRow16sTo16s(highhigh_buffer, highhigh_row_ptr, output_width, highhigh_quantization);
	highhigh_row_ptr += PackRuns16s(highhigh_row_ptr, output_width);

	lowlow_row_ptr += lowlow_pitch;
#else
	// Quantize the first row of results for each 16-bit highpass band
	QuantizeRow16sTo16s(lowhigh_buffer, lowhigh_row_ptr, output_width, lowhigh_quantization);
	QuantizeRow16sTo16s(highlow_buffer, highlow_row_ptr, output_width, highlow_quantization);
	QuantizeRow16sTo16s(highhigh_buffer, highhigh_row_ptr, output_width, highhigh_quantization);

	// Advance to the next output rows
	lowlow_row_ptr += lowlow_pitch;
	highlow_row_ptr += highlow_pitch;
	lowhigh_row_ptr += lowhigh_pitch;
	highhigh_row_ptr += highhigh_pitch;
#endif

#if 0
	// Advance to the next pair of input rows if not using the SIMD code since the
	// SIMD version uses the first two rows again to compute the second output row

	{
		// Rotate the horizontal filter results by two rows
		PIXEL *temp0 = lowpass[0];
		PIXEL *temp1 = lowpass[1];
		PIXEL *high0 = highpass[0];
		PIXEL *high1 = highpass[1];

		for (k = 0; k < buffer_row_count - 2; k++) {
			lowpass[k] = lowpass[k+2];
			highpass[k] = highpass[k+2];
		}

		lowpass[buffer_row_count - 2] = temp0;
		lowpass[buffer_row_count - 1] = temp1;
		highpass[buffer_row_count - 2] = high0;
		highpass[buffer_row_count - 1] = high1;

		// Compute the next two rows of horizontal filter results
		for (; k < buffer_row_count; k++) {
			FilterHorizontalRowYUV16s(rowptr, lowpass[k], highpass[k], roi.width, channel,
									  unpacking_buffer, unpacking_buffer_size, frame, precision, limit_yuv);
			rowptr += input_pitch;
		}
	}
#endif

	row += 2;								// Advance the row being processed

	for (; row < last_row; row += 2)
	{
#if (1 && XMMOPT)
		__m128i *lowlow_ptr = (__m128i *)lowlow_row_ptr;
		__m128i *highlow_ptr = (__m128i *)highlow_buffer;
		__m128i *lowhigh_ptr = (__m128i *)lowhigh_buffer;
		__m128i *highhigh_ptr = (__m128i *)highhigh_buffer;

		int column_step = 8;
		int post_column = output_width - (output_width % column_step);
#endif

#if (0 && PREFETCH)
		size_t output_size = output_width * sizeof(PIXEL);
		const int cache_line_size = 64;
		int num_cache_lines = output_size / cache_line_size;
		uint8_t *prefetch;
		DWORD dummy2;
#endif

#if (0 && PREFETCH)
	// Prefetch the next two rows from the input image
	{
		const int cache_line_size = 64;
		size_t input_row_size = ALIGN(input_pitch, _CACHE_LINE_SIZE);
		int num_cache_lines = 2 * input_row_size / cache_line_size;
		uint8_t *prefetch = rowptr;
		DWORD dummy2 = 0;
		num_cache_lines--;
		for (; num_cache_lines > 0; --num_cache_lines)
		{
			dummy2 += prefetch[num_cache_lines * cache_line_size];
		}
		dummy1 += dummy2;
	}
#endif
		// Start at the first column
		column = 0;

		// Check that the input and output addresses are properly aligned
		for (k = 0; k < buffer_row_count; k++) {
			assert(ISALIGNED16(lowpass[k]));
			assert(ISALIGNED16(highpass[k]));
		}
		assert(ISALIGNED16(lowlow_ptr));
		assert(ISALIGNED16(lowhigh_ptr));
		assert(ISALIGNED16(highlow_ptr));
		assert(ISALIGNED16(highhigh_ptr));

#if (0 && PREFETCH)
		// Prefetch the row for the lowlow coefficients
		prefetch = (uint8_t *)lowlow_row_ptr;
		dummy2 = 0;
		num_cache_lines = output_size / cache_line_size;
		for (; num_cache_lines > 0; num_cache_lines -= 4)
		{
			dummy2 += prefetch[(num_cache_lines - 0) * cache_line_size];
			dummy2 += prefetch[(num_cache_lines - 1) * cache_line_size];
			dummy2 += prefetch[(num_cache_lines - 2) * cache_line_size];
			dummy2 += prefetch[(num_cache_lines - 3) * cache_line_size];
		}
		dummy1 += dummy2;

		// Prefetch the row for the lowhigh coefficients
		prefetch = (uint8_t *)lowhigh_row_ptr;
		dummy2 = 0;
		num_cache_lines = output_size / cache_line_size;
		for (; num_cache_lines > 0; num_cache_lines -= 4)
		{
			dummy2 += prefetch[(num_cache_lines - 0) * cache_line_size];
			dummy2 += prefetch[(num_cache_lines - 1) * cache_line_size];
			dummy2 += prefetch[(num_cache_lines - 2) * cache_line_size];
			dummy2 += prefetch[(num_cache_lines - 3) * cache_line_size];
		}
		dummy1 += dummy2;

		// Prefetch the row for the highlow coefficients
		prefetch = (uint8_t *)highlow_row_ptr;
		dummy2 = 0;
		num_cache_lines = output_size / cache_line_size;
		for (; num_cache_lines > 0; num_cache_lines -= 4)
		{
			dummy2 += prefetch[(num_cache_lines - 0) * cache_line_size];
			dummy2 += prefetch[(num_cache_lines - 1) * cache_line_size];
			dummy2 += prefetch[(num_cache_lines - 2) * cache_line_size];
			dummy2 += prefetch[(num_cache_lines - 3) * cache_line_size];
		}
		dummy1 += dummy2;

		// Prefetch the row for the highhigh coefficients
		prefetch = (uint8_t *)highhigh_row_ptr;
		dummy2 = 0;
		num_cache_lines = output_size / cache_line_size;
		for (; num_cache_lines > 0; num_cache_lines -= 4)
		{
			dummy2 += prefetch[(num_cache_lines - 0) * cache_line_size];
			dummy2 += prefetch[(num_cache_lines - 1) * cache_line_size];
			dummy2 += prefetch[(num_cache_lines - 2) * cache_line_size];
			dummy2 += prefetch[(num_cache_lines - 3) * cache_line_size];
		}
		dummy1 += dummy2;
#endif

#if (1 && XMMOPT)

		// Process a group of eight pixels at a time
		for (; column < post_column; column += column_step)
		{
			__m128i low_epi16;
			__m128i sum_epi16;
			__m128i sum8_epi16;
			__m128i quad_epi16;
			__m128i half_epi16;


			/***** Apply the vertical filters to the horizontal lowpass results *****/

			// Load the first row of four pixels
			quad_epi16 = _mm_load_si128((__m128i *)&lowpass[0][column]);

			// Initialize the highpass filter sum
			sum_epi16 = _mm_setzero_si128();

			// Multiply each pixel by the first filter coefficient and sum the result
			sum_epi16 = _mm_subs_epi16(sum_epi16, quad_epi16);

			// Load the second row of four pixels
			quad_epi16 = _mm_load_si128((__m128i *)&lowpass[1][column]);

			// Multiply each pixel by the second filter coefficient and sum the result
			sum_epi16 = _mm_subs_epi16(sum_epi16, quad_epi16);

			// Load the third row of four pixels
			quad_epi16 = _mm_load_si128((__m128i *)&lowpass[2][column]);

			// Initialize the lowpass sum
			low_epi16 = quad_epi16;

			// Multiply each pixel by the third filter coefficient and sum the result
			sum8_epi16 = _mm_setzero_si128();
			sum8_epi16 = _mm_adds_epi16(sum8_epi16, quad_epi16);

			// Load the fourth row of four pixels
			quad_epi16 = _mm_load_si128((__m128i *)&lowpass[3][column]);

			// Compute the four lowpass results
			low_epi16 = _mm_adds_epi16(low_epi16, quad_epi16);

			// Store the lowpass results
			_mm_store_si128(lowlow_ptr++, low_epi16);

			// Multiply each pixel by the fourth filter coefficient and sum the result
			sum8_epi16 = _mm_subs_epi16(sum8_epi16, quad_epi16);

			// Load the fifth row of four pixels
			quad_epi16 = _mm_load_si128((__m128i *)&lowpass[4][column]);

			// Multiply each pixel by the fifth filter coefficient and sum the result
			sum_epi16 = _mm_adds_epi16(sum_epi16, quad_epi16);

			// Load the sixth (last) row of four pixels
			quad_epi16 = _mm_load_si128((__m128i *)&lowpass[5][column]);

			// Multiply each pixel by the sixth filter coefficient and sum the result
			sum_epi16 = _mm_adds_epi16(sum_epi16, quad_epi16);

			half_epi16 = _mm_set1_epi16(4); //was 4
			sum_epi16 = _mm_adds_epi16(sum_epi16, half_epi16); // +7 rounding
			sum_epi16 = _mm_srai_epi16(sum_epi16, 3); // divide 8

			sum_epi16 = _mm_adds_epi16(sum_epi16, sum8_epi16);

			// Store the four highpass results
			_mm_store_si128(highlow_ptr++, sum_epi16);


			/***** Apply the vertical filters to the horizontal highpass results *****/

			sum_epi16 = _mm_setzero_si128();

			// Load the first row of four pixels
			quad_epi16 = _mm_load_si128((__m128i *)&highpass[0][column]);

			// Multiply each pixel by the first filter coefficient and sum the result
			sum_epi16 = _mm_subs_epi16(sum_epi16, quad_epi16);

			// Load the second row of four pixels
			quad_epi16 = _mm_load_si128((__m128i *)&highpass[1][column]);

			// Multiply each pixel by the second filter coefficient and sum the result
			sum_epi16 = _mm_subs_epi16(sum_epi16, quad_epi16);

			// Load the third row of four pixels
			quad_epi16 = _mm_load_si128((__m128i *)&highpass[2][column]);

			// Initialize the lowpass sum
			low_epi16 = quad_epi16;

			// Multiply each pixel by the third filter coefficient and sum the result
			sum8_epi16 = _mm_setzero_si128();
			sum8_epi16 = _mm_adds_epi16(sum8_epi16, quad_epi16);

			// Load the fourth row of four pixels
			quad_epi16 = _mm_load_si128((__m128i *)&highpass[3][column]);

			// Compute and store the four lowpass results
			low_epi16 = _mm_adds_epi16(low_epi16, quad_epi16);
			_mm_store_si128(lowhigh_ptr++, low_epi16);

			// Multiply each pixel by the fourth filter coefficient and sum the result
			sum8_epi16 = _mm_subs_epi16(sum8_epi16, quad_epi16);

			// Load the fifth row of four pixels
			quad_epi16 = _mm_load_si128((__m128i *)&highpass[4][column]);

			// Multiply each pixel by the fifth filter coefficient and sum the result
			sum_epi16 = _mm_adds_epi16(sum_epi16, quad_epi16);

			// Load the sixth (last) row of four pixels
			quad_epi16 = _mm_load_si128((__m128i *)&highpass[5][column]);

			// Multiply each pixel by the sixth filter coefficient and sum the result
			sum_epi16 = _mm_adds_epi16(sum_epi16, quad_epi16);

			sum_epi16 = _mm_adds_epi16(sum_epi16, half_epi16); // +7 rounding
			sum_epi16 = _mm_srai_epi16(sum_epi16, 3); // divide 8

			sum_epi16 = _mm_adds_epi16(sum_epi16, sum8_epi16);

			// Store the four highpass results
			_mm_store_si128(highhigh_ptr++, sum_epi16);
		}

		// Should have terminated the fast loop at the post processing column
		assert(column == post_column);
#endif

		// Process the remaining pixels to the end of the row
		for (; column < output_width; column++)
		{
			int32_t sum;

			// Apply the lowpass vertical filter to the lowpass horizontal results
			sum  = lowpass[2][column];
			sum += lowpass[3][column];
			lowlow_row_ptr[column] = SATURATE(sum);

			// Apply the highpass vertical filter to the lowpass horizontal results
			sum  = -1 * lowpass[0][column];
			sum += -1 * lowpass[1][column];
			sum +=  1 * lowpass[4][column];
			sum +=  1 * lowpass[5][column];
			sum +=	4;
			sum >>= 3;
			sum +=  1 * lowpass[2][column];
			sum += -1 * lowpass[3][column];
			highlow_buffer[column] = SATURATE(sum);

			// Apply the lowpass vertical filter to the highpass horizontal results
			sum  = highpass[2][column];
			sum += highpass[3][column];
			lowhigh_buffer[column] = SATURATE(sum);

			// Apply the highpass vertical filter to the highpass horizontal results
			sum  = -1 * highpass[0][column];
			sum += -1 * highpass[1][column];
			sum +=  1 * highpass[4][column];
			sum +=  1 * highpass[5][column];
			sum +=	4;
			sum >>= 3;
			sum +=  1 * highpass[2][column];
			sum += -1 * highpass[3][column];
			highhigh_buffer[column] = SATURATE(sum);
		}

		if (row < (last_row - 2))
		{
			// Rotate the horizontal filter results by two rows
			PIXEL *temp0 = lowpass[0];
			PIXEL *temp1 = lowpass[1];
			PIXEL *high0 = highpass[0];
			PIXEL *high1 = highpass[1];

			for (k = 0; k < buffer_row_count - 2; k++) {
				lowpass[k] = lowpass[k+2];
				highpass[k] = highpass[k+2];
			}

			lowpass[buffer_row_count - 2] = temp0;
			lowpass[buffer_row_count - 1] = temp1;
			highpass[buffer_row_count - 2] = high0;
			highpass[buffer_row_count - 1] = high1;

			// Compute the next two rows of horizontal filter results
			for (; k < buffer_row_count; k++) {
				FilterHorizontalRowYUV16s(rowptr, lowpass[k], highpass[k], roi.width, channel,
										  unpacking_buffer, unpacking_buffer_size, frame, 
										  precision, limit_yuv, conv_601_709);
				rowptr += input_pitch;
			}
		}

#if _PACK_RUNS_IN_BAND_16S
		// Quantize the current row of results for each 16-bit output band
		QuantizeRow16sTo16s(lowhigh_buffer, lowhigh_row_ptr, output_width, lowhigh_quantization);
		lowhigh_row_ptr += PackRuns16s(lowhigh_row_ptr, output_width);
		QuantizeRow16sTo16s(highlow_buffer, highlow_row_ptr, output_width, highlow_quantization);
		highlow_row_ptr += PackRuns16s(highlow_row_ptr, output_width);
		QuantizeRow16sTo16s(highhigh_buffer, highhigh_row_ptr, output_width, highhigh_quantization);
		highhigh_row_ptr += PackRuns16s(highhigh_row_ptr, output_width);

		// Advance to the next output rows
		lowlow_row_ptr += lowlow_pitch;
#else
		// Quantize the current row of results for each 16-bit output band
		QuantizeRow16sTo16s(lowhigh_buffer, lowhigh_row_ptr, output_width, lowhigh_quantization);
		QuantizeRow16sTo16s(highlow_buffer, highlow_row_ptr, output_width, highlow_quantization);
		QuantizeRow16sTo16s(highhigh_buffer, highhigh_row_ptr, output_width, highhigh_quantization);

		// Advance to the next output rows
		lowlow_row_ptr += lowlow_pitch;
		highlow_row_ptr += highlow_pitch;
		lowhigh_row_ptr += lowhigh_pitch;
		highhigh_row_ptr += highhigh_pitch;
#endif
	}

	// Should have left the loop at the last row
	assert(row == last_row);

	// Use the border filters for the last row
	for (column = 0; column < output_width; column++)
	{
		int32_t sum;

		// Apply the lowpass vertical filter to the lowpass horizontal results
		sum  = lowpass[4][column];
		sum += lowpass[5][column];
		lowlow_row_ptr[column] = SATURATE(sum);

		// Apply the highpass vertical filter to the lowpass horizontal results
		sum  = 11 * lowpass[4][column];
		sum -=  5 * lowpass[5][column];
		sum -=  4 * lowpass[3][column];
		sum -=  4 * lowpass[2][column];
		sum +=  1 * lowpass[1][column];
		sum +=  1 * lowpass[0][column];
		sum +=  ROUNDING(sum,8);
		sum = DivideByShift(sum, 3);
		highlow_buffer[column] = SATURATE(sum);

		// Apply the lowpass vertical filter to the highpass horizontal results
		sum  = highpass[4][column];
		sum += highpass[5][column];
		lowhigh_buffer[column] = SATURATE(sum);

		// Apply the highpass vertical filter to the highpass horizontal results
		sum  = 11 * highpass[4][column];
		sum -=  5 * highpass[5][column];
		sum -=  4 * highpass[3][column];
		sum -=  4 * highpass[2][column];
		sum +=  1 * highpass[1][column];
		sum +=  1 * highpass[0][column];
		sum +=  ROUNDING(sum,8);
		sum = DivideByShift(sum, 3);
		highhigh_buffer[column] = SATURATE(sum);
	}

#if _PACK_RUNS_IN_BAND_16S
	// Quantize the current row of results for each 16-bit output band
	QuantizeRow16sTo16s(lowhigh_buffer, lowhigh_row_ptr, output_width, lowhigh_quantization);
	lowhigh_row_ptr += PackRuns16s(lowhigh_row_ptr, output_width);
	QuantizeRow16sTo16s(highlow_buffer, highlow_row_ptr, output_width, highlow_quantization);
	highlow_row_ptr += PackRuns16s(highlow_row_ptr, output_width);
	QuantizeRow16sTo16s(highhigh_buffer, highhigh_row_ptr, output_width, highhigh_quantization);
	highhigh_row_ptr += PackRuns16s(highhigh_row_ptr, output_width);
#else
	// Quantize the last row of results for each 16-bit output band
	QuantizeRow16sTo16s(lowhigh_buffer, lowhigh_row_ptr, output_width, lowhigh_quantization);
	QuantizeRow16sTo16s(highlow_buffer, highlow_row_ptr, output_width, highlow_quantization);
	QuantizeRow16sTo16s(highhigh_buffer, highhigh_row_ptr, output_width, highhigh_quantization);
#endif
}

#endif


// Apply the forward spatial (horizontal and vertical) transform
void FilterSpatial8s(PIXEL *input_image, int input_pitch,
					 PIXEL *lowlow_band, int lowlow_pitch,
					 PIXEL *lowhigh_band, int lowhigh_pitch,
					 PIXEL *highlow_band, int highlow_pitch,
					 PIXEL *highhigh_band, int highhigh_pitch,
					 ROI roi, int input_scale)
{
	// Need to finish
	assert(0);
}


void InvertSpatialTopRow16s(PIXEL *lowlow_band, int lowlow_pitch,
							PIXEL *lowhigh_band, int lowhigh_pitch,
							PIXEL *highlow_band, int highlow_pitch,
							PIXEL *highhigh_band, int highhigh_pitch,
							uint8_t *output, int output_pitch,
							int row, int width,
							PIXEL *buffer, size_t buffer_size,
							int precision, FRAME_INFO *info)
{
	PIXEL *lowlow = lowlow_band;
	PIXEL *lowhigh = lowhigh_band;
	PIXEL *highlow = highlow_band;
	PIXEL *highhigh = highhigh_band;
	PIXEL *even_lowpass;
	PIXEL *even_highpass;
	PIXEL *odd_lowpass;
	PIXEL *odd_highpass;
	PIXEL *lowpass;					// Strip of horizontal coefficients
	PIXEL *highpass;
	int lowpass_pitch;				// Distance between strip rows in bytes
	int highpass_pitch;
	ROI strip;						// Dimensions of the processing strip
	size_t buffer_row_size;
	size_t output_row_size = output_pitch;
	int buffer_half_pitch;
	int buffer_width;
	int buffer_pitch;
	int column;

	// Convert pitch from bytes to pixels
	lowlow_pitch /= sizeof(PIXEL);
	lowhigh_pitch /= sizeof(PIXEL);
	highlow_pitch /= sizeof(PIXEL);
	highhigh_pitch /= sizeof(PIXEL);

	// Compute positions within the temporary buffer for each row of horizontal lowpass
	// and highpass intermediate coefficients computed by the vertical inverse transform
	buffer_row_size = width * sizeof(PIXEL);
	buffer_row_size = ALIGN16(buffer_row_size);
	buffer_half_pitch = (int)buffer_row_size/sizeof(PIXEL);
	buffer_pitch = 2 * buffer_half_pitch;
	buffer_width = width;

	// Check that the buffer is large enough to hold four rows of coefficients
	assert(buffer_size >= (4 * buffer_row_size));

	// Set the dimensions of the processing strip
	strip.width = buffer_width;
	strip.height = 2;

	// Compute the positions of the even and odd rows of coefficients
	even_lowpass = &buffer[0];
	even_highpass = &buffer[buffer_half_pitch];
	odd_lowpass = &buffer[2 * buffer_half_pitch];
	odd_highpass = &buffer[3 * buffer_half_pitch];

	// Pointers into the strip of horizontal coefficients
	lowpass = even_lowpass;
	highpass = even_highpass;
	lowpass_pitch = (int)(2 * buffer_row_size);
	highpass_pitch = (int)(2 * buffer_row_size);

	// This routine should be called for the first row
	assert(row == 0);

	// Apply the vertical border filter to the first row
	for (column = 0; column < width; column++)
	{
		int32_t even = 0;		// Result of convolution with even filter
		int32_t odd = 0;		// Result of convolution with odd filter


		/***** Compute the vertical inverse for the left two bands *****/

		// Apply the even reconstruction filter to the lowpass band
		even += 11 * lowlow[column + 0 * lowlow_pitch];
		even -=  4 * lowlow[column + 1 * lowlow_pitch];
		even +=  1 * lowlow[column + 2 * lowlow_pitch];
		even += ROUNDING(even,8);
		even = DivideByShift(even, 3);

		// Add the highpass correction
		even += highlow[column];
		even = DivideByShift(even, 1);

		// Place the even result in the even row
		even_lowpass[column] = SATURATE(even);

		// Apply the odd reconstruction filter to the lowpass band
		odd += 5 * lowlow[column + 0 * lowlow_pitch];
		odd += 4 * lowlow[column + 1 * lowlow_pitch];
		odd -= 1 * lowlow[column + 2 * lowlow_pitch];
		odd += ROUNDING(odd,8);
		odd = DivideByShift(odd, 3);

		// Subtract the highpass correction
		odd -= highlow[column];
		odd = DivideByShift(odd, 1);

		// Place the odd result in the odd row
		odd_lowpass[column] = SATURATE(odd);


		/***** Compute the vertical inverse for the right two bands *****/

		even = 0;
		odd = 0;

		// Apply the even reconstruction filter to the lowpass band
		even += 11 * lowhigh[column + 0 * lowhigh_pitch];
		even -=  4 * lowhigh[column + 1 * lowhigh_pitch];
		even +=  1 * lowhigh[column + 2 * lowhigh_pitch];
		even += ROUNDING(even,8);
		even = DivideByShift(even, 3);

		// Add the highpass correction
		even += highhigh[column];
		even = DivideByShift(even, 1);

		// Place the even result in the even row
		even_highpass[column] = SATURATE(even);

		// Apply the odd reconstruction filter to the lowpass band
		odd += 5 * lowhigh[column + 0 * lowhigh_pitch];
		odd += 4 * lowhigh[column + 1 * lowhigh_pitch];
		odd -= 1 * lowhigh[column + 2 * lowhigh_pitch];
		odd += ROUNDING(odd,8);
		odd = DivideByShift(odd, 3);

		// Subtract the highpass correction
		odd -= highhigh[column];
		odd = DivideByShift(odd, 1);

		// Place the odd result in the odd row
		odd_highpass[column] = SATURATE(odd);
	}

	// Apply the inverse horizontal transform to the even and odd rows
/*DANREMOVE	if(precision == 8 || _NODITHER || DECODEDFORMAT(info)==DECODED_FORMAT_YUYV || DECODEDFORMAT(info)==COLOR_FORMAT_UYVY)
	{
		InvertHorizontalStrip16sTo8u(lowpass, lowpass_pitch,
									 highpass, highpass_pitch,
									 output, output_row_size, strip,
									 precision);
	}
	else */
	{
		InvertHorizontalStrip16sToRow16u(lowpass, lowpass_pitch,
										 highpass, highpass_pitch,
										 (PIXEL16U*)output, (int)output_row_size, strip,
										 precision);
	}
}


#if 0

// Old version that uses MMX instructions
void InvertSpatialMiddleRow16s(PIXEL *lowlow_band, int lowlow_pitch,
							   PIXEL *lowhigh_band, int lowhigh_pitch,
							   PIXEL *highlow_band, int highlow_pitch,
							   PIXEL *highhigh_band, int highhigh_pitch,
							   uint8_t *output, int output_pitch,
							   int row, int width,
							   PIXEL *buffer, size_t buffer_size,
							   int precision, FRAME_INFO *info)
{
	PIXEL *lowlow = lowlow_band;
	PIXEL *lowhigh = lowhigh_band;
	PIXEL *highlow = highlow_band;
	PIXEL *highhigh = highhigh_band;
	PIXEL *even_lowpass;
	PIXEL *even_highpass;
	PIXEL *odd_lowpass;
	PIXEL *odd_highpass;
	PIXEL *even_output;
	PIXEL *odd_output;
	PIXEL *lowpass;					// Strip of horizontal coefficients
	PIXEL *highpass;
	int lowpass_pitch;				// Distance between strip rows in bytes
	int highpass_pitch;
	ROI strip;						// Dimensions of the processing strip
	size_t buffer_row_size;
	size_t output_row_size = output_pitch;
	int buffer_half_pitch;
	int buffer_width;
	int buffer_pitch;
	int column;

#if (1 && XMMOPT)
	const int column_step = 4;
	int post_column = width - (width % column_step);

	__m64 *even_lowpass_ptr;
	__m64 *even_highpass_ptr;
	__m64 *odd_lowpass_ptr;
	__m64 *odd_highpass_ptr;
#endif

	// This routine should not be called to process the first row
	assert(row > 0);

	// Convert pitch from bytes to pixels
	lowlow_pitch /= sizeof(PIXEL);
	lowhigh_pitch /= sizeof(PIXEL);
	highlow_pitch /= sizeof(PIXEL);
	highhigh_pitch /= sizeof(PIXEL);

	// Compute the address of the first row for processing in each wavelet band
	lowlow += (row - 1) * lowlow_pitch;
	lowhigh += (row - 1) * lowhigh_pitch;
	highlow += row * highlow_pitch;
	highhigh += row * highhigh_pitch;

	// Compute positions within the temporary buffer for each row of horizontal lowpass
	// and highpass intermediate coefficients computed by the vertical inverse transform
	buffer_row_size = width * sizeof(PIXEL);
	buffer_row_size = ALIGN16(buffer_row_size);
	buffer_half_pitch = buffer_row_size/sizeof(PIXEL);
	buffer_pitch = 2 * buffer_half_pitch;
	buffer_width = width;

	// Check that the buffer is large enough to hold four rows of coefficients
	assert(buffer_size >= (4 * buffer_row_size));

	// Set the dimensions of the processing strip
	strip.width = buffer_width;
	strip.height = 2;

	// Compute the positions of the even and odd rows of coefficients
	even_lowpass = &buffer[0];
	even_highpass = &buffer[buffer_half_pitch];
	odd_lowpass = &buffer[2 * buffer_half_pitch];
	odd_highpass = &buffer[3 * buffer_half_pitch];

	// Pointers into the strip of horizontal coefficients
	lowpass = even_lowpass;
	highpass = even_highpass;
	lowpass_pitch = 2 * buffer_row_size;
	highpass_pitch = 2 * buffer_row_size;

	// Start at the first column
	column = 0;

#if (1 && XMMOPT)

	even_lowpass_ptr = (__m64 *)even_lowpass;
	even_highpass_ptr = (__m64 *)even_highpass;
	odd_lowpass_ptr = (__m64 *)odd_lowpass;
	odd_highpass_ptr = (__m64 *)odd_highpass;

	// Process groups of four coefficients along the row
	for (; column < post_column; column += column_step)
	{
		__m64 *lowlow_ptr = (__m64 *)&lowlow[column];
		__m64 *highlow_ptr = (__m64 *)&highlow[column];
		__m64 *lowhigh_ptr = (__m64 *)&lowhigh[column];
		__m64 *highhigh_ptr = (__m64 *)&highhigh[column];
		__m64 quad_pi16;
		__m64 even_pi16;
		__m64 odd_pi16;
		__m64 mid_pi16;
		__m64 half_pi16 = _mm_set1_pi16(4); //DAN031604 4 to 6


		/***** Compute the vertical inverse for the left two bands *****/

		// Set the pitch for the lowpass band used in this section of code
		int quad_pitch = (lowlow_pitch * sizeof(PIXEL))/sizeof(__m64);

		// Accumulate parallel sums for the even and odd filters
		quad_pi16 = *lowlow_ptr;	// Get four lowpass coefficients
		lowlow_ptr += quad_pitch;	// Advance to the next row

		even_pi16 = quad_pi16;
		odd_pi16 = _mm_subs_pi16(_mm_setzero_si64(), quad_pi16);

		mid_pi16 = *lowlow_ptr;	// Get four lowpass coefficients
		lowlow_ptr += quad_pitch;	// Advance to the next row

		quad_pi16 = *lowlow_ptr;	// Get four lowpass coefficients

		even_pi16 = _mm_subs_pi16(even_pi16, quad_pi16);
		odd_pi16 = _mm_adds_pi16(odd_pi16, quad_pi16);

		even_pi16 = _mm_adds_pi16(even_pi16, half_pi16);
		odd_pi16 = _mm_adds_pi16(odd_pi16, half_pi16);

		even_pi16 = _mm_srai_pi16(even_pi16, 3);
		odd_pi16 = _mm_srai_pi16(odd_pi16, 3);

		even_pi16 = _mm_adds_pi16(even_pi16, mid_pi16);
		odd_pi16 = _mm_adds_pi16(odd_pi16, mid_pi16);


		// Add the highpass correction to the even result and divide by two
		quad_pi16 = *highlow_ptr;
		even_pi16 = _mm_adds_pi16(even_pi16, quad_pi16);
		even_pi16 = _mm_srai_pi16(even_pi16, 1);

		// Subtract the highpass correction from the odd result and divide by two
		odd_pi16 = _mm_subs_pi16(odd_pi16, quad_pi16);
		odd_pi16 = _mm_srai_pi16(odd_pi16, 1);

		// Store the even and odd groups of horizontal lowpass coefficients
		*(even_lowpass_ptr++) = even_pi16;
		*(odd_lowpass_ptr++) = odd_pi16;


		/***** Compute the vertical inverse for the right two bands *****/

		// Set the pitch for the lowpass band used in this section of code
		quad_pitch = (lowhigh_pitch * sizeof(PIXEL))/sizeof(__m64);

		// Accumulate parallel sums for the even and odd filters
		quad_pi16 = *lowhigh_ptr;	// Get four lowpass coefficients
		lowhigh_ptr += quad_pitch;	// Advance to the next row

		even_pi16 = quad_pi16;
		odd_pi16 = _mm_subs_pi16(_mm_setzero_si64(), quad_pi16);

		mid_pi16 = *lowhigh_ptr;	// Get four lowpass coefficients
		lowhigh_ptr += quad_pitch;	// Advance to the next row

		quad_pi16 = *lowhigh_ptr;	// Get four lowpass coefficients

		even_pi16 = _mm_subs_pi16(even_pi16, quad_pi16);
		odd_pi16 = _mm_adds_pi16(odd_pi16, quad_pi16);

		even_pi16 = _mm_adds_pi16(even_pi16, half_pi16);
		odd_pi16 = _mm_adds_pi16(odd_pi16, half_pi16);

		even_pi16 = _mm_srai_pi16(even_pi16, 3);
		odd_pi16 = _mm_srai_pi16(odd_pi16, 3);

		even_pi16 = _mm_adds_pi16(even_pi16, mid_pi16);
		odd_pi16 = _mm_adds_pi16(odd_pi16, mid_pi16);


		// Add the highpass correction to the even result and divide by two
		quad_pi16 = *highhigh_ptr;
		even_pi16 = _mm_adds_pi16(even_pi16, quad_pi16);
		even_pi16 = _mm_srai_pi16(even_pi16, 1);

		// Subtract the highpass correction from the odd result and divide by two
		odd_pi16 = _mm_subs_pi16(odd_pi16, quad_pi16);
		odd_pi16 = _mm_srai_pi16(odd_pi16, 1);

		// Store the even and odd groups of horizontal highpass coefficients
		*(even_highpass_ptr++) = even_pi16;
		*(odd_highpass_ptr++) = odd_pi16;
	}

	// Should have exited the loop at the post processing column
	assert(column == post_column);

#endif

	// Process the rest of the row
	for (; column < width; column++)
	{
		int32_t even = 0;		// Result of convolution with even filter
		int32_t odd = 0;		// Result of convolution with odd filter


		/***** Compute the vertical inverse for the left two bands *****/

		// Apply the even reconstruction filter to the lowpass band
		even += lowlow[column + 0 * lowlow_pitch];
		even -= lowlow[column + 2 * lowlow_pitch];
		even += 4; //DAN20050921
		even >>= 3;
		even += lowlow[column + 1 * lowlow_pitch];

		// Add the highpass correction
		even += highlow[column];
		even = DivideByShift(even, 1);

		// Place the even result in the even row
		even_lowpass[column] = SATURATE(even);

		// Apply the odd reconstruction filter to the lowpass band
		odd -= lowlow[column + 0 * lowlow_pitch];
		odd += lowlow[column + 2 * lowlow_pitch];
		odd += 4; //DAN20050921
		odd >>= 3;
		odd += lowlow[column + 1 * lowlow_pitch];

		// Subtract the highpass correction
		odd -= highlow[column];
		odd = DivideByShift(odd, 1);

		// Place the odd result in the odd row
		odd_lowpass[column] = SATURATE(odd);


		/***** Compute the vertical inverse for the right two bands *****/

		even = 0;
		odd = 0;

		// Apply the even reconstruction filter to the lowpass band
		even += lowhigh[column + 0 * lowhigh_pitch];
		even -= lowhigh[column + 2 * lowhigh_pitch];
		even += 4; //DAN20050921
		even >>= 3;
		even += lowhigh[column + 1 * lowhigh_pitch];

		// Add the highpass correction
		even += highhigh[column];
		even = DivideByShift(even, 1);

		// Place the even result in the even row
		even_highpass[column] = SATURATE(even);

		// Apply the odd reconstruction filter to the lowpass band
		odd -= lowhigh[column + 0 * lowhigh_pitch];
		odd += lowhigh[column + 2 * lowhigh_pitch];
		odd += 4; //DAN20050921
		odd >>= 3;
		odd += lowhigh[column + 1 * lowhigh_pitch];

		// Subtract the highpass correction
		odd -= highhigh[column];
		odd = DivideByShift(odd, 1);

		// Place the odd result in the odd row
		odd_highpass[column] = SATURATE(odd);
	}

	// Apply the inverse horizontal transform to the even and odd rows
/*DANREMOVE		if(precision == 8 || _NODITHER || DECODEDFORMAT(info)==DECODED_FORMAT_YUYV || DECODEDFORMAT(info)==COLOR_FORMAT_UYVY)
	{
		InvertHorizontalStrip16sTo8u(lowpass, lowpass_pitch,
									 highpass, highpass_pitch,
									 output, output_row_size, strip,
									 precision);
	}
	else */
	{
		InvertHorizontalStrip16sToRow16u(lowpass, lowpass_pitch,
										 highpass, highpass_pitch,
										 (PIXEL16U*)output, output_row_size, strip,
										 precision);
	}

	//_mm_empty();	// Clear the mmx register state
}

#else

// New version optimized with SSE2 instructions
void InvertSpatialMiddleRow16s(PIXEL *lowlow_band, int lowlow_pitch,
							   PIXEL *lowhigh_band, int lowhigh_pitch,
							   PIXEL *highlow_band, int highlow_pitch,
							   PIXEL *highhigh_band, int highhigh_pitch,
							   uint8_t *output, int output_pitch,
							   int row, int width,
							   PIXEL *buffer, size_t buffer_size,
							   int precision, FRAME_INFO *info)
{
	PIXEL *lowlow = lowlow_band;
	PIXEL *lowhigh = lowhigh_band;
	PIXEL *highlow = highlow_band;
	PIXEL *highhigh = highhigh_band;
	PIXEL *even_lowpass;
	PIXEL *even_highpass;
	PIXEL *odd_lowpass;
	PIXEL *odd_highpass;
	PIXEL *lowpass;					// Strip of horizontal coefficients
	PIXEL *highpass;
	int lowpass_pitch;				// Distance between strip rows in bytes
	int highpass_pitch;
	ROI strip;						// Dimensions of the processing strip
	size_t buffer_row_size;
	size_t output_row_size = output_pitch;
	int buffer_half_pitch;
	int buffer_width;
	int buffer_pitch;
	int column;

#if (1 && XMMOPT)
	const int column_step = 8;
	int post_column = width - (width % column_step);

	__m128i *even_lowpass_ptr;
	__m128i *even_highpass_ptr;
	__m128i *odd_lowpass_ptr;
	__m128i *odd_highpass_ptr;
#endif

	// This routine should not be called to process the first row
	assert(row > 0);

	// Convert pitch from bytes to pixels
	lowlow_pitch /= sizeof(PIXEL);
	lowhigh_pitch /= sizeof(PIXEL);
	highlow_pitch /= sizeof(PIXEL);
	highhigh_pitch /= sizeof(PIXEL);

	// Compute the address of the first row for processing in each wavelet band
	lowlow += (row - 1) * lowlow_pitch;
	lowhigh += (row - 1) * lowhigh_pitch;
	highlow += row * highlow_pitch;
	highhigh += row * highhigh_pitch;

	// Compute positions within the temporary buffer for each row of horizontal lowpass
	// and highpass intermediate coefficients computed by the vertical inverse transform
	buffer_row_size = width * sizeof(PIXEL);
	buffer_row_size = ALIGN16(buffer_row_size);
	buffer_half_pitch = (int)buffer_row_size/sizeof(PIXEL);
	buffer_pitch = 2 * buffer_half_pitch;
	buffer_width = width;

	// Check that the buffer is large enough to hold four rows of coefficients
	assert(buffer_size >= (4 * buffer_row_size));

	// Set the dimensions of the processing strip
	strip.width = buffer_width;
	strip.height = 2;

	// Compute the positions of the even and odd rows of coefficients
	even_lowpass = &buffer[0];
	even_highpass = &buffer[buffer_half_pitch];
	odd_lowpass = &buffer[2 * buffer_half_pitch];
	odd_highpass = &buffer[3 * buffer_half_pitch];

	// Pointers into the strip of horizontal coefficients
	lowpass = even_lowpass;
	highpass = even_highpass;
	lowpass_pitch = (int)(2 * buffer_row_size);
	highpass_pitch = (int)(2 * buffer_row_size);

	// Start at the first column
	column = 0;

#if (1 && XMMOPT)

	even_lowpass_ptr = (__m128i *)even_lowpass;
	even_highpass_ptr = (__m128i *)even_highpass;
	odd_lowpass_ptr = (__m128i *)odd_lowpass;
	odd_highpass_ptr = (__m128i *)odd_highpass;

	// Process groups of four coefficients along the row
	for (; column < post_column; column += column_step)
	{
		__m128i *lowlow_ptr = (__m128i *)&lowlow[column];
		__m128i *highlow_ptr = (__m128i *)&highlow[column];
		__m128i *lowhigh_ptr = (__m128i *)&lowhigh[column];
		__m128i *highhigh_ptr = (__m128i *)&highhigh[column];
		__m128i quad_epi16;
		__m128i even_epi16;
		__m128i odd_epi16;
		__m128i mid_epi16;
		__m128i half_epi16 = _mm_set1_epi16(4); //DAN031604 4 to 6


		/***** Compute the vertical inverse for the left two bands *****/

		// Set the pitch for the lowpass band used in this section of code
		int quad_pitch = (lowlow_pitch * sizeof(PIXEL))/sizeof(__m128i);

		// Accumulate parallel sums for the even and odd filters
		quad_epi16 = *lowlow_ptr;	// Get four lowpass coefficients
		lowlow_ptr += quad_pitch;	// Advance to the next row

		even_epi16 = quad_epi16;
		odd_epi16 = _mm_subs_epi16(_mm_setzero_si128(), quad_epi16);

		mid_epi16 = *lowlow_ptr;	// Get four lowpass coefficients
		lowlow_ptr += quad_pitch;	// Advance to the next row

		quad_epi16 = *lowlow_ptr;	// Get four lowpass coefficients

		even_epi16 = _mm_subs_epi16(even_epi16, quad_epi16);
		odd_epi16 = _mm_adds_epi16(odd_epi16, quad_epi16);

		even_epi16 = _mm_adds_epi16(even_epi16, half_epi16);
		odd_epi16 = _mm_adds_epi16(odd_epi16, half_epi16);

		even_epi16 = _mm_srai_epi16(even_epi16, 3);
		odd_epi16 = _mm_srai_epi16(odd_epi16, 3);

		even_epi16 = _mm_adds_epi16(even_epi16, mid_epi16);
		odd_epi16 = _mm_adds_epi16(odd_epi16, mid_epi16);


		// Add the highpass correction to the even result and divide by two
		quad_epi16 = *highlow_ptr;
		even_epi16 = _mm_adds_epi16(even_epi16, quad_epi16);
		even_epi16 = _mm_srai_epi16(even_epi16, 1);

		// Subtract the highpass correction from the odd result and divide by two
		odd_epi16 = _mm_subs_epi16(odd_epi16, quad_epi16);
		odd_epi16 = _mm_srai_epi16(odd_epi16, 1);

		// Store the even and odd groups of horizontal lowpass coefficients
		*(even_lowpass_ptr++) = even_epi16;
		*(odd_lowpass_ptr++) = odd_epi16;


		/***** Compute the vertical inverse for the right two bands *****/

		// Set the pitch for the lowpass band used in this section of code
		quad_pitch = (lowhigh_pitch * sizeof(PIXEL))/sizeof(__m128i);

		// Accumulate parallel sums for the even and odd filters
		quad_epi16 = *lowhigh_ptr;	// Get four lowpass coefficients
		lowhigh_ptr += quad_pitch;	// Advance to the next row

		even_epi16 = quad_epi16;
		odd_epi16 = _mm_subs_epi16(_mm_setzero_si128(), quad_epi16);

		mid_epi16 = *lowhigh_ptr;	// Get four lowpass coefficients
		lowhigh_ptr += quad_pitch;	// Advance to the next row

		quad_epi16 = *lowhigh_ptr;	// Get four lowpass coefficients

		even_epi16 = _mm_subs_epi16(even_epi16, quad_epi16);
		odd_epi16 = _mm_adds_epi16(odd_epi16, quad_epi16);

		even_epi16 = _mm_adds_epi16(even_epi16, half_epi16);
		odd_epi16 = _mm_adds_epi16(odd_epi16, half_epi16);

		even_epi16 = _mm_srai_epi16(even_epi16, 3);
		odd_epi16 = _mm_srai_epi16(odd_epi16, 3);

		even_epi16 = _mm_adds_epi16(even_epi16, mid_epi16);
		odd_epi16 = _mm_adds_epi16(odd_epi16, mid_epi16);


		// Add the highpass correction to the even result and divide by two
		quad_epi16 = *highhigh_ptr;
		even_epi16 = _mm_adds_epi16(even_epi16, quad_epi16);
		even_epi16 = _mm_srai_epi16(even_epi16, 1);

		// Subtract the highpass correction from the odd result and divide by two
		odd_epi16 = _mm_subs_epi16(odd_epi16, quad_epi16);
		odd_epi16 = _mm_srai_epi16(odd_epi16, 1);

		// Store the even and odd groups of horizontal highpass coefficients
		*(even_highpass_ptr++) = even_epi16;
		*(odd_highpass_ptr++) = odd_epi16;
	}

	// Should have exited the loop at the post processing column
	assert(column == post_column);

#endif

	// Process the rest of the row
	for (; column < width; column++)
	{
		int32_t even = 0;		// Result of convolution with even filter
		int32_t odd = 0;		// Result of convolution with odd filter


		/***** Compute the vertical inverse for the left two bands *****/

		// Apply the even reconstruction filter to the lowpass band
		even += lowlow[column + 0 * lowlow_pitch];
		even -= lowlow[column + 2 * lowlow_pitch];
		even += 4; //DAN20050921
		even >>= 3;
		even += lowlow[column + 1 * lowlow_pitch];

		// Add the highpass correction
		even += highlow[column];
		even = DivideByShift(even, 1);

		// Place the even result in the even row
		even_lowpass[column] = SATURATE(even);

		// Apply the odd reconstruction filter to the lowpass band
		odd -= lowlow[column + 0 * lowlow_pitch];
		odd += lowlow[column + 2 * lowlow_pitch];
		odd += 4; //DAN20050921
		odd >>= 3;
		odd += lowlow[column + 1 * lowlow_pitch];

		// Subtract the highpass correction
		odd -= highlow[column];
		odd = DivideByShift(odd, 1);

		// Place the odd result in the odd row
		odd_lowpass[column] = SATURATE(odd);


		/***** Compute the vertical inverse for the right two bands *****/

		even = 0;
		odd = 0;

		// Apply the even reconstruction filter to the lowpass band
		even += lowhigh[column + 0 * lowhigh_pitch];
		even -= lowhigh[column + 2 * lowhigh_pitch];
		even += 4; //DAN20050921
		even >>= 3;
		even += lowhigh[column + 1 * lowhigh_pitch];

		// Add the highpass correction
		even += highhigh[column];
		even = DivideByShift(even, 1);

		// Place the even result in the even row
		even_highpass[column] = SATURATE(even);

		// Apply the odd reconstruction filter to the lowpass band
		odd -= lowhigh[column + 0 * lowhigh_pitch];
		odd += lowhigh[column + 2 * lowhigh_pitch];
		odd += 4; //DAN20050921
		odd >>= 3;
		odd += lowhigh[column + 1 * lowhigh_pitch];

		// Subtract the highpass correction
		odd -= highhigh[column];
		odd = DivideByShift(odd, 1);

		// Place the odd result in the odd row
		odd_highpass[column] = SATURATE(odd);
	}

	// Apply the inverse horizontal transform to the even and odd rows
/*DANREMOVE		if(precision == 8 || _NODITHER || DECODEDFORMAT(info)==DECODED_FORMAT_YUYV || DECODEDFORMAT(info)==COLOR_FORMAT_UYVY)
	{
		InvertHorizontalStrip16sTo8u(lowpass, lowpass_pitch,
									 highpass, highpass_pitch,
									 output, output_row_size, strip,
									 precision);
	}
	else */
	{
		InvertHorizontalStrip16sToRow16u(lowpass, lowpass_pitch,
										 highpass, highpass_pitch,
										 (PIXEL16U*)output, (int)output_row_size, strip,
										 precision);
	}
}

#endif


void InvertSpatialBottomRow16s(PIXEL *lowlow_band, int lowlow_pitch,
							   PIXEL *lowhigh_band, int lowhigh_pitch,
							   PIXEL *highlow_band, int highlow_pitch,
							   PIXEL *highhigh_band, int highhigh_pitch,
							   uint8_t *output, int output_pitch,
							   int row, int width,
							   PIXEL *buffer, size_t buffer_size,
							   int precision, FRAME_INFO *info)
{
	PIXEL *lowlow = lowlow_band;
	PIXEL *lowhigh = lowhigh_band;
	PIXEL *highlow = highlow_band;
	PIXEL *highhigh = highhigh_band;
	PIXEL *even_lowpass;
	PIXEL *even_highpass;
	PIXEL *odd_lowpass;
	PIXEL *odd_highpass;
	PIXEL *lowpass;					// Strip of horizontal coefficients
	PIXEL *highpass;
	int lowpass_pitch;				// Distance between strip rows in bytes
	int highpass_pitch;
	ROI strip;						// Dimensions of the processing strip
	size_t buffer_row_size;
	size_t output_row_size = output_pitch;
	int buffer_half_pitch;
	int buffer_width;
	int buffer_pitch;
	int column;

	// Convert pitch from bytes to pixels
	lowlow_pitch /= sizeof(PIXEL);
	lowhigh_pitch /= sizeof(PIXEL);
	highlow_pitch /= sizeof(PIXEL);
	highhigh_pitch /= sizeof(PIXEL);

	// Compute the address of the first row for processing in each wavelet band
	lowlow += row * lowlow_pitch;
	lowhigh += row * lowhigh_pitch;
	highlow += row * highlow_pitch;
	highhigh += row * highhigh_pitch;

	// Compute positions within the temporary buffer for each row of horizontal lowpass
	// and highpass intermediate coefficients computed by the vertical inverse transform
	buffer_row_size = width * sizeof(PIXEL);
	buffer_row_size = ALIGN16(buffer_row_size);
	buffer_half_pitch = (int)buffer_row_size/sizeof(PIXEL);
	buffer_pitch = 2 * buffer_half_pitch;
	buffer_width = width;

	// Check that the buffer is large enough to hold four rows of coefficients
	assert(buffer_size >= (4 * buffer_row_size));

	// Set the dimensions of the processing strip
	strip.width = buffer_width;
	strip.height = 2;

	// Compute the positions of the even and odd rows of coefficients
	even_lowpass = &buffer[0];
	even_highpass = &buffer[buffer_half_pitch];
	odd_lowpass = &buffer[2 * buffer_half_pitch];
	odd_highpass = &buffer[3 * buffer_half_pitch];

	// Pointers into the strip of horizontal coefficients
	lowpass = even_lowpass;
	highpass = even_highpass;
	lowpass_pitch = (int)(2 * buffer_row_size);
	highpass_pitch = (int)(2 * buffer_row_size);

	// Apply the vertical border filter to the last row
	for (column = 0; column < width; column++)
	{
		int32_t even = 0;		// Result of convolution with even filter
		int32_t odd = 0;		// Result of convolution with odd filter


		// Compute the vertical inverse for the left two bands //

		// Apply the even reconstruction filter to the lowpass band
		even += 5 * lowlow[column + 0 * lowlow_pitch];
		even += 4 * lowlow[column - 1 * lowlow_pitch];
		even -= 1 * lowlow[column - 2 * lowlow_pitch];
		even += ROUNDING(even,8);
		even = DivideByShift(even, 3);

		// Add the highpass correction
		even += highlow[column];
		even = DivideByShift(even, 1);

		// Place the even result in the even row
		even_lowpass[column] = SATURATE(even);

		// Apply the odd reconstruction filter to the lowpass band
		odd += 11 * lowlow[column + 0 * lowlow_pitch];
		odd -=  4 * lowlow[column - 1 * lowlow_pitch];
		odd +=  1 * lowlow[column - 2 * lowlow_pitch];
		odd += ROUNDING(odd,8);
		odd = DivideByShift(odd, 3);

		// Subtract the highpass correction
		odd -= highlow[column];
		odd = DivideByShift(odd, 1);

		// Place the odd result in the odd row
		odd_lowpass[column] = SATURATE(odd);


		// Compute the vertical inverse for the right two bands //

		even = 0;
		odd = 0;

		// Apply the even reconstruction filter to the lowpass band
		even += 5 * lowhigh[column + 0 * lowhigh_pitch];
		even += 4 * lowhigh[column - 1 * lowhigh_pitch];
		even -= 1 * lowhigh[column - 2 * lowhigh_pitch];
		even += ROUNDING(even,8);
		even = DivideByShift(even, 3);

		// Add the highpass correction
		even += highhigh[column];
		even = DivideByShift(even, 1);

		// Place the even result in the even row
		even_highpass[column] = SATURATE(even);

		// Apply the odd reconstruction filter to the lowpass band
		odd += 11 * lowhigh[column + 0 * lowhigh_pitch];
		odd -=  4 * lowhigh[column - 1 * lowhigh_pitch];
		odd +=  1 * lowhigh[column - 2 * lowhigh_pitch];
		odd += ROUNDING(odd,8);
		odd = DivideByShift(odd, 3);

		// Subtract the highpass correction
		odd -= highhigh[column];
		odd = DivideByShift(odd, 1);

		// Place the odd result in the odd row
		odd_highpass[column] = SATURATE(odd);
	}

	// Apply the inverse horizontal transform to the even and odd rows
/*DANREMOVE	if(precision == 8 || _NODITHER || DECODEDFORMAT(info)==DECODED_FORMAT_YUYV || DECODEDFORMAT(info)==COLOR_FORMAT_UYVY)
	{
		InvertHorizontalStrip16sTo8u(lowpass, lowpass_pitch,
									 highpass, highpass_pitch,
									 output, output_row_size, strip,
									 precision);
	}
	else */
	{
		InvertHorizontalStrip16sToRow16u(lowpass, lowpass_pitch,
										 highpass, highpass_pitch,
										 (PIXEL16U*)output, (int)output_row_size, strip,
										 precision);
	}
}





void InvertSpatialTopRow10bit16s(PIXEL *lowlow_band, int lowlow_pitch,
								 PIXEL *lowhigh_band, int lowhigh_pitch,
								 PIXEL *highlow_band, int highlow_pitch,
								 PIXEL *highhigh_band, int highhigh_pitch,
								 PIXEL *output, int output_pitch,
								 int row, int width,
								 PIXEL *buffer, size_t buffer_size)
{
	PIXEL *lowlow = lowlow_band;
	PIXEL *lowhigh = lowhigh_band;
	PIXEL *highlow = highlow_band;
	PIXEL *highhigh = highhigh_band;
	PIXEL *even_lowpass;
	PIXEL *even_highpass;
	PIXEL *odd_lowpass;
	PIXEL *odd_highpass;
	PIXEL *lowpass;					// Strip of horizontal coefficients
	PIXEL *highpass;
	int lowpass_pitch;				// Distance between strip rows in bytes
	int highpass_pitch;
	ROI strip;						// Dimensions of the processing strip
	size_t buffer_row_size;
	size_t output_row_size = output_pitch;
	int buffer_half_pitch;
	int buffer_width;
	int buffer_pitch;
	int column;

	// Convert pitch from bytes to pixels
	lowlow_pitch /= sizeof(PIXEL);
	lowhigh_pitch /= sizeof(PIXEL);
	highlow_pitch /= sizeof(PIXEL);
	highhigh_pitch /= sizeof(PIXEL);
	output_pitch /= sizeof(PIXEL);

	// Compute positions within the temporary buffer for each row of horizontal lowpass
	// and highpass intermediate coefficients computed by the vertical inverse transform
	buffer_row_size = width * sizeof(PIXEL);
	buffer_row_size = ALIGN16(buffer_row_size);
	buffer_half_pitch = (int)buffer_row_size/sizeof(PIXEL);
	buffer_pitch = 2 * buffer_half_pitch;
	buffer_width = width;

	// Check that the buffer is large enough to hold four rows of coefficients
	assert(buffer_size >= (4 * buffer_row_size));

	// Set the dimensions of the processing strip
	strip.width = buffer_width;
	strip.height = 2;

	// Compute the positions of the even and odd rows of coefficients
	even_lowpass = &buffer[0];
	even_highpass = &buffer[buffer_half_pitch];
	odd_lowpass = &buffer[2 * buffer_half_pitch];
	odd_highpass = &buffer[3 * buffer_half_pitch];

	// Pointers into the strip of horizontal coefficients
	lowpass = even_lowpass;
	highpass = even_highpass;
	lowpass_pitch = (int)(2 * buffer_row_size);
	highpass_pitch = (int)(2 * buffer_row_size);

	// This routine should be called for the first row
	assert(row == 0);

	// Apply the vertical border filter to the first row
	for (column = 0; column < width; column++)
	{
		int32_t even = 0;		// Result of convolution with even filter
		int32_t odd = 0;		// Result of convolution with odd filter


		/***** Compute the vertical inverse for the left two bands *****/

		// Apply the even reconstruction filter to the lowpass band
		even += 11 * lowlow[column + 0 * lowlow_pitch];
		even -=  4 * lowlow[column + 1 * lowlow_pitch];
		even +=  1 * lowlow[column + 2 * lowlow_pitch];
		even += ROUNDING(even,8);
		even = DivideByShift(even, 3);

		// Add the highpass correction
		even += highlow[column];
		even = DivideByShift(even, 1);

		// Place the even result in the even row
		even_lowpass[column] = SATURATE(even);

		// Apply the odd reconstruction filter to the lowpass band
		odd += 5 * lowlow[column + 0 * lowlow_pitch];
		odd += 4 * lowlow[column + 1 * lowlow_pitch];
		odd -= 1 * lowlow[column + 2 * lowlow_pitch];
		odd += ROUNDING(odd,8);
		odd = DivideByShift(odd, 3);

		// Subtract the highpass correction
		odd -= highlow[column];
		odd = DivideByShift(odd, 1);

		// Place the odd result in the odd row
		odd_lowpass[column] = SATURATE(odd);


		/***** Compute the vertical inverse for the right two bands *****/

		even = 0;
		odd = 0;

		// Apply the even reconstruction filter to the lowpass band
		even += 11 * lowhigh[column + 0 * lowhigh_pitch];
		even -=  4 * lowhigh[column + 1 * lowhigh_pitch];
		even +=  1 * lowhigh[column + 2 * lowhigh_pitch];
		even += ROUNDING(even,8);
		even = DivideByShift(even, 3);

		// Add the highpass correction
		even += highhigh[column];
		even = DivideByShift(even, 1);

		// Place the even result in the even row
		even_highpass[column] = SATURATE(even);

		// Apply the odd reconstruction filter to the lowpass band
		odd += 5 * lowhigh[column + 0 * lowhigh_pitch];
		odd += 4 * lowhigh[column + 1 * lowhigh_pitch];
		odd -= 1 * lowhigh[column + 2 * lowhigh_pitch];
		odd += ROUNDING(odd,8);
		odd = DivideByShift(odd, 3);

		// Subtract the highpass correction
		odd -= highhigh[column];
		odd = DivideByShift(odd, 1);

		// Place the odd result in the odd row
		odd_highpass[column] = SATURATE(odd);
	}

	// Apply the inverse horizontal transform to the even and odd rows
	InvertHorizontalStrip16s(lowpass, lowpass_pitch,
							 highpass, highpass_pitch,
							 output, (int)output_row_size, strip);
}

void InvertSpatialMiddleRow10bit16s(PIXEL *lowlow_band, int lowlow_pitch,
									PIXEL *lowhigh_band, int lowhigh_pitch,
									PIXEL *highlow_band, int highlow_pitch,
									PIXEL *highhigh_band, int highhigh_pitch,
									PIXEL *output, int output_pitch,
									int row, int width,
									PIXEL *buffer, size_t buffer_size)
{
	PIXEL *lowlow = lowlow_band;
	PIXEL *lowhigh = lowhigh_band;
	PIXEL *highlow = highlow_band;
	PIXEL *highhigh = highhigh_band;
	PIXEL *even_lowpass;
	PIXEL *even_highpass;
	PIXEL *odd_lowpass;
	PIXEL *odd_highpass;
	PIXEL *lowpass;					// Strip of horizontal coefficients
	PIXEL *highpass;
	int lowpass_pitch;				// Distance between strip rows in bytes
	int highpass_pitch;
	ROI strip;						// Dimensions of the processing strip
	size_t buffer_row_size;
	size_t output_row_size = output_pitch;
	int buffer_half_pitch;
	int buffer_width;
	int buffer_pitch;
	int column;

	// This routine should not be called to process the first row
	assert(row > 0);

	// Convert pitch from bytes to pixels
	lowlow_pitch /= sizeof(PIXEL);
	lowhigh_pitch /= sizeof(PIXEL);
	highlow_pitch /= sizeof(PIXEL);
	highhigh_pitch /= sizeof(PIXEL);
	output_pitch /= sizeof(PIXEL);

	// Compute the address of the first row for processing in each wavelet band
	lowlow += (row - 1) * lowlow_pitch;
	lowhigh += (row - 1) * lowhigh_pitch;
	highlow += row * highlow_pitch;
	highhigh += row * highhigh_pitch;

	// Compute positions within the temporary buffer for each row of horizontal lowpass
	// and highpass intermediate coefficients computed by the vertical inverse transform
	buffer_row_size = width * sizeof(PIXEL);
	buffer_row_size = ALIGN16(buffer_row_size);
	buffer_half_pitch = (int)buffer_row_size/sizeof(PIXEL);
	buffer_pitch = 2 * buffer_half_pitch;
	buffer_width = width;

	// Check that the buffer is large enough to hold four rows of coefficients
	assert(buffer_size >= (4 * buffer_row_size));

	// Set the dimensions of the processing strip
	strip.width = buffer_width;
	strip.height = 2;

	// Compute the positions of the even and odd rows of coefficients
	even_lowpass = &buffer[0];
	even_highpass = &buffer[buffer_half_pitch];
	odd_lowpass = &buffer[2 * buffer_half_pitch];
	odd_highpass = &buffer[3 * buffer_half_pitch];

	// Pointers into the strip of horizontal coefficients
	lowpass = even_lowpass;
	highpass = even_highpass;
	lowpass_pitch = (int)(2 * buffer_row_size);
	highpass_pitch = (int)(2 * buffer_row_size);

	// Process the middle rows using the interior reconstruction filters
	//for (; row < last_row; row++)
	{
#if (0 && XMMOPT) //DANREMOVED
		int column_step = 4;
		int post_column = width - (width % column_step);
		__m64 *even_lowpass_ptr = (__m64 *)even_lowpass;
		__m64 *even_highpass_ptr = (__m64 *)even_highpass;
		__m64 *odd_lowpass_ptr = (__m64 *)odd_lowpass;
		__m64 *odd_highpass_ptr = (__m64 *)odd_highpass;
		__m64 half_pi16 = _mm_set1_pi16(4);
		int quad_pitch;
#endif

		// Start at the first column
		column = 0;

#if (0 && XMMOPT) //DANREMOVED

		// Process groups of four coefficients along the row
		for (; column < post_column; column += column_step)
		{
			__m64 *lowlow_ptr = (__m64 *)&lowlow[column];
			__m64 *highlow_ptr = (__m64 *)&highlow[column];
			__m64 *lowhigh_ptr = (__m64 *)&lowhigh[column];
			__m64 *highhigh_ptr = (__m64 *)&highhigh[column];
			__m64 quad_pi16;
			__m64 even_pi16;
			__m64 odd_pi16;
			__m64 mid_pi16;


			// Compute the vertical inverse for the left two bands //

			// Set the pitch for the lowpass band used in this section of code
			quad_pitch = (lowlow_pitch * sizeof(PIXEL))/sizeof(__m64);

			// Accumulate parallel sums for the even and odd filters
			quad_pi16 = *lowlow_ptr;	// Get four lowpass coefficients
			lowlow_ptr += quad_pitch;	// Advance to the next row

			even_pi16 = quad_pi16;
			odd_pi16 = _mm_subs_pi16(_mm_setzero_si64(), quad_pi16);

			mid_pi16 = *lowlow_ptr;	// Get four lowpass coefficients
			lowlow_ptr += quad_pitch;	// Advance to the next row

			quad_pi16 = *lowlow_ptr;	// Get four lowpass coefficients

			even_pi16 = _mm_subs_pi16(even_pi16, quad_pi16);
			odd_pi16 = _mm_adds_pi16(odd_pi16, quad_pi16);

			even_pi16 = _mm_adds_pi16(even_pi16, half_pi16);
			odd_pi16 = _mm_adds_pi16(odd_pi16, half_pi16);

			even_pi16 = _mm_srai_pi16(even_pi16, 3);
			odd_pi16 = _mm_srai_pi16(odd_pi16, 3);

			even_pi16 = _mm_adds_pi16(even_pi16, mid_pi16);
			odd_pi16 = _mm_adds_pi16(odd_pi16, mid_pi16);


			// Add the highpass correction to the even result and divide by two
			quad_pi16 = *highlow_ptr;
			even_pi16 = _mm_adds_pi16(even_pi16, quad_pi16);
			even_pi16 = _mm_srai_pi16(even_pi16, 1);

			// Subtract the highpass correction from the odd result and divide by two
			odd_pi16 = _mm_subs_pi16(odd_pi16, quad_pi16);
			odd_pi16 = _mm_srai_pi16(odd_pi16, 1);


			// Store the even and odd groups of horizontal lowpass coefficients
			*(even_lowpass_ptr++) = even_pi16;
			*(odd_lowpass_ptr++) = odd_pi16;


			// Compute the vertical inverse for the right two bands //

			// Set the pitch for the lowpass band used in this section of code
			quad_pitch = (lowhigh_pitch * sizeof(PIXEL))/sizeof(__m64);

			// Accumulate parallel sums for the even and odd filters
			quad_pi16 = *lowhigh_ptr;	// Get four lowpass coefficients
			lowhigh_ptr += quad_pitch;	// Advance to the next row

			even_pi16 = quad_pi16;
			odd_pi16 = _mm_subs_pi16(_mm_setzero_si64(), quad_pi16);

			mid_pi16 = *lowhigh_ptr;	// Get four lowpass coefficients
			lowhigh_ptr += quad_pitch;	// Advance to the next row

			quad_pi16 = *lowhigh_ptr;	// Get four lowpass coefficients

			even_pi16 = _mm_subs_pi16(even_pi16, quad_pi16);
			odd_pi16 = _mm_adds_pi16(odd_pi16, quad_pi16);

			even_pi16 = _mm_adds_pi16(even_pi16, half_pi16);
			odd_pi16 = _mm_adds_pi16(odd_pi16, half_pi16);

			even_pi16 = _mm_srai_pi16(even_pi16, 3);
			odd_pi16 = _mm_srai_pi16(odd_pi16, 3);

			even_pi16 = _mm_adds_pi16(even_pi16, mid_pi16);
			odd_pi16 = _mm_adds_pi16(odd_pi16, mid_pi16);


			// Add the highpass correction to the even result and divide by two
			quad_pi16 = *highhigh_ptr;
			even_pi16 = _mm_adds_pi16(even_pi16, quad_pi16);
			even_pi16 = _mm_srai_pi16(even_pi16, 1);

			// Subtract the highpass correction from the odd result and divide by two
			odd_pi16 = _mm_subs_pi16(odd_pi16, quad_pi16);
			odd_pi16 = _mm_srai_pi16(odd_pi16, 1);

			// Store the even and odd groups of horizontal highpass coefficients
			*(even_highpass_ptr++) = even_pi16;
			*(odd_highpass_ptr++) = odd_pi16;
		}

		// Should have exited the loop at the post processing column
		assert(column == post_column);

#endif

		// Process the rest of the row
		for (; column < width; column++)
		{
			int32_t even = 0;		// Result of convolution with even filter
			int32_t odd = 0;		// Result of convolution with odd filter


			// Compute the vertical inverse for the left two bands //

			// Apply the even reconstruction filter to the lowpass band
			even += lowlow[column + 0 * lowlow_pitch];
			even -= lowlow[column + 2 * lowlow_pitch];
			even += 4; //DAN20050921
			even >>= 3;
			even += lowlow[column + 1 * lowlow_pitch];

			// Add the highpass correction
			even += highlow[column];
			even = DivideByShift(even, 1);

			// Place the even result in the even row
			even_lowpass[column] = SATURATE(even);

			// Apply the odd reconstruction filter to the lowpass band
			odd -= lowlow[column + 0 * lowlow_pitch];
			odd += lowlow[column + 2 * lowlow_pitch];
			odd += 4; //DAN20050921
			odd >>= 3;
			odd += lowlow[column + 1 * lowlow_pitch];

			// Subtract the highpass correction
			odd -= highlow[column];
			odd = DivideByShift(odd, 1);

			// Place the odd result in the odd row
			odd_lowpass[column] = SATURATE(odd);


			// Compute the vertical inverse for the right two bands //

			even = 0;
			odd = 0;

			// Apply the even reconstruction filter to the lowpass band
			even += lowhigh[column + 0 * lowhigh_pitch];
			even -= lowhigh[column + 2 * lowhigh_pitch];
			even += 4; //DAN20050921
			even >>= 3;
			even += lowhigh[column + 1 * lowhigh_pitch];

			// Add the highpass correction
			even += highhigh[column];
			even = DivideByShift(even, 1);

			// Place the even result in the even row
			even_highpass[column] = SATURATE(even);

			// Apply the odd reconstruction filter to the lowpass band
			odd -= lowhigh[column + 0 * lowhigh_pitch];
			odd += lowhigh[column + 2 * lowhigh_pitch];
			odd += 4; //DAN20050921
			odd >>= 3;
			odd += lowhigh[column + 1 * lowhigh_pitch];

			// Subtract the highpass correction
			odd -= highhigh[column];
			odd = DivideByShift(odd, 1);

			// Place the odd result in the odd row
			odd_highpass[column] = SATURATE(odd);
		}

		// Apply the inverse horizontal transform to the even and odd rows
		InvertHorizontalStrip16s10bitLimit(lowpass, lowpass_pitch,
								 highpass, highpass_pitch,
								 output, (int)output_row_size, strip);

		// Advance to the next input rows and skip the next output row
		//lowlow += lowlow_pitch;
		//lowhigh += lowhigh_pitch;
		//highlow += highlow_pitch;
		//highhigh += highhigh_pitch;
		//output += 2 * output_pitch;
	}


#if (0 && XMMOPT) //DANREMOVED
	//_mm_empty();	// Clear the mmx register state
#endif
}

void InvertSpatialBottomRow10bit16s(PIXEL *lowlow_band, int lowlow_pitch,
									PIXEL *lowhigh_band, int lowhigh_pitch,
									PIXEL *highlow_band, int highlow_pitch,
									PIXEL *highhigh_band, int highhigh_pitch,
									PIXEL *output, int output_pitch,
									int row, int width,
									PIXEL *buffer, size_t buffer_size)
{
	PIXEL *lowlow = lowlow_band;
	PIXEL *lowhigh = lowhigh_band;
	PIXEL *highlow = highlow_band;
	PIXEL *highhigh = highhigh_band;
	PIXEL *even_lowpass;
	PIXEL *even_highpass;
	PIXEL *odd_lowpass;
	PIXEL *odd_highpass;
	PIXEL *lowpass;					// Strip of horizontal coefficients
	PIXEL *highpass;
	int lowpass_pitch;				// Distance between strip rows in bytes
	int highpass_pitch;
	ROI strip;						// Dimensions of the processing strip
	size_t buffer_row_size;
	size_t output_row_size = output_pitch;
	int buffer_half_pitch;
	int buffer_width;
	int buffer_pitch;
	int column;

	// Convert pitch from bytes to pixels
	lowlow_pitch /= sizeof(PIXEL);
	lowhigh_pitch /= sizeof(PIXEL);
	highlow_pitch /= sizeof(PIXEL);
	highhigh_pitch /= sizeof(PIXEL);
	output_pitch /= sizeof(PIXEL);

	// Compute the address of the first row for processing in each wavelet band
	lowlow += row * lowlow_pitch;
	lowhigh += row * lowhigh_pitch;
	highlow += row * highlow_pitch;
	highhigh += row * highhigh_pitch;

	// Compute positions within the temporary buffer for each row of horizontal lowpass
	// and highpass intermediate coefficients computed by the vertical inverse transform
	buffer_row_size = width * sizeof(PIXEL);
	buffer_row_size = ALIGN16(buffer_row_size);
	buffer_half_pitch = (int)buffer_row_size/sizeof(PIXEL);
	buffer_pitch = 2 * buffer_half_pitch;
	buffer_width = width;

	// Check that the buffer is large enough to hold four rows of coefficients
	assert(buffer_size >= (4 * buffer_row_size));

	// Set the dimensions of the processing strip
	strip.width = buffer_width;
	strip.height = 2;

	// Compute the positions of the even and odd rows of coefficients
	even_lowpass = &buffer[0];
	even_highpass = &buffer[buffer_half_pitch];
	odd_lowpass = &buffer[2 * buffer_half_pitch];
	odd_highpass = &buffer[3 * buffer_half_pitch];

	// Pointers into the strip of horizontal coefficients
	lowpass = even_lowpass;
	highpass = even_highpass;
	lowpass_pitch = (int)(2 * buffer_row_size);
	highpass_pitch = (int)(2 * buffer_row_size);

	// Apply the vertical border filter to the last row
	for (column = 0; column < width; column++)
	{
		int32_t even = 0;		// Result of convolution with even filter
		int32_t odd = 0;		// Result of convolution with odd filter


		// Compute the vertical inverse for the left two bands //

		// Apply the even reconstruction filter to the lowpass band
		even += 5 * lowlow[column + 0 * lowlow_pitch];
		even += 4 * lowlow[column - 1 * lowlow_pitch];
		even -= 1 * lowlow[column - 2 * lowlow_pitch];
		even += ROUNDING(even,8);
		even = DivideByShift(even, 3);

		// Add the highpass correction
		even += highlow[column];
		even = DivideByShift(even, 1);

		// Place the even result in the even row
		even_lowpass[column] = SATURATE(even);

		// Apply the odd reconstruction filter to the lowpass band
		odd += 11 * lowlow[column + 0 * lowlow_pitch];
		odd -=  4 * lowlow[column - 1 * lowlow_pitch];
		odd +=  1 * lowlow[column - 2 * lowlow_pitch];
		odd += ROUNDING(odd,8);
		odd = DivideByShift(odd, 3);

		// Subtract the highpass correction
		odd -= highlow[column];
		odd = DivideByShift(odd, 1);

		// Place the odd result in the odd row
		odd_lowpass[column] = SATURATE(odd);


		// Compute the vertical inverse for the right two bands //

		even = 0;
		odd = 0;

		// Apply the even reconstruction filter to the lowpass band
		even += 5 * lowhigh[column + 0 * lowhigh_pitch];
		even += 4 * lowhigh[column - 1 * lowhigh_pitch];
		even -= 1 * lowhigh[column - 2 * lowhigh_pitch];
		even += ROUNDING(even,8);
		even = DivideByShift(even, 3);

		// Add the highpass correction
		even += highhigh[column];
		even = DivideByShift(even, 1);

		// Place the even result in the even row
		even_highpass[column] = SATURATE(even);

		// Apply the odd reconstruction filter to the lowpass band
		odd += 11 * lowhigh[column + 0 * lowhigh_pitch];
		odd -=  4 * lowhigh[column - 1 * lowhigh_pitch];
		odd +=  1 * lowhigh[column - 2 * lowhigh_pitch];
		odd += ROUNDING(odd,8);
		odd = DivideByShift(odd, 3);

		// Subtract the highpass correction
		odd -= highhigh[column];
		odd = DivideByShift(odd, 1);

		// Place the odd result in the odd row
		odd_highpass[column] = SATURATE(odd);
	}

	// Apply the inverse horizontal transform to the even and odd rows
	InvertHorizontalStrip16s(lowpass, lowpass_pitch,
							 highpass, highpass_pitch,
							 output, (int)output_row_size, strip);
}


void InvertSpatialTopRow16sToYUV16(PIXEL *lowlow_band, int lowlow_pitch,
								   PIXEL *lowhigh_band, int lowhigh_pitch,
								   PIXEL *highlow_band, int highlow_pitch,
								   PIXEL *highhigh_band, int highhigh_pitch,
								   PIXEL16U *output, int output_pitch,
								   int row, int width,
								   PIXEL *buffer, size_t buffer_size,
								   int precision)
{
	PIXEL *lowlow = lowlow_band;
	PIXEL *lowhigh = lowhigh_band;
	PIXEL *highlow = highlow_band;
	PIXEL *highhigh = highhigh_band;
	PIXEL *even_lowpass;
	PIXEL *even_highpass;
	PIXEL *odd_lowpass;
	PIXEL *odd_highpass;
	PIXEL *lowpass;					// Strip of horizontal coefficients
	PIXEL *highpass;
	int lowpass_pitch;				// Distance between strip rows in bytes
	int highpass_pitch;
	ROI strip;						// Dimensions of the processing strip
	size_t buffer_row_size;
	size_t output_row_size = output_pitch;
	int buffer_half_pitch;
	int buffer_width;
	int buffer_pitch;
	int column;

	// Convert pitch from bytes to pixels
	lowlow_pitch /= sizeof(PIXEL);
	lowhigh_pitch /= sizeof(PIXEL);
	highlow_pitch /= sizeof(PIXEL);
	highhigh_pitch /= sizeof(PIXEL);
	output_pitch /= sizeof(PIXEL16U);

	// Compute positions within the temporary buffer for each row of horizontal lowpass
	// and highpass intermediate coefficients computed by the vertical inverse transform
	buffer_row_size = width * sizeof(PIXEL);
	buffer_row_size = ALIGN16(buffer_row_size);
	buffer_half_pitch = (int)buffer_row_size/sizeof(PIXEL);
	buffer_pitch = 2 * buffer_half_pitch;
	buffer_width = width;

	// Check that the buffer is large enough to hold four rows of coefficients
	assert(buffer_size >= (4 * buffer_row_size));

	// Set the dimensions of the processing strip
	strip.width = buffer_width;
	strip.height = 2;

	// Compute the positions of the even and odd rows of coefficients
	even_lowpass = &buffer[0];
	even_highpass = &buffer[buffer_half_pitch];
	odd_lowpass = &buffer[2 * buffer_half_pitch];
	odd_highpass = &buffer[3 * buffer_half_pitch];

	// Pointers into the strip of horizontal coefficients
	lowpass = even_lowpass;
	highpass = even_highpass;
	lowpass_pitch = (int)(2 * buffer_row_size);
	highpass_pitch = (int)(2 * buffer_row_size);

	// This routine should be called for the first row
	assert(row == 0);

	// Apply the vertical border filter to the first row
	for (column = 0; column < width; column++)
	{
		int32_t even = 0;		// Result of convolution with even filter
		int32_t odd = 0;		// Result of convolution with odd filter


		/***** Compute the vertical inverse for the left two bands *****/

		// Apply the even reconstruction filter to the lowpass band
		even += 11 * lowlow[column + 0 * lowlow_pitch];
		even -=  4 * lowlow[column + 1 * lowlow_pitch];
		even +=  1 * lowlow[column + 2 * lowlow_pitch];
		even += ROUNDING(even,8);
		even = DivideByShift(even, 3);

		// Add the highpass correction
		even += highlow[column];
		even = DivideByShift(even, 1);

		// Place the even result in the even row
		even_lowpass[column] = SATURATE(even);

		// Apply the odd reconstruction filter to the lowpass band
		odd += 5 * lowlow[column + 0 * lowlow_pitch];
		odd += 4 * lowlow[column + 1 * lowlow_pitch];
		odd -= 1 * lowlow[column + 2 * lowlow_pitch];
		odd += ROUNDING(odd,8);
		odd = DivideByShift(odd, 3);

		// Subtract the highpass correction
		odd -= highlow[column];
		odd = DivideByShift(odd, 1);

		// Place the odd result in the odd row
		odd_lowpass[column] = SATURATE(odd);


		/***** Compute the vertical inverse for the right two bands *****/

		even = 0;
		odd = 0;

		// Apply the even reconstruction filter to the lowpass band
		even += 11 * lowhigh[column + 0 * lowhigh_pitch];
		even -=  4 * lowhigh[column + 1 * lowhigh_pitch];
		even +=  1 * lowhigh[column + 2 * lowhigh_pitch];
		even += ROUNDING(even,8);
		even = DivideByShift(even, 3);

		// Add the highpass correction
		even += highhigh[column];
		even = DivideByShift(even, 1);

		// Place the even result in the even row
		even_highpass[column] = SATURATE(even);

		// Apply the odd reconstruction filter to the lowpass band
		odd += 5 * lowhigh[column + 0 * lowhigh_pitch];
		odd += 4 * lowhigh[column + 1 * lowhigh_pitch];
		odd -= 1 * lowhigh[column + 2 * lowhigh_pitch];
		odd += ROUNDING(odd,8);
		odd = DivideByShift(odd, 3);

		// Subtract the highpass correction
		odd -= highhigh[column];
		odd = DivideByShift(odd, 1);

		// Place the odd result in the odd row
		odd_highpass[column] = SATURATE(odd);
	}

	// Apply the inverse horizontal transform to the even and odd rows
	InvertHorizontalStrip16sToRow16u(lowpass, lowpass_pitch,
									 highpass, highpass_pitch,
									 output, (int)output_row_size, strip,
									 precision);
}

void InvertSpatialMiddleRow16sToYUV16(PIXEL *lowlow_band, int lowlow_pitch,
									  PIXEL *lowhigh_band, int lowhigh_pitch,
									  PIXEL *highlow_band, int highlow_pitch,
									  PIXEL *highhigh_band, int highhigh_pitch,
									  PIXEL16U *output, int output_pitch,
									  int row, int width,
									  PIXEL *buffer, size_t buffer_size,
									  int precision)
{
	PIXEL *lowlow = lowlow_band;
	PIXEL *lowhigh = lowhigh_band;
	PIXEL *highlow = highlow_band;
	PIXEL *highhigh = highhigh_band;
	PIXEL *even_lowpass;
	PIXEL *even_highpass;
	PIXEL *odd_lowpass;
	PIXEL *odd_highpass;
	PIXEL *lowpass;					// Strip of horizontal coefficients
	PIXEL *highpass;
	int lowpass_pitch;				// Distance between strip rows in bytes
	int highpass_pitch;
	ROI strip;						// Dimensions of the processing strip
	size_t buffer_row_size;
	size_t output_row_size = output_pitch;
	int buffer_half_pitch;
	int buffer_width;
	int buffer_pitch;
	int column;

#if (0 && XMMOPT) //DANREMOVED
	const int column_step = 4;
	int post_column = width - (width % column_step);

	__m64 *even_lowpass_ptr;
	__m64 *even_highpass_ptr;
	__m64 *odd_lowpass_ptr;
	__m64 *odd_highpass_ptr;
#endif

	// This routine should not be called to process the first row
	assert(row > 0);

	// Convert pitch from bytes to pixels
	lowlow_pitch /= sizeof(PIXEL);
	lowhigh_pitch /= sizeof(PIXEL);
	highlow_pitch /= sizeof(PIXEL);
	highhigh_pitch /= sizeof(PIXEL);
	output_pitch /= sizeof(PIXEL16U);

	// Compute the address of the first row for processing in each wavelet band
	lowlow += (row - 1) * lowlow_pitch;
	lowhigh += (row - 1) * lowhigh_pitch;
	highlow += row * highlow_pitch;
	highhigh += row * highhigh_pitch;

	// Compute positions within the temporary buffer for each row of horizontal lowpass
	// and highpass intermediate coefficients computed by the vertical inverse transform
	buffer_row_size = width * sizeof(PIXEL);
	buffer_row_size = ALIGN16(buffer_row_size);
	buffer_half_pitch = (int)buffer_row_size/sizeof(PIXEL);
	buffer_pitch = 2 * buffer_half_pitch;
	buffer_width = width;

	// Check that the buffer is large enough to hold four rows of coefficients
	assert(buffer_size >= (4 * buffer_row_size));

	// Set the dimensions of the processing strip
	strip.width = buffer_width;
	strip.height = 2;

	// Compute the positions of the even and odd rows of coefficients
	even_lowpass = &buffer[0];
	even_highpass = &buffer[buffer_half_pitch];
	odd_lowpass = &buffer[2 * buffer_half_pitch];
	odd_highpass = &buffer[3 * buffer_half_pitch];

	// Pointers into the strip of horizontal coefficients
	lowpass = even_lowpass;
	highpass = even_highpass;
	lowpass_pitch = (int)(2 * buffer_row_size);
	highpass_pitch = (int)(2 * buffer_row_size);

	// Start at the first column
	column = 0;

#if (0 && XMMOPT) //DANREMOVED

	even_lowpass_ptr = (__m64 *)even_lowpass;
	even_highpass_ptr = (__m64 *)even_highpass;
	odd_lowpass_ptr = (__m64 *)odd_lowpass;
	odd_highpass_ptr = (__m64 *)odd_highpass;

	// Process groups of four coefficients along the row
	for (; column < post_column; column += column_step)
	{
		__m64 *lowlow_ptr = (__m64 *)&lowlow[column];
		__m64 *highlow_ptr = (__m64 *)&highlow[column];
		__m64 *lowhigh_ptr = (__m64 *)&lowhigh[column];
		__m64 *highhigh_ptr = (__m64 *)&highhigh[column];
		__m64 quad_pi16;
		__m64 even_pi16;
		__m64 odd_pi16;
		__m64 mid_pi16;
		__m64 half_pi16 = _mm_set1_pi16(4); //DAN031604 4 to 6


		/***** Compute the vertical inverse for the left two bands *****/

		// Set the pitch for the lowpass band used in this section of code
		int quad_pitch = (lowlow_pitch * sizeof(PIXEL))/sizeof(__m64);

		// Accumulate parallel sums for the even and odd filters
		quad_pi16 = *lowlow_ptr;	// Get four lowpass coefficients
		lowlow_ptr += quad_pitch;	// Advance to the next row

		even_pi16 = quad_pi16;
		odd_pi16 = _mm_subs_pi16(_mm_setzero_si64(), quad_pi16);

		mid_pi16 = *lowlow_ptr;	// Get four lowpass coefficients
		lowlow_ptr += quad_pitch;	// Advance to the next row

		quad_pi16 = *lowlow_ptr;	// Get four lowpass coefficients

		even_pi16 = _mm_subs_pi16(even_pi16, quad_pi16);
		odd_pi16 = _mm_adds_pi16(odd_pi16, quad_pi16);

		even_pi16 = _mm_adds_pi16(even_pi16, half_pi16);
		odd_pi16 = _mm_adds_pi16(odd_pi16, half_pi16);

		even_pi16 = _mm_srai_pi16(even_pi16, 3);
		odd_pi16 = _mm_srai_pi16(odd_pi16, 3);

		even_pi16 = _mm_adds_pi16(even_pi16, mid_pi16);
		odd_pi16 = _mm_adds_pi16(odd_pi16, mid_pi16);


		// Add the highpass correction to the even result and divide by two
		quad_pi16 = *highlow_ptr;
		even_pi16 = _mm_adds_pi16(even_pi16, quad_pi16);
		even_pi16 = _mm_srai_pi16(even_pi16, 1);

		// Subtract the highpass correction from the odd result and divide by two
		odd_pi16 = _mm_subs_pi16(odd_pi16, quad_pi16);
		odd_pi16 = _mm_srai_pi16(odd_pi16, 1);

		// Store the even and odd groups of horizontal lowpass coefficients
		*(even_lowpass_ptr++) = even_pi16;
		*(odd_lowpass_ptr++) = odd_pi16;


		/***** Compute the vertical inverse for the right two bands *****/

		// Set the pitch for the lowpass band used in this section of code
		quad_pitch = (lowhigh_pitch * sizeof(PIXEL))/sizeof(__m64);

		// Accumulate parallel sums for the even and odd filters
		quad_pi16 = *lowhigh_ptr;	// Get four lowpass coefficients
		lowhigh_ptr += quad_pitch;	// Advance to the next row

		even_pi16 = quad_pi16;
		odd_pi16 = _mm_subs_pi16(_mm_setzero_si64(), quad_pi16);

		mid_pi16 = *lowhigh_ptr;	// Get four lowpass coefficients
		lowhigh_ptr += quad_pitch;	// Advance to the next row

		quad_pi16 = *lowhigh_ptr;	// Get four lowpass coefficients

		even_pi16 = _mm_subs_pi16(even_pi16, quad_pi16);
		odd_pi16 = _mm_adds_pi16(odd_pi16, quad_pi16);

		even_pi16 = _mm_adds_pi16(even_pi16, half_pi16);
		odd_pi16 = _mm_adds_pi16(odd_pi16, half_pi16);

		even_pi16 = _mm_srai_pi16(even_pi16, 3);
		odd_pi16 = _mm_srai_pi16(odd_pi16, 3);

		even_pi16 = _mm_adds_pi16(even_pi16, mid_pi16);
		odd_pi16 = _mm_adds_pi16(odd_pi16, mid_pi16);


		// Add the highpass correction to the even result and divide by two
		quad_pi16 = *highhigh_ptr;
		even_pi16 = _mm_adds_pi16(even_pi16, quad_pi16);
		even_pi16 = _mm_srai_pi16(even_pi16, 1);

		// Subtract the highpass correction from the odd result and divide by two
		odd_pi16 = _mm_subs_pi16(odd_pi16, quad_pi16);
		odd_pi16 = _mm_srai_pi16(odd_pi16, 1);

		// Store the even and odd groups of horizontal highpass coefficients
		*(even_highpass_ptr++) = even_pi16;
		*(odd_highpass_ptr++) = odd_pi16;
	}

	// Should have exited the loop at the post processing column
	assert(column == post_column);

#endif

	// Process the rest of the row
	for (; column < width; column++)
	{
		int32_t even = 0;		// Result of convolution with even filter
		int32_t odd = 0;		// Result of convolution with odd filter


		/***** Compute the vertical inverse for the left two bands *****/

		// Apply the even reconstruction filter to the lowpass band
		even += lowlow[column + 0 * lowlow_pitch];
		even -= lowlow[column + 2 * lowlow_pitch];
		even += 4; //DAN20050921
		even >>= 3;
		even += lowlow[column + 1 * lowlow_pitch];

		// Add the highpass correction
		even += highlow[column];
		even = DivideByShift(even, 1);

		// Place the even result in the even row
		even_lowpass[column] = SATURATE(even);

		// Apply the odd reconstruction filter to the lowpass band
		odd -= lowlow[column + 0 * lowlow_pitch];
		odd += lowlow[column + 2 * lowlow_pitch];
		odd += 4; //DAN20050921
		odd >>= 3;
		odd += lowlow[column + 1 * lowlow_pitch];

		// Subtract the highpass correction
		odd -= highlow[column];
		odd = DivideByShift(odd, 1);

		// Place the odd result in the odd row
		odd_lowpass[column] = SATURATE(odd);


		/***** Compute the vertical inverse for the right two bands *****/

		even = 0;
		odd = 0;

		// Apply the even reconstruction filter to the lowpass band
		even += lowhigh[column + 0 * lowhigh_pitch];
		even -= lowhigh[column + 2 * lowhigh_pitch];
		even += 4; //DAN20050921
		even >>= 3;
		even += lowhigh[column + 1 * lowhigh_pitch];

		// Add the highpass correction
		even += highhigh[column];
		even = DivideByShift(even, 1);

		// Place the even result in the even row
		even_highpass[column] = SATURATE(even);

		// Apply the odd reconstruction filter to the lowpass band
		odd -= lowhigh[column + 0 * lowhigh_pitch];
		odd += lowhigh[column + 2 * lowhigh_pitch];
		odd += 4; //DAN20050921
		odd >>= 3;
		odd += lowhigh[column + 1 * lowhigh_pitch];

		// Subtract the highpass correction
		odd -= highhigh[column];
		odd = DivideByShift(odd, 1);

		// Place the odd result in the odd row
		odd_highpass[column] = SATURATE(odd);
	}

	// Apply the inverse horizontal transform to the even and odd rows
	InvertHorizontalStrip16sToRow16u(lowpass, lowpass_pitch,
									 highpass, highpass_pitch,
									 output, (int)output_row_size, strip,
									 precision);

#if (0 && XMMOPT) //DANREMOVED
	//_mm_empty();	// Clear the mmx register state
#endif
}

void InvertSpatialBottomRow16sToYUV16(PIXEL *lowlow_band, int lowlow_pitch,
									  PIXEL *lowhigh_band, int lowhigh_pitch,
									  PIXEL *highlow_band, int highlow_pitch,
									  PIXEL *highhigh_band, int highhigh_pitch,
									  PIXEL16U *output, int output_pitch,
									  int row, int width,
									  PIXEL *buffer, size_t buffer_size,
									  int precision)
{
	PIXEL *lowlow = lowlow_band;
	PIXEL *lowhigh = lowhigh_band;
	PIXEL *highlow = highlow_band;
	PIXEL *highhigh = highhigh_band;
	PIXEL *even_lowpass;
	PIXEL *even_highpass;
	PIXEL *odd_lowpass;
	PIXEL *odd_highpass;
	PIXEL *lowpass;					// Strip of horizontal coefficients
	PIXEL *highpass;
	int lowpass_pitch;				// Distance between strip rows in bytes
	int highpass_pitch;
	ROI strip;						// Dimensions of the processing strip
	size_t buffer_row_size;
	size_t output_row_size = output_pitch;
	int buffer_half_pitch;
	int buffer_width;
	int buffer_pitch;
	int column;

	// Convert pitch from bytes to pixels
	lowlow_pitch /= sizeof(PIXEL);
	lowhigh_pitch /= sizeof(PIXEL);
	highlow_pitch /= sizeof(PIXEL);
	highhigh_pitch /= sizeof(PIXEL);
	output_pitch /= sizeof(PIXEL16U);

	// Compute the address of the first row for processing in each wavelet band
	lowlow += row * lowlow_pitch;
	lowhigh += row * lowhigh_pitch;
	highlow += row * highlow_pitch;
	highhigh += row * highhigh_pitch;

	// Compute positions within the temporary buffer for each row of horizontal lowpass
	// and highpass intermediate coefficients computed by the vertical inverse transform
	buffer_row_size = width * sizeof(PIXEL);
	buffer_row_size = ALIGN16(buffer_row_size);
	buffer_half_pitch = (int)buffer_row_size/sizeof(PIXEL);
	buffer_pitch = 2 * buffer_half_pitch;
	buffer_width = width;

	// Check that the buffer is large enough to hold four rows of coefficients
	assert(buffer_size >= (4 * buffer_row_size));

	// Set the dimensions of the processing strip
	strip.width = buffer_width;
	strip.height = 2;

	// Compute the positions of the even and odd rows of coefficients
	even_lowpass = &buffer[0];
	even_highpass = &buffer[buffer_half_pitch];
	odd_lowpass = &buffer[2 * buffer_half_pitch];
	odd_highpass = &buffer[3 * buffer_half_pitch];

	// Pointers into the strip of horizontal coefficients
	lowpass = even_lowpass;
	highpass = even_highpass;
	lowpass_pitch = (int)(2 * buffer_row_size);
	highpass_pitch = (int)(2 * buffer_row_size);

	// Apply the vertical border filter to the last row
	for (column = 0; column < width; column++)
	{
		int32_t even = 0;		// Result of convolution with even filter
		int32_t odd = 0;		// Result of convolution with odd filter


		// Compute the vertical inverse for the left two bands //

		// Apply the even reconstruction filter to the lowpass band
		even += 5 * lowlow[column + 0 * lowlow_pitch];
		even += 4 * lowlow[column - 1 * lowlow_pitch];
		even -= 1 * lowlow[column - 2 * lowlow_pitch];
		even += ROUNDING(even,8);
		even = DivideByShift(even, 3);

		// Add the highpass correction
		even += highlow[column];
		even = DivideByShift(even, 1);

		// Place the even result in the even row
		even_lowpass[column] = SATURATE(even);

		// Apply the odd reconstruction filter to the lowpass band
		odd += 11 * lowlow[column + 0 * lowlow_pitch];
		odd -=  4 * lowlow[column - 1 * lowlow_pitch];
		odd +=  1 * lowlow[column - 2 * lowlow_pitch];
		odd += ROUNDING(odd,8);
		odd = DivideByShift(odd, 3);

		// Subtract the highpass correction
		odd -= highlow[column];
		odd = DivideByShift(odd, 1);

		// Place the odd result in the odd row
		odd_lowpass[column] = SATURATE(odd);


		// Compute the vertical inverse for the right two bands //

		even = 0;
		odd = 0;

		// Apply the even reconstruction filter to the lowpass band
		even += 5 * lowhigh[column + 0 * lowhigh_pitch];
		even += 4 * lowhigh[column - 1 * lowhigh_pitch];
		even -= 1 * lowhigh[column - 2 * lowhigh_pitch];
		even += ROUNDING(even,8);
		even = DivideByShift(even, 3);

		// Add the highpass correction
		even += highhigh[column];
		even = DivideByShift(even, 1);

		// Place the even result in the even row
		even_highpass[column] = SATURATE(even);

		// Apply the odd reconstruction filter to the lowpass band
		odd += 11 * lowhigh[column + 0 * lowhigh_pitch];
		odd -=  4 * lowhigh[column - 1 * lowhigh_pitch];
		odd +=  1 * lowhigh[column - 2 * lowhigh_pitch];
		odd += ROUNDING(odd,8);
		odd = DivideByShift(odd, 3);

		// Subtract the highpass correction
		odd -= highhigh[column];
		odd = DivideByShift(odd, 1);

		// Place the odd result in the odd row
		odd_highpass[column] = SATURATE(odd);
	}

	// Apply the inverse horizontal transform to the even and odd rows
	InvertHorizontalStrip16sToRow16u(lowpass, lowpass_pitch,
									 highpass, highpass_pitch,
									 output, (int)output_row_size, strip,
									 precision);
}

#if 0
void InvertRGB444TopRow16sToB64A(PIXEL *lowlow_band, int lowlow_pitch,
								 PIXEL *lowhigh_band, int lowhigh_pitch,
								 PIXEL *highlow_band, int highlow_pitch,
								 PIXEL *highhigh_band, int highhigh_pitch,
								 PIXEL16U *output, int output_pitch,
								 int row, int width,
								 PIXEL *buffer, size_t buffer_size,
								 int precision)
{
	PIXEL *lowlow = lowlow_band;
	PIXEL *lowhigh = lowhigh_band;
	PIXEL *highlow = highlow_band;
	PIXEL *highhigh = highhigh_band;
	PIXEL *even_lowpass;
	PIXEL *even_highpass;
	PIXEL *odd_lowpass;
	PIXEL *odd_highpass;
	PIXEL *even_output;
	PIXEL *odd_output;
	PIXEL *lowpass;					// Strip of horizontal coefficients
	PIXEL *highpass;
	int lowpass_pitch;				// Distance between strip rows in bytes
	int highpass_pitch;
	ROI strip;						// Dimensions of the processing strip
	size_t buffer_row_size;
	size_t output_row_size = output_pitch;
	int buffer_half_pitch;
	int buffer_width;
	int buffer_pitch;
	int column;

	// Convert pitch from bytes to pixels
	lowlow_pitch /= sizeof(PIXEL);
	lowhigh_pitch /= sizeof(PIXEL);
	highlow_pitch /= sizeof(PIXEL);
	highhigh_pitch /= sizeof(PIXEL);
	output_pitch /= sizeof(PIXEL16U);

	// Compute positions within the temporary buffer for each row of horizontal lowpass
	// and highpass intermediate coefficients computed by the vertical inverse transform
	buffer_row_size = width * sizeof(PIXEL);
	buffer_row_size = ALIGN16(buffer_row_size);
	buffer_half_pitch = buffer_row_size/sizeof(PIXEL);
	buffer_pitch = 2 * buffer_half_pitch;
	buffer_width = width;

	// Check that the buffer is large enough to hold four rows of coefficients
	assert(buffer_size >= (4 * buffer_row_size));

	// Set the dimensions of the processing strip
	strip.width = buffer_width;
	strip.height = 2;

	// Compute the positions of the even and odd rows of coefficients
	even_lowpass = &buffer[0];
	even_highpass = &buffer[buffer_half_pitch];
	odd_lowpass = &buffer[2 * buffer_half_pitch];
	odd_highpass = &buffer[3 * buffer_half_pitch];

	// Pointers into the strip of horizontal coefficients
	lowpass = even_lowpass;
	highpass = even_highpass;
	lowpass_pitch = 2 * buffer_row_size;
	highpass_pitch = 2 * buffer_row_size;

	// This routine should be called for the first row
	assert(row == 0);

	// Apply the vertical border filter to the first row
	for (column = 0; column < width; column++)
	{
		int32_t even = 0;		// Result of convolution with even filter
		int32_t odd = 0;		// Result of convolution with odd filter


		/***** Compute the vertical inverse for the left two bands *****/

		// Apply the even reconstruction filter to the lowpass band
		even += 11 * lowlow[column + 0 * lowlow_pitch];
		even -=  4 * lowlow[column + 1 * lowlow_pitch];
		even +=  1 * lowlow[column + 2 * lowlow_pitch];
		even += ROUNDING(even,8);
		even = DivideByShift(even, 3);

		// Add the highpass correction
		even += highlow[column];
		even = DivideByShift(even, 1);

		// Place the even result in the even row
		even_lowpass[column] = SATURATE(even);

		// Apply the odd reconstruction filter to the lowpass band
		odd += 5 * lowlow[column + 0 * lowlow_pitch];
		odd += 4 * lowlow[column + 1 * lowlow_pitch];
		odd -= 1 * lowlow[column + 2 * lowlow_pitch];
		odd += ROUNDING(odd,8);
		odd = DivideByShift(odd, 3);

		// Subtract the highpass correction
		odd -= highlow[column];
		odd = DivideByShift(odd, 1);

		// Place the odd result in the odd row
		odd_lowpass[column] = SATURATE(odd);


		/***** Compute the vertical inverse for the right two bands *****/

		even = 0;
		odd = 0;

		// Apply the even reconstruction filter to the lowpass band
		even += 11 * lowhigh[column + 0 * lowhigh_pitch];
		even -=  4 * lowhigh[column + 1 * lowhigh_pitch];
		even +=  1 * lowhigh[column + 2 * lowhigh_pitch];
		even += ROUNDING(even,8);
		even = DivideByShift(even, 3);

		// Add the highpass correction
		even += highhigh[column];
		even = DivideByShift(even, 1);

		// Place the even result in the even row
		even_highpass[column] = SATURATE(even);

		// Apply the odd reconstruction filter to the lowpass band
		odd += 5 * lowhigh[column + 0 * lowhigh_pitch];
		odd += 4 * lowhigh[column + 1 * lowhigh_pitch];
		odd -= 1 * lowhigh[column + 2 * lowhigh_pitch];
		odd += ROUNDING(odd,8);
		odd = DivideByShift(odd, 3);

		// Subtract the highpass correction
		odd -= highhigh[column];
		odd = DivideByShift(odd, 1);

		// Place the odd result in the odd row
		odd_highpass[column] = SATURATE(odd);
	}

	// Apply the inverse horizontal transform to the even and odd rows
	InvertHorizontalStripRGB444ToB64A(lowpass, lowpass_pitch,
									  highpass, highpass_pitch,
									  output, output_row_size, strip,
									  precision);
}

void InvertRGB444MiddleRow16sToB64A(PIXEL *lowlow_band, int lowlow_pitch,
									PIXEL *lowhigh_band, int lowhigh_pitch,
									PIXEL *highlow_band, int highlow_pitch,
									PIXEL *highhigh_band, int highhigh_pitch,
									PIXEL16U *output, int output_pitch,
									int row, int width,
									PIXEL *buffer, size_t buffer_size,
									int precision)
{
	PIXEL *lowlow = lowlow_band;
	PIXEL *lowhigh = lowhigh_band;
	PIXEL *highlow = highlow_band;
	PIXEL *highhigh = highhigh_band;
	PIXEL *even_lowpass;
	PIXEL *even_highpass;
	PIXEL *odd_lowpass;
	PIXEL *odd_highpass;
	PIXEL *even_output;
	PIXEL *odd_output;
	PIXEL *lowpass;					// Strip of horizontal coefficients
	PIXEL *highpass;
	int lowpass_pitch;				// Distance between strip rows in bytes
	int highpass_pitch;
	ROI strip;						// Dimensions of the processing strip
	size_t buffer_row_size;
	size_t output_row_size = output_pitch;
	int buffer_half_pitch;
	int buffer_width;
	int buffer_pitch;
	int column;

#if (1 && XMMOPT)
	const int column_step = 4;
	int post_column = width - (width % column_step);

	__m64 *even_lowpass_ptr;
	__m64 *even_highpass_ptr;
	__m64 *odd_lowpass_ptr;
	__m64 *odd_highpass_ptr;
#endif

	// This routine should not be called to process the first row
	assert(row > 0);

	// Convert pitch from bytes to pixels
	lowlow_pitch /= sizeof(PIXEL);
	lowhigh_pitch /= sizeof(PIXEL);
	highlow_pitch /= sizeof(PIXEL);
	highhigh_pitch /= sizeof(PIXEL);
	output_pitch /= sizeof(PIXEL16U);

	// Compute the address of the first row for processing in each wavelet band
	lowlow += (row - 1) * lowlow_pitch;
	lowhigh += (row - 1) * lowhigh_pitch;
	highlow += row * highlow_pitch;
	highhigh += row * highhigh_pitch;

	// Compute positions within the temporary buffer for each row of horizontal lowpass
	// and highpass intermediate coefficients computed by the vertical inverse transform
	buffer_row_size = width * sizeof(PIXEL);
	buffer_row_size = ALIGN16(buffer_row_size);
	buffer_half_pitch = buffer_row_size/sizeof(PIXEL);
	buffer_pitch = 2 * buffer_half_pitch;
	buffer_width = width;

	// Check that the buffer is large enough to hold four rows of coefficients
	assert(buffer_size >= (4 * buffer_row_size));

	// Set the dimensions of the processing strip
	strip.width = buffer_width;
	strip.height = 2;

	// Compute the positions of the even and odd rows of coefficients
	even_lowpass = &buffer[0];
	even_highpass = &buffer[buffer_half_pitch];
	odd_lowpass = &buffer[2 * buffer_half_pitch];
	odd_highpass = &buffer[3 * buffer_half_pitch];

	// Pointers into the strip of horizontal coefficients
	lowpass = even_lowpass;
	highpass = even_highpass;
	lowpass_pitch = 2 * buffer_row_size;
	highpass_pitch = 2 * buffer_row_size;

	// Start at the first column
	column = 0;

#if (1 && XMMOPT)

	even_lowpass_ptr = (__m64 *)even_lowpass;
	even_highpass_ptr = (__m64 *)even_highpass;
	odd_lowpass_ptr = (__m64 *)odd_lowpass;
	odd_highpass_ptr = (__m64 *)odd_highpass;

	// Process groups of four coefficients along the row
	for (; column < post_column; column += column_step)
	{
		__m64 *lowlow_ptr = (__m64 *)&lowlow[column];
		__m64 *highlow_ptr = (__m64 *)&highlow[column];
		__m64 *lowhigh_ptr = (__m64 *)&lowhigh[column];
		__m64 *highhigh_ptr = (__m64 *)&highhigh[column];
		__m64 quad_pi16;
		__m64 even_pi16;
		__m64 odd_pi16;
		__m64 mid_pi16;
		__m64 half_pi16 = _mm_set1_pi16(4); //DAN031604 4 to 6


		/***** Compute the vertical inverse for the left two bands *****/

		// Set the pitch for the lowpass band used in this section of code
		int quad_pitch = (lowlow_pitch * sizeof(PIXEL))/sizeof(__m64);

		// Accumulate parallel sums for the even and odd filters
		quad_pi16 = *lowlow_ptr;	// Get four lowpass coefficients
		lowlow_ptr += quad_pitch;	// Advance to the next row

		even_pi16 = quad_pi16;
		odd_pi16 = _mm_subs_pi16(_mm_setzero_si64(), quad_pi16);

		mid_pi16 = *lowlow_ptr;	// Get four lowpass coefficients
		lowlow_ptr += quad_pitch;	// Advance to the next row

		quad_pi16 = *lowlow_ptr;	// Get four lowpass coefficients

		even_pi16 = _mm_subs_pi16(even_pi16, quad_pi16);
		odd_pi16 = _mm_adds_pi16(odd_pi16, quad_pi16);

		even_pi16 = _mm_adds_pi16(even_pi16, half_pi16);
		odd_pi16 = _mm_adds_pi16(odd_pi16, half_pi16);

		even_pi16 = _mm_srai_pi16(even_pi16, 3);
		odd_pi16 = _mm_srai_pi16(odd_pi16, 3);

		even_pi16 = _mm_adds_pi16(even_pi16, mid_pi16);
		odd_pi16 = _mm_adds_pi16(odd_pi16, mid_pi16);


		// Add the highpass correction to the even result and divide by two
		quad_pi16 = *highlow_ptr;
		even_pi16 = _mm_adds_pi16(even_pi16, quad_pi16);
		even_pi16 = _mm_srai_pi16(even_pi16, 1);

		// Subtract the highpass correction from the odd result and divide by two
		odd_pi16 = _mm_subs_pi16(odd_pi16, quad_pi16);
		odd_pi16 = _mm_srai_pi16(odd_pi16, 1);

		// Store the even and odd groups of horizontal lowpass coefficients
		*(even_lowpass_ptr++) = even_pi16;
		*(odd_lowpass_ptr++) = odd_pi16;


		/***** Compute the vertical inverse for the right two bands *****/

		// Set the pitch for the lowpass band used in this section of code
		quad_pitch = (lowhigh_pitch * sizeof(PIXEL))/sizeof(__m64);

		// Accumulate parallel sums for the even and odd filters
		quad_pi16 = *lowhigh_ptr;	// Get four lowpass coefficients
		lowhigh_ptr += quad_pitch;	// Advance to the next row

		even_pi16 = quad_pi16;
		odd_pi16 = _mm_subs_pi16(_mm_setzero_si64(), quad_pi16);

		mid_pi16 = *lowhigh_ptr;	// Get four lowpass coefficients
		lowhigh_ptr += quad_pitch;	// Advance to the next row

		quad_pi16 = *lowhigh_ptr;	// Get four lowpass coefficients

		even_pi16 = _mm_subs_pi16(even_pi16, quad_pi16);
		odd_pi16 = _mm_adds_pi16(odd_pi16, quad_pi16);

		even_pi16 = _mm_adds_pi16(even_pi16, half_pi16);
		odd_pi16 = _mm_adds_pi16(odd_pi16, half_pi16);

		even_pi16 = _mm_srai_pi16(even_pi16, 3);
		odd_pi16 = _mm_srai_pi16(odd_pi16, 3);

		even_pi16 = _mm_adds_pi16(even_pi16, mid_pi16);
		odd_pi16 = _mm_adds_pi16(odd_pi16, mid_pi16);


		// Add the highpass correction to the even result and divide by two
		quad_pi16 = *highhigh_ptr;
		even_pi16 = _mm_adds_pi16(even_pi16, quad_pi16);
		even_pi16 = _mm_srai_pi16(even_pi16, 1);

		// Subtract the highpass correction from the odd result and divide by two
		odd_pi16 = _mm_subs_pi16(odd_pi16, quad_pi16);
		odd_pi16 = _mm_srai_pi16(odd_pi16, 1);

		// Store the even and odd groups of horizontal highpass coefficients
		*(even_highpass_ptr++) = even_pi16;
		*(odd_highpass_ptr++) = odd_pi16;
	}

	// Should have exited the loop at the post processing column
	assert(column == post_column);

#endif

	// Process the rest of the row
	for (; column < width; column++)
	{
		int32_t even = 0;		// Result of convolution with even filter
		int32_t odd = 0;		// Result of convolution with odd filter


		/***** Compute the vertical inverse for the left two bands *****/

		// Apply the even reconstruction filter to the lowpass band
		even += lowlow[column + 0 * lowlow_pitch];
		even -= lowlow[column + 2 * lowlow_pitch];
		even += 4; //DAN20050921
		even >>= 3;
		even += lowlow[column + 1 * lowlow_pitch];

		// Add the highpass correction
		even += highlow[column];
		even = DivideByShift(even, 1);

		// Place the even result in the even row
		even_lowpass[column] = SATURATE(even);

		// Apply the odd reconstruction filter to the lowpass band
		odd -= lowlow[column + 0 * lowlow_pitch];
		odd += lowlow[column + 2 * lowlow_pitch];
		odd += 4; //DAN20050921
		odd >>= 3;
		odd += lowlow[column + 1 * lowlow_pitch];

		// Subtract the highpass correction
		odd -= highlow[column];
		odd = DivideByShift(odd, 1);

		// Place the odd result in the odd row
		odd_lowpass[column] = SATURATE(odd);


		/***** Compute the vertical inverse for the right two bands *****/

		even = 0;
		odd = 0;

		// Apply the even reconstruction filter to the lowpass band
		even += lowhigh[column + 0 * lowhigh_pitch];
		even -= lowhigh[column + 2 * lowhigh_pitch];
		even += 4; //DAN20050921
		even >>= 3;
		even += lowhigh[column + 1 * lowhigh_pitch];

		// Add the highpass correction
		even += highhigh[column];
		even = DivideByShift(even, 1);

		// Place the even result in the even row
		even_highpass[column] = SATURATE(even);

		// Apply the odd reconstruction filter to the lowpass band
		odd -= lowhigh[column + 0 * lowhigh_pitch];
		odd += lowhigh[column + 2 * lowhigh_pitch];
		odd += 4; //DAN20050921
		odd >>= 3;
		odd += lowhigh[column + 1 * lowhigh_pitch];

		// Subtract the highpass correction
		odd -= highhigh[column];
		odd = DivideByShift(odd, 1);

		// Place the odd result in the odd row
		odd_highpass[column] = SATURATE(odd);
	}

	// Apply the inverse horizontal transform to the even and odd rows
	InvertHorizontalStripRGB444ToB64A(lowpass, lowpass_pitch,
									  highpass, highpass_pitch,
									  output, output_row_size, strip,
									  precision);

	//_mm_empty();	// Clear the mmx register state
}

void InvertRGB444BottomRow16sToB64A(PIXEL *lowlow_band, int lowlow_pitch,
									PIXEL *lowhigh_band, int lowhigh_pitch,
									PIXEL *highlow_band, int highlow_pitch,
									PIXEL *highhigh_band, int highhigh_pitch,
									PIXEL16U *output, int output_pitch,
									int row, int width,
									PIXEL *buffer, size_t buffer_size,
									int precision)
{
	PIXEL *lowlow = lowlow_band;
	PIXEL *lowhigh = lowhigh_band;
	PIXEL *highlow = highlow_band;
	PIXEL *highhigh = highhigh_band;
	PIXEL *even_lowpass;
	PIXEL *even_highpass;
	PIXEL *odd_lowpass;
	PIXEL *odd_highpass;
	PIXEL *even_output;
	PIXEL *odd_output;
	PIXEL *lowpass;					// Strip of horizontal coefficients
	PIXEL *highpass;
	int lowpass_pitch;				// Distance between strip rows in bytes
	int highpass_pitch;
	ROI strip;						// Dimensions of the processing strip
	size_t buffer_row_size;
	size_t output_row_size = output_pitch;
	int buffer_half_pitch;
	int buffer_width;
	int buffer_pitch;
	int column;

	// Convert pitch from bytes to pixels
	lowlow_pitch /= sizeof(PIXEL);
	lowhigh_pitch /= sizeof(PIXEL);
	highlow_pitch /= sizeof(PIXEL);
	highhigh_pitch /= sizeof(PIXEL);
	output_pitch /= sizeof(PIXEL16U);

	// Compute the address of the first row for processing in each wavelet band
	lowlow += row * lowlow_pitch;
	lowhigh += row * lowhigh_pitch;
	highlow += row * highlow_pitch;
	highhigh += row * highhigh_pitch;

	// Compute positions within the temporary buffer for each row of horizontal lowpass
	// and highpass intermediate coefficients computed by the vertical inverse transform
	buffer_row_size = width * sizeof(PIXEL);
	buffer_row_size = ALIGN16(buffer_row_size);
	buffer_half_pitch = buffer_row_size/sizeof(PIXEL);
	buffer_pitch = 2 * buffer_half_pitch;
	buffer_width = width;

	// Check that the buffer is large enough to hold four rows of coefficients
	assert(buffer_size >= (4 * buffer_row_size));

	// Set the dimensions of the processing strip
	strip.width = buffer_width;
	strip.height = 2;

	// Compute the positions of the even and odd rows of coefficients
	even_lowpass = &buffer[0];
	even_highpass = &buffer[buffer_half_pitch];
	odd_lowpass = &buffer[2 * buffer_half_pitch];
	odd_highpass = &buffer[3 * buffer_half_pitch];

	// Pointers into the strip of horizontal coefficients
	lowpass = even_lowpass;
	highpass = even_highpass;
	lowpass_pitch = 2 * buffer_row_size;
	highpass_pitch = 2 * buffer_row_size;

	// Apply the vertical border filter to the last row
	for (column = 0; column < width; column++)
	{
		int32_t even = 0;		// Result of convolution with even filter
		int32_t odd = 0;		// Result of convolution with odd filter


		// Compute the vertical inverse for the left two bands //

		// Apply the even reconstruction filter to the lowpass band
		even += 5 * lowlow[column + 0 * lowlow_pitch];
		even += 4 * lowlow[column - 1 * lowlow_pitch];
		even -= 1 * lowlow[column - 2 * lowlow_pitch];
		even += ROUNDING(even,8);
		even = DivideByShift(even, 3);

		// Add the highpass correction
		even += highlow[column];
		even = DivideByShift(even, 1);

		// Place the even result in the even row
		even_lowpass[column] = SATURATE(even);

		// Apply the odd reconstruction filter to the lowpass band
		odd += 11 * lowlow[column + 0 * lowlow_pitch];
		odd -=  4 * lowlow[column - 1 * lowlow_pitch];
		odd +=  1 * lowlow[column - 2 * lowlow_pitch];
		odd += ROUNDING(odd,8);
		odd = DivideByShift(odd, 3);

		// Subtract the highpass correction
		odd -= highlow[column];
		odd = DivideByShift(odd, 1);

		// Place the odd result in the odd row
		odd_lowpass[column] = SATURATE(odd);


		// Compute the vertical inverse for the right two bands //

		even = 0;
		odd = 0;

		// Apply the even reconstruction filter to the lowpass band
		even += 5 * lowhigh[column + 0 * lowhigh_pitch];
		even += 4 * lowhigh[column - 1 * lowhigh_pitch];
		even -= 1 * lowhigh[column - 2 * lowhigh_pitch];
		even += ROUNDING(even,8);
		even = DivideByShift(even, 3);

		// Add the highpass correction
		even += highhigh[column];
		even = DivideByShift(even, 1);

		// Place the even result in the even row
		even_highpass[column] = SATURATE(even);

		// Apply the odd reconstruction filter to the lowpass band
		odd += 11 * lowhigh[column + 0 * lowhigh_pitch];
		odd -=  4 * lowhigh[column - 1 * lowhigh_pitch];
		odd +=  1 * lowhigh[column - 2 * lowhigh_pitch];
		odd += ROUNDING(odd,8);
		odd = DivideByShift(odd, 3);

		// Subtract the highpass correction
		odd -= highhigh[column];
		odd = DivideByShift(odd, 1);

		// Place the odd result in the odd row
		odd_highpass[column] = SATURATE(odd);
	}

	// Apply the inverse horizontal transform to the even and odd rows
	InvertHorizontalStripRGB444ToB64A(lowpass, lowpass_pitch,
									  highpass, highpass_pitch,
									  output, output_row_size, strip,
									  precision);
}
#endif

#if 0

// This subroutine differs from InvertHorizontalFast16s() in that the division by 2 operations are
// taken out. It is called only by InvertSpatial8s() and InvertSpatialQuant8s().

// Apply the horizontal inverse wavelet filter (fast mode)
static void InvertHorizontalNoShift16s(PIXEL *lowpass, int lowpass_pitch,
									   PIXEL *highpass, int highpass_pitch,
									   PIXEL *output, int output_pitch, ROI roi)
{
	int row, column;

	// Convert pitch from bytes to pixels
	lowpass_pitch /= sizeof(PIXEL);
	highpass_pitch /= sizeof(PIXEL);
	output_pitch /= sizeof(PIXEL);

	for (row = 0; row < roi.height; row++)
	{
		const int column_step = 4;
		const int last_column = roi.width - 1;
		int post_column = last_column - (last_column % column_step);

		__m64 low1_pi16;	// Lowpass coefficients
		__m64 low2_pi16;
		__m64 high1_pi16;	// Highpass coefficients
		__m64 high2_pi16;

		// The fast loop computes output points starting at the third column
		__m64 *outptr = (__m64 *)&output[2];

		PIXEL *colptr;

		int32_t even;
		int32_t odd;
		int32_t lsb;

		// Adjust the end of the fast loop if necessary
		if (post_column == last_column)
			post_column -= column_step;

		// Start processing at the beginning of the row
		column = 0;

		// Process the first two output points with special filters for the left border
		even = 0;
		odd = 0;

		// Apply the even reconstruction filter to the lowpass band
		even += 11 * lowpass[column + 0];
		even -=  4 * lowpass[column + 1];
		even +=  1 * lowpass[column + 2];
		even += ROUNDING(even,8);
		even = DivideByShift(even, 3);

		// Add the highpass correction
		even += highpass[column];
//		even = DivideByShift(even, 1);

		// Place the even result in the even column
		output[0] = SATURATE(even);

		// Apply the odd reconstruction filter to the lowpass band
		odd += 5 * lowpass[column + 0];
		odd += 4 * lowpass[column + 1];
		odd -= 1 * lowpass[column + 2];
		odd += ROUNDING(odd,8);
		odd = DivideByShift(odd, 3);

		// Subtract the highpass correction
		odd -= highpass[column];
//		odd = DivideByShift(odd, 1);

		// Place the odd result in the odd column
		output[1] = SATURATE(odd);

		// Preload the first four lowpass coefficients
		low1_pi16 = *((__m64 *)&lowpass[column]);

		// Preload the first four highpass coefficients
		high1_pi16 = *((__m64 *)&highpass[column]);

		// The reconstruction filters use pixels starting at the first column
		for (; column < post_column; column += column_step)
		{
			__m64 even_pi16;	// Result of convolution with even filter
			__m64 odd_pi16;		// Result of convolution with odd filter
			__m64 temp_pi16;
			__m64 out_pi16;		// Reconstructed data
			__m64 mask_pi16;
			__m64 half_pi16;
			__m64 lsb_pi16;
			__m64 sign_pi16;

			// Preload the next four lowpass coefficients
			low2_pi16 = *((__m64 *)&lowpass[column+4]);


			// Compute the first two even and two odd output points //

			// Apply the even reconstruction filter to the lowpass band
			even_pi16 = low1_pi16;
			temp_pi16 = _mm_slli_pi16(low1_pi16, 3);
			temp_pi16 = _mm_shuffle_pi16(temp_pi16, _MM_SHUFFLE(0, 3, 2, 1));
			even_pi16 = _mm_adds_pi16(even_pi16, temp_pi16);
			temp_pi16 = _mm_shuffle_pi16(low1_pi16, _MM_SHUFFLE(1, 0, 3, 2));
			even_pi16 = _mm_subs_pi16(even_pi16, temp_pi16);

			// Apply the rounding adjustment
			even_pi16 = _mm_adds_pi16(even_pi16, _mm_set1_pi16(4));
			// Divide by eight
			even_pi16 = _mm_srai_pi16(even_pi16, 3);

			// Shift the highpass correction by one column
			high1_pi16 = _mm_srli_si64(high1_pi16, 16);

			// Add the highpass correction
			even_pi16 = _mm_adds_pi16(even_pi16, high1_pi16);
//			even_pi16 = _mm_srai_pi16(even_pi16, 1);

			// Apply the odd reconstruction filter to the lowpass band
			odd_pi16 = _mm_slli_pi16(low1_pi16, 3);
			odd_pi16 = _mm_shuffle_pi16(odd_pi16, _MM_SHUFFLE(0, 3, 2, 1));
			temp_pi16 = _mm_shuffle_pi16(low1_pi16, _MM_SHUFFLE(1, 0, 3, 2));
			odd_pi16 = _mm_adds_pi16(odd_pi16, temp_pi16);
			odd_pi16 = _mm_subs_pi16(odd_pi16, low1_pi16);

			// Apply the rounding adjustment
			odd_pi16 = _mm_adds_pi16(odd_pi16, _mm_set1_pi16(4));
			// Divide by eight
			odd_pi16 = _mm_srai_pi16(odd_pi16, 3);

			// Subtract the highpass correction
			odd_pi16 = _mm_subs_pi16(odd_pi16, high1_pi16);
//			odd_pi16 = _mm_srai_pi16(odd_pi16, 1);

			// Interleave the even and odd results
			out_pi16 = _mm_unpacklo_pi16(even_pi16, odd_pi16);
			//out_pi16 = _mm_max_pi16(out_pi16, _mm_setzero_si64());
			*(outptr++) = out_pi16;


			// Compute the second two even and two odd output points //

			// Preload the highpass correction
			high2_pi16 = *((__m64 *)&highpass[column+4]);

			// Shift in the new pixels for the next stage of the loop
			low1_pi16 = _mm_srli_si64(low1_pi16, 32);
			temp_pi16 = _mm_slli_si64(low2_pi16, 32);
			low1_pi16 = _mm_or_si64(low1_pi16, temp_pi16);

			// Apply the even reconstruction filter to the lowpass band
			even_pi16 = low1_pi16;
			temp_pi16 = _mm_slli_pi16(low1_pi16, 3);
			temp_pi16 = _mm_shuffle_pi16(temp_pi16, _MM_SHUFFLE(0, 3, 2, 1));
			even_pi16 = _mm_adds_pi16(even_pi16, temp_pi16);
			temp_pi16 = _mm_shuffle_pi16(low1_pi16, _MM_SHUFFLE(1, 0, 3, 2));
			even_pi16 = _mm_subs_pi16(even_pi16, temp_pi16);

			// Apply the rounding adjustment
			even_pi16 = _mm_adds_pi16(even_pi16, _mm_set1_pi16(4));
			// Divide by eight
			even_pi16 = _mm_srai_pi16(even_pi16, 3);

			// Shift in the next two highpass coefficients
			high1_pi16 = _mm_srli_si64(high1_pi16, 2*16);
			high1_pi16 = _mm_or_si64(high1_pi16, _mm_slli_si64(high2_pi16, 16));

			// Add the highpass correction
			even_pi16 = _mm_adds_pi16(even_pi16, high1_pi16);
//			even_pi16 = _mm_srai_pi16(even_pi16, 1);

			// Apply the odd reconstruction filter to the lowpass band
			odd_pi16 = _mm_slli_pi16(low1_pi16, 3);
			odd_pi16 = _mm_shuffle_pi16(odd_pi16, _MM_SHUFFLE(0, 3, 2, 1));
			temp_pi16 = _mm_shuffle_pi16(low1_pi16, _MM_SHUFFLE(1, 0, 3, 2));
			odd_pi16 = _mm_adds_pi16(odd_pi16, temp_pi16);
			odd_pi16 = _mm_subs_pi16(odd_pi16, low1_pi16);

			// Apply the rounding adjustment
			odd_pi16 = _mm_adds_pi16(odd_pi16, _mm_set1_pi16(4));
			// Divide by eight
			odd_pi16 = _mm_srai_pi16(odd_pi16, 3);

			// Subtract the highpass correction
			odd_pi16 = _mm_subs_pi16(odd_pi16, high1_pi16);
//			odd_pi16 = _mm_srai_pi16(odd_pi16, 1);

			// Interleave the even and odd results
			out_pi16 = _mm_unpacklo_pi16(even_pi16, odd_pi16);
			//out_pi16 = _mm_max_pi16(out_pi16, _mm_setzero_si64());
			*(outptr++) = out_pi16;

			// The second four lowpass coefficients will be the current values
			low1_pi16 = low2_pi16;

			// The second four highpass coefficients will be the current values
			high1_pi16 = high2_pi16;
		}

		// Should have exited the loop with the column equal to the post processing column
		assert(column == post_column);

		// The fast processing loop is one column behind the actual column
		column++;

		// Process the rest of the columns up to the last column in the row
		colptr = (PIXEL *)outptr;

		for (; column < last_column; column++)
		{
			int32_t even = 0;		// Result of convolution with even filter
			int32_t odd = 0;		// Result of convolution with odd filter

			// Apply the even reconstruction filter to the lowpass band
			even += lowpass[column - 1];
			even -= lowpass[column + 1];
			even += ROUNDING(even,8);
			even = DivideByShift(even, 3);
			even += lowpass[column + 0];

			// Add the highpass correction
			even += highpass[column];
//			even = DivideByShift(even, 1);

			// Place the even result in the even column
			*(colptr++) = SATURATE(even);

			// Apply the odd reconstruction filter to the lowpass band
			odd -= lowpass[column - 1];
			odd += lowpass[column + 1];
			odd += ROUNDING(odd,8);
			odd = DivideByShift(odd, 3);
			odd += lowpass[column + 0];

			// Subtract the highpass correction
			odd -= highpass[column];
//			odd = DivideByShift(odd, 1);

			// Place the odd result in the odd column
			*(colptr++) = SATURATE(odd);
		}

		// Should have exited the loop at the column for right border processing
		assert(column == last_column);

		// Process the last two output points with special filters for the right border
		even = 0;
		odd = 0;

		// Apply the even reconstruction filter to the lowpass band
		even += 5 * lowpass[column + 0];
		even += 4 * lowpass[column - 1];
		even -= 1 * lowpass[column - 2];
		even += ROUNDING(even,8);
		even = DivideByShift(even, 3);

		// Add the highpass correction
		even += highpass[column];
//		even = DivideByShift(even, 1);

		// Place the even result in the even column
		*(colptr++) = SATURATE(even);

		// Apply the odd reconstruction filter to the lowpass band
		odd += 11 * lowpass[column + 0];
		odd -=  4 * lowpass[column - 1];
		odd +=  1 * lowpass[column - 2];
		odd += ROUNDING(odd,8);
		odd = DivideByShift(odd, 3);

		// Subtract the highpass correction
		odd -= highpass[column];
//		odd = DivideByShift(odd, 1);

		// Place the odd result in the odd column
		*(colptr++) = SATURATE(odd);

		// Advance to the next row
		lowpass += lowpass_pitch;
		highpass += highpass_pitch;
		output += output_pitch;
	}

	//_mm_empty();	// Clear the mmx register state
}

#endif




#if 0
static void InvertHorizontalQuantSlow16s8sTo16s(PIXEL   *lowpass, int lowpass_quantization, int lowpass_pitch,
												PIXEL8S *highpass, int highpass_quantization, int highpass_pitch,
												PIXEL   *output, int output_pitch, ROI roi)
{
	int row, column;

	// Convert pitch from bytes to pixels
	lowpass_pitch /= sizeof(PIXEL);
	highpass_pitch /= sizeof(PIXEL8S);
	output_pitch /= sizeof(PIXEL);

	for (row = 0; row < roi.height; row++)
	{
		PIXEL *outptr = output;
		const int column_step = 1;
		int last_column = roi.width - column_step;
		int32_t even;
		int32_t odd;

		column = 0;

		// Process the first two output points with special filters for the left border
		even = 0;
		odd = 0;

		// Apply the even reconstruction filter to the lowpass band
		even += 11 * lowpass[column + 0];
		even -=  4 * lowpass[column + 1];
		even +=  1 * lowpass[column + 2];
		even += ROUNDING(even,8);
		even = DivideByShift(even, 3);

		// Add the highpass correction
		even += (highpass[column]) * highpass_quantization;
		even = DivideByShift(even, 1);

		// Place the even result in the even column
		*(outptr++) = SATURATE(even);

		// Apply the odd reconstruction filter to the lowpass band
		odd += 5 * lowpass[column + 0];
		odd += 4 * lowpass[column + 1];
		odd -= 1 * lowpass[column + 2];
		odd += ROUNDING(odd,8);
		odd = DivideByShift(odd, 3);

		// Subtract the highpass correction
		odd -= (highpass[column]) * highpass_quantization;
		odd = DivideByShift(odd, 1);

		// Place the odd result in the odd column
		*(outptr++) = SATURATE(odd);

		column++;

		for (; column < last_column; column += column_step)
		{
			int32_t even = 0;		// Result of convolution with even filter
			int32_t odd = 0;		// Result of convolution with odd filter

			// Apply the even reconstruction filter to the lowpass band
			even += lowpass[column - 1];
			even -= lowpass[column + 1];
			even += ROUNDING(even,8);
			even = DivideByShift(even, 3);
			even += lowpass[column + 0];

			// Add the highpass correction
			even += (highpass[column]) * highpass_quantization;
			even = DivideByShift(even, 1);

			// Place the even result in the even column
			*(outptr++) = SATURATE(even);

			// Apply the odd reconstruction filter to the lowpass band
			odd -= lowpass[column - 1];
			odd += lowpass[column + 1];
			odd += ROUNDING(odd,8);
			odd = DivideByShift(odd, 3);
			odd += lowpass[column + 0];

			// Subtract the highpass correction
			odd -= (highpass[column]) * highpass_quantization;
			odd = DivideByShift(odd, 1);

			// Place the odd result in the odd column
			*(outptr++) = SATURATE(odd);
		}

		// Should have exited the loop with the column equal to the last column
		assert(column == last_column);

		// Process the last two output points with special filters for the right border
		even = 0;
		odd = 0;

		// Apply the even reconstruction filter to the lowpass band
		even += 5 * lowpass[column + 0];
		even += 4 * lowpass[column - 1];
		even -= 1 * lowpass[column - 2];
		even += ROUNDING(even,8);
		even = DivideByShift(even, 3);

		// Add the highpass correction
		even += (highpass[column]) * highpass_quantization;
		even = DivideByShift(even, 1);

		// Place the even result in the even column
		*(outptr++) = SATURATE(even);

		// Apply the odd reconstruction filter to the lowpass band
		odd += 11 * lowpass[column + 0];
		odd -=  4 * lowpass[column - 1];
		odd +=  1 * lowpass[column - 2];
		odd += ROUNDING(odd,8);
		odd = DivideByShift(odd, 3);

		// Subtract the highpass correction
		odd -= (highpass[column]) * highpass_quantization;
		odd = DivideByShift(odd, 1);

		// Place the odd result in the odd column
		*(outptr++) = SATURATE(odd);

		// Advance to the next row
		lowpass += lowpass_pitch;
		highpass += highpass_pitch;
		output += output_pitch;
	}
}

static void InvertHorizontalQuantSlow8s(PIXEL8S *lowpass, int lowpass_quantization, int lowpass_pitch,
										PIXEL8S *highpass, int highpass_quantization, int highpass_pitch,
										PIXEL   *output, int output_pitch, ROI roi)
{
	int row, column;

	// Convert pitch from bytes to pixels
	lowpass_pitch /= sizeof(PIXEL8S);
	highpass_pitch /= sizeof(PIXEL8S);
	output_pitch /= sizeof(PIXEL);

	for (row = 0; row < roi.height; row++)
	{
		PIXEL *outptr = output;
		const int column_step = 1;
		int last_column = roi.width - column_step;
		int32_t even;
		int32_t odd;

		column = 0;

		// Process the first two output points with special filters for the left border
		even = 0;
		odd = 0;

		// Apply the even reconstruction filter to the lowpass band
		even += 11 * lowpass[column + 0] * lowpass_quantization;
		even -=  4 * lowpass[column + 1] * lowpass_quantization;
		even +=  1 * lowpass[column + 2] * lowpass_quantization;
		even += ROUNDING(even,8);
		even = DivideByShift(even, 3);

		// Add the highpass correction
		even += (highpass[column]) * highpass_quantization;
		even = DivideByShift(even, 1);

		// Place the even result in the even column
		*(outptr++) = SATURATE(even);

		// Apply the odd reconstruction filter to the lowpass band
		odd += 5 * lowpass[column + 0] * lowpass_quantization;
		odd += 4 * lowpass[column + 1] * lowpass_quantization;
		odd -= 1 * lowpass[column + 2] * lowpass_quantization;
		odd += ROUNDING(odd,8);
		odd = DivideByShift(odd, 3);

		// Subtract the highpass correction
		odd -= (highpass[column]) * highpass_quantization;
		odd = DivideByShift(odd, 1);

		// Place the odd result in the odd column
		*(outptr++) = SATURATE(odd);

		column++;

		for (; column < last_column; column += column_step)
		{
			int32_t even = 0;		// Result of convolution with even filter
			int32_t odd = 0;		// Result of convolution with odd filter

			// Apply the even reconstruction filter to the lowpass band
			even += lowpass[column - 1] * lowpass_quantization;
			even -= lowpass[column + 1] * lowpass_quantization;
			even += ROUNDING(even,8);
			even = DivideByShift(even, 3);
			even += (lowpass[column + 0]) * lowpass_quantization;

			// Add the highpass correction
			even += (highpass[column]) * highpass_quantization;
			even = DivideByShift(even, 1);

			// Place the even result in the even column
			*(outptr++) = SATURATE(even);

			// Apply the odd reconstruction filter to the lowpass band
			odd -= lowpass[column - 1] * lowpass_quantization;
			odd += lowpass[column + 1] * lowpass_quantization;
			odd += ROUNDING(odd,8);
			odd = DivideByShift(odd, 3);
			odd += (lowpass[column + 0]) * lowpass_quantization;

			// Subtract the highpass correction
			odd -= (highpass[column]) * highpass_quantization;
			odd = DivideByShift(odd, 1);

			// Place the odd result in the odd column
			*(outptr++) = SATURATE(odd);
		}

		// Should have exited the loop with the column equal to the last column
		assert(column == last_column);

		// Process the last two output points with special filters for the right border
		even = 0;
		odd = 0;

		// Apply the even reconstruction filter to the lowpass band
		even += 5 * lowpass[column + 0] * lowpass_quantization;
		even += 4 * lowpass[column - 1] * lowpass_quantization;
		even -= 1 * lowpass[column - 2] * lowpass_quantization;
		even += ROUNDING(even,8);
		even = DivideByShift(even, 3);

		// Add the highpass correction
		even += (highpass[column]) * highpass_quantization;
		even = DivideByShift(even, 1);

		// Place the even result in the even column
		*(outptr++) = SATURATE(even);

		// Apply the odd reconstruction filter to the lowpass band
		odd += 11 * lowpass[column + 0] * lowpass_quantization;
		odd -=  4 * lowpass[column - 1] * lowpass_quantization;
		odd +=  1 * lowpass[column - 2] * lowpass_quantization;
		odd += ROUNDING(odd,8);
		odd = DivideByShift(odd, 3);

		// Subtract the highpass correction
		odd -= (highpass[column]) * highpass_quantization;
		odd = DivideByShift(odd, 1);

		// Place the odd result in the odd column
		*(outptr++) = SATURATE(odd);

		// Advance to the next row
		lowpass += lowpass_pitch;
		highpass += highpass_pitch;
		output += output_pitch;
	}
}
#endif


#if 0 //HACKDAN
// Apply the inverse horizontal transform to reconstruct a single row
void InvertHorizontalRow16s8sTo16s(PIXEL *lowpass,  			// Row of horizontal lowpass coefficients
								   int lowpass_quantization,	// lowpass quantization factor
								   PIXEL8S *highpass,			// Row of horizontal highpass coefficients
								   int highpass_quantization,	// highpass quantization factor
								   PIXEL *output,				// Row of reconstructed results
								   int width)					// Length of each row of horizontal coefficients
{
	// Need to implement this routine for 8-bit decoding

#if _DECODE_LOWPASS_16S
	const int column_step = 8;
	const int last_column = width - 1;
	int post_column = last_column - (last_column % column_step);
	int column;

	__m64 low1_pi16;	// Lowpass coefficients
	__m64 low2_pi16;
	__m64 high_pi8;		// Highpass coefficients
	__m64 high1_pi16;	// Lower four highpass coefficients
	__m64 high2_pi16;	// Upper four highpass coefficients
	__m64 sign_pi8;
	__m64 quantization = _mm_set_pi16(highpass_quantization, highpass_quantization,
									  highpass_quantization, highpass_quantization);

	// The fast loop computes output points starting at the third column
	__m64 *outptr = (__m64 *)&output[2];

	PIXEL *colptr;

	int32_t even;
	int32_t odd;
	//int32_t lsb;

	// Adjust the end of the fast loop if necessary
	if (post_column == last_column)
		post_column -= column_step;

	// Start processing at the beginning of the row
	column = 0;

	// Process the first two output points with special filters for the left border
	even = 0;
	odd = 0;

	// Apply the even reconstruction filter to the lowpass band
	even += 11 * lowpass[column + 0];
	even -=  4 * lowpass[column + 1];
	even +=  1 * lowpass[column + 2];
	even += ROUNDING(even,8);
	even = DivideByShift(even, 3);

	// Add the highpass correction
	even += highpass[column] * highpass_quantization;
	even = DivideByShift(even, 1);

	// Place the even result in the even column
	output[0] = SATURATE(even);

	// Apply the odd reconstruction filter to the lowpass band
	odd += 5 * lowpass[column + 0];
	odd += 4 * lowpass[column + 1];
	odd -= 1 * lowpass[column + 2];
	odd += ROUNDING(odd,8);
	odd = DivideByShift(odd, 3);

	// Subtract the highpass correction
	odd -= highpass[column] * highpass_quantization;
	odd = DivideByShift(odd, 1);

	// Place the odd result in the odd column
	output[1] = SATURATE(odd);

	// Preload the first four lowpass coefficients
	low1_pi16 = *((__m64 *)&lowpass[column]);

	// Preload the eight highpass coefficients
	high_pi8 = *((__m64 *)&highpass[column]);

	// Unpack the first four highpass coefficients
	sign_pi8 = _mm_cmpgt_pi8(_mm_setzero_si64(), high_pi8);
	high1_pi16 = _mm_unpacklo_pi8(high_pi8, sign_pi8);

	// Undo quantization
	high1_pi16 = _mm_mullo_pi16(high1_pi16, quantization);

	// The reconstruction filters use pixels starting at the first column
	for (; column < post_column; column += column_step)
	{
		__m64 even_pi16;	// Result of convolution with even filter
		__m64 odd_pi16;		// Result of convolution with odd filter
		__m64 temp_pi16;
		__m64 out_pi16;		// Reconstructed data
		__m64 mask_pi16;
		__m64 half_pi16;
		__m64 lsb_pi16;
		__m64 sign_pi16;
//		__m64 high_pi16;

		// Preload the next four lowpass coefficients
		low2_pi16 = *((__m64 *)&lowpass[column+4]);


		// Compute the first two even and two odd output points //

		// Apply the even reconstruction filter to the lowpass band
		even_pi16 = low1_pi16;
		temp_pi16 = _mm_slli_pi16(low1_pi16, 3);
		temp_pi16 = _mm_shuffle_pi16(temp_pi16, _MM_SHUFFLE(0, 3, 2, 1));
		even_pi16 = _mm_adds_pi16(even_pi16, temp_pi16);
		temp_pi16 = _mm_shuffle_pi16(low1_pi16, _MM_SHUFFLE(1, 0, 3, 2));
		even_pi16 = _mm_subs_pi16(even_pi16, temp_pi16);

		// Apply the rounding adjustment
		even_pi16 = _mm_adds_pi16(even_pi16, _mm_set1_pi16(4));
		// Divide by eight
		even_pi16 = _mm_srai_pi16(even_pi16, 3);

		// Shift the highpass correction by one column
		high1_pi16 = _mm_srli_si64(high1_pi16, 16);

		// Add the highpass correction
		even_pi16 = _mm_adds_pi16(even_pi16, high1_pi16);
		even_pi16 = _mm_srai_pi16(even_pi16, 1);

		// Apply the odd reconstruction filter to the lowpass band
		odd_pi16 = _mm_slli_pi16(low1_pi16, 3);
		odd_pi16 = _mm_shuffle_pi16(odd_pi16, _MM_SHUFFLE(0, 3, 2, 1));
		temp_pi16 = _mm_shuffle_pi16(low1_pi16, _MM_SHUFFLE(1, 0, 3, 2));
		odd_pi16 = _mm_adds_pi16(odd_pi16, temp_pi16);
		odd_pi16 = _mm_subs_pi16(odd_pi16, low1_pi16);

		// Apply the rounding adjustment
		odd_pi16 = _mm_adds_pi16(odd_pi16, _mm_set1_pi16(4));
		// Divide by eight
		odd_pi16 = _mm_srai_pi16(odd_pi16, 3);

		// Subtract the highpass correction
		odd_pi16 = _mm_subs_pi16(odd_pi16, high1_pi16);
		odd_pi16 = _mm_srai_pi16(odd_pi16, 1);

		// Interleave the even and odd results
		out_pi16 = _mm_unpacklo_pi16(even_pi16, odd_pi16);
		//out_pi16 = _mm_max_pi16(out_pi16, _mm_setzero_si64());
		*(outptr++) = out_pi16;


		// Compute the second two even and two odd output points //

		// Unpack the second four highpass coefficients
		high2_pi16 = _mm_unpackhi_pi8(high_pi8, sign_pi8);

		// Undo quantization
		high2_pi16 = _mm_mullo_pi16(high2_pi16, quantization);

		// Shift in the new pixels for the next stage of the loop
		low1_pi16 = _mm_srli_si64(low1_pi16, 32);
		temp_pi16 = _mm_slli_si64(low2_pi16, 32);
		low1_pi16 = _mm_or_si64(low1_pi16, temp_pi16);

		// Apply the even reconstruction filter to the lowpass band
		even_pi16 = low1_pi16;
		temp_pi16 = _mm_slli_pi16(low1_pi16, 3);
		temp_pi16 = _mm_shuffle_pi16(temp_pi16, _MM_SHUFFLE(0, 3, 2, 1));
		even_pi16 = _mm_adds_pi16(even_pi16, temp_pi16);
		temp_pi16 = _mm_shuffle_pi16(low1_pi16, _MM_SHUFFLE(1, 0, 3, 2));
		even_pi16 = _mm_subs_pi16(even_pi16, temp_pi16);

		// Apply the rounding adjustment
		even_pi16 = _mm_adds_pi16(even_pi16, _mm_set1_pi16(4));
		// Divide by eight
		even_pi16 = _mm_srai_pi16(even_pi16, 3);

		// Shift in the next two highpass coefficients
		high1_pi16 = _mm_srli_si64(high1_pi16, 2*16);
		high1_pi16 = _mm_or_si64(high1_pi16, _mm_slli_si64(high2_pi16, 16));

		// Add the highpass correction
		even_pi16 = _mm_adds_pi16(even_pi16, high1_pi16);
		even_pi16 = _mm_srai_pi16(even_pi16, 1);

		// Apply the odd reconstruction filter to the lowpass band
		odd_pi16 = _mm_slli_pi16(low1_pi16, 3);
		odd_pi16 = _mm_shuffle_pi16(odd_pi16, _MM_SHUFFLE(0, 3, 2, 1));
		temp_pi16 = _mm_shuffle_pi16(low1_pi16, _MM_SHUFFLE(1, 0, 3, 2));
		odd_pi16 = _mm_adds_pi16(odd_pi16, temp_pi16);
		odd_pi16 = _mm_subs_pi16(odd_pi16, low1_pi16);

		// Apply the rounding adjustment
		odd_pi16 = _mm_adds_pi16(odd_pi16, _mm_set1_pi16(4));
		// Divide by eight
		odd_pi16 = _mm_srai_pi16(odd_pi16, 3);

		// Subtract the highpass correction
		odd_pi16 = _mm_subs_pi16(odd_pi16, high1_pi16);
		odd_pi16 = _mm_srai_pi16(odd_pi16, 1);

		// Interleave the even and odd results
		out_pi16 = _mm_unpacklo_pi16(even_pi16, odd_pi16);
		//out_pi16 = _mm_max_pi16(out_pi16, _mm_setzero_si64());
		*(outptr++) = out_pi16;

		// The second four lowpass coefficients will be the current values
		low1_pi16 = low2_pi16;

		// The second four highpass coefficients will be the current values
		high1_pi16 = high2_pi16;


		// Compute the next four even and odd output points //


		// Preload the next four lowpass coefficients
		low2_pi16 = *((__m64 *)&lowpass[column+8]);

		// Compute the third two even and two odd output points //

		// Apply the even reconstruction filter to the lowpass band
		even_pi16 = low1_pi16;
		temp_pi16 = _mm_slli_pi16(low1_pi16, 3);
		temp_pi16 = _mm_shuffle_pi16(temp_pi16, _MM_SHUFFLE(0, 3, 2, 1));
		even_pi16 = _mm_adds_pi16(even_pi16, temp_pi16);
		temp_pi16 = _mm_shuffle_pi16(low1_pi16, _MM_SHUFFLE(1, 0, 3, 2));
		even_pi16 = _mm_subs_pi16(even_pi16, temp_pi16);

		// Apply the rounding adjustment
		even_pi16 = _mm_adds_pi16(even_pi16, _mm_set1_pi16(4));
		// Divide by eight
		even_pi16 = _mm_srai_pi16(even_pi16, 3);

		// Shift the highpass correction by one column
		high1_pi16 = _mm_srli_si64(high1_pi16, 16);

		// Add the highpass correction
		even_pi16 = _mm_adds_pi16(even_pi16, high1_pi16);
		even_pi16 = _mm_srai_pi16(even_pi16, 1);

		// Apply the odd reconstruction filter to the lowpass band
		odd_pi16 = _mm_slli_pi16(low1_pi16, 3);
		odd_pi16 = _mm_shuffle_pi16(odd_pi16, _MM_SHUFFLE(0, 3, 2, 1));
		temp_pi16 = _mm_shuffle_pi16(low1_pi16, _MM_SHUFFLE(1, 0, 3, 2));
		odd_pi16 = _mm_adds_pi16(odd_pi16, temp_pi16);
		odd_pi16 = _mm_subs_pi16(odd_pi16, low1_pi16);

		// Apply the rounding adjustment
		odd_pi16 = _mm_adds_pi16(odd_pi16, _mm_set1_pi16(4));
		// Divide by eight
		odd_pi16 = _mm_srai_pi16(odd_pi16, 3);

		// Subtract the highpass correction
		odd_pi16 = _mm_subs_pi16(odd_pi16, high1_pi16);
		odd_pi16 = _mm_srai_pi16(odd_pi16, 1);

		// Interleave the even and odd results
		out_pi16 = _mm_unpacklo_pi16(even_pi16, odd_pi16);
		//out_pi16 = _mm_max_pi16(out_pi16, _mm_setzero_si64());
		*(outptr++) = out_pi16;


		// Compute the fourth two even and two odd output points //

		// Load the second eight highpass coefficients
		high_pi8 = *((__m64 *)&highpass[column+8]);
		sign_pi8 = _mm_cmpgt_pi8(_mm_setzero_si64(), high_pi8);

		// Unpack the third four highpass coefficients
		high2_pi16 = _mm_unpacklo_pi8(high_pi8, sign_pi8);

		// Undo quantization
		high2_pi16 = _mm_mullo_pi16(high2_pi16, quantization);

		// Shift in the new pixels for the next stage of the loop
		low1_pi16 = _mm_srli_si64(low1_pi16, 32);
		temp_pi16 = _mm_slli_si64(low2_pi16, 32);
		low1_pi16 = _mm_or_si64(low1_pi16, temp_pi16);

		// Apply the even reconstruction filter to the lowpass band
		even_pi16 = low1_pi16;
		temp_pi16 = _mm_slli_pi16(low1_pi16, 3);
		temp_pi16 = _mm_shuffle_pi16(temp_pi16, _MM_SHUFFLE(0, 3, 2, 1));
		even_pi16 = _mm_adds_pi16(even_pi16, temp_pi16);
		temp_pi16 = _mm_shuffle_pi16(low1_pi16, _MM_SHUFFLE(1, 0, 3, 2));
		even_pi16 = _mm_subs_pi16(even_pi16, temp_pi16);

		// Apply the rounding adjustment
		even_pi16 = _mm_adds_pi16(even_pi16, _mm_set1_pi16(4));
		// Divide by eight
		even_pi16 = _mm_srai_pi16(even_pi16, 3);

		// Shift in the next highpass coefficient
		high1_pi16 = _mm_srli_si64(high1_pi16, 2*16);
		high1_pi16 = _mm_or_si64(high1_pi16, _mm_slli_si64(high2_pi16, 16));

		// Add the highpass correction
		even_pi16 = _mm_adds_pi16(even_pi16, high1_pi16);
		even_pi16 = _mm_srai_pi16(even_pi16, 1);

		// Apply the odd reconstruction filter to the lowpass band
		odd_pi16 = _mm_slli_pi16(low1_pi16, 3);
		odd_pi16 = _mm_shuffle_pi16(odd_pi16, _MM_SHUFFLE(0, 3, 2, 1));
		temp_pi16 = _mm_shuffle_pi16(low1_pi16, _MM_SHUFFLE(1, 0, 3, 2));
		odd_pi16 = _mm_adds_pi16(odd_pi16, temp_pi16);
		odd_pi16 = _mm_subs_pi16(odd_pi16, low1_pi16);

		// Apply the rounding adjustment
		odd_pi16 = _mm_adds_pi16(odd_pi16, _mm_set1_pi16(4));
		// Divide by eight
		odd_pi16 = _mm_srai_pi16(odd_pi16, 3);

		// Subtract the highpass correction
		odd_pi16 = _mm_subs_pi16(odd_pi16, high1_pi16);
		odd_pi16 = _mm_srai_pi16(odd_pi16, 1);

		// Interleave the even and odd results
		out_pi16 = _mm_unpacklo_pi16(even_pi16, odd_pi16);
		//out_pi16 = _mm_max_pi16(out_pi16, _mm_setzero_si64());
		*(outptr++) = out_pi16;

		// The second four lowpass coefficients will be the current values
		low1_pi16 = low2_pi16;

		// The second four highpass coefficients will be the current values
		high1_pi16 = high2_pi16;

	}

	// Should have exited the loop with the column equal to the post processing column
	assert(column == post_column);

	// The fast processing loop is one column behind the actual column
	column++;

	// Process the rest of the columns up to the last column in the row
	colptr = (PIXEL *)outptr;

	for (; column < last_column; column++)
	{
		int32_t even = 0;		// Result of convolution with even filter
		int32_t odd = 0;		// Result of convolution with odd filter

		// Apply the even reconstruction filter to the lowpass band
		even += lowpass[column - 1];
		even -= lowpass[column + 1];
		even += ROUNDING(even,8);
		even = DivideByShift(even, 3);
		even += lowpass[column + 0];

		// Add the highpass correction
		even += highpass[column] * highpass_quantization;
		even = DivideByShift(even, 1);

		// Place the even result in the even column
		*(colptr++) = SATURATE(even);

		// Apply the odd reconstruction filter to the lowpass band
		odd -= lowpass[column - 1];
		odd += lowpass[column + 1];
		odd += ROUNDING(odd,8);
		odd = DivideByShift(odd, 3);
		odd += lowpass[column + 0];

		// Subtract the highpass correction
		odd -= highpass[column] * highpass_quantization;
		odd = DivideByShift(odd, 1);

		// Place the odd result in the odd column
		*(colptr++) = SATURATE(odd);
	}

	// Should have exited the loop at the column for right border processing
	assert(column == last_column);

	// Process the last two output points with special filters for the right border
	even = 0;
	odd = 0;

	// Apply the even reconstruction filter to the lowpass band
	even += 5 * lowpass[column + 0];
	even += 4 * lowpass[column - 1];
	even -= 1 * lowpass[column - 2];
	even += ROUNDING(even,8);
	even = DivideByShift(even, 3);

	// Add the highpass correction
	even += highpass[column] * highpass_quantization;
	even = DivideByShift(even, 1);

	// Place the even result in the even column
	*(colptr++) = SATURATE(even);

	// Apply the odd reconstruction filter to the lowpass band
	odd += 11 * lowpass[column + 0];
	odd -=  4 * lowpass[column - 1];
	odd +=  1 * lowpass[column - 2];
	odd += ROUNDING(odd,8);
	odd = DivideByShift(odd, 3);

	// Subtract the highpass correction
	odd -= highpass[column] * highpass_quantization;
	odd = DivideByShift(odd, 1);

	// Place the odd result in the odd column
	*(colptr++) = SATURATE(odd);

	//_mm_empty();	// Clear the mmx register state

#else
#error Have not implemented 8-bit lowpass coefficients
#endif
}
#endif //HACKDAN


#if _PROCESSOR_DISPATCH

__declspec(cpu_dispatch(Pentium_4,Generic))

void InvertHorizontalRow16s8sTo16sBuffered(PIXEL *lowpass,  			// Row of horizontal lowpass coefficients
									 	   int lowpass_quantization,	// lowpass quantization factor
										   PIXEL8S *highpass,			// Row of horizontal highpass coefficients
										   int highpass_quantization,	// highpass quantization factor
										   PIXEL *output,				// Row of reconstructed results
										   int width,					// Length of each row of horizontal coefficients
										   PIXEL *buffer)				// Buffer to hold the dequantized values
{
	// Stub routine for processor specific dispatch
}
#endif


#if _PROCESSOR_GENERIC

#if _PROCESSOR_DISPATCH
__declspec(cpu_specific(Generic))
#endif

// Apply the inverse horizontal transform to reconstruct a single row
void InvertHorizontalRow16s8sTo16sBuffered(PIXEL *lowpass,  			// Row of horizontal lowpass coefficients
									 	   int lowpass_quantization,	// lowpass quantization factor
										   PIXEL8S *highpass_data,			// Row of horizontal highpass coefficients
										   int highpass_quantization,	// highpass quantization factor
										   PIXEL *output,				// Row of reconstructed results
										   int width,					// Length of each row of horizontal coefficients
										   PIXEL *buffer)				// Buffer to hold the dequantized values
{
#if _DECODE_LOWPASS_16S
	const int column_step = 4;
	const int last_column = width - 1;
	int post_column = last_column - (last_column % column_step);
	int column;

	PIXEL *highline = buffer;

	__m64 low1_pi16;	// Lowpass coefficients
	__m64 low2_pi16;
	__m64 high1_pi16;	// Lower four highpass coefficients
	__m64 high2_pi16;	// Upper four highpass coefficients

	// The fast loop computes output points starting at the third column
	__m64 *outptr = (__m64 *)&output[2];

	PIXEL *colptr;

	int32_t even;
	int32_t odd;
	//int32_t lsb;

	PIXEL *highpass = (PIXEL *)highpass_data;

	// Adjust the end of the fast loop if necessary
	if (post_column == last_column)
		post_column -= column_step;

	// Undo quantization for the highpass row
#if _DEQUANTIZE_IN_FSM
	highline = highpass;
#else
	DequantizeBandRow16s(highpass, width, highpass_quantization, highline);
#endif

	// Start processing at the beginning of the row
	column = 0;

	// Process the first two output points with special filters for the left border
	even = 0;
	odd = 0;

	// Apply the even reconstruction filter to the lowpass band
	even += 11 * lowpass[column + 0];
	even -=  4 * lowpass[column + 1];
	even +=  1 * lowpass[column + 2];
	even += ROUNDING(even,8);
	even = DivideByShift(even, 3);

	// Add the highpass correction
	even += highline[column];
	even = DivideByShift(even, 1);

	// Place the even result in the even column
	output[0] = SATURATE(even);

	// Apply the odd reconstruction filter to the lowpass band
	odd += 5 * lowpass[column + 0];
	odd += 4 * lowpass[column + 1];
	odd -= 1 * lowpass[column + 2];
	odd += ROUNDING(odd,8);
	odd = DivideByShift(odd, 3);

	// Subtract the highpass correction
	odd -= highline[column];
	odd = DivideByShift(odd, 1);

	// Place the odd result in the odd column
	output[1] = SATURATE(odd);

#if (1 && XMMOPT)

	// Preload the first four lowpass coefficients
	low1_pi16 = *((__m64 *)&lowpass[column]);

	// Preload the first four highpass coefficients
	high1_pi16 = *((__m64 *)&highline[column]);

	// The reconstruction filters use pixels starting at the first column
	for (; column < post_column; column += column_step)
	{
		__m64 even_pi16;	// Result of convolution with even filter
		__m64 odd_pi16;		// Result of convolution with odd filter
		__m64 temp_pi16;
		__m64 out_pi16;		// Reconstructed data
		__m64 mask_pi16;
		__m64 half_pi16 = _mm_set1_pi16(4);
		__m64 lsb_pi16;
		__m64 sign_pi16;
		//__m64 high_pi16;

		// Preload the next four lowpass coefficients
		low2_pi16 = *((__m64 *)&lowpass[column+4]);


		// Compute the first two even and two odd output points //

		// Apply the even reconstruction filter to the lowpass band
		even_pi16 = low1_pi16;
		temp_pi16 = _mm_slli_pi16(low1_pi16, 3);
		temp_pi16 = _mm_shuffle_pi16(temp_pi16, _MM_SHUFFLE(0, 3, 2, 1));
		even_pi16 = _mm_adds_pi16(even_pi16, temp_pi16);
		temp_pi16 = _mm_shuffle_pi16(low1_pi16, _MM_SHUFFLE(1, 0, 3, 2));
		even_pi16 = _mm_subs_pi16(even_pi16, temp_pi16);

		// Apply the rounding adjustment
		even_pi16 = _mm_adds_pi16(even_pi16, half_pi16);
		// Divide by eight
		even_pi16 = _mm_srai_pi16(even_pi16, 3);

		// Shift the highpass correction by one column
		high1_pi16 = _mm_srli_si64(high1_pi16, 16);

		// Prescale for 8bit output - DAN 4/5/02
		//high_pi16 = _mm_slli_pi16(high1_pi16, prescale);

		// Add the highpass correction
		even_pi16 = _mm_adds_pi16(even_pi16, high1_pi16);
		even_pi16 = _mm_srai_pi16(even_pi16, 1);

		// Apply the odd reconstruction filter to the lowpass band
		odd_pi16 = _mm_slli_pi16(low1_pi16, 3);
		odd_pi16 = _mm_shuffle_pi16(odd_pi16, _MM_SHUFFLE(0, 3, 2, 1));
		temp_pi16 = _mm_shuffle_pi16(low1_pi16, _MM_SHUFFLE(1, 0, 3, 2));
		odd_pi16 = _mm_adds_pi16(odd_pi16, temp_pi16);
		odd_pi16 = _mm_subs_pi16(odd_pi16, low1_pi16);

		// Apply the rounding adjustment
		odd_pi16 = _mm_adds_pi16(odd_pi16, half_pi16);
		// Divide by eight
		odd_pi16 = _mm_srai_pi16(odd_pi16, 3);

		// Subtract the highpass correction
		odd_pi16 = _mm_subs_pi16(odd_pi16, high1_pi16);
		odd_pi16 = _mm_srai_pi16(odd_pi16, 1);

		// Interleave the even and odd results
		out_pi16 = _mm_unpacklo_pi16(even_pi16, odd_pi16);
		//out_pi16 = _mm_max_pi16(out_pi16, _mm_setzero_si64());
		*(outptr++) = out_pi16;


		// Compute the second two even and two odd output points //

		// Preload the highpass correction
		high2_pi16 = *((__m64 *)&highline[column+4]);

		// Shift in the new pixels for the next stage of the loop
		low1_pi16 = _mm_srli_si64(low1_pi16, 32);
		temp_pi16 = _mm_slli_si64(low2_pi16, 32);
		low1_pi16 = _mm_or_si64(low1_pi16, temp_pi16);

		// Apply the even reconstruction filter to the lowpass band
		even_pi16 = low1_pi16;
		temp_pi16 = _mm_slli_pi16(low1_pi16, 3);
		temp_pi16 = _mm_shuffle_pi16(temp_pi16, _MM_SHUFFLE(0, 3, 2, 1));
		even_pi16 = _mm_adds_pi16(even_pi16, temp_pi16);
		temp_pi16 = _mm_shuffle_pi16(low1_pi16, _MM_SHUFFLE(1, 0, 3, 2));
		even_pi16 = _mm_subs_pi16(even_pi16, temp_pi16);


		// Apply the rounding adjustment
		even_pi16 = _mm_adds_pi16(even_pi16, half_pi16);
		// Divide by eight
		even_pi16 = _mm_srai_pi16(even_pi16, 3);

		// Shift in the next two highpass coefficients
		high1_pi16 = _mm_srli_si64(high1_pi16, 2*16);
		high1_pi16 = _mm_or_si64(high1_pi16, _mm_slli_si64(high2_pi16, 16));

		// Prescale for 8bit output - DAN 4/5/02
		//high_pi16 = _mm_slli_pi16(high1_pi16, prescale);

		// Add the highpass correction
		even_pi16 = _mm_adds_pi16(even_pi16, high1_pi16);
		even_pi16 = _mm_srai_pi16(even_pi16, 1);

		// Apply the odd reconstruction filter to the lowpass band
		odd_pi16 = _mm_slli_pi16(low1_pi16, 3);
		odd_pi16 = _mm_shuffle_pi16(odd_pi16, _MM_SHUFFLE(0, 3, 2, 1));
		temp_pi16 = _mm_shuffle_pi16(low1_pi16, _MM_SHUFFLE(1, 0, 3, 2));
		odd_pi16 = _mm_adds_pi16(odd_pi16, temp_pi16);
		odd_pi16 = _mm_subs_pi16(odd_pi16, low1_pi16);

		// Apply the rounding adjustment
		odd_pi16 = _mm_adds_pi16(odd_pi16, half_pi16);
		// Divide by eight
		odd_pi16 = _mm_srai_pi16(odd_pi16, 3);

		// Subtract the highpass correction
		odd_pi16 = _mm_subs_pi16(odd_pi16, high1_pi16);
		odd_pi16 = _mm_srai_pi16(odd_pi16, 1);

		// Interleave the even and odd results
		out_pi16 = _mm_unpacklo_pi16(even_pi16, odd_pi16);
		//out_pi16 = _mm_max_pi16(out_pi16, _mm_setzero_si64());
		*(outptr++) = out_pi16;

		// The second four lowpass coefficients will be the current values
		low1_pi16 = low2_pi16;

		// The second four highpass coefficients will be the current values
		high1_pi16 = high2_pi16;
	}

	// Should have exited the loop with the column equal to the post processing column
	assert(column == post_column);

#endif

	// The fast processing loop is one column behind the actual column
	column++;

	// Process the rest of the columns up to the last column in the row
	colptr = (PIXEL *)outptr;

	for (; column < last_column; column++)
	{
		int32_t even = 0;		// Result of convolution with even filter
		int32_t odd = 0;		// Result of convolution with odd filter

		// Apply the even reconstruction filter to the lowpass band
		even += lowpass[column - 1];
		even -= lowpass[column + 1];
		even += ROUNDING(even,8);
		even = DivideByShift(even, 3);
		even += lowpass[column + 0];

		// Add the highpass correction
		even += highline[column];
		even = DivideByShift(even, 1);

		// Place the even result in the even column
		*(colptr++) = SATURATE(even);

		// Apply the odd reconstruction filter to the lowpass band
		odd -= lowpass[column - 1];
		odd += lowpass[column + 1];
		odd += ROUNDING(odd,8);
		odd = DivideByShift(odd, 3);
		odd += lowpass[column + 0];

		// Subtract the highpass correction
		odd -= highline[column];
		odd = DivideByShift(odd, 1);

		// Place the odd result in the odd column
		*(colptr++) = SATURATE(odd);
	}

	// Should have exited the loop at the column for right border processing
	assert(column == last_column);

	// Process the last two output points with special filters for the right border
	even = 0;
	odd = 0;

	// Apply the even reconstruction filter to the lowpass band
	even += 5 * lowpass[column + 0];
	even += 4 * lowpass[column - 1];
	even -= 1 * lowpass[column - 2];
	even += ROUNDING(even,8);
	even = DivideByShift(even, 3);

	// Add the highpass correction
	even += highline[column];
	even = DivideByShift(even, 1);

	// Place the even result in the even column
	*(colptr++) = SATURATE(even);

	// Apply the odd reconstruction filter to the lowpass band
	odd += 11 * lowpass[column + 0];
	odd -=  4 * lowpass[column - 1];
	odd +=  1 * lowpass[column - 2];
	odd += ROUNDING(odd,8);
	odd = DivideByShift(odd, 3);

	// Subtract the highpass correction
	odd -= highline[column];
	odd = DivideByShift(odd, 1);

	// Place the odd result in the odd column
	*(colptr++) = SATURATE(odd);

	//_mm_empty();	// Clear the mmx register state

#else
#error Have not implemented 8-bit lowpass coefficients
#endif
}

#endif


#if _PROCESSOR_PENTIUM_4

#if _PROCESSOR_DISPATCH
__declspec(cpu_specific(Pentium_4))
#endif

// Apply the inverse horizontal transform to reconstruct a single row
void InvertHorizontalRow16s8sTo16sBuffered(PIXEL *lowpass,  			// Row of horizontal lowpass coefficients
									 	   int lowpass_quantization,	// lowpass quantization factor
										   PIXEL8S *highpass_data,		// Row of horizontal highpass coefficients
										   int highpass_quantization,	// highpass quantization factor
										   PIXEL *output,				// Row of reconstructed results
										   int width,					// Length of each row of horizontal coefficients
										   PIXEL *buffer)				// Buffer to hold the dequantized values
{
#if _DECODE_LOWPASS_16S
	const int column_step = 8;
	const int last_column = width - 1;
	int post_column = last_column - (last_column % column_step);
	int column;

	PIXEL *highline = buffer;

	__m128i low1_epi16;		// Lowpass coefficients
	__m128i low2_epi16;
	__m128i high1_epi16;	// Current eight highpass coefficients
	__m128i high2_epi16;	// Next eight highpass coefficients

	__m128i half_epi16 = _mm_set1_epi16(4);

#if _UNALIGNED
	// The fast loop computes output points starting at the third column
	__m128i *outptr = (__m128i *)&output[2];
#else
	// The fast loop merges values from different phases to allow aligned stores
	__m128i *outptr = (__m128i *)&output[0];

	// Two 16-bit coefficients from the previous loop iteration
	//short remainder[2];
#endif

	PIXEL *colptr;

	int32_t even;
	int32_t odd;
	//int32_t lsb;

	PIXEL *highpass = (PIXEL *)highpass_data;

	// Adjust the end of the fast loop if necessary
	if (post_column == last_column)
		post_column -= column_step;

	// Undo quantization for the highpass row
#if _DEQUANTIZE_IN_FSM
	highline = highpass;
#else
	DequantizeBandRow16s(highpass, width, highpass_quantization, highline);
#endif

	// Start processing at the beginning of the row
	column = 0;

	// Process the first two output points with special filters for the left border
	even = 0;
	odd = 0;

	// Apply the even reconstruction filter to the lowpass band
	even += 11 * lowpass[column + 0];
	even -=  4 * lowpass[column + 1];
	even +=  1 * lowpass[column + 2];
	even += 4;
	even >>= 3;

	// Add the highpass correction
	even += highline[column];
	even = DivideByShift(even, 1);

#if _UNALIGNED
	// Place the even result in the even column
	output[0] = SATURATE(even);
#else
	// The output value will be stored later
	//remainder[0] = SATURATE(even);
#endif

	// Apply the odd reconstruction filter to the lowpass band
	odd += 5 * lowpass[column + 0];
	odd += 4 * lowpass[column + 1];
	odd -= 1 * lowpass[column + 2];
	odd += 4;
	odd >>= 3;

	// Subtract the highpass correction
	odd -= highline[column];
	odd = DivideByShift(odd, 1);

#if _UNALIGNED
	// Place the odd result in the odd column
	output[1] = SATURATE(odd);
#else
	// The output value will be stored later
	//remainder[1] = SATURATE(odd);
#endif

/*
	colptr = &output[2];
	for (column = 2; column < 8; column++)
	{
		int32_t even = 0;		// Result of convolution with even filter
		int32_t odd = 0;		// Result of convolution with odd filter

		// Apply the even reconstruction filter to the lowpass band
		even += lowpass[column - 1];
		even -= lowpass[column + 1];
		even += ROUNDING(even,8);
		even = DivideByShift(even, 3);
		even += lowpass[column + 0];

		// Add the highpass correction
		even += highline[column];
		even = DivideByShift(even, 1);

		// Place the even result in the even column
		*(colptr++) = SATURATE(even);

		// Apply the odd reconstruction filter to the lowpass band
		odd -= lowpass[column - 1];
		odd += lowpass[column + 1];
		odd += ROUNDING(odd,8);
		odd = DivideByShift(odd, 3);
		odd += lowpass[column + 0];

		// Subtract the highpass correction
		odd -= highline[column];
		odd = DivideByShift(odd, 1);

		// Place the odd result in the odd column
		*(colptr++) = SATURATE(odd);
	}
*/

#if (1 && _FASTLOOP && XMMOPT)

	// Preload the first eight lowpass coefficients
	low1_epi16 = _mm_load_si128((__m128i *)&lowpass[column]);
//	low1_epi16 = _mm_adds_epi16(low1_epi16, overflowprotect_epi16);

	// Preload the first eight highpass coefficients
	high1_epi16 = _mm_load_si128((__m128i *)&highline[column]);

	// The reconstruction filters use pixels starting at the first column
	for (; column < post_column; column += column_step)
	{
		__m128i even_epi16;		// Result of convolution with even filter
		__m128i odd_epi16;		// Result of convolution with odd filter
		__m128i temp_epi16;
		__m128i out_epi16;		// Reconstructed data
		//__m128i high_epi16;
		uint32_t temp;		// Temporary register for last two values


		// Preload the next eight lowpass coefficients
		low2_epi16 = _mm_load_si128((__m128i *)&lowpass[column+8]);

//		low2_epi16 = _mm_adds_epi16(low2_epi16, overflowprotect_epi16);

		// Compute the first two even and two odd output points //

		// Apply the even reconstruction filter to the lowpass band
/*		even_epi16 = low1_epi16;
		temp_epi16 = _mm_slli_epi16(low1_epi16, 3);
		temp_epi16 = _mm_srli_si128(temp_epi16, 1*2);
		even_epi16 = _mm_adds_epi16(even_epi16, temp_epi16);
		temp_epi16 = _mm_srli_si128(low1_epi16, 2*2);
		even_epi16 = _mm_subs_epi16(even_epi16, temp_epi16);

#if 1
		// Apply the rounding adjustment
		even_epi16 = _mm_adds_epi16(even_epi16, _mm_set1_epi16(4));
#endif
		// Divide by eight
		even_epi16 = _mm_srai_epi16(even_epi16, 3);
*/
		// better math.
		even_epi16 = low1_epi16;
		temp_epi16 = _mm_srli_si128(even_epi16, 2*2);
		even_epi16 = _mm_subs_epi16(even_epi16, temp_epi16);
		even_epi16 = _mm_adds_epi16(even_epi16, half_epi16);
		even_epi16 = _mm_srai_epi16(even_epi16, 3);
		temp_epi16 = _mm_srli_si128(low1_epi16, 1*2);
		even_epi16 = _mm_adds_epi16(even_epi16, temp_epi16);

		// Shift the highpass correction by one column
		high1_epi16 = _mm_srli_si128(high1_epi16, 1*2);

		// Prescale for 8bit output - DAN 4/5/02
		//high_epi16 = _mm_slli_epi16(high1_epi16, prescale);

		// Add the highpass correction and divide by two
		even_epi16 = _mm_adds_epi16(even_epi16, high1_epi16);
		even_epi16 = _mm_srai_epi16(even_epi16, 1);

		// Apply the odd reconstruction filter to the lowpass band
/*		odd_epi16 = _mm_slli_epi16(low1_epi16, 3);
		odd_epi16 = _mm_srli_si128(odd_epi16, 1*2);
		temp_epi16 = _mm_srli_si128(low1_epi16, 2*2);
		odd_epi16 = _mm_adds_epi16(odd_epi16, temp_epi16);
		odd_epi16 = _mm_subs_epi16(odd_epi16, low1_epi16);

#if 1
		// Apply the rounding adjustment
		odd_epi16 = _mm_adds_epi16(odd_epi16, _mm_set1_epi16(4));
#endif
		// Divide by eight
		odd_epi16 = _mm_srai_epi16(odd_epi16, 3);
*/
		// Apply the odd reconstruction filter to the lowpass band
		// better math.
		odd_epi16 = _mm_srli_si128(low1_epi16, 2*2);
		temp_epi16 = low1_epi16;
		odd_epi16 = _mm_subs_epi16(odd_epi16, temp_epi16);
		odd_epi16 = _mm_adds_epi16(odd_epi16, half_epi16);
		odd_epi16 = _mm_srai_epi16(odd_epi16, 3);
		temp_epi16 = _mm_srli_si128(low1_epi16, 1*2);
		odd_epi16 = _mm_adds_epi16(odd_epi16, temp_epi16);

		// Subtract the highpass correction and divide by two
		odd_epi16 = _mm_subs_epi16(odd_epi16, high1_epi16);
		odd_epi16 = _mm_srai_epi16(odd_epi16, 1);

		// Interleave the first four even and odd results
		out_epi16 = _mm_unpacklo_epi16(even_epi16, odd_epi16);
		//out_epi16 = _mm_max_epi16(out_epi16, _mm_setzero_si64());

#if _UNALIGNED
		// Store the first eight output values
		_mm_storeu_si128(outptr++, out_epi16);
#else
		// Combine the new output values with the two values from the previous phase
		out_epi16 = _mm_shuffle_epi32(out_epi16, _MM_SHUFFLE(2, 1, 0, 3));
		temp = _mm_cvtsi128_si32(out_epi16);
		out_epi16 = _mm_insert_epi16(out_epi16, even, 0);
		out_epi16 = _mm_insert_epi16(out_epi16, odd, 1);

		// Store eight output values
		_mm_store_si128(outptr++, out_epi16);

		// Save the remaining two output values
		//*((int *)remainder) = temp;
		even = (short)temp;
		odd = (short)(temp >> 16);
#endif

		// Compute the second four even and four odd output points //

		// Preload the highpass correction
		high2_epi16 = _mm_load_si128((__m128i *)&highline[column+8]);

		// Shift in the new pixels for the next stage of the loop
		low1_epi16 = _mm_srli_si128(low1_epi16, 4*2);
		temp_epi16 = _mm_slli_si128(low2_epi16, 4*2);
		low1_epi16 = _mm_or_si128(low1_epi16, temp_epi16);

/*		// Apply the even reconstruction filter to the lowpass band
		even_epi16 = low1_epi16;
		temp_epi16 = _mm_slli_epi16(low1_epi16, 3);
		temp_epi16 = _mm_srli_si128(temp_epi16, 1*2);
		even_epi16 = _mm_adds_epi16(even_epi16, temp_epi16);
		temp_epi16 = _mm_srli_si128(low1_epi16, 2*2);
		even_epi16 = _mm_subs_epi16(even_epi16, temp_epi16);

#if 1
		// Apply the rounding adjustment
		even_epi16 = _mm_adds_epi16(even_epi16, _mm_set1_epi16(4));
#endif
		// Divide by eight
		even_epi16 = _mm_srai_epi16(even_epi16, 3);
*/
		// better math.
		even_epi16 = low1_epi16;
		temp_epi16 = _mm_srli_si128(even_epi16, 2*2);
		even_epi16 = _mm_subs_epi16(even_epi16, temp_epi16);
		even_epi16 = _mm_adds_epi16(even_epi16, half_epi16);
		even_epi16 = _mm_srai_epi16(even_epi16, 3);
		temp_epi16 = _mm_srli_si128(low1_epi16, 1*2);
		even_epi16 = _mm_adds_epi16(even_epi16, temp_epi16);


		// Shift in the next four highpass coefficients
		high1_epi16 = _mm_srli_si128(high1_epi16, 4*2);
		temp_epi16 = _mm_slli_si128(high2_epi16, 3*2);
		high1_epi16 = _mm_or_si128(high1_epi16, temp_epi16);

		// Prescale for 8bit output - DAN 4/5/02
		//high_epi16 = _mm_slli_epi16(high1_epi16, prescale);

		// Add the highpass correction and divide by two
		even_epi16 = _mm_adds_epi16(even_epi16, high1_epi16);
		even_epi16 = _mm_srai_epi16(even_epi16, 1);

		// Apply the odd reconstruction filter to the lowpass band
/*		odd_epi16 = _mm_slli_epi16(low1_epi16, 3);
		odd_epi16 = _mm_srli_si128(odd_epi16, 1*2);
		temp_epi16 = _mm_srli_si128(low1_epi16, 2*2);
		odd_epi16 = _mm_adds_epi16(odd_epi16, temp_epi16);
		odd_epi16 = _mm_subs_epi16(odd_epi16, low1_epi16);

#if 1
		// Apply the rounding adjustment
		odd_epi16 = _mm_adds_epi16(odd_epi16, _mm_set1_epi16(4));
#endif
		// Divide by eight
		odd_epi16 = _mm_srai_epi16(odd_epi16, 3);
*/

		// Apply the odd reconstruction filter to the lowpass band
		// better math.
		odd_epi16 = _mm_srli_si128(low1_epi16, 2*2);
		temp_epi16 = low1_epi16;
		odd_epi16 = _mm_subs_epi16(odd_epi16, temp_epi16);
		odd_epi16 = _mm_adds_epi16(odd_epi16, half_epi16);
		odd_epi16 = _mm_srai_epi16(odd_epi16, 3);
		temp_epi16 = _mm_srli_si128(low1_epi16, 1*2);

		odd_epi16 = _mm_adds_epi16(odd_epi16, temp_epi16);
		// Subtract the highpass correction and divide by two
		odd_epi16 = _mm_subs_epi16(odd_epi16, high1_epi16);
		odd_epi16 = _mm_srai_epi16(odd_epi16, 1);

		// Interleave the second four even and odd results
		out_epi16 = _mm_unpacklo_epi16(even_epi16, odd_epi16);
		//out_epi16 = _mm_max_epi16(out_epi16, _mm_setzero_si64());

#if _UNALIGNED
		// Store the first eight output values
		_mm_storeu_si128(outptr++, out_epi16);
#else
		// Combine the new output values with the two values from the previous phase
		out_epi16 = _mm_shuffle_epi32(out_epi16, _MM_SHUFFLE(2, 1, 0, 3));
		temp = _mm_cvtsi128_si32(out_epi16);
		out_epi16 = _mm_insert_epi16(out_epi16, even, 0);
		out_epi16 = _mm_insert_epi16(out_epi16, odd, 1);

		// Store eight output values
		_mm_store_si128(outptr++, out_epi16);

		// Save the remaining two output values
		even = (short)temp;
		odd = (short)(temp >> 16);
#endif

		// Prepare for the next loop iteration //

		// The second eight lowpass coefficients will be the current values
		low1_epi16 = low2_epi16;

		// The second eight highpass coefficients will be the current values
		high1_epi16 = high2_epi16;
	}

	// Should have exited the loop with the column equal to the post processing column
	assert(column == post_column);

#endif

	// The fast processing loop is one column behind the actual column
	column++;

	// Get the pointer to the next output value
	colptr = (PIXEL *)outptr;

#if _UNALIGNED
	// The last two output points have already been stored
#else
	// Store the last two output points produced by the loop
	*(colptr++) = SATURATE(even);
	*(colptr++) = SATURATE(odd);
#endif

	// Process the rest of the columns up to the last column in the row
	for (; column < last_column; column++)
	{
		int32_t even = 0;		// Result of convolution with even filter
		int32_t odd = 0;		// Result of convolution with odd filter

		// Apply the even reconstruction filter to the lowpass band
		even = lowpass[column - 1];
		even -= lowpass[column + 1];
		even += 4; //DAN20050921
		even >>= 3;
		even += lowpass[column + 0];

		// Add the highpass correction
		even += highpass[column];
		even = DivideByShift(even, 1);

		// Place the even result in the even column
		//even >>= _INVERSE_TEMPORAL_PRESCALE;
		*(colptr++) = SATURATE(even);

		// Apply the odd reconstruction filter to the lowpass band
		odd = -lowpass[column - 1];
		odd += lowpass[column + 1];
		odd += 4; //DAN20050921
		odd >>= 3;
		odd += lowpass[column + 0];

		// Subtract the highpass correction
		odd -= highpass[column];
		odd = DivideByShift(odd, 1);


		// Place the odd result in the odd column
		//odd >>= _INVERSE_TEMPORAL_PRESCALE;
		*(colptr++) = SATURATE(odd);
	}

	// Should have exited the loop at the column for right border processing
	assert(column == last_column);

	// Process the last two output points with special filters for the right border
	even = 0;
	odd = 0;

	// Apply the even reconstruction filter to the lowpass band
	even += 5 * lowpass[column + 0];
	even += 4 * lowpass[column - 1];
	even -= 1 * lowpass[column - 2];
	even += 4;
	even >>= 3;

	// Add the highpass correction
	even += highline[column];
	even = DivideByShift(even, 1);

	// Place the even result in the even column
	*(colptr++) = SATURATE(even);

	// Apply the odd reconstruction filter to the lowpass band
	odd += 11 * lowpass[column + 0];
	odd -=  4 * lowpass[column - 1];
	odd +=  1 * lowpass[column - 2];
	odd += 4;
	odd >>= 3;

	// Subtract the highpass correction
	odd -= highline[column];
	odd = DivideByShift(odd, 1);

	// Place the odd result in the odd column
	*(colptr++) = SATURATE(odd);

#else
#error Have not implemented 8-bit lowpass coefficients
#endif
}

#endif



#if _PROCESSOR_DISPATCH

__declspec(cpu_dispatch(Pentium_4,Generic))

void InvertHorizontalRow16s(PIXEL *lowpass,  			// Row of horizontal lowpass coefficients
							//int lowpass_quantization,	// lowpass quantization factor
							PIXEL *highpass,			// Row of horizontal highpass coefficients
							//int highpass_quantization,// highpass quantization factor
							PIXEL *output,				// Row of reconstructed results
							int width)					// Length of each row of horizontal coefficients
							//PIXEL *buffer)			// Buffer to hold the dequantized values
{
	// Stub routine for processor specific dispatch
}
#endif


#if _PROCESSOR_GENERIC

#if _PROCESSOR_DISPATCH
__declspec(cpu_specific(Generic))
#endif

void InvertHorizontalRow16s(PIXEL *lowpass,  			// Row of horizontal lowpass coefficients
							//int lowpass_quantization,	// lowpass quantization factor
							PIXEL *highpass,			// Row of horizontal highpass coefficients
							//int highpass_quantization,// highpass quantization factor
							PIXEL *output,				// Row of reconstructed results
							int width)					// Length of each row of horizontal coefficients
							//PIXEL *buffer)			// Buffer to hold the dequantized values
{
	int InvertHorizontalRow16sNotMMX_yet = 0;
	assert(InvertHorizontalRow16sNotMMX_yet);
}
#endif //_PROCESSOR_GENERIC



#if _PROCESSOR_PENTIUM_4

#if _PROCESSOR_DISPATCH
__declspec(cpu_specific(Pentium_4))
#endif
/***SSE2 Only***/

// Apply the inverse horizontal transform to reconstruct a single row
void InvertHorizontalRow16s(PIXEL *lowpass,  			// Row of horizontal lowpass coefficients
							//int lowpass_quantization,	// lowpass quantization factor
							PIXEL *highpass,			// Row of horizontal highpass coefficients
							//int highpass_quantization,// highpass quantization factor
							PIXEL *output,				// Row of reconstructed results
							int width)					// Length of each row of horizontal coefficients
							//PIXEL *buffer)			// Buffer to hold the dequantized values
{
	const int column_step = 8;
	const int last_column = width - 1;
	int post_column = last_column - (last_column % column_step);
	int column;

	__m128i low1_epi16;		// Lowpass coefficients
	__m128i low2_epi16;
	__m128i high1_epi16;	// Current eight highpass coefficients
	__m128i high2_epi16;	// Next eight highpass coefficients

	// The fast loop merges values from different phases to allow aligned stores
	__m128i *outptr = (__m128i *)&output[0];
	__m128i half_epi16 = _mm_set1_epi16(4);

	PIXEL *colptr;

	int32_t even;
	int32_t odd;

	// Adjust the end of the fast loop if necessary
	if (post_column == last_column)
		post_column -= column_step;

	// Assume that quantization has already been performed by the decoder
	//DequantizeBandRow16s(highpass_data, width, highpass_quantization, highpass);

	// Start processing at the beginning of the row
	column = 0;

	// Process the first two output points with special filters for the left border
	even = 0;
	odd = 0;

	// Apply the even reconstruction filter to the lowpass band
	even += 11 * lowpass[column + 0];
	even -=  4 * lowpass[column + 1];
	even +=  1 * lowpass[column + 2];
	even += ROUNDING(even,8);
	even = DivideByShift(even, 3);

	// Add the highpass correction
	even += highpass[column];
	even = DivideByShift(even, 1);

	// Apply the odd reconstruction filter to the lowpass band
	odd += 5 * lowpass[column + 0];
	odd += 4 * lowpass[column + 1];
	odd -= 1 * lowpass[column + 2];
	odd += ROUNDING(odd,8);
	odd = DivideByShift(odd, 3);

	// Subtract the highpass correction
	odd -= highpass[column];
	odd = DivideByShift(odd, 1);

	//even = 100;		//***DEBUG***
	//odd = 100;		//***DEBUG***

#if (1 && XMMOPT)

	// Preload the first eight lowpass coefficients
	low1_epi16 = _mm_load_si128((__m128i *)&lowpass[column]);

	// Preload the first eight highpass coefficients
	high1_epi16 = _mm_load_si128((__m128i *)&highpass[column]);

	//low1_epi16 = _mm_set1_epi16(200);	//***DEBUG***
	//high1_epi16 = _mm_set1_epi16(0);	//***DEBUG***

	// The reconstruction filters use pixels starting at the first column
	for (; column < post_column; column += column_step)
	{
		__m128i even_epi16;		// Result of convolution with even filter
		__m128i odd_epi16;		// Result of convolution with odd filter
		__m128i temp_epi16;
		__m128i out_epi16;		// Reconstructed data

		uint32_t temp;		// Temporary register for last two values


		// Preload the next eight lowpass coefficients
		low2_epi16 = _mm_load_si128((__m128i *)&lowpass[column+8]);

		//low2_epi16 = _mm_set1_epi16(200);	//***DEBUG***


		/***** Compute the first two even and two odd output points *****/

		// Apply the even reconstruction filter to the lowpass band
/*		even_epi16 = low1_epi16;
		temp_epi16 = _mm_slli_epi16(low1_epi16, 3);
		temp_epi16 = _mm_srli_si128(temp_epi16, 1*2);
		even_epi16 = _mm_adds_epi16(even_epi16, temp_epi16);
		temp_epi16 = _mm_srli_si128(low1_epi16, 2*2);
		even_epi16 = _mm_subs_epi16(even_epi16, temp_epi16);

#if 1
		// Apply the rounding adjustment
		even_epi16 = _mm_adds_epi16(even_epi16, _mm_set1_epi16(4));
#endif
		// Divide by eight
		even_epi16 = _mm_srai_epi16(even_epi16, 3);
*/
		// better math.
		even_epi16 = low1_epi16;
		temp_epi16 = _mm_srli_si128(even_epi16, 2*2);
		even_epi16 = _mm_subs_epi16(even_epi16, temp_epi16);
		even_epi16 = _mm_adds_epi16(even_epi16, half_epi16);
		even_epi16 = _mm_srai_epi16(even_epi16, 3);
		temp_epi16 = _mm_srli_si128(low1_epi16, 1*2);
		even_epi16 = _mm_adds_epi16(even_epi16, temp_epi16);


		// Shift the highpass correction by one column
		high1_epi16 = _mm_srli_si128(high1_epi16, 1*2);

		// Add the highpass correction and divide by two
		even_epi16 = _mm_adds_epi16(even_epi16, high1_epi16);
		even_epi16 = _mm_srai_epi16(even_epi16, 1);

		// Apply the odd reconstruction filter to the lowpass band
/*		odd_epi16 = _mm_slli_epi16(low1_epi16, 3);
		odd_epi16 = _mm_srli_si128(odd_epi16, 1*2);
		temp_epi16 = _mm_srli_si128(low1_epi16, 2*2);
		odd_epi16 = _mm_adds_epi16(odd_epi16, temp_epi16);
		odd_epi16 = _mm_subs_epi16(odd_epi16, low1_epi16);

#if 1
		// Apply the rounding adjustment
		odd_epi16 = _mm_adds_epi16(odd_epi16, _mm_set1_epi16(4));
#endif
		// Divide by eight
		odd_epi16 = _mm_srai_epi16(odd_epi16, 3);
*/
		// better math.
		odd_epi16 = _mm_srli_si128(low1_epi16, 2*2);
		temp_epi16 = low1_epi16;
		odd_epi16 = _mm_subs_epi16(odd_epi16, temp_epi16);
		odd_epi16 = _mm_adds_epi16(odd_epi16, half_epi16);
		odd_epi16 = _mm_srai_epi16(odd_epi16, 3);
		temp_epi16 = _mm_srli_si128(low1_epi16, 1*2);
		odd_epi16 = _mm_adds_epi16(odd_epi16, temp_epi16);

		// Subtract the highpass correction and divide by two
		odd_epi16 = _mm_subs_epi16(odd_epi16, high1_epi16);
		odd_epi16 = _mm_srai_epi16(odd_epi16, 1);

		// Interleave the first four even and odd results
		out_epi16 = _mm_unpacklo_epi16(even_epi16, odd_epi16);

		// Combine the new output values with the two values from the previous phase
		out_epi16 = _mm_shuffle_epi32(out_epi16, _MM_SHUFFLE(2, 1, 0, 3));
		temp = _mm_cvtsi128_si32(out_epi16);
		out_epi16 = _mm_insert_epi16(out_epi16, even, 0);
		out_epi16 = _mm_insert_epi16(out_epi16, odd, 1);

		// Store eight output values
		_mm_store_si128(outptr++, out_epi16);

		// Save the remaining two output values
		even = (short)temp;
		odd = (short)(temp >> 16);


		/***** Compute the second four even and four odd output points *****/

		// Preload the highpass correction
		high2_epi16 = _mm_load_si128((__m128i *)&highpass[column+8]);

		//high2_epi16 = _mm_set1_epi16(0);	//***DEBUG***

		// Shift in the new pixels for the next stage of the loop
		low1_epi16 = _mm_srli_si128(low1_epi16, 4*2);
		temp_epi16 = _mm_slli_si128(low2_epi16, 4*2);
		low1_epi16 = _mm_or_si128(low1_epi16, temp_epi16);

		// Apply the even reconstruction filter to the lowpass band
/*		even_epi16 = low1_epi16;
		temp_epi16 = _mm_slli_epi16(low1_epi16, 3);
		temp_epi16 = _mm_srli_si128(temp_epi16, 1*2);
		even_epi16 = _mm_adds_epi16(even_epi16, temp_epi16);
		temp_epi16 = _mm_srli_si128(low1_epi16, 2*2);
		even_epi16 = _mm_subs_epi16(even_epi16, temp_epi16);

#if 1
		// Apply the rounding adjustment
		even_epi16 = _mm_adds_epi16(even_epi16, _mm_set1_epi16(4));
#endif
		// Divide by eight
		even_epi16 = _mm_srai_epi16(even_epi16, 3);
*/
		// better math.
		even_epi16 = low1_epi16;
		temp_epi16 = _mm_srli_si128(even_epi16, 2*2);
		even_epi16 = _mm_subs_epi16(even_epi16, temp_epi16);
		even_epi16 = _mm_adds_epi16(even_epi16, half_epi16);
		even_epi16 = _mm_srai_epi16(even_epi16, 3);
		temp_epi16 = _mm_srli_si128(low1_epi16, 1*2);
		even_epi16 = _mm_adds_epi16(even_epi16, temp_epi16);

		// Shift in the next four highpass coefficients
		high1_epi16 = _mm_srli_si128(high1_epi16, 4*2);
		temp_epi16 = _mm_slli_si128(high2_epi16, 3*2);
		high1_epi16 = _mm_or_si128(high1_epi16, temp_epi16);

		// Add the highpass correction and divide by two
		even_epi16 = _mm_adds_epi16(even_epi16, high1_epi16);
		even_epi16 = _mm_srai_epi16(even_epi16, 1);

		// Apply the odd reconstruction filter to the lowpass band
/*		odd_epi16 = _mm_slli_epi16(low1_epi16, 3);
		odd_epi16 = _mm_srli_si128(odd_epi16, 1*2);
		temp_epi16 = _mm_srli_si128(low1_epi16, 2*2);
		odd_epi16 = _mm_adds_epi16(odd_epi16, temp_epi16);
		odd_epi16 = _mm_subs_epi16(odd_epi16, low1_epi16);

#if 1
		// Apply the rounding adjustment
		odd_epi16 = _mm_adds_epi16(odd_epi16, _mm_set1_epi16(4));
#endif
		// Divide by eight
		odd_epi16 = _mm_srai_epi16(odd_epi16, 3);
*/
		// better math.
		odd_epi16 = _mm_srli_si128(low1_epi16, 2*2);
		temp_epi16 = low1_epi16;
		odd_epi16 = _mm_subs_epi16(odd_epi16, temp_epi16);
		odd_epi16 = _mm_adds_epi16(odd_epi16, half_epi16);
		odd_epi16 = _mm_srai_epi16(odd_epi16, 3);
		temp_epi16 = _mm_srli_si128(low1_epi16, 1*2);
		odd_epi16 = _mm_adds_epi16(odd_epi16, temp_epi16);


		// Subtract the highpass correction and divide by two
		odd_epi16 = _mm_subs_epi16(odd_epi16, high1_epi16);
		odd_epi16 = _mm_srai_epi16(odd_epi16, 1);

		// Interleave the second four even and odd results
		out_epi16 = _mm_unpacklo_epi16(even_epi16, odd_epi16);

		// Combine the new output values with the two values from the previous phase
		out_epi16 = _mm_shuffle_epi32(out_epi16, _MM_SHUFFLE(2, 1, 0, 3));
		temp = _mm_cvtsi128_si32(out_epi16);
		out_epi16 = _mm_insert_epi16(out_epi16, even, 0);
		out_epi16 = _mm_insert_epi16(out_epi16, odd, 1);

		// Store eight output values
		_mm_store_si128(outptr++, out_epi16);

		// Save the remaining two output values
		even = (short)temp;
		odd = (short)(temp >> 16);


		/***** Prepare for the next loop iteration *****/

		// The second eight lowpass coefficients will be the current values
		low1_epi16 = low2_epi16;

		// The second eight highpass coefficients will be the current values
		high1_epi16 = high2_epi16;
	}

	// Should have exited the loop with the column equal to the post processing column
	assert(column == post_column);

#endif

	// The fast processing loop is one column behind the actual column
	column++;

	// Get the pointer to the next output value
	colptr = (PIXEL *)outptr;

	// Store the last two output points produced by the loop
	*(colptr++) = SATURATE(even);
	*(colptr++) = SATURATE(odd);

	// Process the rest of the columns up to the last column in the row
	for (; column < last_column; column++)
	{
		int32_t even = 0;		// Result of convolution with even filter
		int32_t odd = 0;		// Result of convolution with odd filter

		// Apply the even reconstruction filter to the lowpass band
		even += lowpass[column - 1];
		even -= lowpass[column + 1];
		even += ROUNDING(even,8);
		even = DivideByShift(even, 3);
		even += lowpass[column + 0];

		// Add the highpass correction
		even += highpass[column];
		even = DivideByShift(even, 1);

		//even = 100;		//***DEBUG***

		// Place the even result in the even column
		*(colptr++) = SATURATE(even);

		// Apply the odd reconstruction filter to the lowpass band
		odd -= lowpass[column - 1];
		odd += lowpass[column + 1];
		odd += ROUNDING(odd,8);
		odd = DivideByShift(odd, 3);
		odd += lowpass[column + 0];

		// Subtract the highpass correction
		odd -= highpass[column];
		odd = DivideByShift(odd, 1);

		//odd = 100;		//***DEBUG***

		// Place the odd result in the odd column
		*(colptr++) = SATURATE(odd);
	}

	// Should have exited the loop at the column for right border processing
	assert(column == last_column);

	// Process the last two output points with special filters for the right border
	even = 0;
	odd = 0;

	// Apply the even reconstruction filter to the lowpass band
	even += 5 * lowpass[column + 0];
	even += 4 * lowpass[column - 1];
	even -= 1 * lowpass[column - 2];
	even += ROUNDING(even,8);
	even = DivideByShift(even, 3);

	// Add the highpass correction
	even += highpass[column];
	even = DivideByShift(even, 1);

	//even = 100;		//***DEBUG***

	// Place the even result in the even column
	*(colptr++) = SATURATE(even);

	// Apply the odd reconstruction filter to the lowpass band
	odd += 11 * lowpass[column + 0];
	odd -=  4 * lowpass[column - 1];
	odd +=  1 * lowpass[column - 2];
	odd += ROUNDING(odd,8);
	odd = DivideByShift(odd, 3);

	// Subtract the highpass correction
	odd -= highpass[column];
	odd = DivideByShift(odd, 1);

	//odd = 100;		//***DEBUG***

	// Place the odd result in the odd column
	*(colptr++) = SATURATE(odd);
}

#endif //P4



void BypassHorizontalRow16s(PIXEL *lowpass,  			// Row of horizontal lowpass coefficients
							//int lowpass_quantization,	// lowpass quantization factor
							PIXEL *highpass,			// Row of horizontal highpass coefficients
							//int highpass_quantization,// highpass quantization factor
							PIXEL *output,				// Row of reconstructed results
							int width)					// Length of each row of horizontal coefficients
							//PIXEL *buffer)			// Buffer to hold the dequantized values
{
	const int column_step = 8;
	const int last_column = width;
	int post_column = last_column - (last_column % column_step);
	int column;

	__m128i low_epi16;		// Lowpass coefficients

	// The fast loop merges values from different phases to allow aligned stores
	PIXEL *colptr = &output[0];

	// Start processing at the beginning of the row
	column = 0;


#if (1 && XMMOPT)

	if(ISALIGNED16(lowpass) && ISALIGNED16(colptr))
	{
		for (; column < post_column; column+=8)
		{
			low_epi16 = _mm_load_si128((__m128i *)&lowpass[column]);
			low_epi16 = _mm_srai_epi16(low_epi16, 1);
			_mm_store_si128((__m128i *)&colptr[column], low_epi16);
		}
	}
	else
	{
		for (; column < post_column; column+=8)
		{
			low_epi16 = _mm_loadu_si128((__m128i *)&lowpass[column]);
			low_epi16 = _mm_srai_epi16(low_epi16, 1);
			_mm_storeu_si128((__m128i *)&colptr[column], low_epi16);
		}
	}

#endif

	// Process the rest of the columns up to the last column in the row
	for (; column < last_column; column++)
	{
		int32_t even = 0;		// Result of convolution with even filter
		//int32_t odd = 0;		// Result of convolution with odd filter

		even = lowpass[column + 0];
		even = DivideByShift(even, 1);
		// Place the even result in the even column
		colptr[column] = SATURATE(even);
	}
}



#if _PROCESSOR_DISPATCH

__declspec(cpu_dispatch(Pentium_4,Generic))

void InvertHorizontalRow8sBuffered(PIXEL8S *lowpass,			// Row of horizontal lowpass coefficients
								   int lowpass_quantization,	// Lowpass quantization factor
								   PIXEL8S *highpass,			// Row of horizontal highpass coefficients
								   int highpass_quantization,	// Highpass quantization factor
								   PIXEL   *output,				// Row of reconstructed results
								   int width,					// Length of each row of horizontal coefficients
								   PIXEL *buffer)				// Buffer to hold the dequantized values
{
	// Stub routine for processor specific dispatch
}
#endif


#if _PROCESSOR_GENERIC

#if _PROCESSOR_DISPATCH
__declspec(cpu_specific(Generic))
#endif

// Apply the inverse horizontal transform to reconstruct a single row
void InvertHorizontalRow8sBuffered(PIXEL8S *lowpass_data,			// Row of horizontal lowpass coefficients
								   int lowpass_quantization,	// Lowpass quantization factor
								   PIXEL8S *highpass_data,			// Row of horizontal highpass coefficients
								   int highpass_quantization,	// Highpass quantization factor
								   PIXEL   *output,				// Row of reconstructed results
								   int width,					// Length of each row of horizontal coefficients
								   PIXEL *buffer)				// Buffer to hold the dequantized values
{
	// Need to implement this routine for 8-bit decoding

#if _DECODE_LOWPASS_16S
	const int column_step = 4;
	const int last_column = width - 1;
	int post_column = last_column - (last_column % column_step);
	int column;

	__m64 low1_pi16;	// Lower four lowpass coefficients
	__m64 low2_pi16;	// Upper four lowpass coefficients
	__m64 high1_pi16;	// Lower four highpass coefficients
	__m64 high2_pi16;	// Upper four highpass coefficients

	PIXEL *lowline = buffer;
	PIXEL *highline = buffer + width;

	// The fast loop computes output points starting at the third column
	__m64 *outptr = (__m64 *)&output[2];

	PIXEL *colptr;

	int32_t even;
	int32_t odd;
	//int32_t lsb;

	PIXEL *lowpass = (PIXEL *)lowpass_data;
	PIXEL *highpass = (PIXEL *)highpass_data;

	// Adjust the end of the fast loop if necessary
	if (post_column == last_column)
		post_column -= column_step;

	// Align the highpass buffer to a 16 byte boundary
	highline = (PIXEL *)ALIGN16(highline);

	// Undo quantization for the lowpass and highpass bands
#if _DEQUANTIZE_IN_FSM
	lowline = lowpass;
	highline = highpass;
#else
	DequantizeBandRow16s(lowpass, width, lowpass_quantization, lowline);
	DequantizeBandRow16s(highpass, width, highpass_quantization, highline);
#endif

	// Start processing at the beginning of the row
	column = 0;

	// Process the first two output points with special filters for the left border
	even = 0;
	odd = 0;

	// Apply the even reconstruction filter to the lowpass band
	even += 11 * lowline[column + 0];
	even -=  4 * lowline[column + 1];
	even +=  1 * lowline[column + 2];
	even += ROUNDING(even,8);
	even = DivideByShift(even, 3);

	// Add the highpass correction
	even += highline[column];
	even = DivideByShift(even, 1);

	// Place the even result in the even column
	output[0] = SATURATE(even);

	// Apply the odd reconstruction filter to the lowpass band
	odd += 5 * lowline[column + 0];
	odd += 4 * lowline[column + 1];
	odd -= 1 * lowline[column + 2];
	odd += ROUNDING(odd,8);
	odd = DivideByShift(odd, 3);

	// Subtract the highpass correction
	odd -= highline[column];
	odd = DivideByShift(odd, 1);

	// Place the odd result in the odd column
	output[1] = SATURATE(odd);

#if (1 && XMMOPT)

	// Preload the first four lowpass coefficients
	low1_pi16 = *((__m64 *)&lowline[column]);

	// Preload the first four highpass coefficients
	high1_pi16 = *((__m64 *)&highline[column]);

	// The reconstruction filters use pixels starting at the first column
	for (; column < post_column; column += column_step)
	{
		__m64 even_pi16;	// Result of convolution with even filter
		__m64 odd_pi16;		// Result of convolution with odd filter
		__m64 temp_pi16;
		__m64 out_pi16;		// Reconstructed data
		__m64 mask_pi16;
		__m64 half_pi16 = _mm_set1_pi16(4);
		__m64 lsb_pi16;
		__m64 sign_pi16;
//		__m64 high_pi16;

		// Preload the next four lowpass coefficients
		low2_pi16 = *((__m64 *)&lowline[column+4]);


		// Compute the first two even and two odd output points //

		// Apply the even reconstruction filter to the lowpass band
		even_pi16 = low1_pi16;
		temp_pi16 = _mm_slli_pi16(low1_pi16, 3);
		temp_pi16 = _mm_shuffle_pi16(temp_pi16, _MM_SHUFFLE(0, 3, 2, 1));
		even_pi16 = _mm_adds_pi16(even_pi16, temp_pi16);
		temp_pi16 = _mm_shuffle_pi16(low1_pi16, _MM_SHUFFLE(1, 0, 3, 2));
		even_pi16 = _mm_subs_pi16(even_pi16, temp_pi16);

		// Apply the rounding adjustment
		even_pi16 = _mm_adds_pi16(even_pi16, half_pi16);
		// Divide by eight
		even_pi16 = _mm_srai_pi16(even_pi16, 3);

		// Shift the highpass correction by one column
		high1_pi16 = _mm_srli_si64(high1_pi16, 16);

		// Prescale for 8bit output - DAN 4/5/02
//		high_pi16 = _mm_slli_pi16(high1_pi16, prescale);

		// Add the highpass correction
		even_pi16 = _mm_adds_pi16(even_pi16, high1_pi16);
		even_pi16 = _mm_srai_pi16(even_pi16, 1);

		// Apply the odd reconstruction filter to the lowpass band
		odd_pi16 = _mm_slli_pi16(low1_pi16, 3);
		odd_pi16 = _mm_shuffle_pi16(odd_pi16, _MM_SHUFFLE(0, 3, 2, 1));
		temp_pi16 = _mm_shuffle_pi16(low1_pi16, _MM_SHUFFLE(1, 0, 3, 2));
		odd_pi16 = _mm_adds_pi16(odd_pi16, temp_pi16);
		odd_pi16 = _mm_subs_pi16(odd_pi16, low1_pi16);


		// Apply the rounding adjustment
		odd_pi16 = _mm_adds_pi16(odd_pi16, half_pi16);
		// Divide by eight
		odd_pi16 = _mm_srai_pi16(odd_pi16, 3);

		// Subtract the highpass correction
		odd_pi16 = _mm_subs_pi16(odd_pi16, high1_pi16);
		odd_pi16 = _mm_srai_pi16(odd_pi16, 1);

		// Interleave the even and odd results
		out_pi16 = _mm_unpacklo_pi16(even_pi16, odd_pi16);
		//out_pi16 = _mm_max_pi16(out_pi16, _mm_setzero_si64());
		*(outptr++) = out_pi16;

		// Compute the second two even and two odd output points //

		// Preload the highpass correction
		high2_pi16 = *((__m64 *)&highline[column+4]);

		// Shift in the new pixels for the next stage of the loop
		low1_pi16 = _mm_srli_si64(low1_pi16, 32);
		temp_pi16 = _mm_slli_si64(low2_pi16, 32);
		low1_pi16 = _mm_or_si64(low1_pi16, temp_pi16);

		// Apply the even reconstruction filter to the lowpass band
		even_pi16 = low1_pi16;
		temp_pi16 = _mm_slli_pi16(low1_pi16, 3);
		temp_pi16 = _mm_shuffle_pi16(temp_pi16, _MM_SHUFFLE(0, 3, 2, 1));
		even_pi16 = _mm_adds_pi16(even_pi16, temp_pi16);
		temp_pi16 = _mm_shuffle_pi16(low1_pi16, _MM_SHUFFLE(1, 0, 3, 2));
		even_pi16 = _mm_subs_pi16(even_pi16, temp_pi16);

		// Apply the rounding adjustment
		even_pi16 = _mm_adds_pi16(even_pi16, half_pi16);
		// Divide by eight
		even_pi16 = _mm_srai_pi16(even_pi16, 3);

		// Shift in the next two highpass coefficients
		high1_pi16 = _mm_srli_si64(high1_pi16, 2*16);
		high1_pi16 = _mm_or_si64(high1_pi16, _mm_slli_si64(high2_pi16, 16));

		// Prescale for 8bit output - DAN 4/5/02
//		high_pi16 = _mm_slli_pi16(high1_pi16, prescale);

		// Add the highpass correction
		even_pi16 = _mm_adds_pi16(even_pi16, high1_pi16);
		even_pi16 = _mm_srai_pi16(even_pi16, 1);

		// Apply the odd reconstruction filter to the lowpass band
		odd_pi16 = _mm_slli_pi16(low1_pi16, 3);
		odd_pi16 = _mm_shuffle_pi16(odd_pi16, _MM_SHUFFLE(0, 3, 2, 1));
		temp_pi16 = _mm_shuffle_pi16(low1_pi16, _MM_SHUFFLE(1, 0, 3, 2));
		odd_pi16 = _mm_adds_pi16(odd_pi16, temp_pi16);
		odd_pi16 = _mm_subs_pi16(odd_pi16, low1_pi16);

		// Apply the rounding adjustment
		odd_pi16 = _mm_adds_pi16(odd_pi16, half_pi16);
		// Divide by eight
		odd_pi16 = _mm_srai_pi16(odd_pi16, 3);

		// Subtract the highpass correction
		odd_pi16 = _mm_subs_pi16(odd_pi16, high1_pi16);
		odd_pi16 = _mm_srai_pi16(odd_pi16, 1);

		// Interleave the even and odd results
		out_pi16 = _mm_unpacklo_pi16(even_pi16, odd_pi16);
		//out_pi16 = _mm_max_pi16(out_pi16, _mm_setzero_si64());
		*(outptr++) = out_pi16;

		// The second four lowpass coefficients will be the current values
		low1_pi16 = low2_pi16;

		// The second four highpass coefficients will be the current values
		high1_pi16 = high2_pi16;
	}

	// Should have exited the loop with the column equal to the post processing column
	assert(column == post_column);

#endif

	// The fast processing loop is one column behind the actual column
	column++;

	// Process the rest of the columns up to the last column in the row
	colptr = (PIXEL *)outptr;

	for (; column < last_column; column++)
	{
		int32_t even = 0;		// Result of convolution with even filter
		int32_t odd = 0;		// Result of convolution with odd filter

		// Apply the even reconstruction filter to the lowpass band
		even += lowline[column - 1];
		even -= lowline[column + 1];
		even += ROUNDING(even,8);
		even = DivideByShift(even, 3);
		even += (lowline[column + 0]);

		// Add the highpass correction
		even += highline[column];
		even = DivideByShift(even, 1);

		// Place the even result in the even column
		*(colptr++) = SATURATE(even);

		// Apply the odd reconstruction filter to the lowpass band
		odd -= lowline[column - 1];
		odd += lowline[column + 1];
		odd += ROUNDING(odd,8);
		odd = DivideByShift(odd, 3);
		odd += (lowline[column + 0]);

		// Subtract the highpass correction
		odd -= highline[column];
		odd = DivideByShift(odd, 1);

		// Place the odd result in the odd column
		*(colptr++) = SATURATE(odd);
	}

	// Should have exited the loop at the column for right border processing
	assert(column == last_column);

	// Process the last two output points with special filters for the right border
	even = 0;
	odd = 0;

	// Apply the even reconstruction filter to the lowpass band
	even += 5 * lowline[column + 0];
	even += 4 * lowline[column - 1];
	even -= 1 * lowline[column - 2];
	even += ROUNDING(even,8);
	even = DivideByShift(even, 3);

	// Add the highpass correction
	even += highline[column];
	even = DivideByShift(even, 1);

	// Place the even result in the even column
	*(colptr++) = SATURATE(even);

	// Apply the odd reconstruction filter to the lowpass band
	odd += 11 * lowline[column + 0];
	odd -=  4 * lowline[column - 1];
	odd +=  1 * lowline[column - 2];
	odd += ROUNDING(odd,8);
	odd = DivideByShift(odd, 3);

	// Subtract the highpass correction
	odd -= highline[column];
	odd = DivideByShift(odd, 1);

	// Place the odd result in the odd column
	*(colptr++) = SATURATE(odd);

	//_mm_empty();	// Clear the mmx register state

#else
#error Have not implemented 8-bit lowpass coefficients
#endif
}

#endif


#if _PROCESSOR_PENTIUM_4

#if _PROCESSOR_DISPATCH
__declspec(cpu_specific(Pentium_4))
#endif

// Apply the inverse horizontal transform to reconstruct a single row
void InvertHorizontalRow8sBuffered(PIXEL8S *lowpass_data,			// Row of horizontal lowpass coefficients
								   int lowpass_quantization,	// Lowpass quantization factor
								   PIXEL8S *highpass_data,			// Row of horizontal highpass coefficients
								   int highpass_quantization,	// Highpass quantization factor
								   PIXEL   *output,				// Row of reconstructed results
								   int width,					// Length of each row of horizontal coefficients
								   PIXEL *buffer)				// Buffer to hold the dequantized values
{
	// Need to implement this routine for 8-bit decoding

#if _DECODE_LOWPASS_16S
	const int column_step = 8;
	const int last_column = width - 1;
	int post_column = last_column - (last_column % column_step);
	int column;

	__m128i low1_epi16;		// Lower eight lowpass coefficients
	__m128i low2_epi16;		// Upper eight lowpass coefficients
	__m128i high1_epi16;	// Lower eight highpass coefficients
	__m128i high2_epi16;	// Upper eight highpass coefficients

	PIXEL *lowline = buffer;
	PIXEL *highline = buffer + width;

	// Some calculations can extend past the true length of the row
	//int row_length = ALIGN16(width);

#if _UNALIGNED
	// The fast loop computes output points starting at the third column
	__m128i *outptr = (__m128i *)&output[2];
#else
	// The fast loop merges values from different phases to allow aligned stores
	__m128i *outptr = (__m128i *)&output[0];
#endif

	// Two 16-bit coefficients from the previous loop iteration
	//short remainder[2];

	PIXEL *colptr;

	int32_t even;
	int32_t odd;
	//int32_t lsb;

	PIXEL *lowpass = (PIXEL *)lowpass_data;
	PIXEL *highpass = (PIXEL *)highpass_data;

	// Adjust the end of the fast loop if necessary
	if (post_column == last_column)
		post_column -= column_step;

	// Align the highpass buffer to a 16 byte boundary
	highline = (PIXEL *)ALIGN16(highline);

	// Check that both row buffers are properly aligned
	assert(ISALIGNED16(lowline));
	assert(ISALIGNED16(highline));

	// Undo quantization for the lowpass and highpass bands
#if _DEQUANTIZE_IN_FSM
	lowline = lowpass;
	highline = highpass;
#else
	DequantizeBandRow16s(lowpass, row_length, lowpass_quantization, lowline);
	DequantizeBandRow16s(highpass, row_length, highpass_quantization, highline);
#endif

	// Start processing at the beginning of the row
	column = 0;

	// Process the first two output points with special filters for the left border
	even = 0;
	odd = 0;

	// Apply the even reconstruction filter to the lowpass band
	even += 11 * lowline[column + 0];
	even -=  4 * lowline[column + 1];
	even +=  1 * lowline[column + 2];
	even += ROUNDING(even,8);
	even = DivideByShift(even, 3);

	// Add the highpass correction
	even += highline[column];
	even = DivideByShift(even, 1);

#if _UNALIGNED
	// Place the even result in the even column
	output[0] = SATURATE(even);
#else
	// The output value will be stored later
	//remainder[0] = SATURATE(even);
#endif

	// Apply the odd reconstruction filter to the lowpass band
	odd += 5 * lowline[column + 0];
	odd += 4 * lowline[column + 1];
	odd -= 1 * lowline[column + 2];
	odd += ROUNDING(odd,8);
	odd = DivideByShift(odd, 3);

	// Subtract the highpass correction
	odd -= highline[column];
	odd = DivideByShift(odd, 1);

#if _UNALIGNED
	// Place the odd result in the odd column
	output[1] = SATURATE(odd);
#else
	// The output value will be stored later
	//remainder[1] = SATURATE(odd);
#endif

#if (1 && _FASTLOOP && XMMOPT)

	// Preload the first four lowpass coefficients
	low1_epi16 = _mm_load_si128((__m128i *)&lowline[column]);

	// Preload the first four highpass coefficients
	high1_epi16 = _mm_load_si128((__m128i *)&highline[column]);

	// The reconstruction filters use pixels starting at the first column
	for (; column < post_column; column += column_step)
	{
		__m128i even_epi16;		// Result of convolution with even filter
		__m128i odd_epi16;		// Result of convolution with odd filter
		__m128i temp_epi16;
		__m128i out_epi16;		// Reconstructed data
		__m128i half_epi16 = _mm_set1_epi16(4);
		//__m128i high_epi16;
		uint32_t temp;		// Temporary register for last two values

		// Preload the next eight lowpass coefficients
		low2_epi16 = _mm_load_si128((__m128i *)&lowline[column+8]);


		// Compute the first four even and four odd output points //

		// Apply the even reconstruction filter to the lowpass band
		even_epi16 = low1_epi16;
		temp_epi16 = _mm_slli_epi16(low1_epi16, 3);
		temp_epi16 = _mm_srli_si128(temp_epi16, 1*2);
		even_epi16 = _mm_adds_epi16(even_epi16, temp_epi16);
		temp_epi16 = _mm_srli_si128(low1_epi16, 2*2);
		even_epi16 = _mm_subs_epi16(even_epi16, temp_epi16);

		// Apply the rounding adjustment
		even_epi16 = _mm_adds_epi16(even_epi16, half_epi16);

		// Divide by eight
		even_epi16 = _mm_srai_epi16(even_epi16, 3);

		// Shift the highpass correction by one column
		high1_epi16 = _mm_srli_si128(high1_epi16, 1*2);

		// Prescale for 8bit output - DAN 4/5/02
		//high_epi16 = _mm_slli_epi16(high1_epi16, prescale);

		// Add the highpass correction and divide by two
		even_epi16 = _mm_adds_epi16(even_epi16, high1_epi16);
		even_epi16 = _mm_srai_epi16(even_epi16, 1);

		// Apply the odd reconstruction filter to the lowpass band
		odd_epi16 = _mm_slli_epi16(low1_epi16, 3);
		odd_epi16 = _mm_srli_si128(odd_epi16, 1*2);
		temp_epi16 = _mm_srli_si128(low1_epi16, 2*2);
		odd_epi16 = _mm_adds_epi16(odd_epi16, temp_epi16);
		odd_epi16 = _mm_subs_epi16(odd_epi16, low1_epi16);

		// Apply the rounding adjustment
		odd_epi16 = _mm_adds_epi16(odd_epi16, half_epi16);

		// Divide by eight
		odd_epi16 = _mm_srai_epi16(odd_epi16, 3);

		// Subtract the highpass correction and divide by two
		odd_epi16 = _mm_subs_epi16(odd_epi16, high1_epi16);
		odd_epi16 = _mm_srai_epi16(odd_epi16, 1);

		// Interleave the even and odd results
		out_epi16 = _mm_unpacklo_epi16(even_epi16, odd_epi16);
		//out_epi16 = _mm_max_epi16(out_epi16, _mm_setzero_si64());

#if _UNALIGNED
		// Store the first eight output values
		_mm_storeu_si128(outptr++, out_epi16);
#else
		// Combine the new output values with the two values from the previous phase
		out_epi16 = _mm_shuffle_epi32(out_epi16, _MM_SHUFFLE(2, 1, 0, 3));
		temp = _mm_cvtsi128_si32(out_epi16);
		out_epi16 = _mm_insert_epi16(out_epi16, even, 0);
		out_epi16 = _mm_insert_epi16(out_epi16, odd, 1);

		// Store eight output values
		_mm_store_si128(outptr++, out_epi16);

		// Save the remaining two output values
		even = (short)temp;
		odd = (short)(temp >> 16);
#endif

		// Compute the second four even and four odd output points //

		// Preload the highpass correction
		high2_epi16 = _mm_load_si128((__m128i *)&highline[column+8]);

		// Shift in the new pixels for the next stage of the loop
		low1_epi16 = _mm_srli_si128(low1_epi16, 4*2);
		temp_epi16 = _mm_slli_si128(low2_epi16, 4*2);
		low1_epi16 = _mm_or_si128(low1_epi16, temp_epi16);

		// Apply the even reconstruction filter to the lowpass band
		even_epi16 = low1_epi16;
		temp_epi16 = _mm_slli_epi16(low1_epi16, 3);
		temp_epi16 = _mm_srli_si128(temp_epi16, 1*2);
		even_epi16 = _mm_adds_epi16(even_epi16, temp_epi16);
		temp_epi16 = _mm_srli_si128(low1_epi16, 2*2);
		even_epi16 = _mm_subs_epi16(even_epi16, temp_epi16);

		// Apply the rounding adjustment
		even_epi16 = _mm_adds_epi16(even_epi16, half_epi16);

		// Divide by eight
		even_epi16 = _mm_srai_epi16(even_epi16, 3);

		// Shift in the next four highpass coefficients
		high1_epi16 = _mm_srli_si128(high1_epi16, 4*2);
		temp_epi16 = _mm_slli_si128(high2_epi16, 3*2);
		high1_epi16 = _mm_or_si128(high1_epi16, temp_epi16);

		// Prescale for 8bit output - DAN 4/5/02
		//high_epi16 = _mm_slli_epi16(high1_epi16, prescale);

		// Add the highpass correction and divide by two
		even_epi16 = _mm_adds_epi16(even_epi16, high1_epi16);
		even_epi16 = _mm_srai_epi16(even_epi16, 1);

		// Apply the odd reconstruction filter to the lowpass band
		odd_epi16 = _mm_slli_epi16(low1_epi16, 3);
		odd_epi16 = _mm_srli_si128(odd_epi16, 1*2);
		temp_epi16 = _mm_srli_si128(low1_epi16, 2*2);
		odd_epi16 = _mm_adds_epi16(odd_epi16, temp_epi16);
		odd_epi16 = _mm_subs_epi16(odd_epi16, low1_epi16);

		// Apply the rounding adjustment
		odd_epi16 = _mm_adds_epi16(odd_epi16, half_epi16);

		// Divide by eight
		odd_epi16 = _mm_srai_epi16(odd_epi16, 3);

		// Subtract the highpass correction and divide by two
		odd_epi16 = _mm_subs_epi16(odd_epi16, high1_epi16);
		odd_epi16 = _mm_srai_epi16(odd_epi16, 1);

		// Interleave the even and odd results
		out_epi16 = _mm_unpacklo_epi16(even_epi16, odd_epi16);
		//out_epi16 = _mm_max_epi16(out_epi16, _mm_setzero_si64());

#if _UNALIGNED
		// Store the first eight output values
		_mm_storeu_si128(outptr++, out_epi16);
#else
		// Combine the new output values with the two values from the previous phase
		out_epi16 = _mm_shuffle_epi32(out_epi16, _MM_SHUFFLE(2, 1, 0, 3));
		temp = _mm_cvtsi128_si32(out_epi16);
		out_epi16 = _mm_insert_epi16(out_epi16, even, 0);
		out_epi16 = _mm_insert_epi16(out_epi16, odd, 1);

		// Store eight output values
		_mm_store_si128(outptr++, out_epi16);

		// Save the remaining two output values
		even = (short)temp;
		odd = (short)(temp >> 16);
#endif
		// The second four lowpass coefficients will be the current values
		low1_epi16 = low2_epi16;

		// The second four highpass coefficients will be the current values
		high1_epi16 = high2_epi16;
	}

	// Should have exited the loop with the column equal to the post processing column
	assert(column == post_column);

#endif

	// The fast processing loop is one column behind the actual column
	column++;

	// Get the pointer to the next output value
	colptr = (PIXEL *)outptr;

#if _UNALIGNED
	// The last two output points have already been stored
#else
	// Store the last two output points produced by the loop
	*(colptr++) = SATURATE(even);
	*(colptr++) = SATURATE(odd);
#endif

	// Process the rest of the columns up to the last column in the row
	for (; column < last_column; column++)
	{
		int32_t even = 0;		// Result of convolution with even filter
		int32_t odd = 0;		// Result of convolution with odd filter

		// Apply the even reconstruction filter to the lowpass band
		even += lowline[column - 1];
		even -= lowline[column + 1];
		even += 4; //DAN20050921
		even >>= 3;
		even += lowline[column + 0];

		// Add the highpass correction
		even += highline[column];
		even = DivideByShift(even, 1);

		// Place the even result in the even column
		*(colptr++) = SATURATE(even);

		// Apply the odd reconstruction filter to the lowpass band
		odd -= lowline[column - 1];
		odd += lowline[column + 1];
		odd += 4; //DAN20050921
		odd >>= 3;
		odd += lowline[column + 0];

		// Subtract the highpass correction
		odd -= highline[column];
		odd = DivideByShift(odd, 1);

		// Place the odd result in the odd column
		*(colptr++) = SATURATE(odd);
	}

	// Should have exited the loop at the column for right border processing
	assert(column == last_column);

	// Process the last two output points with special filters for the right border
	even = 0;
	odd = 0;

	// Apply the even reconstruction filter to the lowpass band
	even += 5 * lowline[column + 0];
	even += 4 * lowline[column - 1];
	even -= 1 * lowline[column - 2];
	even += 4;
	even >>= 3;

	// Add the highpass correction
	even += highline[column];
	even = DivideByShift(even, 1);

	// Place the even result in the even column
	*(colptr++) = SATURATE(even);

	// Apply the odd reconstruction filter to the lowpass band
	odd += 11 * lowline[column + 0];
	odd -=  4 * lowline[column - 1];
	odd +=  1 * lowline[column - 2];
	odd += 4;
	odd >>= 3;

	// Subtract the highpass correction
	odd -= highline[column];
	odd = DivideByShift(odd, 1);

	// Place the odd result in the odd column
	*(colptr++) = SATURATE(odd);

#else
#error Have not implemented 8-bit lowpass coefficients
#endif
}

#endif

#if _DEBUG

//#if BUILD_PROSPECT

// Apply the inverse horizontal transform to reconstruct a single row using pixel duplication
void InvertHorizontalRowDuplicated16s(PIXEL *lowpass,				// Row of horizontal lowpass coefficients
									  int lowpass_quantization,		// Lowpass quantization factor
									  PIXEL8S *highpass_data,		// Row of horizontal highpass coefficients
									  int highpass_quantization,	// highpass quantization factor
									  PIXEL *output,				// Row of reconstructed results
									  int width,					// Length of each row of horizontal coefficients
									  PIXEL *buffer)				// Buffer to hold the dequantized values
{
	const int column_step = 8;
	const int last_column = width;
	int post_column = last_column - (last_column % column_step);
	int column;

	__m128i low1_epi16;		// Lowpass coefficients
	__m128i low2_epi16;
	__m128i *outptr = (__m128i *)&output[0];

	PIXEL *colptr;

	// Start processing at the beginning of the row
	column = 0;

#if (1 && XMMOPT)

	// Preload the first eight lowpass coefficients
	low1_epi16 = _mm_load_si128((__m128i *)&lowpass[column]);

	// Preload the first eight highpass coefficients
	//high1_epi16 = _mm_load_si128((__m128i *)&highline[column]);

	// The reconstruction filters use pixels starting at the first column
	for (; column < post_column; column += column_step)
	{
		__m128i even_epi16;		// Result of convolution with even filter
		__m128i odd_epi16;		// Result of convolution with odd filter
		__m128i temp_epi16;
		__m128i out_epi16;		// Reconstructed data


		// Preload the next eight lowpass coefficients
		low2_epi16 = _mm_load_si128((__m128i *)&lowpass[column+8]);


		/***** Compute the first two even and two odd output points *****/

		// Apply the even reconstruction filter to the lowpass band
		even_epi16 = low1_epi16;
		even_epi16 = _mm_srai_epi16(even_epi16, 1);

		// Apply the odd reconstruction filter to the lowpass band
		odd_epi16 = low1_epi16;
		odd_epi16 = _mm_srai_epi16(odd_epi16, 1);

		// Interleave the first four even and odd results
		out_epi16 = _mm_unpacklo_epi16(even_epi16, odd_epi16);

		// Store the first eight output values
		_mm_store_si128(outptr++, out_epi16);


		/***** Compute the second four even and four odd output points *****/

		// Preload the highpass correction
		//high2_epi16 = _mm_load_si128((__m128i *)&highline[column+8]);

		// Shift in the new pixels for the next stage of the loop
		low1_epi16 = _mm_srli_si128(low1_epi16, 4*2);
		temp_epi16 = _mm_slli_si128(low2_epi16, 4*2);
		low1_epi16 = _mm_or_si128(low1_epi16, temp_epi16);

		// Apply the even reconstruction filter to the lowpass band
		even_epi16 = low1_epi16;
		even_epi16 = _mm_srai_epi16(even_epi16, 1);

		// Apply the odd reconstruction filter to the lowpass band
		odd_epi16 = low1_epi16;
		odd_epi16 = _mm_srai_epi16(odd_epi16, 1);

		// Interleave the second four even and odd results
		out_epi16 = _mm_unpacklo_epi16(even_epi16, odd_epi16);

		// Store the first eight output values
		_mm_store_si128(outptr++, out_epi16);


		/***** Prepare for the next loop iteration *****/

		// The second eight lowpass coefficients will be the current values
		low1_epi16 = low2_epi16;

		// The second eight highpass coefficients will be the current values
		//high1_epi16 = high2_epi16;
	}

	// Should have exited the loop with the column equal to the post processing column
	assert(column == post_column);

#endif

	// Get the pointer to the next output value
	colptr = (PIXEL *)outptr;

	// Process the rest of the columns up to the last column in the row
	for (; column < last_column; column++)
	{
		int32_t even;
		int32_t odd;

		// Apply the even reconstruction filter to the lowpass band
		even = lowpass[column + 0];
		even = DivideByShift(even, 1);

		// Place the even result in the even column
		*(colptr++) = SATURATE(even);

		// Apply the odd reconstruction filter to the lowpass band
		odd = lowpass[column + 0];
		odd = DivideByShift(odd, 1);

		// Place the odd result in the odd column
		*(colptr++) = SATURATE(odd);
	}

	// Should have exited the loop at the column for right border processing
	assert(column == last_column);
}
//#endif //BUILD_PROSPECT

#endif


#if 1

// Apply the inverse spatial (horizontal and vertical) transform by
// performing the inverse horizontal transform as each row is output
// by the inverse vertical transform.

#if 0	//_PROCESSOR_DISPATCH		// This routine contains only MMX optimizations

__declspec(cpu_dispatch(Pentium_II,Pentium_III,Pentium_4,Generic))

void InvertSpatialQuant8s(PIXEL8S *lowlow_band, int lowlow_pitch,
						  PIXEL8S *lowhigh_band, int lowhigh_pitch,
						  PIXEL8S *highlow_band, int highlow_pitch,
						  PIXEL8S *highhigh_band, int highhigh_pitch,
						  PIXEL *output_image, int output_pitch,
						  ROI roi, PIXEL *buffer, size_t buffer_size,
						  int quantization[])
{
	// Stub routine for processor specific dispatch
}

__declspec(cpu_specific(Pentium_II))

#endif


// Adapted from the 8s version above
void InvertSpatialQuantOverflowProtected16s(PIXEL *lowlow_band, int lowlow_pitch,
											PIXEL *lowhigh_band, int lowhigh_pitch,
											PIXEL *highlow_band, int highlow_pitch,
											PIXEL *highhigh_band, int highhigh_pitch,
											PIXEL *output_image, int output_pitch,
											ROI roi, PIXEL *buffer, size_t buffer_size,
											int quantization[])
{
	PIXEL *lowlow = (PIXEL *)lowlow_band;
	PIXEL *lowhigh = lowhigh_band;
	PIXEL *highlow = highlow_band;
	PIXEL *highhigh = highhigh_band;
	PIXEL *output = output_image;
	PIXEL *even_lowpass;
	PIXEL *even_highpass;
	PIXEL *odd_lowpass;
	PIXEL *odd_highpass;
	PIXEL *lowpass;					// Strip of horizontal coefficients
	PIXEL *highpass;
	int lowpass_pitch;				// Distance between strip rows in bytes
	int highpass_pitch;
	ROI strip;					// Dimensions of the processing strip
	size_t buffer_row_size;
	size_t output_row_size = output_pitch;
	int buffer_half_pitch;
	int buffer_width;
	int buffer_pitch;
	int width = roi.width;
	int height = roi.height;
	int last_row = height - 1;
	int row, column;

	SCRATCH scratch_buffer = SCRATCH_INITIALIZER(buffer, buffer_size);
	SCRATCH *scratch = &scratch_buffer;
	PIXEL *lowhigh_line[3];
	PIXEL *highlow_line;
	PIXEL *highhigh_line;

	//int lowlow_quantization = quantization[LL_BAND];
	//int highlow_quantization = quantization[HL_BAND];
	//int lowhigh_quantization = quantization[LH_BAND];
	//int highhigh_quantization = quantization[HH_BAND];

	// Compute positions within the temporary buffer for each row of horizontal lowpass
	// and highpass intermediate coefficients computed by the vertical inverse transform
	buffer_row_size = width * sizeof(PIXEL);
	buffer_row_size = ALIGN16(buffer_row_size);
	buffer_half_pitch = (int)buffer_row_size/sizeof(PIXEL);
	buffer_pitch = 2 * buffer_half_pitch;
	buffer_width = width;

	// Check that the buffer is large enough to hold four rows of
	// vertical results and 5 rows of dequantized highpass coefficients
	assert(buffer_size >= (9 * buffer_row_size));

	// Set the dimensions of the processing strip
	strip.width = buffer_width;
	strip.height = 2;

	// Compute the positions of the even and odd rows of coefficients
	even_lowpass = (PIXEL *)AllocScratchBuffer(scratch, buffer_row_size);
	even_highpass = (PIXEL *)AllocScratchBuffer(scratch, buffer_row_size);
	odd_lowpass = (PIXEL *)AllocScratchBuffer(scratch, buffer_row_size);
	odd_highpass = (PIXEL *)AllocScratchBuffer(scratch, buffer_row_size);

	// Pointers into the strip of horizontal coefficients
	lowpass = even_lowpass;
	highpass = even_highpass;
	lowpass_pitch = (int)(2 * buffer_row_size);
	highpass_pitch = (int)(2 * buffer_row_size);

	// Compute the positions of the dequantized highpass rows
	lowhigh_line[0] = (PIXEL *)AllocScratchBuffer(scratch, buffer_row_size);
	lowhigh_line[1] = (PIXEL *)AllocScratchBuffer(scratch, buffer_row_size);
	lowhigh_line[2] = (PIXEL *)AllocScratchBuffer(scratch, buffer_row_size);
	highlow_line = (PIXEL *)AllocScratchBuffer(scratch, buffer_row_size);
	highhigh_line = (PIXEL *)AllocScratchBuffer(scratch, buffer_row_size);

	// Convert pitch from bytes to pixels
	lowlow_pitch /= sizeof(PIXEL);
	lowhigh_pitch /= sizeof(PIXEL);
	highlow_pitch /= sizeof(PIXEL);
	highhigh_pitch /= sizeof(PIXEL);
	output_pitch /= sizeof(PIXEL);

	// Apply the vertical border filter to the first row
	row = 0;

	// Dequantize three rows of highpass coefficients in the lowhigh band
#if _DEQUANTIZE_IN_FSM
	lowhigh_line[0] = lowhigh;
	lowhigh_line[1] = lowhigh+lowhigh_pitch;
	lowhigh_line[2] = lowhigh+2*lowhigh_pitch;

	highlow_line = highlow;
	highhigh_line = highhigh;
#else
	DequantizeBandRow16s(lowhigh, width, lowhigh_quantization, lowhigh_line[0]);
	DequantizeBandRow16s(lowhigh+lowhigh_pitch, width, lowhigh_quantization, lowhigh_line[1]);
	DequantizeBandRow16s(lowhigh+2*lowhigh_pitch, width, lowhigh_quantization, lowhigh_line[2]);

	// Dequantize one row of coefficients each in the highlow and highhigh bands
	DequantizeBandRow16s(highlow, width, highlow_quantization, highlow_line);
	DequantizeBandRow16s(highhigh, width, highhigh_quantization, highhigh_line);
#endif

	for (column = 0; column < width; column++)
	{
		int32_t even = 0;		// Result of convolution with even filter
		int32_t odd = 0;		// Result of convolution with odd filter


		/***** Compute the vertical inverse for the left two bands *****/

		// Apply the even reconstruction filter to the lowpass band
		even += 11 * lowlow[column + 0 * lowlow_pitch];
		even -=  4 * lowlow[column + 1 * lowlow_pitch];
		even +=  1 * lowlow[column + 2 * lowlow_pitch];
		even += ROUNDING(even,8);
		even = DivideByShift(even, 3);

		// Add the highpass correction
		even += highlow_line[column];
		even = DivideByShift(even, 1);

		// Place the even result in the even row
		even_lowpass[column] = SATURATE(even);

		// Apply the odd reconstruction filter to the lowpass band
		odd += 5 * lowlow[column + 0 * lowlow_pitch];
		odd += 4 * lowlow[column + 1 * lowlow_pitch];
		odd -= 1 * lowlow[column + 2 * lowlow_pitch];
		odd += ROUNDING(odd,8);
		odd = DivideByShift(odd, 3);

		// Subtract the highpass correction
		odd -= highlow_line[column];
		odd = DivideByShift(odd, 1);

		// Place the odd result in the odd row
		odd_lowpass[column] = SATURATE(odd);


		/***** Compute the vertical inverse for the right two bands *****/

		even = 0;
		odd = 0;

		// Apply the even reconstruction filter to the lowpass band
		even += 11 * lowhigh_line[0][column];
		even -=  4 * lowhigh_line[1][column];
		even +=  1 * lowhigh_line[2][column];
		even += ROUNDING(even,8);
		even = DivideByShift(even, 3);

		// Add the highpass correction
		even += highhigh_line[column];
		even = DivideByShift(even, 1);

		// Place the even result in the even row
		even_highpass[column] = SATURATE(even);

		// Apply the odd reconstruction filter to the lowpass band
		odd += 5 * lowhigh_line[0][column];
		odd += 4 * lowhigh_line[1][column];
		odd -= 1 * lowhigh_line[2][column];
		odd += ROUNDING(odd,8);
		odd = DivideByShift(odd, 3);

		// Subtract the highpass correction
		odd -= highhigh_line[column];
		odd = DivideByShift(odd, 1);

		// Place the odd result in the odd row
		odd_highpass[column] = SATURATE(odd);
	}

#if (0 && DEBUG)
	if (logfile) {
		DumpArray16s("Lowpass Strip", lowpass, strip.width, strip.height, lowpass_pitch, logfile);
		DumpArray16s("Highpass Strip", highpass, strip.width, strip.height, highpass_pitch, logfile);
	}
#endif

	// Apply the inverse horizontal transform to the even and odd rows (without descaling)
	InvertHorizontalStrip16s(lowpass, lowpass_pitch, highpass, highpass_pitch,
								 output, (int)output_row_size, strip);

	// Advance to the next pair of even and odd output rows
	output += 2 * output_pitch;

	// Do not advance the lowpass row pointers until after the fast loop
	//lowlow += lowlow_pitch;
	//lowhigh += lowhigh_pitch;

	// Always advance the highpass row pointers
	highlow += highlow_pitch;
	highhigh += highhigh_pitch;

	// Advance the row index
	row++;

	// Process the middle rows using the interior reconstruction filters
	for (; row < last_row; row++)
	{
//		assert(0);
#if (0 && XMMOPT) //DANREMOVED
		int column_step = 4;
		int post_column = width - (width % column_step);
		__m64 *even_lowpass_ptr = (__m64 *)even_lowpass;
		__m64 *even_highpass_ptr = (__m64 *)even_highpass;
		__m64 *odd_lowpass_ptr = (__m64 *)odd_lowpass;
		__m64 *odd_highpass_ptr = (__m64 *)odd_highpass;
		int quad_pitch;
#endif

		// Dequantize one row from each of the two highpass bands
#if _DEQUANTIZE_IN_FSM
		highlow_line = highlow;
		highhigh_line = highhigh;
#else
		DequantizeBandRow16s(highlow, width, highlow_quantization, highlow_line);
		DequantizeBandRow16s(highhigh, width, highhigh_quantization, highhigh_line);
#endif

		// Start at the first column
		column = 0;

#if (0 && XMMOPT) //DANREMOVED

		// Process groups of four coefficients along the row
		for (; column < post_column; column += column_step)
		{
			__m64 *lowlow_ptr = (__m64 *)&lowlow[column];
			__m64 *highlow_ptr = (__m64 *)&highlow_line[column];
			__m64 *lowhigh_ptr1 = (__m64 *)&lowhigh_line[0][column];
			__m64 *lowhigh_ptr2 = (__m64 *)&lowhigh_line[1][column];
			__m64 *lowhigh_ptr3 = (__m64 *)&lowhigh_line[2][column];
			__m64 *highhigh_ptr = (__m64 *)&highhigh_line[column];
			__m64 low0_pi16;
			__m64 low1_pi16;
			__m64 low2_pi16;
			__m64 high_pi16;
			__m64 even_pi16;
			__m64 odd_pi16;
			__m64 addition_pi16;
			__m64 diff_pi16;

			__m64 additionA_pi32;
			__m64 additionB_pi32;
			__m64 diffA_pi32;
			__m64 diffB_pi32;
			__m64 evenA_pi32;
			__m64 oddA_pi32;
			__m64 evenB_pi32;
			__m64 oddB_pi32;
			__m64 lowA_pi32;
			__m64 lowB_pi32;
			__m64 highA_pi32;
			__m64 highB_pi32;
			__m64 low1A_pi32;
			__m64 low1B_pi32;

			 // Was 4 but 7 makes for more accurate rounding to prevent luma/chroma shifts -- DAN 6/2/03
			__m64 half_pi32 = _mm_set1_pi32(4);
			__m64 zero = _mm_set1_pi16(0);


			/***** Compute the vertical inverse for the left two bands *****/

			// Set the pitch for the lowpass band used in this section of code
			quad_pitch = (lowlow_pitch * sizeof(PIXEL))/sizeof(__m64);

			// Accumulate parallel sums for the even and odd filters
		//even += lowlow[column + 0 * lowlow_pitch];
			low0_pi16 = *lowlow_ptr;	// Get four lowpass coefficients
			evenA_pi32 = _mm_unpackhi_pi16(zero,low0_pi16);
			evenA_pi32 = _mm_srai_pi32(evenA_pi32, 16); // presevere sign
			evenB_pi32 = _mm_unpacklo_pi16(zero,low0_pi16);
			evenB_pi32 = _mm_srai_pi32(evenB_pi32, 16); // presevere sign
			lowlow_ptr += quad_pitch;	// Advance to the next row

		//odd -= lowlow[column + 0 * lowlow_pitch];
			oddA_pi32 = _mm_sub_pi32(zero, evenA_pi32);
			oddB_pi32 = _mm_sub_pi32(zero, evenB_pi32);

			low1_pi16 = *lowlow_ptr;	// Get four lowpass coefficients
			low1A_pi32 = _mm_unpackhi_pi16(zero,low1_pi16);
			low1A_pi32 = _mm_srai_pi32(low1A_pi32, 16); // presevere sign
			low1B_pi32 = _mm_unpacklo_pi16(zero,low1_pi16);
			low1B_pi32 = _mm_srai_pi32(low1B_pi32, 16); // presevere sign
			lowlow_ptr += quad_pitch;	// Advance to the next row

			low2_pi16 = *lowlow_ptr;	// Get four lowpass coefficients
			lowA_pi32 = _mm_unpackhi_pi16(zero,low2_pi16);
			lowA_pi32 = _mm_srai_pi32(lowA_pi32, 16); // presevere sign
			lowB_pi32 = _mm_unpacklo_pi16(zero,low2_pi16);
			lowB_pi32 = _mm_srai_pi32(lowB_pi32, 16); // presevere sign


			//even_pi16 = _mm_subs_pi16(even_pi16, low_pi16);
		//even -= lowlow[column + 2 * lowlow_pitch];
			evenA_pi32 = _mm_sub_pi32(evenA_pi32, lowA_pi32);
			evenB_pi32 = _mm_sub_pi32(evenB_pi32, lowB_pi32);

			//odd_pi16 = _mm_adds_pi16(odd_pi16, low_pi16);
		//odd += lowlow[column + 2 * lowlow_pitch];
			oddA_pi32 = _mm_add_pi32(oddA_pi32, lowA_pi32);
			oddB_pi32 = _mm_add_pi32(oddB_pi32, lowB_pi32);


			//even_pi16 = _mm_adds_pi16(even_pi16, half_pi16); // +4 rounding
		//even += 4; //DAN20050921
			evenA_pi32 = _mm_add_pi32(evenA_pi32, half_pi32);
			evenB_pi32 = _mm_add_pi32(evenB_pi32, half_pi32);

		//odd += 4; //DAN20050921
			//odd_pi16 = _mm_adds_pi16(odd_pi16, half_pi16); // +4 rounding
			oddA_pi32 = _mm_add_pi32(oddA_pi32, half_pi32);
			oddB_pi32 = _mm_add_pi32(oddB_pi32, half_pi32);

		//even >>= 3;
			//even_pi16 = _mm_srai_pi16(even_pi16, 3); // divide by 8
			evenA_pi32 = _mm_srai_pi32(evenA_pi32, 3);
			evenB_pi32 = _mm_srai_pi32(evenB_pi32, 3);

		//odd >>= 3;
			//odd_pi16 = _mm_srai_pi16(odd_pi16, 3);  // divide by 8
			oddA_pi32 = _mm_srai_pi32(oddA_pi32, 3);
			oddB_pi32 = _mm_srai_pi32(oddB_pi32, 3);

		//addition = (lowlow[column + 1 * lowlow_pitch] + highlow_line[column]);
			high_pi16 = *highlow_ptr;
			highA_pi32 = _mm_unpackhi_pi16(zero,high_pi16);
			highA_pi32 = _mm_srai_pi32(highA_pi32, 16); // presevere sign
			highB_pi32 = _mm_unpacklo_pi16(zero,high_pi16);
			highB_pi32 = _mm_srai_pi32(highB_pi32, 16); // presevere sign
			//addition_pi16 = _mm_adds_pi16(low8_pi16, high_pi16);
			additionA_pi32 = _mm_add_pi32(low1A_pi32, highA_pi32);
			additionB_pi32 = _mm_add_pi32(low1B_pi32, highB_pi32);


		//diff = (lowlow[column + 1 * lowlow_pitch] - highlow_line[column]);
			//diff_pi16 = _mm_subs_pi16(low8_pi16, high_pi16);
			diffA_pi32 = _mm_sub_pi32(low1A_pi32, highA_pi32);
			diffB_pi32 = _mm_sub_pi32(low1B_pi32, highB_pi32);

			// These can clip inapproxiately (signed shorts are no enough)
			//even_pi16 = _mm_adds_pi16(even_pi16, addition_pi16);
		//even += addition;
			evenA_pi32 = _mm_add_pi32(evenA_pi32, additionA_pi32);
			evenB_pi32 = _mm_add_pi32(evenB_pi32, additionB_pi32);

		//odd += diff;
			//odd_pi16 = _mm_adds_pi16(odd_pi16, diff_pi16);
			oddA_pi32 = _mm_add_pi32(oddA_pi32, diffA_pi32);
			oddB_pi32 = _mm_add_pi32(oddB_pi32, diffB_pi32);

			//even_pi16 = _mm_srai_pi16(even_pi16, 1); // divide by 2
		//even = DivideByShift(even, 1);
			evenA_pi32 = _mm_srai_pi32(evenA_pi32, 1);
			evenB_pi32 = _mm_srai_pi32(evenB_pi32, 1);

		//odd = DivideByShift(odd, 1);
			//odd_pi16 = _mm_srai_pi16(odd_pi16, 1);  // divide by 2
			oddA_pi32 = _mm_srai_pi32(oddA_pi32, 1);
			oddB_pi32 = _mm_srai_pi32(oddB_pi32, 1);

			even_pi16 = _mm_packs_pi32 (evenB_pi32, evenA_pi32);
			odd_pi16 = _mm_packs_pi32 (oddB_pi32, oddA_pi32);


			// Store the even and odd groups of horizontal lowpass coefficients
			*(even_lowpass_ptr++) = even_pi16;
			*(odd_lowpass_ptr++) = odd_pi16;


			/**** Compute the vertical inverse for the right two bands *****/

			// Set the pitch for the lowpass band used in this section of code
			//quad_pitch = (lowhigh_pitch * sizeof(PIXEL))/sizeof(__m64);

			// Accumulate parallel sums for the even and odd filters

			low0_pi16 = *lowhigh_ptr1;		// Get four lowpass coefficients
			evenA_pi32 = _mm_unpackhi_pi16(zero,low0_pi16);
			evenA_pi32 = _mm_srai_pi32(evenA_pi32, 16); // presevere sign
			evenB_pi32 = _mm_unpacklo_pi16(zero,low0_pi16);
			evenB_pi32 = _mm_srai_pi32(evenB_pi32, 16); // presevere sign

			//lowhigh_ptr += quad_pitch;	// Advance to the next row

			oddA_pi32 = _mm_sub_pi32(zero, evenA_pi32);
			oddB_pi32 = _mm_sub_pi32(zero, evenB_pi32);

			low2_pi16 = *lowhigh_ptr3;		// Get four lowpass coefficients
			lowA_pi32 = _mm_unpackhi_pi16(zero,low2_pi16);
			lowA_pi32 = _mm_srai_pi32(lowA_pi32, 16); // presevere sign
			lowB_pi32 = _mm_unpacklo_pi16(zero,low2_pi16);
			lowB_pi32 = _mm_srai_pi32(lowB_pi32, 16); // presevere sign

			//even_pi16 = _mm_subs_pi16(even_pi16, low_pi16);
			evenA_pi32 = _mm_sub_pi32(evenA_pi32, lowA_pi32);
			evenB_pi32 = _mm_sub_pi32(evenB_pi32, lowB_pi32);

			//odd_pi16 = _mm_adds_pi16(odd_pi16, low_pi16);
			oddA_pi32 = _mm_add_pi32(oddA_pi32, lowA_pi32);
			oddB_pi32 = _mm_add_pi32(oddB_pi32, lowB_pi32);



			low1_pi16 = *lowhigh_ptr2;
			low1A_pi32 = _mm_unpackhi_pi16(zero,low1_pi16);
			low1A_pi32 = _mm_srai_pi32(low1A_pi32, 16); // presevere sign
			low1B_pi32 = _mm_unpacklo_pi16(zero,low1_pi16);
			low1B_pi32 = _mm_srai_pi32(low1B_pi32, 16); // presevere sign

			//even_pi16 = _mm_adds_pi16(even_pi16, half_pi16); // +4 rounding
			evenA_pi32 = _mm_add_pi32(evenA_pi32, half_pi32);
			evenB_pi32 = _mm_add_pi32(evenB_pi32, half_pi32);

			//odd_pi16 = _mm_adds_pi16(odd_pi16, half_pi16); // +4 rounding
			oddA_pi32 = _mm_add_pi32(oddA_pi32, half_pi32);
			oddB_pi32 = _mm_add_pi32(oddB_pi32, half_pi32);

			//even_pi16 = _mm_srai_pi16(even_pi16, 3); // divide by 8
			evenA_pi32 = _mm_srai_pi32(evenA_pi32, 3);
			evenB_pi32 = _mm_srai_pi32(evenB_pi32, 3);

			//odd_pi16 = _mm_srai_pi16(odd_pi16, 3);  // divide by 8
			oddA_pi32 = _mm_srai_pi32(oddA_pi32, 3);
			oddB_pi32 = _mm_srai_pi32(oddB_pi32, 3);


			high_pi16 = *highhigh_ptr;
			highA_pi32 = _mm_unpackhi_pi16(zero,high_pi16);
			highA_pi32 = _mm_srai_pi32(highA_pi32, 16); // presevere sign
			highB_pi32 = _mm_unpacklo_pi16(zero,high_pi16);
			highB_pi32 = _mm_srai_pi32(highB_pi32, 16); // presevere sign


			//addition_pi16 = _mm_adds_pi16(low8_pi16, high_pi16);
			additionA_pi32 = _mm_add_pi32(low1A_pi32, highA_pi32);
			additionB_pi32 = _mm_add_pi32(low1B_pi32, highB_pi32);

			//diff_pi16 = _mm_subs_pi16(low8_pi16, high_pi16);
			diffA_pi32 = _mm_sub_pi32(low1A_pi32, highA_pi32);
			diffB_pi32 = _mm_sub_pi32(low1B_pi32, highB_pi32);

			// These can clip inapproxiately (signed shorts are no enough)
			//even_pi16 = _mm_adds_pi16(even_pi16, addition_pi16);
			evenA_pi32 = _mm_add_pi32(evenA_pi32, additionA_pi32);
			evenB_pi32 = _mm_add_pi32(evenB_pi32, additionB_pi32);

			//odd_pi16 = _mm_adds_pi16(odd_pi16, diff_pi16);
			oddA_pi32 = _mm_add_pi32(oddA_pi32, diffA_pi32);
			oddB_pi32 = _mm_add_pi32(oddB_pi32, diffB_pi32);

			//even_pi16 = _mm_srai_pi16(even_pi16, 1); // divide by 2
			evenA_pi32 = _mm_srai_pi32(evenA_pi32, 1);
			evenB_pi32 = _mm_srai_pi32(evenB_pi32, 1);

			//odd_pi16 = _mm_srai_pi16(odd_pi16, 1);  // divide by 2
			oddA_pi32 = _mm_srai_pi32(oddA_pi32, 1);
			oddB_pi32 = _mm_srai_pi32(oddB_pi32, 1);

			even_pi16 = _mm_packs_pi32 (evenB_pi32, evenA_pi32);
			odd_pi16 = _mm_packs_pi32 (oddB_pi32, oddA_pi32);




			// Store the even and odd groups of horizontal highpass coefficients
			*(even_highpass_ptr++) = even_pi16;
			*(odd_highpass_ptr++) = odd_pi16;
		}


	// test this row.
	/*	for (column=0; column < width; column++)
		{
			int32_t even = 0;		// Result of convolution with even filter
			int32_t odd = 0;		// Result of convolution with odd filter
			int32_t addition, diff;


			// Compute the vertical inverse for the left two bands

			// Apply the even reconstruction filter to the lowpass band
			even += lowlow[column + 0 * lowlow_pitch];
			even -= lowlow[column + 2 * lowlow_pitch];
			even += 4; //DAN20050921
			even >>= 3;
			addition = (lowlow[column + 1 * lowlow_pitch] + highlow_line[column]);
			even += addition;

			// Add the highpass correction
			//even += highlow_line[column];
			even = DivideByShift(even, 1);

			// Place the even result in the even row
			assert(even_lowpass[column] == SATURATE(even));

			// Apply the odd reconstruction filter to the lowpass band
			odd -= lowlow[column + 0 * lowlow_pitch];
			odd += lowlow[column + 2 * lowlow_pitch];
			odd += 4; //DAN20050921
			odd >>= 3;
			diff = (lowlow[column + 1 * lowlow_pitch] - highlow_line[column]);
			odd += diff;

			// Subtract the highpass correction
			//odd -= highlow_line[column];
			odd = DivideByShift(odd, 1);

			// Place the odd result in the odd row
			assert(odd_lowpass[column] == SATURATE(odd));


			// Compute the vertical inverse for the right two bands

			even = 0;
			odd = 0;

			// Apply the even reconstruction filter to the lowpass band
			even += lowhigh_line[0][column];
			even -= lowhigh_line[2][column];
			even += 4; //DAN20050921
			even >>= 3;
			addition = (lowhigh_line[1][column]+highhigh_line[column]);
			even += addition;

			// Add the highpass correction
			//even += highhigh_line[column];
			even = DivideByShift(even, 1);

			// Place the even result in the even row
			assert(even_highpass[column] == SATURATE(even));


			// Apply the odd reconstruction filter to the lowpass band
			odd -= lowhigh_line[0][column];
			odd += lowhigh_line[2][column];
			odd += 4; //DAN20050921
			odd >>= 3;
			diff = (lowhigh_line[1][column] - highhigh_line[column]);
			odd += diff;

			// Subtract the highpass correction
			//odd -= highhigh_line[column];
			odd = DivideByShift(odd, 1);

			// Place the odd result in the odd row
			assert(odd_highpass[column] == SATURATE(odd));
		}
*/
		// Should have exited the loop at the post processing column
		assert(column == post_column);

#endif
		
		// Process the rest of the row
		for (; column < width; column++)
		{
			int32_t even = 0;		// Result of convolution with even filter
			int32_t odd = 0;		// Result of convolution with odd filter
			int32_t addition, diff;


			/***** Compute the vertical inverse for the left two bands *****/

			// Apply the even reconstruction filter to the lowpass band
			even += lowlow[column + 0 * lowlow_pitch];
			even -= lowlow[column + 2 * lowlow_pitch];
			even += 4; //DAN20050921
			even >>= 3;
			addition = (lowlow[column + 1 * lowlow_pitch] + highlow_line[column]);
			even += addition;

			// Add the highpass correction
			//even += highlow_line[column];
			even = DivideByShift(even, 1);

			// Place the even result in the even row
			even_lowpass[column] = SATURATE(even);

			// Apply the odd reconstruction filter to the lowpass band
			odd -= lowlow[column + 0 * lowlow_pitch];
			odd += lowlow[column + 2 * lowlow_pitch];
			odd += 4; //DAN20050921
			odd >>= 3;
			diff = (lowlow[column + 1 * lowlow_pitch] - highlow_line[column]);
			odd += diff;

			// Subtract the highpass correction
			//odd -= highlow_line[column];
			odd = DivideByShift(odd, 1);

			// Place the odd result in the odd row
			odd_lowpass[column] = SATURATE(odd);


			/***** Compute the vertical inverse for the right two bands *****/

			even = 0;
			odd = 0;

			// Apply the even reconstruction filter to the lowpass band
			even += lowhigh_line[0][column];
			even -= lowhigh_line[2][column];
			even += 4; //DAN20050921
			even >>= 3;
			addition = (lowhigh_line[1][column]+highhigh_line[column]);
			even += addition;

			// Add the highpass correction
			//even += highhigh_line[column];
			even = DivideByShift(even, 1);

			// Place the even result in the even row
			even_highpass[column] = SATURATE(even);

			// Apply the odd reconstruction filter to the lowpass band
			odd -= lowhigh_line[0][column];
			odd += lowhigh_line[2][column];
			odd += 4; //DAN20050921
			odd >>= 3;
			diff = (lowhigh_line[1][column] - highhigh_line[column]);
			odd += diff;

			// Subtract the highpass correction
			//odd -= highhigh_line[column];
			odd = DivideByShift(odd, 1);

			// Place the odd result in the odd row
			odd_highpass[column] = SATURATE(odd);
		}
		
		InvertHorizontalStrip16s(lowpass, lowpass_pitch,
									 highpass, highpass_pitch,
									 output, (int)output_row_size, strip);

		// Advance to the next input rows and skip the next output row
		lowlow += lowlow_pitch;
		lowhigh += lowhigh_pitch;
		highlow += highlow_pitch;
		highhigh += highhigh_pitch;
		output += 2 * output_pitch;

		if (row < last_row - 1) {
			PIXEL *temp = lowhigh_line[0];
			lowhigh_line[0] = lowhigh_line[1];
			lowhigh_line[1] = lowhigh_line[2];
			lowhigh_line[2] = temp;

			// Undo quantization for the next row in the lowhigh band
		  #if _DEQUANTIZE_IN_FSM
			lowhigh_line[2] = lowhigh+2*lowhigh_pitch;
		  #else
			DequantizeBandRow16s(lowhigh+2*lowhigh_pitch, width, lowhigh_quantization, lowhigh_line[2]);
		  #endif
		}
	}

#if (0 && XMMOPT) //DANREMOVED
	//_mm_empty();	// Clear the mmx register state

	// Need to advance the lowpass pointer if using SIMD instructions
	lowlow += lowlow_pitch;
	lowhigh += lowhigh_pitch;
#endif

	// Should have exited the loop at the last row
	assert(row == last_row);

	// Undo quantization for the highlow and highhigh bands
#if _DEQUANTIZE_IN_FSM
	highlow_line = highlow;
	highhigh_line = highhigh;
#else
	DequantizeBandRow16s(highlow, width, highlow_quantization, highlow_line);
	DequantizeBandRow16s(highhigh, width, highhigh_quantization, highhigh_line);
#endif

	// Apply the vertical border filter to the last row
	for (column = 0; column < width; column++)
	{
		int32_t even = 0;		// Result of convolution with even filter
		int32_t odd = 0;		// Result of convolution with odd filter


		/***** Compute the vertical inverse for the left two bands *****/

		// Apply the even reconstruction filter to the lowpass band
		even += 5 * lowlow[column + 0 * lowlow_pitch];
		even += 4 * lowlow[column - 1 * lowlow_pitch];
		even -= 1 * lowlow[column - 2 * lowlow_pitch];
		even += ROUNDING(even,8);
		even = DivideByShift(even, 3);

		// Add the highpass correction
		even += highlow_line[column];
		even = DivideByShift(even, 1);

		// Place the even result in the even row
		even_lowpass[column] = SATURATE(even);

		// Apply the odd reconstruction filter to the lowpass band
		odd += 11 * lowlow[column + 0 * lowlow_pitch];
		odd -=  4 * lowlow[column - 1 * lowlow_pitch];
		odd +=  1 * lowlow[column - 2 * lowlow_pitch];
		odd += ROUNDING(odd,8);
		odd = DivideByShift(odd, 3);

		// Subtract the highpass correction
		odd -= highlow_line[column];
		odd = DivideByShift(odd, 1);

		// Place the odd result in the odd row
		odd_lowpass[column] = SATURATE(odd);


		/***** Compute the vertical inverse for the right two bands *****/

		even = 0;
		odd = 0;

		// Apply the even reconstruction filter to the lowpass band
		even += 5 * lowhigh_line[2][column];
		even += 4 * lowhigh_line[1][column];
		even -= 1 * lowhigh_line[0][column];
		even += ROUNDING(even,8);
		even = DivideByShift(even, 3);

		// Add the highpass correction
		even += highhigh_line[column];
		even = DivideByShift(even, 1);

		// Place the even result in the even row
		even_highpass[column] = SATURATE(even);

		// Apply the odd reconstruction filter to the lowpass band
		odd += 11 * lowhigh_line[2][column];
		odd -=  4 * lowhigh_line[1][column];
		odd +=  1 * lowhigh_line[0][column];
		odd += ROUNDING(odd,8);
		odd = DivideByShift(odd, 3);

		// Subtract the highpass correction
		odd -= highhigh_line[column];
		odd = DivideByShift(odd, 1);

		// Place the odd result in the odd row
		odd_highpass[column] = SATURATE(odd);
	}

	// Apply the inverse horizontal transform to the even and odd rows and descale the results
	InvertHorizontalStrip16s(lowpass, lowpass_pitch,
								 highpass, highpass_pitch,
								 output, (int)output_row_size, strip);
}

// Adapted from the 8s version above
void InvertSpatialQuant16s(PIXEL *lowlow_band, int lowlow_pitch,
						  PIXEL *lowhigh_band, int lowhigh_pitch,
						  PIXEL *highlow_band, int highlow_pitch,
						  PIXEL *highhigh_band, int highhigh_pitch,
						  PIXEL *output_image, int output_pitch,
						  ROI roi, PIXEL *buffer, size_t buffer_size,
						  int quantization[])
{
	PIXEL *lowlow = (PIXEL *)lowlow_band;
	PIXEL *lowhigh = lowhigh_band;
	PIXEL *highlow = highlow_band;
	PIXEL *highhigh = highhigh_band;
	PIXEL *output = output_image;
	PIXEL *even_lowpass;
	PIXEL *even_highpass;
	PIXEL *odd_lowpass;
	PIXEL *odd_highpass;
	PIXEL *lowpass;					// Strip of horizontal coefficients
	PIXEL *highpass;
	int lowpass_pitch;				// Distance between strip rows in bytes
	int highpass_pitch;
	ROI strip;					// Dimensions of the processing strip
	size_t buffer_row_size;
	size_t output_row_size = output_pitch;
	int buffer_half_pitch;
	int buffer_width;
	int buffer_pitch;
	int width = roi.width;
	int height = roi.height;
	int last_row = height - 1;
	int row, column;

	SCRATCH scratch_buffer = SCRATCH_INITIALIZER(buffer, buffer_size);
	SCRATCH *scratch = &scratch_buffer;
	PIXEL *lowhigh_line[3];
	PIXEL *highlow_line;
	PIXEL *highhigh_line;

	//int lowlow_quantization = quantization[LL_BAND];
	//int highlow_quantization = quantization[HL_BAND];
	//int lowhigh_quantization = quantization[LH_BAND];
	//int highhigh_quantization = quantization[HH_BAND];

	// Compute positions within the temporary buffer for each row of horizontal lowpass
	// and highpass intermediate coefficients computed by the vertical inverse transform
	buffer_row_size = width * sizeof(PIXEL);
	buffer_row_size = ALIGN16(buffer_row_size);
	buffer_half_pitch = (int)buffer_row_size/sizeof(PIXEL);
	buffer_pitch = 2 * buffer_half_pitch;
	buffer_width = width;

	// Check that the buffer is large enough to hold four rows of
	// vertical results and 5 rows of dequantized highpass coefficients
	assert(buffer_size >= (9 * buffer_row_size));

	// Set the dimensions of the processing strip
	strip.width = buffer_width;
	strip.height = 2;

	// Compute the positions of the even and odd rows of coefficients
	even_lowpass = (PIXEL *)AllocScratchBuffer(scratch, buffer_row_size);
	even_highpass = (PIXEL *)AllocScratchBuffer(scratch, buffer_row_size);
	odd_lowpass = (PIXEL *)AllocScratchBuffer(scratch, buffer_row_size);
	odd_highpass = (PIXEL *)AllocScratchBuffer(scratch, buffer_row_size);

	// Pointers into the strip of horizontal coefficients
	lowpass = even_lowpass;
	highpass = even_highpass;
	lowpass_pitch = (int)(2 * buffer_row_size);
	highpass_pitch = (int)(2 * buffer_row_size);

	// Compute the positions of the dequantized highpass rows
	lowhigh_line[0] = (PIXEL *)AllocScratchBuffer(scratch, buffer_row_size);
	lowhigh_line[1] = (PIXEL *)AllocScratchBuffer(scratch, buffer_row_size);
	lowhigh_line[2] = (PIXEL *)AllocScratchBuffer(scratch, buffer_row_size);
	highlow_line = (PIXEL *)AllocScratchBuffer(scratch, buffer_row_size);
	highhigh_line = (PIXEL *)AllocScratchBuffer(scratch, buffer_row_size);

	// Convert pitch from bytes to pixels
	lowlow_pitch /= sizeof(PIXEL);
	lowhigh_pitch /= sizeof(PIXEL);
	highlow_pitch /= sizeof(PIXEL);
	highhigh_pitch /= sizeof(PIXEL);
	output_pitch /= sizeof(PIXEL);

	// Apply the vertical border filter to the first row
	row = 0;

	// Dequantize three rows of highpass coefficients in the lowhigh band
#if _DEQUANTIZE_IN_FSM
	lowhigh_line[0] = lowhigh;
	lowhigh_line[1] = lowhigh+lowhigh_pitch;
	lowhigh_line[2] = lowhigh+2*lowhigh_pitch;

	highlow_line = highlow;
	highhigh_line = highhigh;
#else
	DequantizeBandRow16s(lowhigh, width, lowhigh_quantization, lowhigh_line[0]);
	DequantizeBandRow16s(lowhigh+lowhigh_pitch, width, lowhigh_quantization, lowhigh_line[1]);
	DequantizeBandRow16s(lowhigh+2*lowhigh_pitch, width, lowhigh_quantization, lowhigh_line[2]);

	// Dequantize one row of coefficients each in the highlow and highhigh bands
	DequantizeBandRow16s(highlow, width, highlow_quantization, highlow_line);
	DequantizeBandRow16s(highhigh, width, highhigh_quantization, highhigh_line);
#endif

	for (column = 0; column < width; column++)
	{
		int32_t even = 0;		// Result of convolution with even filter
		int32_t odd = 0;		// Result of convolution with odd filter


		// Compute the vertical inverse for the left two bands //

		// Apply the even reconstruction filter to the lowpass band
		even += 11 * lowlow[column + 0 * lowlow_pitch];
		even -=  4 * lowlow[column + 1 * lowlow_pitch];
		even +=  1 * lowlow[column + 2 * lowlow_pitch];
		even += ROUNDING(even,8);
		even = DivideByShift(even, 3);

		// Add the highpass correction
		even += highlow_line[column];
		even >>= 1;//DAN20050913 - DivideByShift(even, 1);

		// Place the even result in the even row
		even_lowpass[column] = SATURATE(even);

		// Apply the odd reconstruction filter to the lowpass band
		odd += 5 * lowlow[column + 0 * lowlow_pitch];
		odd += 4 * lowlow[column + 1 * lowlow_pitch];
		odd -= 1 * lowlow[column + 2 * lowlow_pitch];
		odd += ROUNDING(odd,8);
		odd = DivideByShift(odd, 3);

		// Subtract the highpass correction
		odd -= highlow_line[column];
		odd >>= 1;//DAN20050913 - DivideByShift(odd, 1);

		// Place the odd result in the odd row
		odd_lowpass[column] = SATURATE(odd);


		// Compute the vertical inverse for the right two bands //

		even = 0;
		odd = 0;

		// Apply the even reconstruction filter to the lowpass band
		even += 11 * lowhigh_line[0][column];
		even -=  4 * lowhigh_line[1][column];
		even +=  1 * lowhigh_line[2][column];
		even += ROUNDING(even,8);
		even = DivideByShift(even, 3);

		// Add the highpass correction
		even += highhigh_line[column];
		even >>= 1;//DAN20050913 - DivideByShift(even, 1);

		// Place the even result in the even row
		even_highpass[column] = SATURATE(even);

		// Apply the odd reconstruction filter to the lowpass band
		odd += 5 * lowhigh_line[0][column];
		odd += 4 * lowhigh_line[1][column];
		odd -= 1 * lowhigh_line[2][column];
		odd += ROUNDING(odd,8);
		odd = DivideByShift(odd, 3);

		// Subtract the highpass correction
		odd -= highhigh_line[column];
		odd >>= 1;//DAN20050913 - DivideByShift(odd, 1);

		// Place the odd result in the odd row
		odd_highpass[column] = SATURATE(odd);
	}

#if (0 && DEBUG)
	if (logfile) {
		DumpArray16s("Lowpass Strip", lowpass, strip.width, strip.height, lowpass_pitch, logfile);
		DumpArray16s("Highpass Strip", highpass, strip.width, strip.height, highpass_pitch, logfile);
	}
#endif

	// Apply the inverse horizontal transform to the even and odd rows and descale the results
	InvertHorizontalStrip16s(lowpass, lowpass_pitch,
							 highpass, highpass_pitch,
							 output, (int)output_row_size, strip);

	// Advance to the next pair of even and odd output rows
	output += 2 * output_pitch;

	// Do not advance the lowpass row pointers until after the fast loop
	//lowlow += lowlow_pitch;
	//lowhigh += lowhigh_pitch;

	// Always advance the highpass row pointers
	highlow += highlow_pitch;
	highhigh += highhigh_pitch;

	// Advance the row index
	row++;

	// Process the middle rows using the interior reconstruction filters
	for (; row < last_row; row++)
	{
#if (1 && XMMOPT)
		int column_step = 8;
		int post_column = width - (width % column_step);
        __m128i *even_lowpass_ptr  = (__m128i *)even_lowpass;
        __m128i *even_highpass_ptr = (__m128i *)even_highpass;
        __m128i *odd_lowpass_ptr   = (__m128i *)odd_lowpass;
        __m128i *odd_highpass_ptr  = (__m128i *)odd_highpass;
        int oct_pitch;
#endif

		// Dequantize one row from each of the two highpass bands
	#if _DEQUANTIZE_IN_FSM
		highlow_line = highlow;
		highhigh_line = highhigh;
	#else
		DequantizeBandRow16s(highlow, width, highlow_quantization, highlow_line);
		DequantizeBandRow16s(highhigh, width, highhigh_quantization, highhigh_line);
	#endif

		// Start at the first column
		column = 0;

#if (1 && XMMOPT)

		// Process groups of four coefficients along the row
		for (; column < post_column; column += column_step)
		{
            __m128i *lowlow_ptr = (__m128i *)(lowlow + column);
            __m128i *highlow_ptr = (__m128i *)(highlow_line + column);
            __m128i *lowhigh1_ptr = (__m128i *)(lowhigh_line[0] + column);
            __m128i *lowhigh2_ptr = (__m128i *)(lowhigh_line[1] + column);
            __m128i *lowhigh3_ptr = (__m128i *)(lowhigh_line[2] + column);
            __m128i *highhigh_ptr = (__m128i *)(highhigh_line + column);
            __m128i quad_epi16, quad8_epi16, even_epi16, odd_epi16;
            __m128i half_epi16 = _mm_set1_epi16(4); // used for rounding
            __m128i zero_epi16 = _mm_set1_epi16(0);

			// Compute the vertical inverse for the left two bands //

			// Set the pitch for the lowpass band used in this section of code
            oct_pitch = (lowlow_pitch * sizeof(PIXEL)) / sizeof(__m128i);

			// Accumulate parallel sums for the even and odd filters
            quad_epi16 = _mm_loadu_si128(lowlow_ptr);   // get 8 lowpass coefficients
            lowlow_ptr += oct_pitch;                    // advance to next row
            
            even_epi16 = quad_epi16;
            odd_epi16 = _mm_subs_epi16(zero_epi16, quad_epi16);
            
            quad8_epi16 = _mm_loadu_si128(lowlow_ptr);  // get 8 lowpass coefficients
            lowlow_ptr += oct_pitch;                    // advance to next row
            
            quad_epi16 = _mm_loadu_si128(lowlow_ptr);   // get 8 lowpass coefficients
            
            even_epi16 = _mm_subs_epi16(even_epi16, quad_epi16);
            even_epi16 = _mm_adds_epi16(even_epi16, half_epi16); // rounding
            even_epi16 = _mm_srai_epi16(even_epi16, 3);          // divide by 8
            even_epi16 = _mm_adds_epi16(even_epi16, quad8_epi16);
            
            odd_epi16 = _mm_adds_epi16(odd_epi16, quad_epi16);
            odd_epi16 = _mm_adds_epi16(odd_epi16, half_epi16);   // rounding
            odd_epi16 = _mm_srai_epi16(odd_epi16, 3);            // divide by 8
            odd_epi16 = _mm_adds_epi16(odd_epi16, quad8_epi16);
            
            // Add the highpass correction to the even result and divide by 2
            quad_epi16 = _mm_loadu_si128(highlow_ptr);
            even_epi16 = _mm_adds_epi16(even_epi16, quad_epi16);
            even_epi16 = _mm_srai_epi16(even_epi16, 1);
            
            // Subtract the highpass correction from the odd result and divide by 2
            odd_epi16 = _mm_subs_epi16(odd_epi16, quad_epi16);
            odd_epi16 = _mm_srai_epi16(odd_epi16, 1);
            
            // Store the even and odd groups of horizontal lowpass coefficients
            _mm_storeu_si128(even_lowpass_ptr++, even_epi16);
            _mm_storeu_si128(odd_lowpass_ptr++, odd_epi16);
            

			// Compute the vertical inverse for the right two bands //

			// Set the pitch for the lowpass band used in this section of code
            oct_pitch = (lowhigh_pitch * sizeof(PIXEL)) / sizeof(__m128i);

			// Accumulate parallel sums for the even and odd filters
            quad_epi16 = _mm_loadu_si128(lowhigh1_ptr);     // get 8 lowpass coefficients
            even_epi16 = quad_epi16;
            odd_epi16 = _mm_subs_epi16(zero_epi16, quad_epi16);
            quad_epi16 = _mm_loadu_si128(lowhigh3_ptr);     // get 8 lowpass coefficients
            
            even_epi16 = _mm_subs_epi16(even_epi16, quad_epi16);
            even_epi16 = _mm_adds_epi16(even_epi16, half_epi16); // rounding
            even_epi16 = _mm_srai_epi16(even_epi16, 3);          // divide by 8
            
            odd_epi16 = _mm_adds_epi16(odd_epi16, quad_epi16);
            odd_epi16 = _mm_adds_epi16(odd_epi16, half_epi16);   // rounding
            odd_epi16 = _mm_srai_epi16(odd_epi16, 3);            // divide by 8
            
            quad_epi16 = _mm_loadu_si128(lowhigh2_ptr); // get 8 lowpass coefficients
            even_epi16 = _mm_adds_epi16(even_epi16, quad_epi16);
            odd_epi16 = _mm_adds_epi16(odd_epi16, quad_epi16);
            
            // Add the highpass correction to the even result and divide by 2
            quad_epi16 = _mm_loadu_si128(highhigh_ptr);
            even_epi16 = _mm_adds_epi16(even_epi16, quad_epi16);
            even_epi16 = _mm_srai_epi16(even_epi16, 1);
            
            // Subtract the highpass correction from the odd result and divide by 2
            odd_epi16 = _mm_subs_epi16(odd_epi16, quad_epi16);
            odd_epi16 = _mm_srai_epi16(odd_epi16, 1);
            
            // Store the even and odd groups of horizontal highpass coefficients
            _mm_storeu_si128(even_highpass_ptr++, even_epi16);
            _mm_storeu_si128(odd_highpass_ptr++, odd_epi16);
        }

		// Should have exited the loop at the post processing column
		assert(column == post_column);

#endif

#if (0 && DEBUG)
		if (logfile) {
			DumpArray16s("Lowpass Strip", lowpass, strip.width, strip.height, lowpass_pitch, logfile);
			DumpArray16s("Highpass Strip", highpass, strip.width, strip.height, highpass_pitch, logfile);
		}
#endif

		// Process the rest of the row
		for (; column < width; column++)
		{
			int32_t even = 0;		// Result of convolution with even filter
			int32_t odd = 0;		// Result of convolution with odd filter


			// Compute the vertical inverse for the left two bands //

			// Apply the even reconstruction filter to the lowpass band
			even += lowlow[column + 0 * lowlow_pitch];
			even -= lowlow[column + 2 * lowlow_pitch];
			even += 4; //DAN20050921
			even >>= 3;
			even += lowlow[column + 1 * lowlow_pitch];

			// Add the highpass correction
			even += highlow_line[column];
			even >>= 1;//DAN20050913 - DivideByShift(even, 1);

			// Place the even result in the even row
			even_lowpass[column] = SATURATE(even);

			// Apply the odd reconstruction filter to the lowpass band
			odd -= lowlow[column + 0 * lowlow_pitch];
			odd += lowlow[column + 2 * lowlow_pitch];
			odd += 4; //DAN20050921
			odd >>= 3;
			odd += lowlow[column + 1 * lowlow_pitch];

			// Subtract the highpass correction
			odd -= highlow_line[column];
			odd >>= 1;//DAN20050913 - DivideByShift(odd, 1);

			// Place the odd result in the odd row
			odd_lowpass[column] = SATURATE(odd);


			// Compute the vertical inverse for the right two bands //

			even = 0;
			odd = 0;

			// Apply the even reconstruction filter to the lowpass band
			even += lowhigh_line[0][column];
			even -= lowhigh_line[2][column];
			even += 4; //DAN20050921
			even >>= 3;
			even += lowhigh_line[1][column];

			// Add the highpass correction
			even += highhigh_line[column];
			even >>= 1;//DAN20050913 - DivideByShift(even, 1);

			// Place the even result in the even row
			even_highpass[column] = SATURATE(even);

			// Apply the odd reconstruction filter to the lowpass band
			odd -= lowhigh_line[0][column];
			odd += lowhigh_line[2][column];
			odd += 4; //DAN20050921
			odd >>= 3;
			odd += lowhigh_line[1][column];

			// Subtract the highpass correction
			odd -= highhigh_line[column];
			odd >>= 1;//DAN20050913 - DivideByShift(odd, 1);

			// Place the odd result in the odd row
			odd_highpass[column] = SATURATE(odd);
		}

#if (0 && DEBUG)
		if (logfile) {
			DumpArray16s("Lowpass Strip", lowpass, strip.width, strip.height, lowpass_pitch, logfile);
			DumpArray16s("Highpass Strip", highpass, strip.width, strip.height, highpass_pitch, logfile);
		}
#endif

		// Apply the inverse horizontal transform to the even and odd rows and descale the results
		InvertHorizontalStrip16s(lowpass, lowpass_pitch,
								 highpass, highpass_pitch,
								 output, (int)output_row_size, strip);

		// Advance to the next input rows and skip the next output row
		lowlow += lowlow_pitch;
		lowhigh += lowhigh_pitch;
		highlow += highlow_pitch;
		highhigh += highhigh_pitch;
		output += 2 * output_pitch;

		if (row < last_row - 1) {
			PIXEL *temp = lowhigh_line[0];
			lowhigh_line[0] = lowhigh_line[1];
			lowhigh_line[1] = lowhigh_line[2];
			lowhigh_line[2] = temp;

			// Undo quantization for the next row in the lowhigh band
		  #if _DEQUANTIZE_IN_FSM
			lowhigh_line[2] = lowhigh+2*lowhigh_pitch;
		  #else
			DequantizeBandRow16s(lowhigh+2*lowhigh_pitch, width, lowhigh_quantization, lowhigh_line[2]);
		  #endif
		}
	}

#if (1 && XMMOPT)
	// Need to advance the lowpass pointer if using SIMD instructions
	lowlow += lowlow_pitch;
	lowhigh += lowhigh_pitch;
#endif

	// Should have exited the loop at the last row
	assert(row == last_row);

	// Undo quantization for the highlow and highhigh bands
#if _DEQUANTIZE_IN_FSM
	highlow_line = highlow;
	highhigh_line = highhigh;
#else
	DequantizeBandRow16s(highlow, width, highlow_quantization, highlow_line);
	DequantizeBandRow16s(highhigh, width, highhigh_quantization, highhigh_line);
#endif

	// Apply the vertical border filter to the last row
	for (column = 0; column < width; column++)
	{
		int32_t even = 0;		// Result of convolution with even filter
		int32_t odd = 0;		// Result of convolution with odd filter


		// Compute the vertical inverse for the left two bands //

		// Apply the even reconstruction filter to the lowpass band
		even += 5 * lowlow[column + 0 * lowlow_pitch];
		even += 4 * lowlow[column - 1 * lowlow_pitch];
		even -= 1 * lowlow[column - 2 * lowlow_pitch];
		even += 4; //DAN20050921
		even = DivideByShift(even, 3);

		// Add the highpass correction
		even += highlow_line[column];
		even >>= 1;//DAN20050913 - DivideByShift(even, 1);

		// Place the even result in the even row
		even_lowpass[column] = SATURATE(even);

		// Apply the odd reconstruction filter to the lowpass band
		odd += 11 * lowlow[column + 0 * lowlow_pitch];
		odd -=  4 * lowlow[column - 1 * lowlow_pitch];
		odd +=  1 * lowlow[column - 2 * lowlow_pitch];
		odd += 4; //DAN20050921
		odd = DivideByShift(odd, 3);

		// Subtract the highpass correction
		odd -= highlow_line[column];
		odd >>= 1;//DAN20050913 - DivideByShift(odd, 1);

		// Place the odd result in the odd row
		odd_lowpass[column] = SATURATE(odd);


		// Compute the vertical inverse for the right two bands //

		even = 0;
		odd = 0;

		// Apply the even reconstruction filter to the lowpass band
		even += 5 * lowhigh_line[2][column];
		even += 4 * lowhigh_line[1][column];
		even -= 1 * lowhigh_line[0][column];
		even += 4; //DAN20050921
		even = DivideByShift(even, 3);

		// Add the highpass correction
		even += highhigh_line[column];
		even >>= 1;//DAN20050913 - DivideByShift(even, 1);

		// Place the even result in the even row
		even_highpass[column] = SATURATE(even);

		// Apply the odd reconstruction filter to the lowpass band
		odd += 11 * lowhigh_line[2][column];
		odd -=  4 * lowhigh_line[1][column];
		odd +=  1 * lowhigh_line[0][column];
		odd += 4; //DAN20050921
		odd = DivideByShift(odd, 3);

		// Subtract the highpass correction
		odd -= highhigh_line[column];
		odd >>= 1;//DAN20050913 - DivideByShift(odd, 1);

		// Place the odd result in the odd row
		odd_highpass[column] = SATURATE(odd);
	}

	// Apply the inverse horizontal transform to the even and odd rows and descale the results
	InvertHorizontalStrip16s(lowpass, lowpass_pitch,
							 highpass, highpass_pitch,
							 output, (int)output_row_size, strip);
}

///universal decoder
// Spatial transform inversion with descaling
void InvertSpatialQuantDescale16s(PIXEL *lowlow_band, int lowlow_pitch,
								  PIXEL *lowhigh_band, int lowhigh_pitch,
								  PIXEL *highlow_band, int highlow_pitch,
								  PIXEL *highhigh_band, int highhigh_pitch,
								  PIXEL *output_image, int output_pitch,
								  ROI roi, PIXEL *buffer, size_t buffer_size,
								  int descale, int quantization[])
{
	PIXEL *lowlow = (PIXEL *)lowlow_band;
	PIXEL *lowhigh = lowhigh_band;
	PIXEL *highlow = highlow_band;
	PIXEL *highhigh = highhigh_band;
	PIXEL *output = output_image;
	PIXEL *even_lowpass;
	PIXEL *even_highpass;
	PIXEL *odd_lowpass;
	PIXEL *odd_highpass;
	PIXEL *lowpass;					// Strip of horizontal coefficients
	PIXEL *highpass;
	int lowpass_pitch;				// Distance between strip rows in bytes
	int highpass_pitch;
	ROI strip;					// Dimensions of the processing strip
	size_t buffer_row_size;
	size_t output_row_size = output_pitch;
	int buffer_half_pitch;
	int buffer_width;
	int buffer_pitch;
	int width = roi.width;
	int height = roi.height;
	int last_row = height - 1;
	int row, column;

	SCRATCH scratch_buffer = SCRATCH_INITIALIZER(buffer, buffer_size);
	SCRATCH *scratch = &scratch_buffer;
	PIXEL *lowhigh_line[3];
	PIXEL *highlow_line;
	PIXEL *highhigh_line;

	//int lowlow_quantization = quantization[LL_BAND];
	//int highlow_quantization = quantization[HL_BAND];
	//int lowhigh_quantization = quantization[LH_BAND];
	//int highhigh_quantization = quantization[HH_BAND];

	// Compute positions within the temporary buffer for each row of horizontal lowpass
	// and highpass intermediate coefficients computed by the vertical inverse transform
	buffer_row_size = width * sizeof(PIXEL);
	buffer_row_size = ALIGN16(buffer_row_size);
	buffer_half_pitch = (int)buffer_row_size/sizeof(PIXEL);
	buffer_pitch = 2 * buffer_half_pitch;
	buffer_width = width;

	// Check that the buffer is large enough to hold four rows of
	// vertical results and 5 rows of dequantized highpass coefficients
	assert(buffer_size >= (9 * buffer_row_size));

	// Set the dimensions of the processing strip
	strip.width = buffer_width;
	strip.height = 2;

	// Compute the positions of the even and odd rows of coefficients
	even_lowpass = (PIXEL *)AllocScratchBuffer(scratch, buffer_row_size);
	even_highpass = (PIXEL *)AllocScratchBuffer(scratch, buffer_row_size);
	odd_lowpass = (PIXEL *)AllocScratchBuffer(scratch, buffer_row_size);
	odd_highpass = (PIXEL *)AllocScratchBuffer(scratch, buffer_row_size);

	// Pointers into the strip of horizontal coefficients
	lowpass = even_lowpass;
	highpass = even_highpass;
	lowpass_pitch = (int)(2 * buffer_row_size);
	highpass_pitch = (int)(2 * buffer_row_size);

	// Compute the positions of the dequantized highpass rows
	lowhigh_line[0] = (PIXEL *)AllocScratchBuffer(scratch, buffer_row_size);
	lowhigh_line[1] = (PIXEL *)AllocScratchBuffer(scratch, buffer_row_size);
	lowhigh_line[2] = (PIXEL *)AllocScratchBuffer(scratch, buffer_row_size);
	highlow_line = (PIXEL *)AllocScratchBuffer(scratch, buffer_row_size);
	highhigh_line = (PIXEL *)AllocScratchBuffer(scratch, buffer_row_size);

	// Convert pitch from bytes to pixels
	lowlow_pitch /= sizeof(PIXEL);
	lowhigh_pitch /= sizeof(PIXEL);
	highlow_pitch /= sizeof(PIXEL);
	highhigh_pitch /= sizeof(PIXEL);
	output_pitch /= sizeof(PIXEL);

	// Apply the vertical border filter to the first row
	row = 0;

	// Dequantize three rows of highpass coefficients in the lowhigh band
#if _DEQUANTIZE_IN_FSM
	lowhigh_line[0] = lowhigh;
	lowhigh_line[1] = lowhigh+lowhigh_pitch;
	lowhigh_line[2] = lowhigh+2*lowhigh_pitch;

	highlow_line = highlow;
	highhigh_line = highhigh;
#else
	DequantizeBandRow16s(lowhigh, width, lowhigh_quantization, lowhigh_line[0]);
	DequantizeBandRow16s(lowhigh+lowhigh_pitch, width, lowhigh_quantization, lowhigh_line[1]);
	DequantizeBandRow16s(lowhigh+2*lowhigh_pitch, width, lowhigh_quantization, lowhigh_line[2]);

	// Dequantize one row of coefficients each in the highlow and highhigh bands
	DequantizeBandRow16s(highlow, width, highlow_quantization, highlow_line);
	DequantizeBandRow16s(highhigh, width, highhigh_quantization, highhigh_line);
#endif

	for (column = 0; column < width; column++)
	{
		int32_t even = 0;		// Result of convolution with even filter
		int32_t odd = 0;		// Result of convolution with odd filter


		/***** Compute the vertical inverse for the left two bands *****/

		// Apply the even reconstruction filter to the lowpass band
		even += 11 * lowlow[column + 0 * lowlow_pitch];
		even -=  4 * lowlow[column + 1 * lowlow_pitch];
		even +=  1 * lowlow[column + 2 * lowlow_pitch];
		even += ROUNDING(even,8);
		even = DivideByShift(even, 3);

		// Add the highpass correction
		even += highlow_line[column];
		even = DivideByShift(even, 1);

		// Place the even result in the even row
		even_lowpass[column] = SATURATE(even);

		// Apply the odd reconstruction filter to the lowpass band
		odd += 5 * lowlow[column + 0 * lowlow_pitch];
		odd += 4 * lowlow[column + 1 * lowlow_pitch];
		odd -= 1 * lowlow[column + 2 * lowlow_pitch];
		odd += ROUNDING(odd,8);
		odd = DivideByShift(odd, 3);

		// Subtract the highpass correction
		odd -= highlow_line[column];
		odd = DivideByShift(odd, 1);

		// Place the odd result in the odd row
		odd_lowpass[column] = SATURATE(odd);


		/***** Compute the vertical inverse for the right two bands *****/

		even = 0;
		odd = 0;

		// Apply the even reconstruction filter to the lowpass band
		even += 11 * lowhigh_line[0][column];
		even -=  4 * lowhigh_line[1][column];
		even +=  1 * lowhigh_line[2][column];
		even += ROUNDING(even,8);
		even = DivideByShift(even, 3);

		// Add the highpass correction
		even += highhigh_line[column];
		even = DivideByShift(even, 1);

		// Place the even result in the even row
		even_highpass[column] = SATURATE(even);

		// Apply the odd reconstruction filter to the lowpass band
		odd += 5 * lowhigh_line[0][column];
		odd += 4 * lowhigh_line[1][column];
		odd -= 1 * lowhigh_line[2][column];
		odd += ROUNDING(odd,8);
		odd = DivideByShift(odd, 3);

		// Subtract the highpass correction
		odd -= highhigh_line[column];
		odd = DivideByShift(odd, 1);

		// Place the odd result in the odd row
		odd_highpass[column] = SATURATE(odd);
	}

#if (0 && DEBUG)
	if (logfile) {
		DumpArray16s("Lowpass Strip", lowpass, strip.width, strip.height, lowpass_pitch, logfile);
		DumpArray16s("Highpass Strip", highpass, strip.width, strip.height, highpass_pitch, logfile);
	}
#endif

	// Apply the inverse horizontal transform to the even and odd rows and descale the results
	InvertHorizontalStripDescale16s(lowpass, lowpass_pitch,
									highpass, highpass_pitch,
									output, (int)output_row_size,
									strip, descale);

	// Advance to the next pair of even and odd output rows
	output += 2 * output_pitch;

	// Do not advance the lowpass row pointers until after the fast loop
	//lowlow += lowlow_pitch;
	//lowhigh += lowhigh_pitch;

	// Always advance the highpass row pointers
	highlow += highlow_pitch;
	highhigh += highhigh_pitch;

	// Advance the row index
	row++;

	// Process the middle rows using the interior reconstruction filters
	for (; row < last_row; row++)
	{
#if (1 && XMMOPT)
        int column_step = 8;
		int post_column = width - (width % column_step);
        __m128i *even_lowpass_ptr  = (__m128i *)even_lowpass;
        __m128i *even_highpass_ptr = (__m128i *)even_highpass;
        __m128i *odd_lowpass_ptr   = (__m128i *)odd_lowpass;
        __m128i *odd_highpass_ptr  = (__m128i *)odd_highpass;
        int oct_pitch;
#endif

		// Dequantize one row from each of the two highpass bands
	#if _DEQUANTIZE_IN_FSM
		highlow_line = highlow;
		highhigh_line = highhigh;
	#else
		DequantizeBandRow16s(highlow, width, highlow_quantization, highlow_line);
		DequantizeBandRow16s(highhigh, width, highhigh_quantization, highhigh_line);
	#endif

		// Start at the first column
		column = 0;

#if (1 && XMMOPT)

		// Process groups of four coefficients along the row
		for (; column < post_column; column += column_step)
		{
#if 1 //use 32-bit math
            __m128i *lowlow_ptr   = (__m128i *)(lowlow + column);
            __m128i *lowhigh1_ptr = (__m128i *)(lowhigh_line[0] + column);
            __m128i *lowhigh2_ptr = (__m128i *)(lowhigh_line[1] + column);
            __m128i *lowhigh3_ptr = (__m128i *)(lowhigh_line[2] + column);
            __m128i *highlow_ptr  = (__m128i *)(highlow_line + column);
            __m128i *highhigh_ptr = (__m128i *)(highhigh_line + column);
            __m128i low0_epi16, low1_epi16, low2_epi16, high_epi16;
            __m128i even_epi32, odd_epi32;
            __m128i additionA_epi32, additionB_epi32;
            __m128i diffA_epi32, diffB_epi32;
            __m128i evenA_epi32, evenB_epi32;
            __m128i oddA_epi32, oddB_epi32;
            __m128i lowA_epi32, lowB_epi32;
            __m128i low1A_epi32, low1B_epi32;
            __m128i highA_epi32, highB_epi32;
            __m128i half_epi32 = _mm_set1_epi32(4); // used for rounding
            __m128i zero_epi16 = _mm_set1_epi16(0);

            oct_pitch = (lowlow_pitch * sizeof(PIXEL)) / sizeof(__m128i);
            
			/***** Compute the vertical inverse for the left two bands *****/

			// Accumulate parallel sums for the even and odd filters.
            // Put 16 bit values in 32 bit containers, preserving sign.

            // even += lowlow[column + 0 * lowlow_pitch];
            low0_epi16 = _mm_loadu_si128(lowlow_ptr); // get 8 lowpass coefficients
            evenA_epi32 = _mm_unpackhi_epi16(zero_epi16, low0_epi16);
            evenA_epi32 = _mm_srai_epi32(evenA_epi32, 16);
            evenB_epi32 = _mm_unpacklo_epi16(zero_epi16, low0_epi16);
            evenB_epi32 = _mm_srai_epi32(evenB_epi32, 16);

            lowlow_ptr += oct_pitch; // advance to the next row

            // odd -= lowlow[column + 0 * lowlow_pitch];
            oddA_epi32  = _mm_sub_epi32(zero_epi16, evenA_epi32);
            oddB_epi32  = _mm_sub_epi32(zero_epi16, evenB_epi32);

            low1_epi16 = _mm_loadu_si128(lowlow_ptr); // get 8 lowpass coefficients
            low1A_epi32 = _mm_unpackhi_epi16(zero_epi16, low1_epi16);
            low1A_epi32 = _mm_srai_epi32(low1A_epi32, 16);
            low1B_epi32 = _mm_unpacklo_epi16(zero_epi16, low1_epi16);
            low1B_epi32 = _mm_srai_epi32(low1B_epi32, 16);
            lowlow_ptr += oct_pitch; // advance to the next row
            
            low2_epi16 = _mm_loadu_si128(lowlow_ptr); // get 8 lowpass coefficients
            lowA_epi32 = _mm_unpackhi_epi16(zero_epi16, low2_epi16);
            lowA_epi32 = _mm_srai_epi32(lowA_epi32, 16);
            lowB_epi32 = _mm_unpacklo_epi16(zero_epi16, low2_epi16);
            lowB_epi32 = _mm_srai_epi32(lowB_epi32, 16);
            
            // even -= lowlow[column + 2 * lowlow_pitch];
            // even = (even + 4) / 8;
            evenA_epi32 = _mm_sub_epi32(evenA_epi32, lowA_epi32);
            evenA_epi32 = _mm_add_epi32(evenA_epi32, half_epi32); // rounding
            evenA_epi32 = _mm_srai_epi32(evenA_epi32, 3);         // divide by 8
            evenB_epi32 = _mm_sub_epi32(evenB_epi32, lowB_epi32);
            evenB_epi32 = _mm_add_epi32(evenB_epi32, half_epi32); // rounding
            evenB_epi32 = _mm_srai_epi32(evenB_epi32, 3);         // divide by 8
            
            // odd += lowlow[column + 2 * lowlow_pitch];
            // odd = (odd + 4) / 8;
            oddA_epi32 = _mm_add_epi32(oddA_epi32, lowA_epi32);
            oddA_epi32 = _mm_add_epi32(oddA_epi32, half_epi32); // rounding
            oddA_epi32 = _mm_srai_epi32(oddA_epi32, 3);         // divide by 8
            oddB_epi32 = _mm_add_epi32(oddB_epi32, lowB_epi32);
            oddB_epi32 = _mm_add_epi32(oddB_epi32, half_epi32); // rounding
            oddB_epi32 = _mm_srai_epi32(oddB_epi32, 3);         // divide by 8
            
            // addition = (lowlow[column + 1 * lowlow_pitch] + highlow_line[column]);
            high_epi16 = _mm_loadu_si128(highlow_ptr);
            highA_epi32 = _mm_unpackhi_epi16(zero_epi16, high_epi16);
            highA_epi32 = _mm_srai_epi32(highA_epi32, 16);
            highB_epi32 = _mm_unpacklo_epi16(zero_epi16, high_epi16);
            highB_epi32 = _mm_srai_epi32(highB_epi32, 16);
            additionA_epi32 = _mm_add_epi32(low1A_epi32, highA_epi32);
            additionB_epi32 = _mm_add_epi32(low1B_epi32, highB_epi32);
            
            // diff = (lowlow[column + 1 * lowlow_pitch] - highlow_line[column]);
            diffA_epi32 = _mm_sub_epi32(low1A_epi32, highA_epi32);
            diffB_epi32 = _mm_sub_epi32(low1B_epi32, highB_epi32);
            
            // even = (even + addition) >> 1;
            evenA_epi32 = _mm_add_epi32(evenA_epi32, additionA_epi32);
            evenA_epi32 = _mm_srai_epi32(evenA_epi32, 1);
            evenB_epi32 = _mm_add_epi32(evenB_epi32, additionB_epi32);
            evenB_epi32 = _mm_srai_epi32(evenB_epi32, 1);
            
            // odd = (odd + diff) >> 1;
            oddA_epi32 = _mm_add_epi32(oddA_epi32, diffA_epi32);
            oddA_epi32 = _mm_srai_epi32(oddA_epi32, 1);
            oddB_epi32 = _mm_add_epi32(oddB_epi32, diffB_epi32);
            oddB_epi32 = _mm_srai_epi32(oddB_epi32, 1);
            
            even_epi32 = _mm_packs_epi32(evenB_epi32, evenA_epi32);
            odd_epi32 = _mm_packs_epi32(oddB_epi32, oddA_epi32);

            // Store the even and odd groups of horizontal lowpass coefficients
            _mm_storeu_si128(even_lowpass_ptr++, even_epi32);
            _mm_storeu_si128(odd_lowpass_ptr++, odd_epi32);
            
			/**** Compute the vertical inverse for the right two bands *****/

			// Accumulate parallel sums for the even and odd filters.
            // Put 16 bit coefficients into 32 bit containers, preserving sign.

            low0_epi16 = _mm_loadu_si128(lowhigh1_ptr); // get 8 lowpass coefficients
            evenA_epi32 = _mm_unpackhi_epi16(zero_epi16, low0_epi16);
            evenA_epi32 = _mm_srai_epi32(evenA_epi32, 16);
            evenB_epi32 = _mm_unpacklo_epi16(zero_epi16, low0_epi16);
            evenB_epi32 = _mm_srai_epi32(evenB_epi32, 16);
            
            oddA_epi32 = _mm_sub_epi32(zero_epi16, evenA_epi32);
            oddB_epi32 = _mm_sub_epi32(zero_epi16, evenB_epi32);

            low2_epi16 = _mm_loadu_si128(lowhigh3_ptr); // get 8 lowpass coefficients
            lowA_epi32 = _mm_unpackhi_epi16(zero_epi16, low2_epi16);
            lowA_epi32 = _mm_srai_epi32(lowA_epi32, 16);
            lowB_epi32 = _mm_unpacklo_epi16(zero_epi16, low2_epi16);
            lowB_epi32 = _mm_srai_epi32(lowB_epi32, 16);
            
            evenA_epi32 = _mm_sub_epi32(evenA_epi32, lowA_epi32);
            evenB_epi32 = _mm_sub_epi32(evenB_epi32, lowB_epi32);
            oddA_epi32 = _mm_add_epi32(oddA_epi32, lowA_epi32);
            oddB_epi32 = _mm_add_epi32(oddB_epi32, lowB_epi32);
            
            

            low1_epi16 = _mm_loadu_si128(lowhigh2_ptr); // get 8 coefficients
            low1A_epi32 = _mm_unpackhi_epi16(zero_epi16, low1_epi16);
            low1A_epi32 = _mm_srai_epi32(low1A_epi32, 16);
            low1B_epi32 = _mm_unpacklo_epi16(zero_epi16, low1_epi16);
            low1B_epi32 = _mm_srai_epi32(low1B_epi32, 16);
            
            evenA_epi32 = _mm_add_epi32(evenA_epi32, half_epi32); // rounding
            evenA_epi32 = _mm_srai_epi32(evenA_epi32, 3);         // divide by 8
            evenB_epi32 = _mm_add_epi32(evenB_epi32, half_epi32); // rounding
            evenB_epi32 = _mm_srai_epi32(evenB_epi32, 3);         // divide by 8
            
            oddA_epi32 = _mm_add_epi32(oddA_epi32, half_epi32);   // rounding
            oddA_epi32 = _mm_srai_epi32(oddA_epi32, 3);           // divide by 8
            oddB_epi32 = _mm_add_epi32(oddB_epi32, half_epi32);   // rounding
            oddB_epi32 = _mm_srai_epi32(oddB_epi32, 3);           // divide by 8
            
            

            high_epi16 = _mm_loadu_si128(highhigh_ptr);
            highA_epi32 = _mm_unpackhi_epi16(zero_epi16, high_epi16);
            highA_epi32 = _mm_srai_epi32(highA_epi32, 16);
            highB_epi32 = _mm_unpacklo_epi16(zero_epi16, high_epi16);
            highB_epi32 = _mm_srai_epi32(highB_epi32, 16);
            
            
            
            additionA_epi32 = _mm_add_epi32(low1A_epi32, highA_epi32);
            additionB_epi32 = _mm_add_epi32(low1B_epi32, highB_epi32);
            
            diffA_epi32 = _mm_sub_epi32(low1A_epi32, highA_epi32);
            diffB_epi32 = _mm_sub_epi32(low1B_epi32, highB_epi32);
            
            evenA_epi32 = _mm_add_epi32(evenA_epi32, additionA_epi32);
            evenA_epi32 = _mm_srai_epi32(evenA_epi32, 1);
            evenB_epi32 = _mm_add_epi32(evenB_epi32, additionB_epi32);
            evenB_epi32 = _mm_srai_epi32(evenB_epi32, 1);
            
            oddA_epi32 = _mm_add_epi32(oddA_epi32, diffA_epi32);
            oddA_epi32 = _mm_srai_epi32(oddA_epi32, 1);
            oddB_epi32 = _mm_add_epi32(oddB_epi32, diffB_epi32);
            oddB_epi32 = _mm_srai_epi32(oddB_epi32, 1);
            
            even_epi32 = _mm_packs_epi32(evenB_epi32, evenA_epi32);
            odd_epi32 = _mm_packs_epi32(oddB_epi32, oddA_epi32);

            // Store the even and odd groups of horizontal highpass coefficients
            _mm_storeu_si128(even_highpass_ptr++, even_epi32);
            _mm_storeu_si128(odd_highpass_ptr++, odd_epi32);

#else //use 16-bit math


			__m64 *lowlow_ptr = (__m64 *)&lowlow[column];
			__m64 *highlow_ptr = (__m64 *)&highlow_line[column];
			__m64 *lowhigh_ptr1 = (__m64 *)&lowhigh_line[0][column];
			__m64 *lowhigh_ptr2 = (__m64 *)&lowhigh_line[1][column];
			__m64 *lowhigh_ptr3 = (__m64 *)&lowhigh_line[2][column];
			__m64 *highhigh_ptr = (__m64 *)&highhigh_line[column];
			__m64 quad_pi16;
			__m64 quad8_pi16;
			__m64 even_pi16;
			__m64 odd_pi16;

			 // Was 4 but 7 makes for more accurate rounding to prevent luma/chroma shifts -- DAN 6/2/03
			__m64 half_pi16 = _mm_set1_pi16(4);


			// Compute the vertical inverse for the left two bands //

			// Set the pitch for the lowpass band used in this section of code
			quad_pitch = (lowlow_pitch * sizeof(PIXEL))/sizeof(__m64);

			// Accumulate parallel sums for the even and odd filters
			quad_pi16 = *lowlow_ptr;	// Get four lowpass coefficients
			lowlow_ptr += quad_pitch;	// Advance to the next row

			even_pi16 = quad_pi16;
			odd_pi16 = _mm_subs_pi16(_mm_setzero_si64(), quad_pi16);

			quad8_pi16 = *lowlow_ptr;	// Get four lowpass coefficients
			lowlow_ptr += quad_pitch;	// Advance to the next row

			quad_pi16 = *lowlow_ptr;	// Get four lowpass coefficients

			even_pi16 = _mm_subs_pi16(even_pi16, quad_pi16);
			odd_pi16 = _mm_adds_pi16(odd_pi16, quad_pi16);

			even_pi16 = _mm_adds_pi16(even_pi16, half_pi16); // +4 rounding
			odd_pi16 = _mm_adds_pi16(odd_pi16, half_pi16); // +4 rounding
			even_pi16 = _mm_srai_pi16(even_pi16, 3); // divide by 8
			odd_pi16 = _mm_srai_pi16(odd_pi16, 3);  // divide by 8

			even_pi16 = _mm_adds_pi16(even_pi16, quad8_pi16);
			odd_pi16 = _mm_adds_pi16(odd_pi16, quad8_pi16);


			// Add the highpass correction to the even result and divide by two
			quad_pi16 = *highlow_ptr;
			even_pi16 = _mm_adds_pi16(even_pi16, quad_pi16);
			even_pi16 = _mm_srai_pi16(even_pi16, 1);

			// Subtract the highpass correction from the odd result and divide by two
			odd_pi16 = _mm_subs_pi16(odd_pi16, quad_pi16);
			odd_pi16 = _mm_srai_pi16(odd_pi16, 1);

			// Store the even and odd groups of horizontal lowpass coefficients
			*(even_lowpass_ptr++) = even_pi16;
			*(odd_lowpass_ptr++) = odd_pi16;


			// Compute the vertical inverse for the right two bands //

			// Set the pitch for the lowpass band used in this section of code
			quad_pitch = (lowhigh_pitch * sizeof(PIXEL))/sizeof(__m64);

			// Accumulate parallel sums for the even and odd filters

			quad_pi16 = *lowhigh_ptr1;		// Get four lowpass coefficients
			//lowhigh_ptr += quad_pitch;	// Advance to the next row

			even_pi16 = quad_pi16;
			odd_pi16 = _mm_subs_pi16(_mm_setzero_si64(), quad_pi16);

			quad_pi16 = *lowhigh_ptr3;		// Get four lowpass coefficients

			even_pi16 = _mm_subs_pi16(even_pi16, quad_pi16);
			odd_pi16 = _mm_adds_pi16(odd_pi16, quad_pi16);


			even_pi16 = _mm_adds_pi16(even_pi16, half_pi16); // +4 rounding
			odd_pi16 = _mm_adds_pi16(odd_pi16, half_pi16); // +4 rounding
			even_pi16 = _mm_srai_pi16(even_pi16, 3); // divide by 8
			odd_pi16 = _mm_srai_pi16(odd_pi16, 3);  // divide by 8

			quad_pi16 = *lowhigh_ptr2;		// Get four lowpass coefficients
			even_pi16 = _mm_adds_pi16(even_pi16, quad_pi16);
			odd_pi16 = _mm_adds_pi16(odd_pi16, quad_pi16);


			// Add the highpass correction to the even result and divide by two
			quad_pi16 = *highhigh_ptr;
			even_pi16 = _mm_adds_pi16(even_pi16, quad_pi16);
			even_pi16 = _mm_srai_pi16(even_pi16, 1);

			// Subtract the highpass correction from the odd result and divide by two
			odd_pi16 = _mm_subs_pi16(odd_pi16, quad_pi16);
			odd_pi16 = _mm_srai_pi16(odd_pi16, 1);

			// Store the even and odd groups of horizontal highpass coefficients
			*(even_highpass_ptr++) = even_pi16;
			*(odd_highpass_ptr++) = odd_pi16;
#endif
		}

		// Should have exited the loop at the post processing column
		assert(column == post_column);

#endif

#if (0 && DEBUG)
		if (logfile) {
			DumpArray16s("Lowpass Strip", lowpass, strip.width, strip.height, lowpass_pitch, logfile);
			DumpArray16s("Highpass Strip", highpass, strip.width, strip.height, highpass_pitch, logfile);
		}
#endif

		// Process the rest of the row
		for (; column < width; column++)
		{
			int32_t even = 0;		// Result of convolution with even filter
			int32_t odd = 0;		// Result of convolution with odd filter


			/***** Compute the vertical inverse for the left two bands *****/

			// Apply the even reconstruction filter to the lowpass band
			even += lowlow[column + 0 * lowlow_pitch];
			even -= lowlow[column + 2 * lowlow_pitch];
			even += 4; //DAN20050921
			even >>= 3;
			even += lowlow[column + 1 * lowlow_pitch];

			// Add the highpass correction
			even += highlow_line[column];
			even = DivideByShift(even, 1);

			// Place the even result in the even row
			even_lowpass[column] = SATURATE(even);

			// Apply the odd reconstruction filter to the lowpass band
			odd -= lowlow[column + 0 * lowlow_pitch];
			odd += lowlow[column + 2 * lowlow_pitch];
			odd += 4; //DAN20050921
			odd >>= 3;
			odd += lowlow[column + 1 * lowlow_pitch];

			// Subtract the highpass correction
			odd -= highlow_line[column];
			odd = DivideByShift(odd, 1);

			// Place the odd result in the odd row
			odd_lowpass[column] = SATURATE(odd);


			/***** Compute the vertical inverse for the right two bands *****/

			even = 0;
			odd = 0;

			// Apply the even reconstruction filter to the lowpass band
			even += lowhigh_line[0][column];
			even -= lowhigh_line[2][column];
			even += 4; //DAN20050921
			even >>= 3;
			even += lowhigh_line[1][column];

			// Add the highpass correction
			even += highhigh_line[column];
			even = DivideByShift(even, 1);

			// Place the even result in the even row
			even_highpass[column] = SATURATE(even);

			// Apply the odd reconstruction filter to the lowpass band
			odd -= lowhigh_line[0][column];
			odd += lowhigh_line[2][column];
			odd += 4; //DAN20050921
			odd >>= 3;
			odd += lowhigh_line[1][column];

			// Subtract the highpass correction
			odd -= highhigh_line[column];
			odd = DivideByShift(odd, 1);

			// Place the odd result in the odd row
			odd_highpass[column] = SATURATE(odd);
		}

#if (0 && DEBUG)
		if (logfile) {
			DumpArray16s("Lowpass Strip", lowpass, strip.width, strip.height, lowpass_pitch, logfile);
			DumpArray16s("Highpass Strip", highpass, strip.width, strip.height, highpass_pitch, logfile);
		}
#endif

		// Apply the inverse horizontal transform to the even and odd rows and descale the results
		InvertHorizontalStripDescale16s(lowpass, lowpass_pitch,
										highpass, highpass_pitch,
										output, (int)output_row_size,
										strip, descale);

		// Advance to the next input rows and skip the next output row
		lowlow += lowlow_pitch;
		lowhigh += lowhigh_pitch;
		highlow += highlow_pitch;
		highhigh += highhigh_pitch;
		output += 2 * output_pitch;

		if (row < last_row - 1) {
			PIXEL *temp = lowhigh_line[0];
			lowhigh_line[0] = lowhigh_line[1];
			lowhigh_line[1] = lowhigh_line[2];
			lowhigh_line[2] = temp;

			// Undo quantization for the next row in the lowhigh band
		  #if _DEQUANTIZE_IN_FSM
			lowhigh_line[2] = lowhigh+2*lowhigh_pitch;
		  #else
			DequantizeBandRow16s(lowhigh+2*lowhigh_pitch, width, lowhigh_quantization, lowhigh_line[2]);
		  #endif
		}
	}


#if (1 && XMMOPT)
	// Need to advance the lowpass pointer if using SIMD instructions
	lowlow += lowlow_pitch;
	lowhigh += lowhigh_pitch;
#endif

	// Should have exited the loop at the last row
	assert(row == last_row);

	// Undo quantization for the highlow and highhigh bands
#if _DEQUANTIZE_IN_FSM
	highlow_line = highlow;
	highhigh_line = highhigh;
#else
	DequantizeBandRow16s(highlow, width, highlow_quantization, highlow_line);
	DequantizeBandRow16s(highhigh, width, highhigh_quantization, highhigh_line);
#endif

	// Apply the vertical border filter to the last row
	for (column = 0; column < width; column++)
	{
		int32_t even = 0;		// Result of convolution with even filter
		int32_t odd = 0;		// Result of convolution with odd filter


		// Compute the vertical inverse for the left two bands //

		// Apply the even reconstruction filter to the lowpass band
		even += 5 * lowlow[column + 0 * lowlow_pitch];
		even += 4 * lowlow[column - 1 * lowlow_pitch];
		even -= 1 * lowlow[column - 2 * lowlow_pitch];
		even += ROUNDING(even,8);
		even = DivideByShift(even, 3);

		// Add the highpass correction
		even += highlow_line[column];
		even = DivideByShift(even, 1);

		// Place the even result in the even row
		even_lowpass[column] = SATURATE(even);

		// Apply the odd reconstruction filter to the lowpass band
		odd += 11 * lowlow[column + 0 * lowlow_pitch];
		odd -=  4 * lowlow[column - 1 * lowlow_pitch];
		odd +=  1 * lowlow[column - 2 * lowlow_pitch];
		odd += ROUNDING(odd,8);
		odd = DivideByShift(odd, 3);

		// Subtract the highpass correction
		odd -= highlow_line[column];
		odd = DivideByShift(odd, 1);

		// Place the odd result in the odd row
		odd_lowpass[column] = SATURATE(odd);


		// Compute the vertical inverse for the right two bands //

		even = 0;
		odd = 0;

		// Apply the even reconstruction filter to the lowpass band
		even += 5 * lowhigh_line[2][column];
		even += 4 * lowhigh_line[1][column];
		even -= 1 * lowhigh_line[0][column];
		even += ROUNDING(even,8);
		even = DivideByShift(even, 3);

		// Add the highpass correction
		even += highhigh_line[column];
		even = DivideByShift(even, 1);

		// Place the even result in the even row
		even_highpass[column] = SATURATE(even);

		// Apply the odd reconstruction filter to the lowpass band
		odd += 11 * lowhigh_line[2][column];
		odd -=  4 * lowhigh_line[1][column];
		odd +=  1 * lowhigh_line[0][column];
		odd += ROUNDING(odd,8);
		odd = DivideByShift(odd, 3);

		// Subtract the highpass correction
		odd -= highhigh_line[column];
		odd = DivideByShift(odd, 1);

		// Place the odd result in the odd row
		odd_highpass[column] = SATURATE(odd);
	}

	// Apply the inverse horizontal transform to the even and odd rows and descale the results
	InvertHorizontalStripDescale16s(lowpass, lowpass_pitch,
									highpass, highpass_pitch,
									output, (int)output_row_size,
									strip, descale);
}

#endif


#if 0

// Adapted from the 8s version above
void InvertSpatialPrescaledQuant16s(PIXEL *lowlow_band, int lowlow_pitch,
									PIXEL *lowhigh_band, int lowhigh_pitch,
									PIXEL *highlow_band, int highlow_pitch,
									PIXEL *highhigh_band, int highhigh_pitch,
									PIXEL *output_image, int output_pitch,
									ROI roi, PIXEL *buffer, size_t buffer_size,
									int quantization[])
{
	PIXEL *lowlow = (PIXEL *)lowlow_band;
	PIXEL *lowhigh = lowhigh_band;
	PIXEL *highlow = highlow_band;
	PIXEL *highhigh = highhigh_band;
	PIXEL *output = output_image;
	PIXEL *even_lowpass;
	PIXEL *even_highpass;
	PIXEL *odd_lowpass;
	PIXEL *odd_highpass;
	PIXEL *even_output;
	PIXEL *odd_output;
	PIXEL *lowpass;					// Strip of horizontal coefficients
	PIXEL *highpass;
	int lowpass_pitch;				// Distance between strip rows in bytes
	int highpass_pitch;
	ROI strip;					// Dimensions of the processing strip
	size_t buffer_row_size;
	size_t output_row_size = output_pitch;
	int buffer_half_pitch;
	int buffer_width;
	int buffer_pitch;
	int width = roi.width;
	int height = roi.height;
	int last_row = height - 1;
	int row, column;

	SCRATCH scratch_buffer = SCRATCH_INITIALIZER(buffer, buffer_size);
	SCRATCH *scratch = &scratch_buffer;
	PIXEL *lowhigh_line[3];
	PIXEL *highlow_line;
	PIXEL *highhigh_line;

	int lowlow_quantization = quantization[LL_BAND];
	int highlow_quantization = quantization[HL_BAND];
	int lowhigh_quantization = quantization[LH_BAND];
	int highhigh_quantization = quantization[HH_BAND];

	// Compute positions within the temporary buffer for each row of horizontal lowpass
	// and highpass intermediate coefficients computed by the vertical inverse transform
	buffer_row_size = width * sizeof(PIXEL);
	buffer_row_size = ALIGN16(buffer_row_size);
	buffer_half_pitch = buffer_row_size/sizeof(PIXEL);
	buffer_pitch = 2 * buffer_half_pitch;
	buffer_width = width;

	// Check that the buffer is large enough to hold four rows of
	// vertical results and 5 rows of dequantized highpass coefficients
	assert(buffer_size >= (9 * buffer_row_size));

	// Set the dimensions of the processing strip
	strip.width = buffer_width;
	strip.height = 2;

	// Compute the positions of the even and odd rows of coefficients
	even_lowpass = (PIXEL *)AllocScratchBuffer(scratch, buffer_row_size);
	even_highpass = (PIXEL *)AllocScratchBuffer(scratch, buffer_row_size);
	odd_lowpass = (PIXEL *)AllocScratchBuffer(scratch, buffer_row_size);
	odd_highpass = (PIXEL *)AllocScratchBuffer(scratch, buffer_row_size);

	// Pointers into the strip of horizontal coefficients
	lowpass = even_lowpass;
	highpass = even_highpass;
	lowpass_pitch = 2 * buffer_row_size;
	highpass_pitch = 2 * buffer_row_size;

	// Compute the positions of the dequantized highpass rows
	lowhigh_line[0] = (PIXEL *)AllocScratchBuffer(scratch, buffer_row_size);
	lowhigh_line[1] = (PIXEL *)AllocScratchBuffer(scratch, buffer_row_size);
	lowhigh_line[2] = (PIXEL *)AllocScratchBuffer(scratch, buffer_row_size);
	highlow_line = (PIXEL *)AllocScratchBuffer(scratch, buffer_row_size);
	highhigh_line = (PIXEL *)AllocScratchBuffer(scratch, buffer_row_size);

	// Convert pitch from bytes to pixels
	lowlow_pitch /= sizeof(PIXEL);
	lowhigh_pitch /= sizeof(PIXEL);
	highlow_pitch /= sizeof(PIXEL);
	highhigh_pitch /= sizeof(PIXEL);
	output_pitch /= sizeof(PIXEL);

	// Apply the vertical border filter to the first row
	row = 0;

	// Dequantize three rows of highpass coefficients in the lowhigh band
#if _DEQUANTIZE_IN_FSM
	lowhigh_line[0] = lowhigh;
	lowhigh_line[1] = lowhigh+lowhigh_pitch;
	lowhigh_line[2] = lowhigh+2*lowhigh_pitch;

	highlow_line = highlow;
	highhigh_line = highhigh;
#else
	DequantizeBandRow16s(lowhigh, width, lowhigh_quantization, lowhigh_line[0]);
	DequantizeBandRow16s(lowhigh+lowhigh_pitch, width, lowhigh_quantization, lowhigh_line[1]);
	DequantizeBandRow16s(lowhigh+2*lowhigh_pitch, width, lowhigh_quantization, lowhigh_line[2]);

	// Dequantize one row of coefficients each in the highlow and highhigh bands
	DequantizeBandRow16s(highlow, width, highlow_quantization, highlow_line);
	DequantizeBandRow16s(highhigh, width, highhigh_quantization, highhigh_line);
#endif

	for (column = 0; column < width; column++)
	{
		int32_t even = 0;		// Result of convolution with even filter
		int32_t odd = 0;		// Result of convolution with odd filter


		// Compute the vertical inverse for the left two bands //

		// Apply the even reconstruction filter to the lowpass band
		even += 11 * lowlow[column + 0 * lowlow_pitch];
		even -=  4 * lowlow[column + 1 * lowlow_pitch];
		even +=  1 * lowlow[column + 2 * lowlow_pitch];
		even += ROUNDING(even,8);
		even = DivideByShift(even, 3);

		// Add the highpass correction
		even += highlow_line[column];
		even = DivideByShift(even, 1);

		// Place the even result in the even row
		even_lowpass[column] = SATURATE(even);

		// Apply the odd reconstruction filter to the lowpass band
		odd += 5 * lowlow[column + 0 * lowlow_pitch];
		odd += 4 * lowlow[column + 1 * lowlow_pitch];
		odd -= 1 * lowlow[column + 2 * lowlow_pitch];
		odd += ROUNDING(odd,8);
		odd = DivideByShift(odd, 3);

		// Subtract the highpass correction
		odd -= highlow_line[column];
		odd = DivideByShift(odd, 1);

		// Place the odd result in the odd row
		odd_lowpass[column] = SATURATE(odd);


		// Compute the vertical inverse for the right two bands //

		even = 0;
		odd = 0;

		// Apply the even reconstruction filter to the lowpass band
		even += 11 * lowhigh_line[0][column];
		even -=  4 * lowhigh_line[1][column];
		even +=  1 * lowhigh_line[2][column];
		even += ROUNDING(even,8);
		even = DivideByShift(even, 3);

		// Add the highpass correction
		even += highhigh_line[column];
		even = DivideByShift(even, 1);

		// Place the even result in the even row
		even_highpass[column] = SATURATE(even);

		// Apply the odd reconstruction filter to the lowpass band
		odd += 5 * lowhigh_line[0][column];
		odd += 4 * lowhigh_line[1][column];
		odd -= 1 * lowhigh_line[2][column];
		odd += ROUNDING(odd,8);
		odd = DivideByShift(odd, 3);

		// Subtract the highpass correction
		odd -= highhigh_line[column];
		odd = DivideByShift(odd, 1);

		// Place the odd result in the odd row
		odd_highpass[column] = SATURATE(odd);
	}

#if (0 && DEBUG)
	if (logfile) {
		DumpArray16s("Lowpass Strip", lowpass, strip.width, strip.height, lowpass_pitch, logfile);
		DumpArray16s("Highpass Strip", highpass, strip.width, strip.height, highpass_pitch, logfile);
	}
#endif

	// Apply the inverse horizontal transform to the even and odd rows and descale the results
	InvertHorizontalStripDescale16s(lowpass, lowpass_pitch,
									highpass, highpass_pitch,
									output, output_row_size, strip);

	// Advance to the next pair of even and odd output rows
	output += 2 * output_pitch;

	// Do not advance the lowpass row pointers until after the fast loop
	//lowlow += lowlow_pitch;
	//lowhigh += lowhigh_pitch;

	// Always advance the highpass row pointers
	highlow += highlow_pitch;
	highhigh += highhigh_pitch;

	// Advance the row index
	row++;

	// Process the middle rows using the interior reconstruction filters
	for (; row < last_row; row++)
	{
#if (1 && XMMOPT)
		int column_step = 4;
		int post_column = width - (width % column_step);
		__m64 *even_lowpass_ptr = (__m64 *)even_lowpass;
		__m64 *even_highpass_ptr = (__m64 *)even_highpass;
		__m64 *odd_lowpass_ptr = (__m64 *)odd_lowpass;
		__m64 *odd_highpass_ptr = (__m64 *)odd_highpass;
		int quad_pitch;
#endif

		// Dequantize one row from each of the two highpass bands
	#if _DEQUANTIZE_IN_FSM
		highlow_line = highlow;
		highhigh_line = highhigh;
	#else
		DequantizeBandRow16s(highlow, width, highlow_quantization, highlow_line);
		DequantizeBandRow16s(highhigh, width, highhigh_quantization, highhigh_line);
	#endif

		// Start at the first column
		column = 0;

#if (1 && XMMOPT)

		// Process groups of four coefficients along the row
		for (; column < post_column; column += column_step)
		{
			__m64 *lowlow_ptr = (__m64 *)&lowlow[column];
			__m64 *highlow_ptr = (__m64 *)&highlow_line[column];
			__m64 *lowhigh_ptr1 = (__m64 *)&lowhigh_line[0][column];
			__m64 *lowhigh_ptr2 = (__m64 *)&lowhigh_line[1][column];
			__m64 *lowhigh_ptr3 = (__m64 *)&lowhigh_line[2][column];
			__m64 *highhigh_ptr = (__m64 *)&highhigh_line[column];
			__m64 quad_pi16;
			__m64 quad8_pi16;
			__m64 even_pi16;
			__m64 odd_pi16;

			 // Was 4 but 7 makes for more accurate rounding to prevent luma/chroma shifts -- DAN 6/2/03
			__m64 half_pi16 = _mm_set1_pi16(4);


			// Compute the vertical inverse for the left two bands //

			// Set the pitch for the lowpass band used in this section of code
			quad_pitch = (lowlow_pitch * sizeof(PIXEL))/sizeof(__m64);

			// Accumulate parallel sums for the even and odd filters
			quad_pi16 = *lowlow_ptr;	// Get four lowpass coefficients
			lowlow_ptr += quad_pitch;	// Advance to the next row

			even_pi16 = quad_pi16;
			odd_pi16 = _mm_subs_pi16(_mm_setzero_si64(), quad_pi16);

			quad8_pi16 = *lowlow_ptr;	// Get four lowpass coefficients
			lowlow_ptr += quad_pitch;	// Advance to the next row

			quad_pi16 = *lowlow_ptr;	// Get four lowpass coefficients

			even_pi16 = _mm_subs_pi16(even_pi16, quad_pi16);
			odd_pi16 = _mm_adds_pi16(odd_pi16, quad_pi16);

			even_pi16 = _mm_adds_pi16(even_pi16, half_pi16); // +4 rounding
			odd_pi16 = _mm_adds_pi16(odd_pi16, half_pi16); // +4 rounding
			even_pi16 = _mm_srai_pi16(even_pi16, 3); // divide by 8
			odd_pi16 = _mm_srai_pi16(odd_pi16, 3);  // divide by 8

			even_pi16 = _mm_adds_pi16(even_pi16, quad8_pi16);
			odd_pi16 = _mm_adds_pi16(odd_pi16, quad8_pi16);


			// Add the highpass correction to the even result and divide by two
			quad_pi16 = *highlow_ptr;
			even_pi16 = _mm_adds_pi16(even_pi16, quad_pi16);
			even_pi16 = _mm_srai_pi16(even_pi16, 1);

			// Subtract the highpass correction from the odd result and divide by two
			odd_pi16 = _mm_subs_pi16(odd_pi16, quad_pi16);
			odd_pi16 = _mm_srai_pi16(odd_pi16, 1);

			// Store the even and odd groups of horizontal lowpass coefficients
			*(even_lowpass_ptr++) = even_pi16;
			*(odd_lowpass_ptr++) = odd_pi16;


			// Compute the vertical inverse for the right two bands //

			// Set the pitch for the lowpass band used in this section of code
			quad_pitch = (lowhigh_pitch * sizeof(PIXEL))/sizeof(__m64);

			// Accumulate parallel sums for the even and odd filters

			quad_pi16 = *lowhigh_ptr1;		// Get four lowpass coefficients
			//lowhigh_ptr += quad_pitch;	// Advance to the next row

			even_pi16 = quad_pi16;
			odd_pi16 = _mm_subs_pi16(_mm_setzero_si64(), quad_pi16);

			quad_pi16 = *lowhigh_ptr3;		// Get four lowpass coefficients

			even_pi16 = _mm_subs_pi16(even_pi16, quad_pi16);
			odd_pi16 = _mm_adds_pi16(odd_pi16, quad_pi16);


			even_pi16 = _mm_adds_pi16(even_pi16, half_pi16); // +4 rounding
			odd_pi16 = _mm_adds_pi16(odd_pi16, half_pi16); // +4 rounding
			even_pi16 = _mm_srai_pi16(even_pi16, 3); // divide by 8
			odd_pi16 = _mm_srai_pi16(odd_pi16, 3);  // divide by 8

			quad_pi16 = *lowhigh_ptr2;		// Get four lowpass coefficients
			even_pi16 = _mm_adds_pi16(even_pi16, quad_pi16);
			odd_pi16 = _mm_adds_pi16(odd_pi16, quad_pi16);


			// Add the highpass correction to the even result and divide by two
			quad_pi16 = *highhigh_ptr;
			even_pi16 = _mm_adds_pi16(even_pi16, quad_pi16);
			even_pi16 = _mm_srai_pi16(even_pi16, 1);

			// Subtract the highpass correction from the odd result and divide by two
			odd_pi16 = _mm_subs_pi16(odd_pi16, quad_pi16);
			odd_pi16 = _mm_srai_pi16(odd_pi16, 1);

			// Store the even and odd groups of horizontal highpass coefficients
			*(even_highpass_ptr++) = even_pi16;
			*(odd_highpass_ptr++) = odd_pi16;
		}

		// Should have exited the loop at the post processing column
		assert(column == post_column);

#endif

#if (0 && DEBUG)
		if (logfile) {
			DumpArray16s("Lowpass Strip", lowpass, strip.width, strip.height, lowpass_pitch, logfile);
			DumpArray16s("Highpass Strip", highpass, strip.width, strip.height, highpass_pitch, logfile);
		}
#endif

		// Process the rest of the row
		for (; column < width; column++)
		{
			int32_t even = 0;		// Result of convolution with even filter
			int32_t odd = 0;		// Result of convolution with odd filter


			// Compute the vertical inverse for the left two bands //

			// Apply the even reconstruction filter to the lowpass band
			even += lowlow[column + 0 * lowlow_pitch];
			even -= lowlow[column + 2 * lowlow_pitch];
			even += 4; //DAN20050921
			even >>= 3;
			even += lowlow[column + 1 * lowlow_pitch];

			// Add the highpass correction
			even += highlow_line[column];
			even = DivideByShift(even, 1);

			// Place the even result in the even row
			even_lowpass[column] = SATURATE(even);

			// Apply the odd reconstruction filter to the lowpass band
			odd -= lowlow[column + 0 * lowlow_pitch];
			odd += lowlow[column + 2 * lowlow_pitch];
			odd += 4; //DAN20050921
			odd >>= 3;
			odd += lowlow[column + 1 * lowlow_pitch];

			// Subtract the highpass correction
			odd -= highlow_line[column];
			odd = DivideByShift(odd, 1);

			// Place the odd result in the odd row
			odd_lowpass[column] = SATURATE(odd);


			// Compute the vertical inverse for the right two bands //

			even = 0;
			odd = 0;

			// Apply the even reconstruction filter to the lowpass band
			even += lowhigh_line[0][column];
			even -= lowhigh_line[2][column];
			even += 4; //DAN20050921
			even >>= 3;
			even += lowhigh_line[1][column];

			// Add the highpass correction
			even += highhigh_line[column];
			even = DivideByShift(even, 1);

			// Place the even result in the even row
			even_highpass[column] = SATURATE(even);

			// Apply the odd reconstruction filter to the lowpass band
			odd -= lowhigh_line[0][column];
			odd += lowhigh_line[2][column];
			odd += 4; //DAN20050921
			odd >>= 3;
			odd += lowhigh_line[1][column];

			// Subtract the highpass correction
			odd -= highhigh_line[column];
			odd = DivideByShift(odd, 1);

			// Place the odd result in the odd row
			odd_highpass[column] = SATURATE(odd);
		}

#if (0 && DEBUG)
		if (logfile) {
			DumpArray16s("Lowpass Strip", lowpass, strip.width, strip.height, lowpass_pitch, logfile);
			DumpArray16s("Highpass Strip", highpass, strip.width, strip.height, highpass_pitch, logfile);
		}
#endif

		// Apply the inverse horizontal transform to the even and odd rows and descale the results
		InvertHorizontalStripDescale16s(lowpass, lowpass_pitch,
										highpass, highpass_pitch,
										output, output_row_size, strip);

		// Advance to the next input rows and skip the next output row
		lowlow += lowlow_pitch;
		lowhigh += lowhigh_pitch;
		highlow += highlow_pitch;
		highhigh += highhigh_pitch;
		output += 2 * output_pitch;

		if (row < last_row - 1) {
			PIXEL *temp = lowhigh_line[0];
			lowhigh_line[0] = lowhigh_line[1];
			lowhigh_line[1] = lowhigh_line[2];
			lowhigh_line[2] = temp;

			// Undo quantization for the next row in the lowhigh band
		  #if _DEQUANTIZE_IN_FSM
			lowhigh_line[2] = lowhigh+2*lowhigh_pitch;
		  #else
			DequantizeBandRow16s(lowhigh+2*lowhigh_pitch, width, lowhigh_quantization, lowhigh_line[2]);
		  #endif
		}
	}

	//_mm_empty();	// Clear the mmx register state

#if (1 && XMMOPT)
	// Need to advance the lowpass pointer if using SIMD instructions
	lowlow += lowlow_pitch;
	lowhigh += lowhigh_pitch;
#endif

	// Should have exited the loop at the last row
	assert(row == last_row);

	// Undo quantization for the highlow and highhigh bands
#if _DEQUANTIZE_IN_FSM
	highlow_line = highlow;
	highhigh_line = highhigh;
#else
	DequantizeBandRow16s(highlow, width, highlow_quantization, highlow_line);
	DequantizeBandRow16s(highhigh, width, highhigh_quantization, highhigh_line);
#endif

	// Apply the vertical border filter to the last row
	for (column = 0; column < width; column++)
	{
		int32_t even = 0;		// Result of convolution with even filter
		int32_t odd = 0;		// Result of convolution with odd filter


		// Compute the vertical inverse for the left two bands //

		// Apply the even reconstruction filter to the lowpass band
		even += 5 * lowlow[column + 0 * lowlow_pitch];
		even += 4 * lowlow[column - 1 * lowlow_pitch];
		even -= 1 * lowlow[column - 2 * lowlow_pitch];
		even += ROUNDING(even,8);
		even = DivideByShift(even, 3);

		// Add the highpass correction
		even += highlow_line[column];
		even = DivideByShift(even, 1);

		// Place the even result in the even row
		even_lowpass[column] = SATURATE(even);

		// Apply the odd reconstruction filter to the lowpass band
		odd += 11 * lowlow[column + 0 * lowlow_pitch];
		odd -=  4 * lowlow[column - 1 * lowlow_pitch];
		odd +=  1 * lowlow[column - 2 * lowlow_pitch];
		odd += ROUNDING(odd,8);
		odd = DivideByShift(odd, 3);

		// Subtract the highpass correction
		odd -= highlow_line[column];
		odd = DivideByShift(odd, 1);

		// Place the odd result in the odd row
		odd_lowpass[column] = SATURATE(odd);


		// Compute the vertical inverse for the right two bands //

		even = 0;
		odd = 0;

		// Apply the even reconstruction filter to the lowpass band
		even += 5 * lowhigh_line[2][column];
		even += 4 * lowhigh_line[1][column];
		even -= 1 * lowhigh_line[0][column];
		even += ROUNDING(even,8);
		even = DivideByShift(even, 3);

		// Add the highpass correction
		even += highhigh_line[column];
		even = DivideByShift(even, 1);

		// Place the even result in the even row
		even_highpass[column] = SATURATE(even);

		// Apply the odd reconstruction filter to the lowpass band
		odd += 11 * lowhigh_line[2][column];
		odd -=  4 * lowhigh_line[1][column];
		odd +=  1 * lowhigh_line[0][column];
		odd += ROUNDING(odd,8);
		odd = DivideByShift(odd, 3);

		// Subtract the highpass correction
		odd -= highhigh_line[column];
		odd = DivideByShift(odd, 1);

		// Place the odd result in the odd row
		odd_highpass[column] = SATURATE(odd);
	}

	// Apply the inverse horizontal transform to the even and odd rows and descale the results
	InvertHorizontalStripDescale16s(lowpass, lowpass_pitch,
									highpass, highpass_pitch,
									output, output_row_size, strip);
}

#else

//universal decoder
// New version of InvertSpatialPrescaledQuant16s with better naming convention
void InvertSpatialQuant1x16s(PIXEL *lowlow_band, int lowlow_pitch,
							 PIXEL *lowhigh_band, int lowhigh_pitch,
							 PIXEL *highlow_band, int highlow_pitch,
							 PIXEL *highhigh_band, int highhigh_pitch,
							 PIXEL *output_image, int output_pitch,
							 ROI roi, PIXEL *buffer, size_t buffer_size,
							 int quantization[])
{
	PIXEL *lowlow = (PIXEL *)lowlow_band;
	PIXEL *lowhigh = lowhigh_band;
	PIXEL *highlow = highlow_band;
	PIXEL *highhigh = highhigh_band;
	PIXEL *output = output_image;
	PIXEL *even_lowpass;
	PIXEL *even_highpass;
	PIXEL *odd_lowpass;
	PIXEL *odd_highpass;
	PIXEL *lowpass;					// Strip of horizontal coefficients
	PIXEL *highpass;
	int lowpass_pitch;				// Distance between strip rows in bytes
	int highpass_pitch;
	ROI strip;					// Dimensions of the processing strip
	size_t buffer_row_size;
	size_t output_row_size = output_pitch;
	int buffer_half_pitch;
	int buffer_width;
	int buffer_pitch;
	int width = roi.width;
	int height = roi.height;
	int last_row = height - 1;
	int row, column;

	SCRATCH scratch_buffer = SCRATCH_INITIALIZER(buffer, buffer_size);
	SCRATCH *scratch = &scratch_buffer;
	PIXEL *lowhigh_line[3];
	PIXEL *highlow_line;
	PIXEL *highhigh_line;

	//int lowlow_quantization = quantization[LL_BAND];
	//int highlow_quantization = quantization[HL_BAND];
	//int lowhigh_quantization = quantization[LH_BAND];
	//int highhigh_quantization = quantization[HH_BAND];

	// Compute positions within the temporary buffer for each row of horizontal lowpass
	// and highpass intermediate coefficients computed by the vertical inverse transform
	buffer_row_size = width * sizeof(PIXEL);
	buffer_row_size = ALIGN16(buffer_row_size);
	buffer_half_pitch = (int)buffer_row_size/sizeof(PIXEL);
	buffer_pitch = 2 * buffer_half_pitch;
	buffer_width = width;

	// Check that the buffer is large enough to hold four rows of
	// vertical results and 5 rows of dequantized highpass coefficients
	assert(buffer_size >= (9 * buffer_row_size));

	// Set the dimensions of the processing strip
	strip.width = buffer_width;
	strip.height = 2;

	// Compute the positions of the even and odd rows of coefficients
	even_lowpass = (PIXEL *)AllocScratchBuffer(scratch, buffer_row_size);
	even_highpass = (PIXEL *)AllocScratchBuffer(scratch, buffer_row_size);
	odd_lowpass = (PIXEL *)AllocScratchBuffer(scratch, buffer_row_size);
	odd_highpass = (PIXEL *)AllocScratchBuffer(scratch, buffer_row_size);

	// Pointers into the strip of horizontal coefficients
	lowpass = even_lowpass;
	highpass = even_highpass;
	lowpass_pitch = (int)(2 * buffer_row_size);
	highpass_pitch = (int)(2 * buffer_row_size);

	// Compute the positions of the dequantized highpass rows
	lowhigh_line[0] = (PIXEL *)AllocScratchBuffer(scratch, buffer_row_size);
	lowhigh_line[1] = (PIXEL *)AllocScratchBuffer(scratch, buffer_row_size);
	lowhigh_line[2] = (PIXEL *)AllocScratchBuffer(scratch, buffer_row_size);
	highlow_line = (PIXEL *)AllocScratchBuffer(scratch, buffer_row_size);
	highhigh_line = (PIXEL *)AllocScratchBuffer(scratch, buffer_row_size);

	// Convert pitch from bytes to pixels
	lowlow_pitch /= sizeof(PIXEL);
	lowhigh_pitch /= sizeof(PIXEL);
	highlow_pitch /= sizeof(PIXEL);
	highhigh_pitch /= sizeof(PIXEL);
	output_pitch /= sizeof(PIXEL);

	// Apply the vertical border filter to the first row
	row = 0;

	// Dequantize three rows of highpass coefficients in the lowhigh band
#if _DEQUANTIZE_IN_FSM
	lowhigh_line[0] = lowhigh;
	lowhigh_line[1] = lowhigh+lowhigh_pitch;
	lowhigh_line[2] = lowhigh+2*lowhigh_pitch;

	highlow_line = highlow;
	highhigh_line = highhigh;
#else
	DequantizeBandRow16s(lowhigh, width, lowhigh_quantization, lowhigh_line[0]);
	DequantizeBandRow16s(lowhigh+lowhigh_pitch, width, lowhigh_quantization, lowhigh_line[1]);
	DequantizeBandRow16s(lowhigh+2*lowhigh_pitch, width, lowhigh_quantization, lowhigh_line[2]);

	// Dequantize one row of coefficients each in the highlow and highhigh bands
	DequantizeBandRow16s(highlow, width, highlow_quantization, highlow_line);
	DequantizeBandRow16s(highhigh, width, highhigh_quantization, highhigh_line);
#endif

	for (column = 0; column < width; column++)
	{
		int32_t even = 0;		// Result of convolution with even filter
		int32_t odd = 0;		// Result of convolution with odd filter


		// Compute the vertical inverse for the left two bands //

		// Apply the even reconstruction filter to the lowpass band
		even += 11 * lowlow[column + 0 * lowlow_pitch];
		even -=  4 * lowlow[column + 1 * lowlow_pitch];
		even +=  1 * lowlow[column + 2 * lowlow_pitch];
		even += ROUNDING(even,8);
		even = DivideByShift(even, 3);

		// Add the highpass correction
		even += highlow_line[column];
		even = DivideByShift(even, 1);

		// Place the even result in the even row
		even_lowpass[column] = SATURATE(even);

		// Apply the odd reconstruction filter to the lowpass band
		odd += 5 * lowlow[column + 0 * lowlow_pitch];
		odd += 4 * lowlow[column + 1 * lowlow_pitch];
		odd -= 1 * lowlow[column + 2 * lowlow_pitch];
		odd += ROUNDING(odd,8);
		odd = DivideByShift(odd, 3);

		// Subtract the highpass correction
		odd -= highlow_line[column];
		odd = DivideByShift(odd, 1);

		// Place the odd result in the odd row
		odd_lowpass[column] = SATURATE(odd);


		// Compute the vertical inverse for the right two bands //

		even = 0;
		odd = 0;

		// Apply the even reconstruction filter to the lowpass band
		even += 11 * lowhigh_line[0][column];
		even -=  4 * lowhigh_line[1][column];
		even +=  1 * lowhigh_line[2][column];
		even += ROUNDING(even,8);
		even = DivideByShift(even, 3);

		// Add the highpass correction
		even += highhigh_line[column];
		even = DivideByShift(even, 1);

		// Place the even result in the even row
		even_highpass[column] = SATURATE(even);

		// Apply the odd reconstruction filter to the lowpass band
		odd += 5 * lowhigh_line[0][column];
		odd += 4 * lowhigh_line[1][column];
		odd -= 1 * lowhigh_line[2][column];
		odd += ROUNDING(odd,8);
		odd = DivideByShift(odd, 3);

		// Subtract the highpass correction
		odd -= highhigh_line[column];
		odd = DivideByShift(odd, 1);

		// Place the odd result in the odd row
		odd_highpass[column] = SATURATE(odd);
	}

#if (0 && DEBUG)
	if (logfile) {
		DumpArray16s("Lowpass Strip", lowpass, strip.width, strip.height, lowpass_pitch, logfile);
		DumpArray16s("Highpass Strip", highpass, strip.width, strip.height, highpass_pitch, logfile);
	}
#endif

	// Apply the inverse horizontal transform to the even and odd rows and descale the results
	InvertHorizontalStrip1x16s(lowpass, lowpass_pitch,
							   highpass, highpass_pitch,
							   output, (int)output_row_size, strip);

	// Advance to the next pair of even and odd output rows
	output += 2 * output_pitch;

	// Do not advance the lowpass row pointers until after the fast loop
	//lowlow += lowlow_pitch;
	//lowhigh += lowhigh_pitch;

	// Always advance the highpass row pointers
	highlow += highlow_pitch;
	highhigh += highhigh_pitch;

	// Advance the row index
	row++;

	// Process the middle rows using the interior reconstruction filters
	for (; row < last_row; row++)
	{
		//assert(0);
#if (0 && XMMOPT) //DANREMOVED
		int column_step = 4;
		int post_column = width - (width % column_step);
		__m64 *even_lowpass_ptr = (__m64 *)even_lowpass;
		__m64 *even_highpass_ptr = (__m64 *)even_highpass;
		__m64 *odd_lowpass_ptr = (__m64 *)odd_lowpass;
		__m64 *odd_highpass_ptr = (__m64 *)odd_highpass;
		int quad_pitch;
#endif

		// Dequantize one row from each of the two highpass bands
	#if _DEQUANTIZE_IN_FSM
		highlow_line = highlow;
		highhigh_line = highhigh;
	#else
		DequantizeBandRow16s(highlow, width, highlow_quantization, highlow_line);
		DequantizeBandRow16s(highhigh, width, highhigh_quantization, highhigh_line);
	#endif

		// Start at the first column
		column = 0;

#if (0 && XMMOPT) //DANREMOVED

		// Process groups of four coefficients along the row
		for (; column < post_column; column += column_step)
		{
			__m64 *lowlow_ptr = (__m64 *)&lowlow[column];
			__m64 *highlow_ptr = (__m64 *)&highlow_line[column];
			__m64 *lowhigh_ptr1 = (__m64 *)&lowhigh_line[0][column];
			__m64 *lowhigh_ptr2 = (__m64 *)&lowhigh_line[1][column];
			__m64 *lowhigh_ptr3 = (__m64 *)&lowhigh_line[2][column];
			__m64 *highhigh_ptr = (__m64 *)&highhigh_line[column];
			__m64 quad_pi16;
			__m64 quad8_pi16;
			__m64 even_pi16;
			__m64 odd_pi16;

			 // Was 4 but 7 makes for more accurate rounding to prevent luma/chroma shifts -- DAN 6/2/03
			__m64 half_pi16 = _mm_set1_pi16(4);


			// Compute the vertical inverse for the left two bands //

			// Set the pitch for the lowpass band used in this section of code
			quad_pitch = (lowlow_pitch * sizeof(PIXEL))/sizeof(__m64);

			// Accumulate parallel sums for the even and odd filters
			quad_pi16 = *lowlow_ptr;	// Get four lowpass coefficients
			lowlow_ptr += quad_pitch;	// Advance to the next row

			even_pi16 = quad_pi16;
			odd_pi16 = _mm_subs_pi16(_mm_setzero_si64(), quad_pi16);

			quad8_pi16 = *lowlow_ptr;	// Get four lowpass coefficients
			lowlow_ptr += quad_pitch;	// Advance to the next row

			quad_pi16 = *lowlow_ptr;	// Get four lowpass coefficients

			even_pi16 = _mm_subs_pi16(even_pi16, quad_pi16);
			odd_pi16 = _mm_adds_pi16(odd_pi16, quad_pi16);

			even_pi16 = _mm_adds_pi16(even_pi16, half_pi16); // +4 rounding
			odd_pi16 = _mm_adds_pi16(odd_pi16, half_pi16); // +4 rounding
			even_pi16 = _mm_srai_pi16(even_pi16, 3); // divide by 8
			odd_pi16 = _mm_srai_pi16(odd_pi16, 3);  // divide by 8

			even_pi16 = _mm_adds_pi16(even_pi16, quad8_pi16);
			odd_pi16 = _mm_adds_pi16(odd_pi16, quad8_pi16);


			// Add the highpass correction to the even result and divide by two
			quad_pi16 = *highlow_ptr;
			even_pi16 = _mm_adds_pi16(even_pi16, quad_pi16);
			even_pi16 = _mm_srai_pi16(even_pi16, 1);

			// Subtract the highpass correction from the odd result and divide by two
			odd_pi16 = _mm_subs_pi16(odd_pi16, quad_pi16);
			odd_pi16 = _mm_srai_pi16(odd_pi16, 1);

			// Store the even and odd groups of horizontal lowpass coefficients
			*(even_lowpass_ptr++) = even_pi16;
			*(odd_lowpass_ptr++) = odd_pi16;


			// Compute the vertical inverse for the right two bands //

			// Set the pitch for the lowpass band used in this section of code
			quad_pitch = (lowhigh_pitch * sizeof(PIXEL))/sizeof(__m64);

			// Accumulate parallel sums for the even and odd filters

			quad_pi16 = *lowhigh_ptr1;		// Get four lowpass coefficients
			//lowhigh_ptr += quad_pitch;	// Advance to the next row

			even_pi16 = quad_pi16;
			odd_pi16 = _mm_subs_pi16(_mm_setzero_si64(), quad_pi16);

			quad_pi16 = *lowhigh_ptr3;		// Get four lowpass coefficients

			even_pi16 = _mm_subs_pi16(even_pi16, quad_pi16);
			odd_pi16 = _mm_adds_pi16(odd_pi16, quad_pi16);


			even_pi16 = _mm_adds_pi16(even_pi16, half_pi16); // +4 rounding
			odd_pi16 = _mm_adds_pi16(odd_pi16, half_pi16); // +4 rounding
			even_pi16 = _mm_srai_pi16(even_pi16, 3); // divide by 8
			odd_pi16 = _mm_srai_pi16(odd_pi16, 3);  // divide by 8

			quad_pi16 = *lowhigh_ptr2;		// Get four lowpass coefficients
			even_pi16 = _mm_adds_pi16(even_pi16, quad_pi16);
			odd_pi16 = _mm_adds_pi16(odd_pi16, quad_pi16);


			// Add the highpass correction to the even result and divide by two
			quad_pi16 = *highhigh_ptr;
			even_pi16 = _mm_adds_pi16(even_pi16, quad_pi16);
			even_pi16 = _mm_srai_pi16(even_pi16, 1);

			// Subtract the highpass correction from the odd result and divide by two
			odd_pi16 = _mm_subs_pi16(odd_pi16, quad_pi16);
			odd_pi16 = _mm_srai_pi16(odd_pi16, 1);

			// Store the even and odd groups of horizontal highpass coefficients
			*(even_highpass_ptr++) = even_pi16;
			*(odd_highpass_ptr++) = odd_pi16;
		}

		// Should have exited the loop at the post processing column
		assert(column == post_column);

#endif

#if (0 && DEBUG)
		if (logfile) {
			DumpArray16s("Lowpass Strip", lowpass, strip.width, strip.height, lowpass_pitch, logfile);
			DumpArray16s("Highpass Strip", highpass, strip.width, strip.height, highpass_pitch, logfile);
		}
#endif

		// Process the rest of the row
		for (; column < width; column++)
		{
			int32_t even = 0;		// Result of convolution with even filter
			int32_t odd = 0;		// Result of convolution with odd filter


			// Compute the vertical inverse for the left two bands //

			// Apply the even reconstruction filter to the lowpass band
			even += lowlow[column + 0 * lowlow_pitch];
			even -= lowlow[column + 2 * lowlow_pitch];
			even += 4; //DAN20050921
			even >>= 3;
			even += lowlow[column + 1 * lowlow_pitch];

			// Add the highpass correction
			even += highlow_line[column];
			even = DivideByShift(even, 1);

			// Place the even result in the even row
			even_lowpass[column] = SATURATE(even);

			// Apply the odd reconstruction filter to the lowpass band
			odd -= lowlow[column + 0 * lowlow_pitch];
			odd += lowlow[column + 2 * lowlow_pitch];
			odd += 4; //DAN20050921
			odd >>= 3;
			odd += lowlow[column + 1 * lowlow_pitch];

			// Subtract the highpass correction
			odd -= highlow_line[column];
			odd = DivideByShift(odd, 1);

			// Place the odd result in the odd row
			odd_lowpass[column] = SATURATE(odd);


			// Compute the vertical inverse for the right two bands //

			even = 0;
			odd = 0;

			// Apply the even reconstruction filter to the lowpass band
			even += lowhigh_line[0][column];
			even -= lowhigh_line[2][column];
			even += 4; //DAN20050921
			even >>= 3;
			even += lowhigh_line[1][column];

			// Add the highpass correction
			even += highhigh_line[column];
			even = DivideByShift(even, 1);

			// Place the even result in the even row
			even_highpass[column] = SATURATE(even);

			// Apply the odd reconstruction filter to the lowpass band
			odd -= lowhigh_line[0][column];
			odd += lowhigh_line[2][column];
			odd += 4; //DAN20050921
			odd >>= 3;
			odd += lowhigh_line[1][column];

			// Subtract the highpass correction
			odd -= highhigh_line[column];
			odd = DivideByShift(odd, 1);

			// Place the odd result in the odd row
			odd_highpass[column] = SATURATE(odd);
		}

#if (0 && DEBUG)
		if (logfile) {
			DumpArray16s("Lowpass Strip", lowpass, strip.width, strip.height, lowpass_pitch, logfile);
			DumpArray16s("Highpass Strip", highpass, strip.width, strip.height, highpass_pitch, logfile);
		}
#endif

		// Apply the inverse horizontal transform to the even and odd rows and descale the results
		InvertHorizontalStrip1x16s(lowpass, lowpass_pitch,
								   highpass, highpass_pitch,
								   output, (int)output_row_size, strip);

		// Advance to the next input rows and skip the next output row
		lowlow += lowlow_pitch;
		lowhigh += lowhigh_pitch;
		highlow += highlow_pitch;
		highhigh += highhigh_pitch;
		output += 2 * output_pitch;

		if (row < last_row - 1) {
			PIXEL *temp = lowhigh_line[0];
			lowhigh_line[0] = lowhigh_line[1];
			lowhigh_line[1] = lowhigh_line[2];
			lowhigh_line[2] = temp;

			// Undo quantization for the next row in the lowhigh band
		  #if _DEQUANTIZE_IN_FSM
			lowhigh_line[2] = lowhigh+2*lowhigh_pitch;
		  #else
			DequantizeBandRow16s(lowhigh+2*lowhigh_pitch, width, lowhigh_quantization, lowhigh_line[2]);
		  #endif
		}
	}

#if (1 && XMMOPT)
	// Need to advance the lowpass pointer if using SIMD instructions
	lowlow += lowlow_pitch;
	lowhigh += lowhigh_pitch;
#endif

	// Should have exited the loop at the last row
	assert(row == last_row);

	// Undo quantization for the highlow and highhigh bands
#if _DEQUANTIZE_IN_FSM
	highlow_line = highlow;
	highhigh_line = highhigh;
#else
	DequantizeBandRow16s(highlow, width, highlow_quantization, highlow_line);
	DequantizeBandRow16s(highhigh, width, highhigh_quantization, highhigh_line);
#endif

	// Apply the vertical border filter to the last row
	for (column = 0; column < width; column++)
	{
		int32_t even = 0;		// Result of convolution with even filter
		int32_t odd = 0;		// Result of convolution with odd filter


		// Compute the vertical inverse for the left two bands //

		// Apply the even reconstruction filter to the lowpass band
		even += 5 * lowlow[column + 0 * lowlow_pitch];
		even += 4 * lowlow[column - 1 * lowlow_pitch];
		even -= 1 * lowlow[column - 2 * lowlow_pitch];
		even += ROUNDING(even,8);
		even = DivideByShift(even, 3);

		// Add the highpass correction
		even += highlow_line[column];
		even = DivideByShift(even, 1);

		// Place the even result in the even row
		even_lowpass[column] = SATURATE(even);

		// Apply the odd reconstruction filter to the lowpass band
		odd += 11 * lowlow[column + 0 * lowlow_pitch];
		odd -=  4 * lowlow[column - 1 * lowlow_pitch];
		odd +=  1 * lowlow[column - 2 * lowlow_pitch];
		odd += ROUNDING(odd,8);
		odd = DivideByShift(odd, 3);

		// Subtract the highpass correction
		odd -= highlow_line[column];
		odd = DivideByShift(odd, 1);

		// Place the odd result in the odd row
		odd_lowpass[column] = SATURATE(odd);


		// Compute the vertical inverse for the right two bands //

		even = 0;
		odd = 0;

		// Apply the even reconstruction filter to the lowpass band
		even += 5 * lowhigh_line[2][column];
		even += 4 * lowhigh_line[1][column];
		even -= 1 * lowhigh_line[0][column];
		even += ROUNDING(even,8);
		even = DivideByShift(even, 3);

		// Add the highpass correction
		even += highhigh_line[column];
		even = DivideByShift(even, 1);

		// Place the even result in the even row
		even_highpass[column] = SATURATE(even);

		// Apply the odd reconstruction filter to the lowpass band
		odd += 11 * lowhigh_line[2][column];
		odd -=  4 * lowhigh_line[1][column];
		odd +=  1 * lowhigh_line[0][column];
		odd += ROUNDING(odd,8);
		odd = DivideByShift(odd, 3);

		// Subtract the highpass correction
		odd -= highhigh_line[column];
		odd = DivideByShift(odd, 1);

		// Place the odd result in the odd row
		odd_highpass[column] = SATURATE(odd);
	}

	// Apply the inverse horizontal transform to the even and odd rows and descale the results
	InvertHorizontalStrip1x16s(lowpass, lowpass_pitch,
							   highpass, highpass_pitch,
							   output, (int)output_row_size, strip);
}

#endif



#if _PROCESSOR_DISPATCH

__declspec(cpu_dispatch(Pentium_4,Generic))

void InvertSpatialPrescaledQuant8s(PIXEL8S *lowlow_band, int lowlow_pitch,
								   PIXEL8S *lowhigh_band, int lowhigh_pitch,
								   PIXEL8S *highlow_band, int highlow_pitch,
								   PIXEL8S *highhigh_band, int highhigh_pitch,
								   PIXEL *output_image, int output_pitch,
								   ROI roi, PIXEL *buffer, size_t buffer_size,
								   int quantization[])
{
	// Stub routine for processor specific dispatch
}
#endif


#if _PROCESSOR_GENERIC

#if _PROCESSOR_DISPATCH
__declspec(cpu_specific(Generic))
#endif

// Apply the inverse transform on coefficients that were prescaled
void InvertSpatialPrescaledQuant8s(PIXEL8S *lowlow_band, int lowlow_pitch,
								   PIXEL8S *lowhigh_band, int lowhigh_pitch,
								   PIXEL8S *highlow_band, int highlow_pitch,
								   PIXEL8S *highhigh_band, int highhigh_pitch,
								   PIXEL *output_image, int output_pitch,
								   ROI roi, PIXEL *buffer, size_t buffer_size,
								   int quantization[])
{
	PIXEL *lowlow = (PIXEL *)lowlow_band;
	PIXEL8S *lowhigh = lowhigh_band;
	PIXEL8S *highlow = highlow_band;
	PIXEL8S *highhigh = highhigh_band;
	PIXEL *output = output_image;
	PIXEL *even_lowpass;
	PIXEL *even_highpass;
	PIXEL *odd_lowpass;
	PIXEL *odd_highpass;
	PIXEL *even_output;
	PIXEL *odd_output;
	PIXEL *lowpass;					// Strip of horizontal coefficients
	PIXEL *highpass;
	int lowpass_pitch;				// Distance between strip rows in bytes
	int highpass_pitch;
	ROI strip;						// Dimensions of the processing strip
	size_t buffer_row_size;
	size_t output_row_size = output_pitch;
	int buffer_half_pitch;
	int buffer_width;
	int buffer_pitch;
	int width = roi.width;
	int height = roi.height;
	int last_row = height - 1;
	int row, column;

	SCRATCH scratch_buffer = SCRATCH_INITIALIZER(buffer, buffer_size);
	SCRATCH *scratch = &scratch_buffer;
	PIXEL *lowhigh_line[3];
	PIXEL *highlow_line;
	PIXEL *highhigh_line;

	int lowlow_quantization = quantization[LL_BAND];
	int highlow_quantization = quantization[HL_BAND];
	int lowhigh_quantization = quantization[LH_BAND];
	int highhigh_quantization = quantization[HH_BAND];

	// Compute positions within the temporary buffer for each row of horizontal lowpass
	// and highpass intermediate coefficients computed by the vertical inverse transform
	buffer_row_size = width * sizeof(PIXEL);
	buffer_row_size = ALIGN16(buffer_row_size);
	buffer_half_pitch = buffer_row_size/sizeof(PIXEL);
	buffer_pitch = 2 * buffer_half_pitch;
	buffer_width = width;

	// Check that the buffer is large enough to hold four rows of vertical
	// intermediate results and five rows of dequantized highpass coefficients
	assert(buffer_size >= (9 * buffer_row_size));

	// Set the dimensions of the processing strip
	strip.width = buffer_width;
	strip.height = 2;

	// Compute the positions of the even and odd rows of coefficients
	even_lowpass = (PIXEL *)AllocScratchBuffer(scratch, buffer_row_size);
	even_highpass = (PIXEL *)AllocScratchBuffer(scratch, buffer_row_size);
	odd_lowpass = (PIXEL *)AllocScratchBuffer(scratch, buffer_row_size);
	odd_highpass = (PIXEL *)AllocScratchBuffer(scratch, buffer_row_size);

	// Pointers into the strip of horizontal coefficients
	lowpass = even_lowpass;
	highpass = even_highpass;
	lowpass_pitch = 2 * buffer_row_size;
	highpass_pitch = 2 * buffer_row_size;

	// Compute the positions of the dequantized highpass rows
	lowhigh_line[0] = (PIXEL *)AllocScratchBuffer(scratch, buffer_row_size);
	lowhigh_line[1] = (PIXEL *)AllocScratchBuffer(scratch, buffer_row_size);
	lowhigh_line[2] = (PIXEL *)AllocScratchBuffer(scratch, buffer_row_size);
	highlow_line = (PIXEL *)AllocScratchBuffer(scratch, buffer_row_size);
	highhigh_line = (PIXEL *)AllocScratchBuffer(scratch, buffer_row_size);

	// Convert pitch from bytes to pixels
	lowlow_pitch /= sizeof(PIXEL);
	lowhigh_pitch /= sizeof(PIXEL8S);
	highlow_pitch /= sizeof(PIXEL8S);
	highhigh_pitch /= sizeof(PIXEL8S);
	output_pitch /= sizeof(PIXEL);

	// Apply the vertical border filter to the first row
	row = 0;

	// Undo quantization to highpass bands
	DequantizeBandRow(lowhigh, width, lowhigh_quantization, lowhigh_line[0]);
	DequantizeBandRow(lowhigh+lowhigh_pitch, width, lowhigh_quantization, lowhigh_line[1]);
	DequantizeBandRow(lowhigh+2*lowhigh_pitch, width, lowhigh_quantization, lowhigh_line[2]);

	DequantizeBandRow(highlow, width, highlow_quantization, highlow_line);
	DequantizeBandRow(highhigh, width, highhigh_quantization, highhigh_line);

	for (column = 0; column < width; column++)
	{
		int32_t even = 0;		// Result of convolution with even filter
		int32_t odd = 0;		// Result of convolution with odd filter


		// Compute the vertical inverse for the left two bands //

		// Apply the even reconstruction filter to the lowpass band
		even += 11 * lowlow[column + 0 * lowlow_pitch];
		even -=  4 * lowlow[column + 1 * lowlow_pitch];
		even +=  1 * lowlow[column + 2 * lowlow_pitch];
		even += ROUNDING(even,8);
		even = DivideByShift(even, 3);

		// Add the highpass correction
		even += highlow_line[column];
		even = DivideByShift(even, 1);

		// Place the even result in the even row
		even_lowpass[column] = SATURATE(even);

		// Apply the odd reconstruction filter to the lowpass band
		odd += 5 * lowlow[column + 0 * lowlow_pitch];
		odd += 4 * lowlow[column + 1 * lowlow_pitch];
		odd -= 1 * lowlow[column + 2 * lowlow_pitch];
		odd += ROUNDING(odd,8);
		odd = DivideByShift(odd, 3);

		// Subtract the highpass correction
		odd -= highlow_line[column];
		odd = DivideByShift(odd, 1);

		// Place the odd result in the odd row
		odd_lowpass[column] = SATURATE(odd);


		// Compute the vertical inverse for the right two bands //

		even = 0;
		odd = 0;

		// Apply the even reconstruction filter to the lowpass band
		even += 11 * lowhigh_line[0][column];
		even -=  4 * lowhigh_line[1][column];
		even +=  1 * lowhigh_line[2][column];
		even += ROUNDING(even,8);
		even = DivideByShift(even, 3);

		// Add the highpass correction
		even += highhigh_line[column];
		even = DivideByShift(even, 1);

		// Place the even result in the even row
		even_highpass[column] = SATURATE(even);

		// Apply the odd reconstruction filter to the lowpass band
		odd += 5 * lowhigh_line[0][column];
		odd += 4 * lowhigh_line[1][column];
		odd -= 1 * lowhigh_line[2][column];
		odd += ROUNDING(odd,8);
		odd = DivideByShift(odd, 3);

		// Subtract the highpass correction
		odd -= highhigh_line[column];
		odd = DivideByShift(odd, 1);

		// Place the odd result in the odd row
		odd_highpass[column] = SATURATE(odd);
	}

#if (0 && DEBUG)
	if (logfile) {
		DumpArray16s("Lowpass Strip", lowpass, strip.width, strip.height, lowpass_pitch, logfile);
		DumpArray16s("Highpass Strip", highpass, strip.width, strip.height, highpass_pitch, logfile);
	}
#endif

#if (_LOWPASS_PRESCALE > 0)
	// Apply the inverse horizontal transform to the prescaled even and odd rows
	InvertHorizontalStripPrescaled16s(lowpass, lowpass_pitch,
									  highpass, highpass_pitch,
									  output, output_row_size, strip);
#else
	// Apply the inverse horizontal transform to the even and odd rows and descale the results
	InvertHorizontalStrip16s(lowpass, lowpass_pitch,
							 highpass, highpass_pitch,
							 output, output_row_size, strip);
#endif

	// Advance to the next pair of even and odd output rows
	output += 2 * output_pitch;

	// Do not advance the lowpass row pointers until after the fast loop
	//lowlow += lowlow_pitch;
	//lowhigh += lowhigh_pitch;

	// Always advance the highpass row pointers
	highlow += highlow_pitch;
	highhigh += highhigh_pitch;

	// Advance the row index
	row++;

	// Process the middle rows using the interior reconstruction filters
	for (; row < last_row; row++)
	{
#if (1 && XMMOPT)
		int column_step = 4;
		int post_column = width - (width % column_step);
		__m64 *even_lowpass_ptr = (__m64 *)even_lowpass;
		__m64 *even_highpass_ptr = (__m64 *)even_highpass;
		__m64 *odd_lowpass_ptr = (__m64 *)odd_lowpass;
		__m64 *odd_highpass_ptr = (__m64 *)odd_highpass;
		int quad_pitch;
#endif

		// Undo quantization to highpass bands
		DequantizeBandRow(highlow, width, highlow_quantization, highlow_line);
		DequantizeBandRow(highhigh, width, highhigh_quantization, highhigh_line);

		// Start at the first column
		column = 0;

#if (1 && XMMOPT)

		// Process groups of four coefficients along the row
		for (; column < post_column; column += column_step)
		{
			__m64 *lowlow_ptr = (__m64 *)&lowlow[column];
			__m64 *highlow_ptr = (__m64 *)&highlow_line[column];
			__m64 *lowhigh_ptr1 = (__m64 *)&lowhigh_line[0][column];
			__m64 *lowhigh_ptr2 = (__m64 *)&lowhigh_line[1][column];
			__m64 *lowhigh_ptr3 = (__m64 *)&lowhigh_line[2][column];
			__m64 *highhigh_ptr = (__m64 *)&highhigh_line[column];
			__m64 quad_pi16;
			__m64 even_pi16;
			__m64 odd_pi16;


			// Compute the vertical inverse for the left two bands //

			// Set the pitch for the lowpass band used in this section of code
			quad_pitch = (lowlow_pitch * sizeof(PIXEL))/sizeof(__m64);

			// Accumulate parallel sums for the even and odd filters
			quad_pi16 = *lowlow_ptr;	// Get four lowpass coefficients
			lowlow_ptr += quad_pitch;	// Advance to the next row

			even_pi16 = quad_pi16;
			odd_pi16 = _mm_subs_pi16(_mm_setzero_si64(), quad_pi16);

			quad_pi16 = *lowlow_ptr;	// Get four lowpass coefficients
			lowlow_ptr += quad_pitch;	// Advance to the next row

			// Multiply the lowpass coefficients by eight
			quad_pi16 = _mm_slli_pi16(quad_pi16, 3);

			even_pi16 = _mm_adds_pi16(even_pi16, quad_pi16);
			odd_pi16 = _mm_adds_pi16(odd_pi16, quad_pi16);

			quad_pi16 = *lowlow_ptr;	// Get four lowpass coefficients

			even_pi16 = _mm_subs_pi16(even_pi16, quad_pi16);
			odd_pi16 = _mm_adds_pi16(odd_pi16, quad_pi16);

			// Apply the rounding adjustment
			even_pi16 = _mm_adds_pi16(even_pi16, _mm_set1_pi16(4));
			// Divide by eight
			even_pi16 = _mm_srai_pi16(even_pi16, 3);

			// Apply the rounding adjustment
			odd_pi16 = _mm_adds_pi16(odd_pi16, _mm_set1_pi16(4));
			// Divide by eight
			odd_pi16 = _mm_srai_pi16(odd_pi16, 3);

			// Add the highpass correction to the even result and divide by two
			quad_pi16 = *highlow_ptr;
			even_pi16 = _mm_adds_pi16(even_pi16, quad_pi16);
			even_pi16 = _mm_srai_pi16(even_pi16, 1);

			// Subtract the highpass correction from the odd result and divide by two
			odd_pi16 = _mm_subs_pi16(odd_pi16, quad_pi16);
			odd_pi16 = _mm_srai_pi16(odd_pi16, 1);

			// Store the even and odd groups of horizontal lowpass coefficients
			*(even_lowpass_ptr++) = even_pi16;
			*(odd_lowpass_ptr++) = odd_pi16;


			// Compute the vertical inverse for the right two bands //

			// Set the pitch for the lowpass band used in this section of code
			quad_pitch = (lowhigh_pitch * sizeof(PIXEL))/sizeof(__m64);

			// Accumulate parallel sums for the even and odd filters

			quad_pi16 = *lowhigh_ptr1;		// Get four lowpass coefficients
			//lowhigh_ptr += quad_pitch;	// Advance to the next row

			even_pi16 = quad_pi16;
			odd_pi16 = _mm_subs_pi16(_mm_setzero_si64(), quad_pi16);

			quad_pi16 = *lowhigh_ptr2;		// Get four lowpass coefficients
			//lowhigh_ptr += quad_pitch;	// Advance to the next row

			// Multiply the lowpass coefficients by eight
			quad_pi16 = _mm_slli_pi16(quad_pi16, 3);

			even_pi16 = _mm_adds_pi16(even_pi16, quad_pi16);
			odd_pi16 = _mm_adds_pi16(odd_pi16, quad_pi16);

			quad_pi16 = *lowhigh_ptr3;		// Get four lowpass coefficients

			even_pi16 = _mm_subs_pi16(even_pi16, quad_pi16);
			odd_pi16 = _mm_adds_pi16(odd_pi16, quad_pi16);
#if 1
			// Apply the rounding adjustment
			even_pi16 = _mm_adds_pi16(even_pi16, _mm_set1_pi16(4));
			// Divide by eight
			even_pi16 = _mm_srai_pi16(even_pi16, 3);

			// Apply the rounding adjustment
			odd_pi16 = _mm_adds_pi16(odd_pi16, _mm_set1_pi16(4));
			// Divide by eight
			odd_pi16 = _mm_srai_pi16(odd_pi16, 3);
#endif
			// Add the highpass correction to the even result and divide by two
			quad_pi16 = *highhigh_ptr;
			even_pi16 = _mm_adds_pi16(even_pi16, quad_pi16);
			even_pi16 = _mm_srai_pi16(even_pi16, 1);

			// Subtract the highpass correction from the odd result and divide by two
			odd_pi16 = _mm_subs_pi16(odd_pi16, quad_pi16);
			odd_pi16 = _mm_srai_pi16(odd_pi16, 1);

			// Store the even and odd groups of horizontal highpass coefficients
			*(even_highpass_ptr++) = even_pi16;
			*(odd_highpass_ptr++) = odd_pi16;
		}

		// Should have exited the loop at the post processing column
		assert(column == post_column);

#endif

		// Process the rest of the row
		for (; column < width; column++)
		{
			int32_t even = 0;		// Result of convolution with even filter
			int32_t odd = 0;		// Result of convolution with odd filter


			// Compute the vertical inverse for the left two bands //

			// Apply the even reconstruction filter to the lowpass band
			even += lowlow[column + 0 * lowlow_pitch];
			even -= lowlow[column + 2 * lowlow_pitch];
			even += ROUNDING(even,8);
			even = DivideByShift(even, 3);
			even += lowlow[column + 1 * lowlow_pitch];

			// Add the highpass correction
			even += highlow_line[column];
			even = DivideByShift(even, 1);

			// Place the even result in the even row
			even_lowpass[column] = SATURATE(even);

			// Apply the odd reconstruction filter to the lowpass band
			odd -= lowlow[column + 0 * lowlow_pitch];
			odd += lowlow[column + 2 * lowlow_pitch];
			odd += ROUNDING(odd,8);
			odd = DivideByShift(odd, 3);
			odd += lowlow[column + 1 * lowlow_pitch];

			// Subtract the highpass correction
			odd -= highlow_line[column];
			odd = DivideByShift(odd, 1);

			// Place the odd result in the odd row
			odd_lowpass[column] = SATURATE(odd);


			// Compute the vertical inverse for the right two bands //

			even = 0;
			odd = 0;

			// Apply the even reconstruction filter to the lowpass band
			even += lowhigh_line[0][column];
			even -= lowhigh_line[2][column];
			even += ROUNDING(even,8);
			even = DivideByShift(even, 3);
			even += lowhigh_line[1][column];

			// Add the highpass correction
			even += highhigh_line[column];
			even = DivideByShift(even, 1);

			// Place the even result in the even row
			even_highpass[column] = SATURATE(even);

			// Apply the odd reconstruction filter to the lowpass band
			odd -= lowhigh_line[0][column];
			odd += lowhigh_line[2][column];
			odd += ROUNDING(odd,8);
			odd = DivideByShift(odd, 3);
			odd += lowhigh_line[1][column];

			// Subtract the highpass correction
			odd -= highhigh_line[column];
			odd = DivideByShift(odd, 1);

			// Place the odd result in the odd row
			odd_highpass[column] = SATURATE(odd);
		}

#if (0 && DEBUG)
	if (logfile) {
		DumpArray16s("Lowpass Strip", lowpass, strip.width, strip.height, lowpass_pitch, logfile);
		DumpArray16s("Highpass Strip", highpass, strip.width, strip.height, highpass_pitch, logfile);
	}
#endif

#if (_LOWPASS_PRESCALE > 0)
	// Apply the inverse horizontal transform to the prescaled even and odd rows
	InvertHorizontalStripPrescaled16s(lowpass, lowpass_pitch,
									  highpass, highpass_pitch,
									  output, output_row_size, strip);
#else
	// Apply the inverse horizontal transform to the even and odd rows and descale the results
	InvertHorizontalStrip16s(lowpass, lowpass_pitch,
							 highpass, highpass_pitch,
							 output, output_row_size, strip);
#endif

		// Advance to the next input rows and skip the next output row
		lowlow += lowlow_pitch;
		lowhigh += lowhigh_pitch;
		highlow += highlow_pitch;
		highhigh += highhigh_pitch;
		output += 2 * output_pitch;

		if (row < last_row - 1) {
			PIXEL *temp = lowhigh_line[0];
			lowhigh_line[0] = lowhigh_line[1];
			lowhigh_line[1] = lowhigh_line[2];
			lowhigh_line[2] = temp;

			// Undo quantization for the new row in the lowhigh band
			DequantizeBandRow(lowhigh+2*lowhigh_pitch, width, lowhigh_quantization, lowhigh_line[2]);
		}
	}

	//_mm_empty();	// Clear the mmx register state

#if (1 && XMMOPT)
	// Need to advance the lowpass pointer if using SIMD instructions
	lowlow += lowlow_pitch;
	lowhigh += lowhigh_pitch;
#endif

	// Should have exited the loop at the last row
	assert(row == last_row);

	// Undo quantization for the highlow and highhigh bands
	DequantizeBandRow(highlow, width, highlow_quantization, highlow_line);
	DequantizeBandRow(highhigh, width, highhigh_quantization, highhigh_line);

	// Apply the vertical border filter to the last row
	for (column = 0; column < width; column++)
	{
		int32_t even = 0;		// Result of convolution with even filter
		int32_t odd = 0;		// Result of convolution with odd filter


		// Compute the vertical inverse for the left two bands //

		// Apply the even reconstruction filter to the lowpass band
		even += 5 * lowlow[column + 0 * lowlow_pitch];
		even += 4 * lowlow[column - 1 * lowlow_pitch];
		even -= 1 * lowlow[column - 2 * lowlow_pitch];
		even += ROUNDING(even,8);
		even = DivideByShift(even, 3);

		// Add the highpass correction
		even += highlow_line[column];
		even = DivideByShift(even, 1);

		// Place the even result in the even row
		even_lowpass[column] = SATURATE(even);

		// Apply the odd reconstruction filter to the lowpass band
		odd += 11 * lowlow[column + 0 * lowlow_pitch];
		odd -=  4 * lowlow[column - 1 * lowlow_pitch];
		odd +=  1 * lowlow[column - 2 * lowlow_pitch];
		odd += ROUNDING(odd,8);
		odd = DivideByShift(odd, 3);

		// Subtract the highpass correction
		odd -= highlow_line[column];
		odd = DivideByShift(odd, 1);

		// Place the odd result in the odd row
		odd_lowpass[column] = SATURATE(odd);


		// Compute the vertical inverse for the right two bands //

		even = 0;
		odd = 0;

		// Apply the even reconstruction filter to the lowpass band
		even += 5 * lowhigh_line[2][column];
		even += 4 * lowhigh_line[1][column];
		even -= 1 * lowhigh_line[0][column];
		even += ROUNDING(even,8);
		even = DivideByShift(even, 3);

		// Add the highpass correction
		even += highhigh_line[column];
		even = DivideByShift(even, 1);

		// Place the even result in the even row
		even_highpass[column] = SATURATE(even);

		// Apply the odd reconstruction filter to the lowpass band
		odd += 11 * lowhigh_line[2][column];
		odd -=  4 * lowhigh_line[1][column];
		odd +=  1 * lowhigh_line[0][column];
		odd += ROUNDING(odd,8);
		odd = DivideByShift(odd, 3);

		// Subtract the highpass correction
		odd -= highhigh_line[column];
		odd = DivideByShift(odd, 1);

		// Place the odd result in the odd row
		odd_highpass[column] = SATURATE(odd);
	}

#if (_LOWPASS_PRESCALE > 0)
	// Apply the inverse horizontal transform to the prescaled even and odd rows
	InvertHorizontalStripPrescaled16s(lowpass, lowpass_pitch,
									  highpass, highpass_pitch,
									  output, output_row_size, strip);
#else
	// Apply the inverse horizontal transform to the even and odd rows and descale the results
	InvertHorizontalStrip16s(lowpass, lowpass_pitch,
							 highpass, highpass_pitch,
							 output, output_row_size, strip);
#endif
}

#endif


#if _PROCESSOR_PENTIUM_4

#if _PROCESSOR_DISPATCH
__declspec(cpu_specific(Pentium_4))
#endif

// Apply the inverse transform on coefficients that were prescaled
void InvertSpatialPrescaledQuant8s(PIXEL8S *lowlow_band, int lowlow_pitch,
								   PIXEL8S *lowhigh_band, int lowhigh_pitch,
								   PIXEL8S *highlow_band, int highlow_pitch,
								   PIXEL8S *highhigh_band, int highhigh_pitch,
								   PIXEL *output_image, int output_pitch,
								   ROI roi, PIXEL *buffer, size_t buffer_size,
								   int quantization[])
{
	PIXEL *lowlow = (PIXEL *)lowlow_band;
	PIXEL8S *lowhigh = lowhigh_band;
	PIXEL8S *highlow = highlow_band;
	PIXEL8S *highhigh = highhigh_band;
	PIXEL *output = output_image;
	PIXEL *even_lowpass;
	PIXEL *even_highpass;
	PIXEL *odd_lowpass;
	PIXEL *odd_highpass;
	PIXEL *lowpass;					// Strip of horizontal coefficients
	PIXEL *highpass;
	int lowpass_pitch;				// Distance between strip rows in bytes
	int highpass_pitch;
	ROI strip;						// Dimensions of the processing strip
	size_t buffer_row_size;
	size_t output_row_size = output_pitch;
	int buffer_half_pitch;
	int buffer_width;
	int buffer_pitch;
	int width = roi.width;
	int height = roi.height;
	int last_row = height - 1;
	int row, column;

	SCRATCH scratch_buffer = SCRATCH_INITIALIZER(buffer, buffer_size);
	SCRATCH *scratch = &scratch_buffer;
	PIXEL *lowhigh_line[3];
	PIXEL *highlow_line;
	PIXEL *highhigh_line;

	//int lowlow_quantization = quantization[LL_BAND];
	int highlow_quantization = quantization[HL_BAND];
	int lowhigh_quantization = quantization[LH_BAND];
	int highhigh_quantization = quantization[HH_BAND];

	// Compute positions within the temporary buffer for each row of horizontal lowpass
	// and highpass intermediate coefficients computed by the vertical inverse transform
	buffer_row_size = width * sizeof(PIXEL);
	buffer_row_size = ALIGN16(buffer_row_size);
	buffer_half_pitch = (int)buffer_row_size/sizeof(PIXEL);
	buffer_pitch = 2 * buffer_half_pitch;
	buffer_width = width;

	// Check that the buffer is large enough to hold four rows of vertical
	// intermediate results and five rows of dequantized highpass coefficients
	assert(buffer_size >= (9 * buffer_row_size));

	// Set the dimensions of the processing strip
	strip.width = buffer_width;
	strip.height = 2;

	// Compute the positions of the even and odd rows of coefficients
	even_lowpass = (PIXEL *)AllocScratchBuffer(scratch, buffer_row_size);
	even_highpass = (PIXEL *)AllocScratchBuffer(scratch, buffer_row_size);
	odd_lowpass = (PIXEL *)AllocScratchBuffer(scratch, buffer_row_size);
	odd_highpass = (PIXEL *)AllocScratchBuffer(scratch, buffer_row_size);

	// Pointers into the strip of horizontal coefficients
	lowpass = even_lowpass;
	highpass = even_highpass;
	lowpass_pitch = (int)(2 * buffer_row_size);
	highpass_pitch = (int)(2 * buffer_row_size);

	// Compute the positions of the dequantized highpass rows
	lowhigh_line[0] = (PIXEL *)AllocScratchBuffer(scratch, buffer_row_size);
	lowhigh_line[1] = (PIXEL *)AllocScratchBuffer(scratch, buffer_row_size);
	lowhigh_line[2] = (PIXEL *)AllocScratchBuffer(scratch, buffer_row_size);
	highlow_line = (PIXEL *)AllocScratchBuffer(scratch, buffer_row_size);
	highhigh_line = (PIXEL *)AllocScratchBuffer(scratch, buffer_row_size);

	// Convert pitch from bytes to pixels
	lowlow_pitch /= sizeof(PIXEL);
	lowhigh_pitch /= sizeof(PIXEL8S);
	highlow_pitch /= sizeof(PIXEL8S);
	highhigh_pitch /= sizeof(PIXEL8S);
	output_pitch /= sizeof(PIXEL);

	// Apply the vertical border filter to the first row
	row = 0;

	// Undo quantization to highpass bands
	DequantizeBandRow(lowhigh, width, lowhigh_quantization, lowhigh_line[0]);
	DequantizeBandRow(lowhigh+lowhigh_pitch, width, lowhigh_quantization, lowhigh_line[1]);
	DequantizeBandRow(lowhigh+2*lowhigh_pitch, width, lowhigh_quantization, lowhigh_line[2]);

	DequantizeBandRow(highlow, width, highlow_quantization, highlow_line);
	DequantizeBandRow(highhigh, width, highhigh_quantization, highhigh_line);

	for (column = 0; column < width; column++)
	{
		int32_t even = 0;		// Result of convolution with even filter
		int32_t odd = 0;		// Result of convolution with odd filter


		// Compute the vertical inverse for the left two bands //

		// Apply the even reconstruction filter to the lowpass band
		even += 11 * lowlow[column + 0 * lowlow_pitch];
		even -=  4 * lowlow[column + 1 * lowlow_pitch];
		even +=  1 * lowlow[column + 2 * lowlow_pitch];
		even += ROUNDING(even,8);
		even = DivideByShift(even, 3);

		// Add the highpass correction
		even += highlow_line[column];
		even = DivideByShift(even, 1);

		// Place the even result in the even row
		even_lowpass[column] = SATURATE(even);

		// Apply the odd reconstruction filter to the lowpass band
		odd += 5 * lowlow[column + 0 * lowlow_pitch];
		odd += 4 * lowlow[column + 1 * lowlow_pitch];
		odd -= 1 * lowlow[column + 2 * lowlow_pitch];
		odd += ROUNDING(odd,8);
		odd = DivideByShift(odd, 3);

		// Subtract the highpass correction
		odd -= highlow_line[column];
		odd = DivideByShift(odd, 1);

		// Place the odd result in the odd row
		odd_lowpass[column] = SATURATE(odd);


		// Compute the vertical inverse for the right two bands //

		even = 0;
		odd = 0;

		// Apply the even reconstruction filter to the lowpass band
		even += 11 * lowhigh_line[0][column];
		even -=  4 * lowhigh_line[1][column];
		even +=  1 * lowhigh_line[2][column];
		even += ROUNDING(even,8);
		even = DivideByShift(even, 3);

		// Add the highpass correction
		even += highhigh_line[column];
		even = DivideByShift(even, 1);

		// Place the even result in the even row
		even_highpass[column] = SATURATE(even);

		// Apply the odd reconstruction filter to the lowpass band
		odd += 5 * lowhigh_line[0][column];
		odd += 4 * lowhigh_line[1][column];
		odd -= 1 * lowhigh_line[2][column];
		odd += ROUNDING(odd,8);
		odd = DivideByShift(odd, 3);

		// Subtract the highpass correction
		odd -= highhigh_line[column];
		odd = DivideByShift(odd, 1);

		// Place the odd result in the odd row
		odd_highpass[column] = SATURATE(odd);
	}

#if (0 && DEBUG)
	if (logfile) {
		DumpArray16s("Lowpass Strip", lowpass, strip.width, strip.height, lowpass_pitch, logfile);
		DumpArray16s("Highpass Strip", highpass, strip.width, strip.height, highpass_pitch, logfile);
	}
#endif

#if (_LOWPASS_PRESCALE > 0)
	// Apply the inverse horizontal transform to the prescaled even and odd rows
	InvertHorizontalStripPrescaled16s(lowpass, lowpass_pitch,
									  highpass, highpass_pitch,
									  output, (int)output_row_size, strip);
#else
	// Apply the inverse horizontal transform to the even and odd rows and descale the results
	InvertHorizontalStrip16s(lowpass, lowpass_pitch,
							 highpass, highpass_pitch,
							 output, output_row_size, strip);
#endif

	// Advance to the next pair of even and odd output rows
	output += 2 * output_pitch;

	// Do not advance the lowpass row pointers until after the fast loop
	//lowlow += lowlow_pitch;
	//lowhigh += lowhigh_pitch;

	// Always advance the highpass row pointers
	highlow += highlow_pitch;
	highhigh += highhigh_pitch;

	// Advance the row index
	row++;

	// Process the middle rows using the interior reconstruction filters
	for (; row < last_row; row++)
	{
#if (1 && XMMOPT)
		int column_step = 8;
		int post_column = width - (width % column_step);
		__m128i *even_lowpass_ptr = (__m128i *)even_lowpass;
		__m128i *even_highpass_ptr = (__m128i *)even_highpass;
		__m128i *odd_lowpass_ptr = (__m128i *)odd_lowpass;
		__m128i *odd_highpass_ptr = (__m128i *)odd_highpass;
		int quad_pitch;
#endif

		// Undo quantization to the highpass bands
		DequantizeBandRow(highlow, width, highlow_quantization, highlow_line);
		DequantizeBandRow(highhigh, width, highhigh_quantization, highhigh_line);

		// Start at the first column
		column = 0;

#if (1 && XMMOPT)

		// Process groups of four coefficients along the row
		for (; column < post_column; column += column_step)
		{
			__m128i *lowlow_ptr = (__m128i *)&lowlow[column];
			__m128i *highlow_ptr = (__m128i *)&highlow_line[column];
			__m128i *lowhigh_ptr1 = (__m128i *)&lowhigh_line[0][column];
			__m128i *lowhigh_ptr2 = (__m128i *)&lowhigh_line[1][column];
			__m128i *lowhigh_ptr3 = (__m128i *)&lowhigh_line[2][column];
			__m128i *highhigh_ptr = (__m128i *)&highhigh_line[column];
			__m128i quad_epi16;
			__m128i even_epi16;
			__m128i odd_epi16;


			// Compute the vertical inverse for the left two bands //

			// Set the pitch for the lowpass band used in this section of code
			quad_pitch = (lowlow_pitch * sizeof(PIXEL))/sizeof(__m128i);

			// Accumulate parallel sums for the even and odd filters
			quad_epi16 = _mm_load_si128(lowlow_ptr);	// Get eight lowpass coefficients
			lowlow_ptr += quad_pitch;					// Advance to the next row

			even_epi16 = quad_epi16;
			odd_epi16 = _mm_setzero_si128();
			odd_epi16 = _mm_subs_epi16(odd_epi16, quad_epi16);

			quad_epi16 = _mm_load_si128(lowlow_ptr);	// Get four lowpass coefficients
			lowlow_ptr += quad_pitch;					// Advance to the next row

			// Multiply the lowpass coefficients by eight
			quad_epi16 = _mm_slli_epi16(quad_epi16, 3);

			even_epi16 = _mm_adds_epi16(even_epi16, quad_epi16);
			odd_epi16 = _mm_adds_epi16(odd_epi16, quad_epi16);

			quad_epi16 = _mm_load_si128(lowlow_ptr);	// Get four lowpass coefficients

			even_epi16 = _mm_subs_epi16(even_epi16, quad_epi16);
			odd_epi16 = _mm_adds_epi16(odd_epi16, quad_epi16);

			// Apply the rounding adjustment
			even_epi16 = _mm_adds_epi16(even_epi16, _mm_set1_epi16(4));
			// Divide by eight
			even_epi16 = _mm_srai_epi16(even_epi16, 3);

			// Apply the rounding adjustment
			odd_epi16 = _mm_adds_epi16(odd_epi16, _mm_set1_epi16(4));
			// Divide by eight
			odd_epi16 = _mm_srai_epi16(odd_epi16, 3);

			// Add the highpass correction to the even result and divide by two
			quad_epi16 = _mm_load_si128(highlow_ptr);
			even_epi16 = _mm_adds_epi16(even_epi16, quad_epi16);
			even_epi16 = _mm_srai_epi16(even_epi16, 1);

			// Subtract the highpass correction from the odd result and divide by two
			odd_epi16 = _mm_subs_epi16(odd_epi16, quad_epi16);
			odd_epi16 = _mm_srai_epi16(odd_epi16, 1);

			// Store the even and odd groups of horizontal lowpass coefficients
			_mm_store_si128(even_lowpass_ptr++, even_epi16);
			_mm_store_si128(odd_lowpass_ptr++, odd_epi16);


			// Compute the vertical inverse for the right two bands //

			// Set the pitch for the lowpass band used in this section of code
			quad_pitch = (lowhigh_pitch * sizeof(PIXEL))/sizeof(__m128i);

			// Accumulate parallel sums for the even and odd filters

			quad_epi16 = _mm_load_si128(lowhigh_ptr1);	// Get four lowpass coefficients
			//lowhigh_ptr += quad_pitch;				// Advance to the next row

			even_epi16 = quad_epi16;
			odd_epi16 = _mm_setzero_si128();
			odd_epi16 = _mm_subs_epi16(odd_epi16, quad_epi16);

			quad_epi16 = _mm_load_si128(lowhigh_ptr2);	// Get four lowpass coefficients
			//lowhigh_ptr += quad_pitch;				// Advance to the next row

			// Multiply the lowpass coefficients by eight
			quad_epi16 = _mm_slli_epi16(quad_epi16, 3);

			even_epi16 = _mm_adds_epi16(even_epi16, quad_epi16);
			odd_epi16 = _mm_adds_epi16(odd_epi16, quad_epi16);

			quad_epi16 = _mm_load_si128(lowhigh_ptr3);		// Get four lowpass coefficients

			even_epi16 = _mm_subs_epi16(even_epi16, quad_epi16);
			odd_epi16 = _mm_adds_epi16(odd_epi16, quad_epi16);
#if 1
			// Apply the rounding adjustment
			even_epi16 = _mm_adds_epi16(even_epi16, _mm_set1_epi16(4));
			// Divide by eight
			even_epi16 = _mm_srai_epi16(even_epi16, 3);

			// Apply the rounding adjustment
			odd_epi16 = _mm_adds_epi16(odd_epi16, _mm_set1_epi16(4));
			// Divide by eight
			odd_epi16 = _mm_srai_epi16(odd_epi16, 3);
#endif
			// Add the highpass correction to the even result and divide by two
			quad_epi16 = _mm_load_si128(highhigh_ptr);
			even_epi16 = _mm_adds_epi16(even_epi16, quad_epi16);
			even_epi16 = _mm_srai_epi16(even_epi16, 1);

			// Subtract the highpass correction from the odd result and divide by two
			odd_epi16 = _mm_subs_epi16(odd_epi16, quad_epi16);
			odd_epi16 = _mm_srai_epi16(odd_epi16, 1);

			// Store the even and odd groups of horizontal highpass coefficients
			_mm_store_si128(even_highpass_ptr++, even_epi16);
			_mm_store_si128(odd_highpass_ptr++, odd_epi16);
		}

		// Should have exited the loop at the post processing column
		assert(column == post_column);

#endif

		// Process the rest of the row
		for (; column < width; column++)
		{
			int32_t even = 0;		// Result of convolution with even filter
			int32_t odd = 0;		// Result of convolution with odd filter


			// Compute the vertical inverse for the left two bands //

			// Apply the even reconstruction filter to the lowpass band
			even += lowlow[column + 0 * lowlow_pitch];
			even -= lowlow[column + 2 * lowlow_pitch];
			even += ROUNDING(even,8);
			even = DivideByShift(even, 3);
			even += lowlow[column + 1 * lowlow_pitch];

			// Add the highpass correction
			even += highlow_line[column];
			even = DivideByShift(even, 1);

			// Place the even result in the even row
			even_lowpass[column] = SATURATE(even);

			// Apply the odd reconstruction filter to the lowpass band
			odd -= lowlow[column + 0 * lowlow_pitch];
			odd += lowlow[column + 2 * lowlow_pitch];
			odd += ROUNDING(odd,8);
			odd = DivideByShift(odd, 3);
			odd += lowlow[column + 1 * lowlow_pitch];

			// Subtract the highpass correction
			odd -= highlow_line[column];
			odd = DivideByShift(odd, 1);

			// Place the odd result in the odd row
			odd_lowpass[column] = SATURATE(odd);


			// Compute the vertical inverse for the right two bands //

			even = 0;
			odd = 0;

			// Apply the even reconstruction filter to the lowpass band
			even += lowhigh_line[0][column];
			even -= lowhigh_line[2][column];
			even += ROUNDING(even,8);
			even = DivideByShift(even, 3);
			even += lowhigh_line[1][column];

			// Add the highpass correction
			even += highhigh_line[column];
			even = DivideByShift(even, 1);

			// Place the even result in the even row
			even_highpass[column] = SATURATE(even);

			// Apply the odd reconstruction filter to the lowpass band
			odd -= lowhigh_line[0][column];
			odd += lowhigh_line[2][column];
			odd += ROUNDING(odd,8);
			odd = DivideByShift(odd, 3);
			odd += lowhigh_line[1][column];

			// Subtract the highpass correction
			odd -= highhigh_line[column];
			odd = DivideByShift(odd, 1);

			// Place the odd result in the odd row
			odd_highpass[column] = SATURATE(odd);
		}

#if (0 && DEBUG)
	if (logfile) {
		DumpArray16s("Lowpass Strip", lowpass, strip.width, strip.height, lowpass_pitch, logfile);
		DumpArray16s("Highpass Strip", highpass, strip.width, strip.height, highpass_pitch, logfile);
	}
#endif

#if (_LOWPASS_PRESCALE > 0)
	// Apply the inverse horizontal transform to the prescaled even and odd rows
	InvertHorizontalStripPrescaled16s(lowpass, lowpass_pitch,
									  highpass, highpass_pitch,
									  output, (int)output_row_size, strip);
#else
	// Apply the inverse horizontal transform to the even and odd rows and descale the results
	InvertHorizontalStrip16s(lowpass, lowpass_pitch,
							 highpass, highpass_pitch,
							 output, output_row_size, strip);
#endif

		// Advance to the next input rows and skip the next output row
		lowlow += lowlow_pitch;
		lowhigh += lowhigh_pitch;
		highlow += highlow_pitch;
		highhigh += highhigh_pitch;
		output += 2 * output_pitch;

		if (row < last_row - 1) {
			PIXEL *temp = lowhigh_line[0];
			lowhigh_line[0] = lowhigh_line[1];
			lowhigh_line[1] = lowhigh_line[2];
			lowhigh_line[2] = temp;

			// Undo quantization for the new row in the lowhigh band
			DequantizeBandRow(lowhigh+2*lowhigh_pitch, width, lowhigh_quantization, lowhigh_line[2]);
		}
	}

	//_mm_empty();	// Clear the mmx register state

#if (1 && XMMOPT)
	// Need to advance the lowpass pointer if using SIMD instructions
	lowlow += lowlow_pitch;
	lowhigh += lowhigh_pitch;
#endif

	// Should have exited the loop at the last row
	assert(row == last_row);

	// Undo quantization for the highlow and highhigh bands
	DequantizeBandRow(highlow, width, highlow_quantization, highlow_line);
	DequantizeBandRow(highhigh, width, highhigh_quantization, highhigh_line);

	// Apply the vertical border filter to the last row
	for (column = 0; column < width; column++)
	{
		int32_t even = 0;		// Result of convolution with even filter
		int32_t odd = 0;		// Result of convolution with odd filter


		// Compute the vertical inverse for the left two bands //

		// Apply the even reconstruction filter to the lowpass band
		even += 5 * lowlow[column + 0 * lowlow_pitch];
		even += 4 * lowlow[column - 1 * lowlow_pitch];
		even -= 1 * lowlow[column - 2 * lowlow_pitch];
		even += ROUNDING(even,8);
		even = DivideByShift(even, 3);

		// Add the highpass correction
		even += highlow_line[column];
		even = DivideByShift(even, 1);

		// Place the even result in the even row
		even_lowpass[column] = SATURATE(even);

		// Apply the odd reconstruction filter to the lowpass band
		odd += 11 * lowlow[column + 0 * lowlow_pitch];
		odd -=  4 * lowlow[column - 1 * lowlow_pitch];
		odd +=  1 * lowlow[column - 2 * lowlow_pitch];
		odd += ROUNDING(odd,8);
		odd = DivideByShift(odd, 3);

		// Subtract the highpass correction
		odd -= highlow_line[column];
		odd = DivideByShift(odd, 1);

		// Place the odd result in the odd row
		odd_lowpass[column] = SATURATE(odd);


		// Compute the vertical inverse for the right two bands //

		even = 0;
		odd = 0;

		// Apply the even reconstruction filter to the lowpass band
		even += 5 * lowhigh_line[2][column];
		even += 4 * lowhigh_line[1][column];
		even -= 1 * lowhigh_line[0][column];
		even += ROUNDING(even,8);
		even = DivideByShift(even, 3);

		// Add the highpass correction
		even += highhigh_line[column];
		even = DivideByShift(even, 1);

		// Place the even result in the even row
		even_highpass[column] = SATURATE(even);

		// Apply the odd reconstruction filter to the lowpass band
		odd += 11 * lowhigh_line[2][column];
		odd -=  4 * lowhigh_line[1][column];
		odd +=  1 * lowhigh_line[0][column];
		odd += ROUNDING(odd,8);
		odd = DivideByShift(odd, 3);

		// Subtract the highpass correction
		odd -= highhigh_line[column];
		odd = DivideByShift(odd, 1);

		// Place the odd result in the odd row
		odd_highpass[column] = SATURATE(odd);
	}

#if (_LOWPASS_PRESCALE > 0)
	// Apply the inverse horizontal transform to the prescaled even and odd rows
	InvertHorizontalStripPrescaled16s(lowpass, lowpass_pitch,
									  highpass, highpass_pitch,
									  output, (int)output_row_size, strip);
#else
	// Apply the inverse horizontal transform to the even and odd rows and descale the results
	InvertHorizontalStrip16s(lowpass, lowpass_pitch,
							 highpass, highpass_pitch,
							 output, output_row_size, strip);
#endif
}

#endif



#if _PROCESSOR_DISPATCH

__declspec(cpu_dispatch(Pentium_4,Generic))

void InvertSpatial8sTo16s(PIXEL8S *lowlow_band, int lowlow_pitch,
						  PIXEL8S *lowhigh_band, int lowhigh_pitch,
						  PIXEL8S *highlow_band, int highlow_pitch,
						  PIXEL8S *highhigh_band, int highhigh_pitch,
						  PIXEL16S *output_image, int output_pitch,
						  ROI roi, PIXEL *buffer, int quantization[],
						  PIXEL *line_buffer)
{
	// Stub routine for processor specific dispatch
}
#endif


#if _PROCESSOR_GENERIC

#if _PROCESSOR_DISPATCH
__declspec(cpu_specific(Generic))
#endif

// Apply the inverse spatial (horizontal and vertical) transform by
// performing the inverse horizontal transform as each row is output
// by the inverse vertical transform and produce a 16-but result.
void InvertSpatial8sTo16s(PIXEL8S *lowlow_band, int lowlow_pitch,
						  PIXEL8S *lowhigh_band, int lowhigh_pitch,
						  PIXEL8S *highlow_band, int highlow_pitch,
						  PIXEL8S *highhigh_band, int highhigh_pitch,
						  PIXEL16S *output_image, int output_pitch,
						  ROI roi, PIXEL *buffer, int quantization[],
						  PIXEL *line_buffer)
{
	PIXEL8S *lowlow = lowlow_band;
	PIXEL8S *lowhigh = lowhigh_band;
	PIXEL8S *highlow = highlow_band;
	PIXEL8S *highhigh = highhigh_band;
	PIXEL16S *output = output_image;
	PIXEL *even_lowpass;
	PIXEL *even_highpass;
	PIXEL *odd_lowpass;
	PIXEL *odd_highpass;
	PIXEL *even_output;
	PIXEL *odd_output;
	PIXEL *lowpass;					// Strip of horizontal coefficients
	PIXEL *highpass;
	int lowpass_pitch;				// Distance between strip rows in bytes
	int highpass_pitch;
	ROI strip;						// Dimensions of the processing strip
	size_t buffer_row_size;
	size_t output_row_size = output_pitch;
	int buffer_half_pitch;
	int buffer_width;
	int buffer_pitch;
	int last_row = roi.height - 1;
	int row, column;

	PIXEL *llline1;		// Dequantized lowlow band row 1
	PIXEL *llline2;		// Dequantized lowlow band row 2
	PIXEL *llline3;		// Dequantized lowlow band row 3
	PIXEL *lhline1;		// Dequantized lowhigh band row 1
	PIXEL *lhline2;		// Dequantized lowhigh band row 2
	PIXEL *lhline3;		// Dequantized lowhigh band row 3
	PIXEL *hlline;		// Dequantized highlow band row
	PIXEL *hhline;		// Dequantized highhigh band row
	PIXEL *temp;

	int lowlow_quantization = quantization[LL_BAND];
	int highlow_quantization = quantization[HL_BAND];
	int lowhigh_quantization = quantization[LH_BAND];
	int highhigh_quantization = quantization[HH_BAND];

	// Convert pitch from bytes to pixels
	lowlow_pitch /= sizeof(PIXEL8S);
	lowhigh_pitch /= sizeof(PIXEL8S);
	highlow_pitch /= sizeof(PIXEL8S);
	highhigh_pitch /= sizeof(PIXEL8S);
	output_pitch /= sizeof(PIXEL16S);

	// Compute positions within the temporary buffer for each row of horizontal lowpass
	// and highpass intermediate coefficients computed by the vertical inverse transform
	buffer_row_size = roi.width * sizeof(PIXEL);
	buffer_row_size = ALIGN16(buffer_row_size);
	buffer_half_pitch = buffer_row_size/sizeof(PIXEL);
	buffer_pitch = 2 * buffer_half_pitch;
	buffer_width = roi.width;

	// Check that the buffer is large enough to hold four rows of highpass coefficients
	//assert(buffer_size >= (4 * buffer_row_size));

	// Set the dimensions of the processing strip
	strip.width = buffer_width;
	strip.height = 2;

	// Compute the positions of the even and odd rows of coefficients
	even_lowpass = &buffer[0];
	even_highpass = &buffer[buffer_half_pitch];
	odd_lowpass = &buffer[2 * buffer_half_pitch];
	odd_highpass = &buffer[3 * buffer_half_pitch];

	// Compute the positions of the dequantized highpass rows
	llline1 = line_buffer;
	llline2 = llline1 + lowlow_pitch;
	llline3 = llline2 + lowlow_pitch;
	lhline1 = llline3 + lowlow_pitch;
	lhline2 = lhline1 + lowhigh_pitch;
	lhline3 = lhline2 + lowhigh_pitch;
	hlline = lhline3 + lowhigh_pitch;
	hhline = hlline + highlow_pitch;

	// Pointers into the strip of horizontal coefficients
	lowpass = even_lowpass;
	highpass = even_highpass;
	lowpass_pitch = 2 * buffer_row_size;
	highpass_pitch = 2 * buffer_row_size;

	// Apply the vertical border filter to the first row
	row = 0;

	// Undo quantization
	DequantizeBandRow(lowlow, roi.width, lowlow_quantization, llline1);
	DequantizeBandRow(lowlow+lowlow_pitch, roi.width, lowlow_quantization, llline2);
	DequantizeBandRow(lowlow+2*lowlow_pitch, roi.width, lowlow_quantization, llline3);

	DequantizeBandRow(lowhigh, roi.width, lowhigh_quantization, lhline1);
	DequantizeBandRow(lowhigh+lowhigh_pitch, roi.width, lowhigh_quantization, lhline2);
	DequantizeBandRow(lowhigh+2*lowhigh_pitch, roi.width, lowhigh_quantization, lhline3);

	DequantizeBandRow(highlow, roi.width, highlow_quantization, hlline);

	DequantizeBandRow(highhigh, roi.width, highhigh_quantization, hhline);

	for (column = 0; column < roi.width; column++)
	{
		int32_t even = 0;		// Result of convolution with even filter
		int32_t odd = 0;		// Result of convolution with odd filter


		// Compute the vertical inverse for the left two bands //

		// Apply the even reconstruction filter to the lowpass band
		even += 11 * llline1[column];
		even -=  4 * llline2[column];
		even +=  1 * llline3[column];
		even += ROUNDING(even,8);
		even = DivideByShift(even, 3);

		// Add the highpass correction
		even += hlline[column];
		even = DivideByShift(even, 1);

		// Place the even result in the even row
		even_lowpass[column] = SATURATE(even);

		// Apply the odd reconstruction filter to the lowpass band
		odd += 5 * llline1[column];
		odd += 4 * llline2[column];
		odd -= 1 * llline3[column];
		odd += ROUNDING(odd,8);
		odd = DivideByShift(odd, 3);

		// Subtract the highpass correction
		odd -= hlline[column];
		odd = DivideByShift(odd, 1);

		// Place the odd result in the odd row
		odd_lowpass[column] = SATURATE(odd);


		// Compute the vertical inverse for the right two bands //

		even = 0;
		odd = 0;

		// Apply the even reconstruction filter to the lowpass band
		even += 11 * lhline1[column];
		even -=  4 * lhline2[column];
		even +=  1 * lhline3[column];
		even += ROUNDING(even,8);
		even = DivideByShift(even, 3);

		// Add the highpass correction
		even += hhline[column];
		even = DivideByShift(even, 1);

		// Place the even result in the even row
		even_highpass[column] = SATURATE(even);

		// Apply the odd reconstruction filter to the lowpass band
		odd += 5 * lhline1[column];
		odd += 4 * lhline2[column];
		odd -= 1 * lhline3[column];
		odd += ROUNDING(odd,8);
		odd = DivideByShift(odd, 3);

		// Subtract the highpass correction
		odd -= hhline[column];
		odd = DivideByShift(odd, 1);

		// Place the odd result in the odd row
		odd_highpass[column] = SATURATE(odd);
	}

	// Apply the inverse horizontal transform to the even and odd rows
	InvertHorizontalStrip16s(lowpass, lowpass_pitch,
							 highpass, highpass_pitch,
							 output, output_row_size, strip);

	// Advance to the next pair of even and odd output rows
	output += 2 * output_pitch;

	// Do not advance the lowpass row pointers until after the fast loop
	//lowlow += lowlow_pitch;
	//lowhigh += lowhigh_pitch;

	// Always advance the highpass row pointers
	highlow += highlow_pitch;
	highhigh += highhigh_pitch;

	// Advance the row index
	row++;

	// Process the middle rows using the interior reconstruction filters
	for (; row < last_row; row++)
	{
#if (1 && XMMOPT)
		int column_step = 4;
		int post_column = roi.width - (roi.width % column_step);
		__m64 *even_lowpass_ptr = (__m64 *)even_lowpass;
		__m64 *even_highpass_ptr = (__m64 *)even_highpass;
		__m64 *odd_lowpass_ptr = (__m64 *)odd_lowpass;
		__m64 *odd_highpass_ptr = (__m64 *)odd_highpass;
		int quad_pitch;
#endif

		// Undo quantization to highpass bands
		DequantizeBandRow(highlow, roi.width, highlow_quantization, hlline);
		DequantizeBandRow(highhigh, roi.width, highhigh_quantization, hhline);

		// Start at the first column
		column = 0;

#if (1 && XMMOPT)

		// Process groups of four coefficients along the row
		for (; column < post_column; column += column_step)
		{
			__m64 *lowlow_ptr1 = (__m64 *)&llline1[column];
			__m64 *lowlow_ptr2 = (__m64 *)&llline2[column];
			__m64 *lowlow_ptr3 = (__m64 *)&llline3[column];
			__m64 *highlow_ptr = (__m64 *)&hlline[column];
			__m64 *lowhigh_ptr1 = (__m64 *)&lhline1[column];
			__m64 *lowhigh_ptr2 = (__m64 *)&lhline2[column];
			__m64 *lowhigh_ptr3 = (__m64 *)&lhline3[column];
			__m64 *highhigh_ptr = (__m64 *)&hhline[column];
			__m64 quad_pi16;
			__m64 even_pi16;
			__m64 odd_pi16;


			// Compute the vertical inverse for the left two bands //

			// Set the pitch for the lowpass band used in this section of code
			quad_pitch = (lowlow_pitch * sizeof(PIXEL))/sizeof(__m64);

			// Accumulate parallel sums for the even and odd filters
			quad_pi16 = *lowlow_ptr1;	// Get four lowpass coefficients
			//lowlow_ptr += quad_pitch;	// Advance to the next row

			even_pi16 = quad_pi16;
			odd_pi16 = _mm_subs_pi16(_mm_setzero_si64(), quad_pi16);

			quad_pi16 = *lowlow_ptr2;	// Get four lowpass coefficients
			//lowlow_ptr += quad_pitch;	// Advance to the next row

			// Multiply the lowpass coefficients by eight
			quad_pi16 = _mm_slli_pi16(quad_pi16, 3);

			even_pi16 = _mm_adds_pi16(even_pi16, quad_pi16);
			odd_pi16 = _mm_adds_pi16(odd_pi16, quad_pi16);

			quad_pi16 = *lowlow_ptr3;	// Get four lowpass coefficients

			even_pi16 = _mm_subs_pi16(even_pi16, quad_pi16);
			odd_pi16 = _mm_adds_pi16(odd_pi16, quad_pi16);

			// Apply the rounding adjustment
			even_pi16 = _mm_adds_pi16(even_pi16, _mm_set1_pi16(4));
			// Divide by eight
			even_pi16 = _mm_srai_pi16(even_pi16, 3);

			// Apply the rounding adjustment
			odd_pi16 = _mm_adds_pi16(odd_pi16, _mm_set1_pi16(4));
			// Divide by eight
			odd_pi16 = _mm_srai_pi16(odd_pi16, 3);

			// Add the highpass correction to the even result and divide by two
			quad_pi16 = *highlow_ptr;
			even_pi16 = _mm_adds_pi16(even_pi16, quad_pi16);
			even_pi16 = _mm_srai_pi16(even_pi16, 1);

			// Subtract the highpass correction from the odd result and divide by two
			odd_pi16 = _mm_subs_pi16(odd_pi16, quad_pi16);
			odd_pi16 = _mm_srai_pi16(odd_pi16, 1);

			// Store the even and odd groups of horizontal lowpass coefficients
			*(even_lowpass_ptr++) = even_pi16;
			*(odd_lowpass_ptr++) = odd_pi16;


			// Compute the vertical inverse for the right two bands //

			// Set the pitch for the lowpass band used in this section of code
			quad_pitch = (lowhigh_pitch * sizeof(PIXEL))/sizeof(__m64);

			// Accumulate parallel sums for the even and odd filters

			quad_pi16 = *lowhigh_ptr1;		// Get four lowpass coefficients
			//lowhigh_ptr += quad_pitch;	// Advance to the next row

			even_pi16 = quad_pi16;
			odd_pi16 = _mm_subs_pi16(_mm_setzero_si64(), quad_pi16);

			quad_pi16 = *lowhigh_ptr2;		// Get four lowpass coefficients
			//lowhigh_ptr += quad_pitch;	// Advance to the next row

			// Multiply the lowpass coefficients by eight
			quad_pi16 = _mm_slli_pi16(quad_pi16, 3);

			even_pi16 = _mm_adds_pi16(even_pi16, quad_pi16);
			odd_pi16 = _mm_adds_pi16(odd_pi16, quad_pi16);

			quad_pi16 = *lowhigh_ptr3;		// Get four lowpass coefficients

			even_pi16 = _mm_subs_pi16(even_pi16, quad_pi16);
			odd_pi16 = _mm_adds_pi16(odd_pi16, quad_pi16);

			// Apply the rounding adjustment
			even_pi16 = _mm_adds_pi16(even_pi16, _mm_set1_pi16(4));
			// Divide by eight
			even_pi16 = _mm_srai_pi16(even_pi16, 3);

			// Apply the rounding adjustment
			odd_pi16 = _mm_adds_pi16(odd_pi16, _mm_set1_pi16(4));
			// Divide by eight
			odd_pi16 = _mm_srai_pi16(odd_pi16, 3);

			// Add the highpass correction to the even result and divide by two
			quad_pi16 = *highhigh_ptr;
			even_pi16 = _mm_adds_pi16(even_pi16, quad_pi16);
			even_pi16 = _mm_srai_pi16(even_pi16, 1);

			// Subtract the highpass correction from the odd result and divide by two
			odd_pi16 = _mm_subs_pi16(odd_pi16, quad_pi16);
			odd_pi16 = _mm_srai_pi16(odd_pi16, 1);

			// Store the even and odd groups of horizontal highpass coefficients
			*(even_highpass_ptr++) = even_pi16;
			*(odd_highpass_ptr++) = odd_pi16;
		}

		// Should have exited the loop at the post processing column
		assert(column == post_column);

#endif

		// Process the rest of the row
		for (; column < roi.width; column++)
		{
			int32_t even = 0;		// Result of convolution with even filter
			int32_t odd = 0;		// Result of convolution with odd filter


			// Compute the vertical inverse for the left two bands //

			// Apply the even reconstruction filter to the lowpass band
			even += llline1[column];
			even -= llline3[column];
			even += ROUNDING(even,8);
			even = DivideByShift(even, 3);
			even += llline2[column];

			// Add the highpass correction
			even += hlline[column];
			even = DivideByShift(even, 1);

			// Place the even result in the even row
			even_lowpass[column] = SATURATE(even);

			// Apply the odd reconstruction filter to the lowpass band
			odd -= llline1[column];
			odd += llline3[column];
			odd += ROUNDING(odd,8);
			odd = DivideByShift(odd, 3);
			odd += llline2[column];

			// Subtract the highpass correction
			odd -= hlline[column];
			odd = DivideByShift(odd, 1);

			// Place the odd result in the odd row
			odd_lowpass[column] = SATURATE(odd);


			// Compute the vertical inverse for the right two bands //

			even = 0;
			odd = 0;

			// Apply the even reconstruction filter to the lowpass band
			even += lhline1[column];
			even -= lhline3[column];
			even += ROUNDING(even,8);
			even = DivideByShift(even, 3);
			even += lhline2[column];

			// Add the highpass correction
			even += hhline[column];
			even = DivideByShift(even, 1);

			// Place the even result in the even row
			even_highpass[column] = SATURATE(even);

			// Apply the odd reconstruction filter to the lowpass band
			odd -= lhline1[column];
			odd += lhline3[column];
			odd += ROUNDING(odd,8);
			odd = DivideByShift(odd, 3);
			odd += lhline2[column];

			// Subtract the highpass correction
			odd -= hhline[column];
			odd = DivideByShift(odd, 1);

			// Place the odd result in the odd row
			odd_highpass[column] = SATURATE(odd);
		}

		// Apply the inverse horizontal transform to the even and odd rows
		InvertHorizontalStrip16s(lowpass, lowpass_pitch,
								 highpass, highpass_pitch,
								 output, output_row_size, strip);

		// Advance to the next input rows and skip the next output row
		lowlow += lowlow_pitch;
		lowhigh += lowhigh_pitch;
		highlow += highlow_pitch;
		highhigh += highhigh_pitch;
		output += 2 * output_pitch;

		if (row < last_row - 1) {
			temp = llline1;
			llline1 = llline2;
			llline2 = llline3;
			llline3 = temp;

			// Undo quantization for the new row in lowlow band
			DequantizeBandRow(lowlow+2*lowlow_pitch, roi.width, lowlow_quantization, llline3);

			temp = lhline1;
			lhline1 = lhline2;
			lhline2 = lhline3;
			lhline3 = temp;

			// Undo quantization for the new row in lowhigh band
			DequantizeBandRow(lowhigh+2*lowhigh_pitch, roi.width, lowhigh_quantization, lhline3);
		}
	}

	//_mm_empty();	// Clear the mmx register state

#if (1 && XMMOPT)
	// Need to advance the lowpass pointer if using SIMD instructions
	lowlow += lowlow_pitch;
	lowhigh += lowhigh_pitch;
#endif

	// Should have exited the loop at the last row
	assert(row == last_row);

	// Undo quantization for the highlow and highhigh bands
	DequantizeBandRow(highlow, roi.width, highlow_quantization, hlline);
	DequantizeBandRow(highhigh, roi.width, highhigh_quantization, hhline);

	// Apply the vertical border filter to the last row
	for (column = 0; column < roi.width; column++)
	{
		int32_t even = 0;		// Result of convolution with even filter
		int32_t odd = 0;		// Result of convolution with odd filter


		// Compute the vertical inverse for the left two bands //

		// Apply the even reconstruction filter to the lowpass band
		even += 5 * llline3[column];
		even += 4 * llline2[column];
		even -= 1 * llline1[column];
		even += ROUNDING(even,8);
		even = DivideByShift(even, 3);

		// Add the highpass correction
		even += hlline[column];
		even = DivideByShift(even, 1);

		// Place the even result in the even row
		even_lowpass[column] = SATURATE(even);

		// Apply the odd reconstruction filter to the lowpass band
		odd += 11 * llline3[column];
		odd -=  4 * llline2[column];
		odd +=  1 * llline1[column];
		odd += ROUNDING(odd,8);
		odd = DivideByShift(odd, 3);

		// Subtract the highpass correction
		odd -= hlline[column];
		odd = DivideByShift(odd, 1);

		// Place the odd result in the odd row
		odd_lowpass[column] = SATURATE(odd);


		// Compute the vertical inverse for the right two bands //

		even = 0;
		odd = 0;

		// Apply the even reconstruction filter to the lowpass band
		even += 5 * lhline3[column];
		even += 4 * lhline2[column];
		even -= 1 * lhline1[column];
		even += ROUNDING(even,8);
		even = DivideByShift(even, 3);

		// Add the highpass correction
		even += hhline[column];
		even = DivideByShift(even, 1);

		// Place the even result in the even row
		even_highpass[column] = SATURATE(even);

		// Apply the odd reconstruction filter to the lowpass band
		odd += 11 * lhline3[column];
		odd -=  4 * lhline2[column];
		odd +=  1 * lhline1[column];
		odd += ROUNDING(odd,8);
		odd = DivideByShift(odd, 3);

		// Subtract the highpass correction
		odd -= hhline[column];
		odd = DivideByShift(odd, 1);

		// Place the odd result in the odd row
		odd_highpass[column] = SATURATE(odd);
	}

	// Apply the inverse horizontal transform to the even and odd rows
	InvertHorizontalStrip16s(lowpass, lowpass_pitch,
							 highpass, highpass_pitch,
							 output, output_row_size, strip);
}

#endif


#if _PROCESSOR_PENTIUM_4

#if _PROCESSOR_DISPATCH
__declspec(cpu_specific(Pentium_4))
#endif

// Apply the inverse spatial (horizontal and vertical) transform by
// performing the inverse horizontal transform as each row is output
// by the inverse vertical transform and produce a 16-but result.
void InvertSpatial8sTo16s(PIXEL8S *lowlow_band, int lowlow_pitch,
						  PIXEL8S *lowhigh_band, int lowhigh_pitch,
						  PIXEL8S *highlow_band, int highlow_pitch,
						  PIXEL8S *highhigh_band, int highhigh_pitch,
						  PIXEL16S *output_image, int output_pitch,
						  ROI roi, PIXEL *buffer, int quantization[],
						  PIXEL *line_buffer)
{
	PIXEL8S *lowlow = lowlow_band;
	PIXEL8S *lowhigh = lowhigh_band;
	PIXEL8S *highlow = highlow_band;
	PIXEL8S *highhigh = highhigh_band;
	PIXEL16S *output = output_image;
	PIXEL *even_lowpass;
	PIXEL *even_highpass;
	PIXEL *odd_lowpass;
	PIXEL *odd_highpass;
	PIXEL *lowpass;					// Strip of horizontal coefficients
	PIXEL *highpass;
	int lowpass_pitch;				// Distance between strip rows in bytes
	int highpass_pitch;
	ROI strip;						// Dimensions of the processing strip
	size_t buffer_row_size;
	size_t output_row_size = output_pitch;
	int buffer_half_pitch;
	int buffer_width;
	int buffer_pitch;
	int last_row = roi.height - 1;
	int row, column;

	PIXEL *llline1;		// Dequantized lowlow band row 1
	PIXEL *llline2;		// Dequantized lowlow band row 2
	PIXEL *llline3;		// Dequantized lowlow band row 3
	PIXEL *lhline1;		// Dequantized lowhigh band row 1
	PIXEL *lhline2;		// Dequantized lowhigh band row 2
	PIXEL *lhline3;		// Dequantized lowhigh band row 3
	PIXEL *hlline;		// Dequantized highlow band row
	PIXEL *hhline;		// Dequantized highhigh band row
	PIXEL *temp;

	int lowlow_quantization = quantization[LL_BAND];
	int highlow_quantization = quantization[HL_BAND];
	int lowhigh_quantization = quantization[LH_BAND];
	int highhigh_quantization = quantization[HH_BAND];

	// Convert pitch from bytes to pixels
	lowlow_pitch /= sizeof(PIXEL8S);
	lowhigh_pitch /= sizeof(PIXEL8S);
	highlow_pitch /= sizeof(PIXEL8S);
	highhigh_pitch /= sizeof(PIXEL8S);
	output_pitch /= sizeof(PIXEL16S);

	// Compute positions within the temporary buffer for each row of horizontal lowpass
	// and highpass intermediate coefficients computed by the vertical inverse transform
	buffer_row_size = roi.width * sizeof(PIXEL);
	buffer_row_size = ALIGN16(buffer_row_size);
	buffer_half_pitch = (int)buffer_row_size/sizeof(PIXEL);
	buffer_pitch = 2 * buffer_half_pitch;
	buffer_width = roi.width;

	// Check that the buffer is large enough to hold four rows of highpass coefficients
	//assert(buffer_size >= (4 * buffer_row_size));

	// Set the dimensions of the processing strip
	strip.width = buffer_width;
	strip.height = 2;

	// Compute the positions of the even and odd rows of coefficients
	even_lowpass = &buffer[0];
	even_highpass = &buffer[buffer_half_pitch];
	odd_lowpass = &buffer[2 * buffer_half_pitch];
	odd_highpass = &buffer[3 * buffer_half_pitch];

	// Compute the positions of the dequantized highpass rows
	llline1 = line_buffer;
	llline2 = llline1 + lowlow_pitch;
	llline3 = llline2 + lowlow_pitch;
	lhline1 = llline3 + lowlow_pitch;
	lhline2 = lhline1 + lowhigh_pitch;
	lhline3 = lhline2 + lowhigh_pitch;
	hlline = lhline3 + lowhigh_pitch;
	hhline = hlline + highlow_pitch;

	// Pointers into the strip of horizontal coefficients
	lowpass = even_lowpass;
	highpass = even_highpass;
	lowpass_pitch = (int)(2 * buffer_row_size);
	highpass_pitch = (int)(2 * buffer_row_size);

	// Apply the vertical border filter to the first row
	row = 0;

	// Undo quantization
	DequantizeBandRow(lowlow, roi.width, lowlow_quantization, llline1);
	DequantizeBandRow(lowlow+lowlow_pitch, roi.width, lowlow_quantization, llline2);
	DequantizeBandRow(lowlow+2*lowlow_pitch, roi.width, lowlow_quantization, llline3);

	DequantizeBandRow(lowhigh, roi.width, lowhigh_quantization, lhline1);
	DequantizeBandRow(lowhigh+lowhigh_pitch, roi.width, lowhigh_quantization, lhline2);
	DequantizeBandRow(lowhigh+2*lowhigh_pitch, roi.width, lowhigh_quantization, lhline3);

	DequantizeBandRow(highlow, roi.width, highlow_quantization, hlline);

	DequantizeBandRow(highhigh, roi.width, highhigh_quantization, hhline);

	for (column = 0; column < roi.width; column++)
	{
		int32_t even = 0;		// Result of convolution with even filter
		int32_t odd = 0;		// Result of convolution with odd filter


		// Compute the vertical inverse for the left two bands //

		// Apply the even reconstruction filter to the lowpass band
		even += 11 * llline1[column];
		even -=  4 * llline2[column];
		even +=  1 * llline3[column];
		even += ROUNDING(even,8);
		even = DivideByShift(even, 3);

		// Add the highpass correction
		even += hlline[column];
		even = DivideByShift(even, 1);

		// Place the even result in the even row
		even_lowpass[column] = SATURATE(even);

		// Apply the odd reconstruction filter to the lowpass band
		odd += 5 * llline1[column];
		odd += 4 * llline2[column];
		odd -= 1 * llline3[column];
		odd += ROUNDING(odd,8);
		odd = DivideByShift(odd, 3);

		// Subtract the highpass correction
		odd -= hlline[column];
		odd = DivideByShift(odd, 1);

		// Place the odd result in the odd row
		odd_lowpass[column] = SATURATE(odd);


		// Compute the vertical inverse for the right two bands //

		even = 0;
		odd = 0;

		// Apply the even reconstruction filter to the lowpass band
		even += 11 * lhline1[column];
		even -=  4 * lhline2[column];
		even +=  1 * lhline3[column];
		even += ROUNDING(even,8);
		even = DivideByShift(even, 3);

		// Add the highpass correction
		even += hhline[column];
		even = DivideByShift(even, 1);

		// Place the even result in the even row
		even_highpass[column] = SATURATE(even);

		// Apply the odd reconstruction filter to the lowpass band
		odd += 5 * lhline1[column];
		odd += 4 * lhline2[column];
		odd -= 1 * lhline3[column];
		odd += ROUNDING(odd,8);
		odd = DivideByShift(odd, 3);

		// Subtract the highpass correction
		odd -= hhline[column];
		odd = DivideByShift(odd, 1);

		// Place the odd result in the odd row
		odd_highpass[column] = SATURATE(odd);
	}

	// Apply the inverse horizontal transform to the even and odd rows
	InvertHorizontalStrip16s(lowpass, lowpass_pitch,
							 highpass, highpass_pitch,
							 output, (int)output_row_size, strip);

	// Advance to the next pair of even and odd output rows
	output += 2 * output_pitch;

	// Do not advance the lowpass row pointers until after the fast loop
	//lowlow += lowlow_pitch;
	//lowhigh += lowhigh_pitch;

	// Always advance the highpass row pointers
	highlow += highlow_pitch;
	highhigh += highhigh_pitch;

	// Advance the row index
	row++;

	// Process the middle rows using the interior reconstruction filters
	for (; row < last_row; row++)
	{
#if (1 && XMMOPT)
		int column_step = 8;
		int post_column = roi.width - (roi.width % column_step);
		__m128i *even_lowpass_ptr = (__m128i *)even_lowpass;
		__m128i *even_highpass_ptr = (__m128i *)even_highpass;
		__m128i *odd_lowpass_ptr = (__m128i *)odd_lowpass;
		__m128i *odd_highpass_ptr = (__m128i *)odd_highpass;
		int quad_pitch;
#endif

		// Undo quantization to highpass bands
		DequantizeBandRow(highlow, roi.width, highlow_quantization, hlline);
		DequantizeBandRow(highhigh, roi.width, highhigh_quantization, hhline);

		// Start at the first column
		column = 0;

#if (1 && XMMOPT)

		// Process groups of four coefficients along the row
		for (; column < post_column; column += column_step)
		{
			__m128i *lowlow_ptr1 = (__m128i *)&llline1[column];
			__m128i *lowlow_ptr2 = (__m128i *)&llline2[column];
			__m128i *lowlow_ptr3 = (__m128i *)&llline3[column];
			__m128i *highlow_ptr = (__m128i *)&hlline[column];
			__m128i *lowhigh_ptr1 = (__m128i *)&lhline1[column];
			__m128i *lowhigh_ptr2 = (__m128i *)&lhline2[column];
			__m128i *lowhigh_ptr3 = (__m128i *)&lhline3[column];
			__m128i *highhigh_ptr = (__m128i *)&hhline[column];
			__m128i quad_epi16;
			__m128i even_epi16;
			__m128i odd_epi16;


			// Compute the vertical inverse for the left two bands //

			// Set the pitch for the lowpass band used in this section of code
			quad_pitch = (lowlow_pitch * sizeof(PIXEL))/sizeof(__m128i);

			// Accumulate parallel sums for the even and odd filters
			quad_epi16 = _mm_load_si128(lowlow_ptr1);	// Get four lowpass coefficients
			//lowlow_ptr += quad_pitch;					// Advance to the next row

			even_epi16 = quad_epi16;
			odd_epi16 = _mm_setzero_si128();
			odd_epi16 = _mm_subs_epi16(odd_epi16, quad_epi16);

			quad_epi16 = _mm_load_si128(lowlow_ptr2);	// Get four lowpass coefficients
			//lowlow_ptr += quad_pitch;					// Advance to the next row

			// Multiply the lowpass coefficients by eight
			quad_epi16 = _mm_slli_epi16(quad_epi16, 3);

			even_epi16 = _mm_adds_epi16(even_epi16, quad_epi16);
			odd_epi16 = _mm_adds_epi16(odd_epi16, quad_epi16);

			quad_epi16 = _mm_load_si128(lowlow_ptr3);	// Get four lowpass coefficients

			even_epi16 = _mm_subs_epi16(even_epi16, quad_epi16);
			odd_epi16 = _mm_adds_epi16(odd_epi16, quad_epi16);

			// Apply the rounding adjustment
			even_epi16 = _mm_adds_epi16(even_epi16, _mm_set1_epi16(4));
			// Divide by eight
			even_epi16 = _mm_srai_epi16(even_epi16, 3);

			// Apply the rounding adjustment
			odd_epi16 = _mm_adds_epi16(odd_epi16, _mm_set1_epi16(4));
			// Divide by eight
			odd_epi16 = _mm_srai_epi16(odd_epi16, 3);

			// Add the highpass correction to the even result and divide by two
			quad_epi16 = _mm_load_si128(highlow_ptr);
			even_epi16 = _mm_adds_epi16(even_epi16, quad_epi16);
			even_epi16 = _mm_srai_epi16(even_epi16, 1);

			// Subtract the highpass correction from the odd result and divide by two
			odd_epi16 = _mm_subs_epi16(odd_epi16, quad_epi16);
			odd_epi16 = _mm_srai_epi16(odd_epi16, 1);

			// Store the even and odd groups of horizontal lowpass coefficients
			_mm_store_si128(even_lowpass_ptr++, even_epi16);
			_mm_store_si128(odd_lowpass_ptr++, odd_epi16);


			// Compute the vertical inverse for the right two bands //

			// Set the pitch for the lowpass band used in this section of code
			quad_pitch = (lowhigh_pitch * sizeof(PIXEL))/sizeof(__m128i);

			// Accumulate parallel sums for the even and odd filters

			quad_epi16 = _mm_load_si128(lowhigh_ptr1);	// Get four lowpass coefficients
			//lowhigh_ptr += quad_pitch;				// Advance to the next row

			even_epi16 = quad_epi16;
			odd_epi16 = _mm_setzero_si128();
			odd_epi16 = _mm_subs_epi16(odd_epi16, quad_epi16);

			quad_epi16 = _mm_load_si128(lowhigh_ptr2);	// Get four lowpass coefficients
			//lowhigh_ptr += quad_pitch;				// Advance to the next row

			// Multiply the lowpass coefficients by eight
			quad_epi16 = _mm_slli_epi16(quad_epi16, 3);

			even_epi16 = _mm_adds_epi16(even_epi16, quad_epi16);
			odd_epi16 = _mm_adds_epi16(odd_epi16, quad_epi16);

			quad_epi16 = _mm_load_si128(lowhigh_ptr3);	// Get four lowpass coefficients

			even_epi16 = _mm_subs_epi16(even_epi16, quad_epi16);
			odd_epi16 = _mm_adds_epi16(odd_epi16, quad_epi16);

			// Apply the rounding adjustment
			even_epi16 = _mm_adds_epi16(even_epi16, _mm_set1_epi16(4));
			// Divide by eight
			even_epi16 = _mm_srai_epi16(even_epi16, 3);

			// Apply the rounding adjustment
			odd_epi16 = _mm_adds_epi16(odd_epi16, _mm_set1_epi16(4));
			// Divide by eight
			odd_epi16 = _mm_srai_epi16(odd_epi16, 3);

			// Add the highpass correction to the even result and divide by two
			quad_epi16 = _mm_load_si128(highhigh_ptr);
			even_epi16 = _mm_adds_epi16(even_epi16, quad_epi16);
			even_epi16 = _mm_srai_epi16(even_epi16, 1);

			// Subtract the highpass correction from the odd result and divide by two
			odd_epi16 = _mm_subs_epi16(odd_epi16, quad_epi16);
			odd_epi16 = _mm_srai_epi16(odd_epi16, 1);

			// Store the even and odd groups of horizontal highpass coefficients
			_mm_store_si128(even_highpass_ptr++, even_epi16);
			_mm_store_si128(odd_highpass_ptr++, odd_epi16);
		}

		// Should have exited the loop at the post processing column
		assert(column == post_column);

#endif

		// Process the rest of the row
		for (; column < roi.width; column++)
		{
			int32_t even = 0;		// Result of convolution with even filter
			int32_t odd = 0;		// Result of convolution with odd filter


			// Compute the vertical inverse for the left two bands //

			// Apply the even reconstruction filter to the lowpass band
			even += llline1[column];
			even -= llline3[column];
			even += ROUNDING(even,8);
			even = DivideByShift(even, 3);
			even += llline2[column];

			// Add the highpass correction
			even += hlline[column];
			even = DivideByShift(even, 1);

			// Place the even result in the even row
			even_lowpass[column] = SATURATE(even);

			// Apply the odd reconstruction filter to the lowpass band
			odd -= llline1[column];
			odd += llline3[column];
			odd += ROUNDING(odd,8);
			odd = DivideByShift(odd, 3);
			odd += llline2[column];

			// Subtract the highpass correction
			odd -= hlline[column];
			odd = DivideByShift(odd, 1);

			// Place the odd result in the odd row
			odd_lowpass[column] = SATURATE(odd);


			// Compute the vertical inverse for the right two bands //

			even = 0;
			odd = 0;

			// Apply the even reconstruction filter to the lowpass band
			even += lhline1[column];
			even -= lhline3[column];
			even += ROUNDING(even,8);
			even = DivideByShift(even, 3);
			even += lhline2[column];

			// Add the highpass correction
			even += hhline[column];
			even = DivideByShift(even, 1);

			// Place the even result in the even row
			even_highpass[column] = SATURATE(even);

			// Apply the odd reconstruction filter to the lowpass band
			odd -= lhline1[column];
			odd += lhline3[column];
			odd += ROUNDING(odd,8);
			odd = DivideByShift(odd, 3);
			odd += lhline2[column];

			// Subtract the highpass correction
			odd -= hhline[column];
			odd = DivideByShift(odd, 1);

			// Place the odd result in the odd row
			odd_highpass[column] = SATURATE(odd);
		}

		// Apply the inverse horizontal transform to the even and odd rows
		InvertHorizontalStrip16s(lowpass, lowpass_pitch,
								 highpass, highpass_pitch,
								 output, (int)output_row_size, strip);

		// Advance to the next input rows and skip the next output row
		lowlow += lowlow_pitch;
		lowhigh += lowhigh_pitch;
		highlow += highlow_pitch;
		highhigh += highhigh_pitch;
		output += 2 * output_pitch;

		if (row < last_row - 1) {
			temp = llline1;
			llline1 = llline2;
			llline2 = llline3;
			llline3 = temp;

			// Undo quantization for the new row in lowlow band
			DequantizeBandRow(lowlow+2*lowlow_pitch, roi.width, lowlow_quantization, llline3);

			temp = lhline1;
			lhline1 = lhline2;
			lhline2 = lhline3;
			lhline3 = temp;

			// Undo quantization for the new row in lowhigh band
			DequantizeBandRow(lowhigh+2*lowhigh_pitch, roi.width, lowhigh_quantization, lhline3);
		}
	}

	//_mm_empty();	// Clear the mmx register state

#if (1 && XMMOPT)
	// Need to advance the lowpass pointer if using SIMD instructions
	lowlow += lowlow_pitch;
	lowhigh += lowhigh_pitch;
#endif

	// Should have exited the loop at the last row
	assert(row == last_row);

	// Undo quantization for the highlow and highhigh bands
	DequantizeBandRow(highlow, roi.width, highlow_quantization, hlline);
	DequantizeBandRow(highhigh, roi.width, highhigh_quantization, hhline);

	// Apply the vertical border filter to the last row
	for (column = 0; column < roi.width; column++)
	{
		int32_t even = 0;		// Result of convolution with even filter
		int32_t odd = 0;		// Result of convolution with odd filter


		// Compute the vertical inverse for the left two bands //

		// Apply the even reconstruction filter to the lowpass band
		even += 5 * llline3[column];
		even += 4 * llline2[column];
		even -= 1 * llline1[column];
		even += ROUNDING(even,8);
		even = DivideByShift(even, 3);

		// Add the highpass correction
		even += hlline[column];
		even = DivideByShift(even, 1);

		// Place the even result in the even row
		even_lowpass[column] = SATURATE(even);

		// Apply the odd reconstruction filter to the lowpass band
		odd += 11 * llline3[column];
		odd -=  4 * llline2[column];
		odd +=  1 * llline1[column];
		odd += ROUNDING(odd,8);
		odd = DivideByShift(odd, 3);

		// Subtract the highpass correction
		odd -= hlline[column];
		odd = DivideByShift(odd, 1);

		// Place the odd result in the odd row
		odd_lowpass[column] = SATURATE(odd);


		// Compute the vertical inverse for the right two bands //

		even = 0;
		odd = 0;

		// Apply the even reconstruction filter to the lowpass band
		even += 5 * lhline3[column];
		even += 4 * lhline2[column];
		even -= 1 * lhline1[column];
		even += ROUNDING(even,8);
		even = DivideByShift(even, 3);

		// Add the highpass correction
		even += hhline[column];
		even = DivideByShift(even, 1);

		// Place the even result in the even row
		even_highpass[column] = SATURATE(even);

		// Apply the odd reconstruction filter to the lowpass band
		odd += 11 * lhline3[column];
		odd -=  4 * lhline2[column];
		odd +=  1 * lhline1[column];
		odd += ROUNDING(odd,8);
		odd = DivideByShift(odd, 3);

		// Subtract the highpass correction
		odd -= hhline[column];
		odd = DivideByShift(odd, 1);

		// Place the odd result in the odd row
		odd_highpass[column] = SATURATE(odd);
	}

	// Apply the inverse horizontal transform to the even and odd rows
	InvertHorizontalStrip16s(lowpass, lowpass_pitch,
							 highpass, highpass_pitch,
							 output, (int)output_row_size, strip);
}

#endif


#if _PROCESSOR_DISPATCH

__declspec(cpu_dispatch(Pentium_4,Generic))

void InvertSpatial16sTo16s(PIXEL16S *lowlow_band, int lowlow_pitch,
						  PIXEL16S *lowhigh_band, int lowhigh_pitch,
						  PIXEL16S *highlow_band, int highlow_pitch,
						  PIXEL16S *highhigh_band, int highhigh_pitch,
						  PIXEL16S *output_image, int output_pitch,
						  ROI roi, PIXEL *buffer, int quantization[],
						  PIXEL *line_buffer)
{
	// Stub routine for processor specific dispatch
}
#endif


#if _PROCESSOR_GENERIC

  #if _PROCESSOR_DISPATCH
  __declspec(cpu_specific(Generic))
  #endif

  // Apply the inverse spatial (horizontal and vertical) transform by
  // performing the inverse horizontal transform as each row is output
  // by the inverse vertical transform and produce a 16-but result.
  void InvertSpatial16sTo16s(PIXEL16S *lowlow_band, int lowlow_pitch,
						  PIXEL16S *lowhigh_band, int lowhigh_pitch,
						  PIXEL16S *highlow_band, int highlow_pitch,
						  PIXEL16S *highhigh_band, int highhigh_pitch,
						  PIXEL16S *output_image, int output_pitch,
						  ROI roi, PIXEL *buffer, int quantization[],
						  PIXEL *line_buffer)
  {
	PIXEL16S *lowlow = lowlow_band;
	PIXEL16S *lowhigh = lowhigh_band;
	PIXEL16S *highlow = highlow_band;
	PIXEL16S *highhigh = highhigh_band;
	PIXEL16S *output = output_image;
	PIXEL *even_lowpass;
	PIXEL *even_highpass;
	PIXEL *odd_lowpass;
	PIXEL *odd_highpass;
	PIXEL *even_output;
	PIXEL *odd_output;
	PIXEL *lowpass;					// Strip of horizontal coefficients
	PIXEL *highpass;
	int lowpass_pitch;				// Distance between strip rows in bytes
	int highpass_pitch;
	ROI strip;						// Dimensions of the processing strip
	size_t buffer_row_size;
	size_t output_row_size = output_pitch;
	int buffer_half_pitch;
	int buffer_width;
	int buffer_pitch;
	int last_row = roi.height - 1;
	int row, column;

	PIXEL *llline1;		// Dequantized lowlow band row 1
	PIXEL *llline2;		// Dequantized lowlow band row 2
	PIXEL *llline3;		// Dequantized lowlow band row 3
	PIXEL *lhline1;		// Dequantized lowhigh band row 1
	PIXEL *lhline2;		// Dequantized lowhigh band row 2
	PIXEL *lhline3;		// Dequantized lowhigh band row 3
	PIXEL *hlline;		// Dequantized highlow band row
	PIXEL *hhline;		// Dequantized highhigh band row
	PIXEL *temp;

	int lowlow_quantization = quantization[LL_BAND];
	int highlow_quantization = quantization[HL_BAND];
	int lowhigh_quantization = quantization[LH_BAND];
	int highhigh_quantization = quantization[HH_BAND];

	// Convert pitch from bytes to pixels
	lowlow_pitch /= sizeof(PIXEL16S);
	lowhigh_pitch /= sizeof(PIXEL16S);
	highlow_pitch /= sizeof(PIXEL16S);
	highhigh_pitch /= sizeof(PIXEL16S);
	output_pitch /= sizeof(PIXEL16S);

	// Compute positions within the temporary buffer for each row of horizontal lowpass
	// and highpass intermediate coefficients computed by the vertical inverse transform
	buffer_row_size = roi.width * sizeof(PIXEL);
	buffer_row_size = ALIGN16(buffer_row_size);
	buffer_half_pitch = buffer_row_size/sizeof(PIXEL);
	buffer_pitch = 2 * buffer_half_pitch;
	buffer_width = roi.width;

	// Check that the buffer is large enough to hold four rows of highpass coefficients
	//assert(buffer_size >= (4 * buffer_row_size));

	// Set the dimensions of the processing strip
	strip.width = buffer_width;
	strip.height = 2;

	// Compute the positions of the even and odd rows of coefficients
	even_lowpass = &buffer[0];
	even_highpass = &buffer[buffer_half_pitch];
	odd_lowpass = &buffer[2 * buffer_half_pitch];
	odd_highpass = &buffer[3 * buffer_half_pitch];

	// Compute the positions of the dequantized highpass rows
	llline1 = line_buffer;
	llline2 = llline1 + lowlow_pitch;
	llline3 = llline2 + lowlow_pitch;
	lhline1 = llline3 + lowlow_pitch;
	lhline2 = lhline1 + lowhigh_pitch;
	lhline3 = lhline2 + lowhigh_pitch;
	hlline = lhline3 + lowhigh_pitch;
	hhline = hlline + highlow_pitch;

	// Pointers into the strip of horizontal coefficients
	lowpass = even_lowpass;
	highpass = even_highpass;
	lowpass_pitch = 2 * buffer_row_size;
	highpass_pitch = 2 * buffer_row_size;

	// Apply the vertical border filter to the first row
	row = 0;

	// Undo quantization
#if _DEQUANTIZE_IN_FSM
	llline1 = lowlow;
	llline2 = lowlow+lowlow_pitch;
	llline3 = lowlow+2*lowlow_pitch;

	lhline1 = lowhigh;
	lhline2 = lowhigh+lowhigh_pitch;
	lhline3 = lowhigh+2*lowhigh_pitch;

	hlline = highlow;
	hhline = highhigh;
#else
	DequantizeBandRow16s(lowlow, roi.width, lowlow_quantization, llline1);
	DequantizeBandRow16s(lowlow+lowlow_pitch, roi.width, lowlow_quantization, llline2);
	DequantizeBandRow16s(lowlow+2*lowlow_pitch, roi.width, lowlow_quantization, llline3);

	DequantizeBandRow16s(lowhigh, roi.width, lowhigh_quantization, lhline1);
	DequantizeBandRow16s(lowhigh+lowhigh_pitch, roi.width, lowhigh_quantization, lhline2);
	DequantizeBandRow16s(lowhigh+2*lowhigh_pitch, roi.width, lowhigh_quantization, lhline3);

	DequantizeBandRow16s(highlow, roi.width, highlow_quantization, hlline);
	DequantizeBandRow16s(highhigh, roi.width, highhigh_quantization, hhline);
#endif

	for (column = 0; column < roi.width; column++)
	{
		int32_t even = 0;		// Result of convolution with even filter
		int32_t odd = 0;		// Result of convolution with odd filter


		// Compute the vertical inverse for the left two bands //

		// Apply the even reconstruction filter to the lowpass band
		even += 11 * llline1[column];
		even -=  4 * llline2[column];
		even +=  1 * llline3[column];
		even += ROUNDING(even,8);
		even = DivideByShift(even, 3);

		// Add the highpass correction
		even += hlline[column];
		even = DivideByShift(even, 1);

		// Place the even result in the even row
		even_lowpass[column] = SATURATE(even);

		// Apply the odd reconstruction filter to the lowpass band
		odd += 5 * llline1[column];
		odd += 4 * llline2[column];
		odd -= 1 * llline3[column];
		odd += ROUNDING(odd,8);
		odd = DivideByShift(odd, 3);

		// Subtract the highpass correction
		odd -= hlline[column];
		odd = DivideByShift(odd, 1);

		// Place the odd result in the odd row
		odd_lowpass[column] = SATURATE(odd);


		// Compute the vertical inverse for the right two bands //

		even = 0;
		odd = 0;

		// Apply the even reconstruction filter to the lowpass band
		even += 11 * lhline1[column];
		even -=  4 * lhline2[column];
		even +=  1 * lhline3[column];
		even += ROUNDING(even,8);
		even = DivideByShift(even, 3);

		// Add the highpass correction
		even += hhline[column];
		even = DivideByShift(even, 1);

		// Place the even result in the even row
		even_highpass[column] = SATURATE(even);

		// Apply the odd reconstruction filter to the lowpass band
		odd += 5 * lhline1[column];
		odd += 4 * lhline2[column];
		odd -= 1 * lhline3[column];
		odd += ROUNDING(odd,8);
		odd = DivideByShift(odd, 3);

		// Subtract the highpass correction
		odd -= hhline[column];
		odd = DivideByShift(odd, 1);

		// Place the odd result in the odd row
		odd_highpass[column] = SATURATE(odd);
	}

	// Apply the inverse horizontal transform to the even and odd rows
	InvertHorizontalStrip16s(lowpass, lowpass_pitch,
							 highpass, highpass_pitch,
							 output, output_row_size, strip);

	// Advance to the next pair of even and odd output rows
	output += 2 * output_pitch;

	// Do not advance the lowpass row pointers until after the fast loop
	//lowlow += lowlow_pitch;
	//lowhigh += lowhigh_pitch;

	// Always advance the highpass row pointers
	highlow += highlow_pitch;
	highhigh += highhigh_pitch;

	// Advance the row index
	row++;

	// Process the middle rows using the interior reconstruction filters
	for (; row < last_row; row++)
	{
#if (1 && XMMOPT)
		int column_step = 4;
		int post_column = roi.width - (roi.width % column_step);
		__m64 *even_lowpass_ptr = (__m64 *)even_lowpass;
		__m64 *even_highpass_ptr = (__m64 *)even_highpass;
		__m64 *odd_lowpass_ptr = (__m64 *)odd_lowpass;
		__m64 *odd_highpass_ptr = (__m64 *)odd_highpass;
		int quad_pitch;
#endif

		// Undo quantization to highpass bands
	#if _DEQUANTIZE_IN_FSM
		hlline = highlow;
		hhline = highhigh;
	#else
		DequantizeBandRow16s(highlow, roi.width, highlow_quantization, hlline);
		DequantizeBandRow16s(highhigh, roi.width, highhigh_quantization, hhline);
	#endif

		// Start at the first column
		column = 0;

#if (1 && XMMOPT)

		// Process groups of four coefficients along the row
		for (; column < post_column; column += column_step)
		{
			__m64 *lowlow_ptr1 = (__m64 *)&llline1[column];
			__m64 *lowlow_ptr2 = (__m64 *)&llline2[column];
			__m64 *lowlow_ptr3 = (__m64 *)&llline3[column];
			__m64 *highlow_ptr = (__m64 *)&hlline[column];
			__m64 *lowhigh_ptr1 = (__m64 *)&lhline1[column];
			__m64 *lowhigh_ptr2 = (__m64 *)&lhline2[column];
			__m64 *lowhigh_ptr3 = (__m64 *)&lhline3[column];
			__m64 *highhigh_ptr = (__m64 *)&hhline[column];
			__m64 quad_pi16;
			__m64 even_pi16;
			__m64 odd_pi16;


			// Compute the vertical inverse for the left two bands //

			// Set the pitch for the lowpass band used in this section of code
			quad_pitch = (lowlow_pitch * sizeof(PIXEL))/sizeof(__m64);

			// Accumulate parallel sums for the even and odd filters
			quad_pi16 = *lowlow_ptr1;	// Get four lowpass coefficients
			//lowlow_ptr += quad_pitch;	// Advance to the next row

			even_pi16 = quad_pi16;
			odd_pi16 = _mm_subs_pi16(_mm_setzero_si64(), quad_pi16);

			quad_pi16 = *lowlow_ptr2;	// Get four lowpass coefficients
			//lowlow_ptr += quad_pitch;	// Advance to the next row

			// Multiply the lowpass coefficients by eight
			quad_pi16 = _mm_slli_pi16(quad_pi16, 3);

			even_pi16 = _mm_adds_pi16(even_pi16, quad_pi16);
			odd_pi16 = _mm_adds_pi16(odd_pi16, quad_pi16);

			quad_pi16 = *lowlow_ptr3;	// Get four lowpass coefficients

			even_pi16 = _mm_subs_pi16(even_pi16, quad_pi16);
			odd_pi16 = _mm_adds_pi16(odd_pi16, quad_pi16);

			// Apply the rounding adjustment
			even_pi16 = _mm_adds_pi16(even_pi16, _mm_set1_pi16(4));
			// Divide by eight
			even_pi16 = _mm_srai_pi16(even_pi16, 3);

			// Apply the rounding adjustment
			odd_pi16 = _mm_adds_pi16(odd_pi16, _mm_set1_pi16(4));
			// Divide by eight
			odd_pi16 = _mm_srai_pi16(odd_pi16, 3);

			// Add the highpass correction to the even result and divide by two
			quad_pi16 = *highlow_ptr;
			even_pi16 = _mm_adds_pi16(even_pi16, quad_pi16);
			even_pi16 = _mm_srai_pi16(even_pi16, 1);

			// Subtract the highpass correction from the odd result and divide by two
			odd_pi16 = _mm_subs_pi16(odd_pi16, quad_pi16);
			odd_pi16 = _mm_srai_pi16(odd_pi16, 1);

			// Store the even and odd groups of horizontal lowpass coefficients
			*(even_lowpass_ptr++) = even_pi16;
			*(odd_lowpass_ptr++) = odd_pi16;


			// Compute the vertical inverse for the right two bands //

			// Set the pitch for the lowpass band used in this section of code
			quad_pitch = (lowhigh_pitch * sizeof(PIXEL))/sizeof(__m64);

			// Accumulate parallel sums for the even and odd filters

			quad_pi16 = *lowhigh_ptr1;		// Get four lowpass coefficients
			//lowhigh_ptr += quad_pitch;	// Advance to the next row

			even_pi16 = quad_pi16;
			odd_pi16 = _mm_subs_pi16(_mm_setzero_si64(), quad_pi16);

			quad_pi16 = *lowhigh_ptr2;		// Get four lowpass coefficients
			//lowhigh_ptr += quad_pitch;	// Advance to the next row

			// Multiply the lowpass coefficients by eight
			quad_pi16 = _mm_slli_pi16(quad_pi16, 3);

			even_pi16 = _mm_adds_pi16(even_pi16, quad_pi16);
			odd_pi16 = _mm_adds_pi16(odd_pi16, quad_pi16);

			quad_pi16 = *lowhigh_ptr3;		// Get four lowpass coefficients

			even_pi16 = _mm_subs_pi16(even_pi16, quad_pi16);
			odd_pi16 = _mm_adds_pi16(odd_pi16, quad_pi16);

			// Apply the rounding adjustment
			even_pi16 = _mm_adds_pi16(even_pi16, _mm_set1_pi16(4));
			// Divide by eight
			even_pi16 = _mm_srai_pi16(even_pi16, 3);

			// Apply the rounding adjustment
			odd_pi16 = _mm_adds_pi16(odd_pi16, _mm_set1_pi16(4));
			// Divide by eight
			odd_pi16 = _mm_srai_pi16(odd_pi16, 3);

			// Add the highpass correction to the even result and divide by two
			quad_pi16 = *highhigh_ptr;
			even_pi16 = _mm_adds_pi16(even_pi16, quad_pi16);
			even_pi16 = _mm_srai_pi16(even_pi16, 1);

			// Subtract the highpass correction from the odd result and divide by two
			odd_pi16 = _mm_subs_pi16(odd_pi16, quad_pi16);
			odd_pi16 = _mm_srai_pi16(odd_pi16, 1);

			// Store the even and odd groups of horizontal highpass coefficients
			*(even_highpass_ptr++) = even_pi16;
			*(odd_highpass_ptr++) = odd_pi16;
		}

		// Should have exited the loop at the post processing column
		assert(column == post_column);

#endif

		// Process the rest of the row
		for (; column < roi.width; column++)
		{
			int32_t even = 0;		// Result of convolution with even filter
			int32_t odd = 0;		// Result of convolution with odd filter


			// Compute the vertical inverse for the left two bands //

			// Apply the even reconstruction filter to the lowpass band
			even += llline1[column];
			even -= llline3[column];
			even += ROUNDING(even,8);
			even = DivideByShift(even, 3);
			even += llline2[column];

			// Add the highpass correction
			even += hlline[column];
			even = DivideByShift(even, 1);

			// Place the even result in the even row
			even_lowpass[column] = SATURATE(even);

			// Apply the odd reconstruction filter to the lowpass band
			odd -= llline1[column];
			odd += llline3[column];
			odd += ROUNDING(odd,8);
			odd = DivideByShift(odd, 3);
			odd += llline2[column];

			// Subtract the highpass correction
			odd -= hlline[column];
			odd = DivideByShift(odd, 1);

			// Place the odd result in the odd row
			odd_lowpass[column] = SATURATE(odd);


			// Compute the vertical inverse for the right two bands //

			even = 0;
			odd = 0;

			// Apply the even reconstruction filter to the lowpass band
			even += lhline1[column];
			even -= lhline3[column];
			even += ROUNDING(even,8);
			even = DivideByShift(even, 3);
			even += lhline2[column];

			// Add the highpass correction
			even += hhline[column];
			even = DivideByShift(even, 1);

			// Place the even result in the even row
			even_highpass[column] = SATURATE(even);

			// Apply the odd reconstruction filter to the lowpass band
			odd -= lhline1[column];
			odd += lhline3[column];
			odd += ROUNDING(odd,8);
			odd = DivideByShift(odd, 3);
			odd += lhline2[column];

			// Subtract the highpass correction
			odd -= hhline[column];
			odd = DivideByShift(odd, 1);

			// Place the odd result in the odd row
			odd_highpass[column] = SATURATE(odd);
		}

		// Apply the inverse horizontal transform to the even and odd rows
		InvertHorizontalStrip16s(lowpass, lowpass_pitch,
								 highpass, highpass_pitch,
								 output, output_row_size, strip);

		// Advance to the next input rows and skip the next output row
		lowlow += lowlow_pitch;
		lowhigh += lowhigh_pitch;
		highlow += highlow_pitch;
		highhigh += highhigh_pitch;
		output += 2 * output_pitch;

		if (row < last_row - 1) {
			temp = llline1;
			llline1 = llline2;
			llline2 = llline3;
			llline3 = temp;

			// Undo quantization for the new row in lowlow band
		#if _DEQUANTIZE_IN_FSM
			llline3 = lowlow+2*lowlow_pitch;
		#else
			DequantizeBandRow16s(lowlow+2*lowlow_pitch, roi.width, lowlow_quantization, llline3);
		#endif

			temp = lhline1;
			lhline1 = lhline2;
			lhline2 = lhline3;
			lhline3 = temp;

			// Undo quantization for the new row in lowhigh band
		#if _DEQUANTIZE_IN_FSM
			lhline3 = lowhigh+2*lowhigh_pitch;
		#else
			DequantizeBandRow16s(lowhigh+2*lowhigh_pitch, roi.width, lowhigh_quantization, lhline3);
		#endif
		}
	}

	//_mm_empty();	// Clear the mmx register state

#if (1 && XMMOPT)
	// Need to advance the lowpass pointer if using SIMD instructions
	lowlow += lowlow_pitch;
	lowhigh += lowhigh_pitch;
#endif

	// Should have exited the loop at the last row
	assert(row == last_row);

	// Undo quantization for the highlow and highhigh bands
#if _DEQUANTIZE_IN_FSM
	hlline = highlow;
	hhline = highhigh;
#else
	DequantizeBandRow16s(highlow, roi.width, highlow_quantization, hlline);
	DequantizeBandRow16s(highhigh, roi.width, highhigh_quantization, hhline);
#endif

	// Apply the vertical border filter to the last row
	for (column = 0; column < roi.width; column++)
	{
		int32_t even = 0;		// Result of convolution with even filter
		int32_t odd = 0;		// Result of convolution with odd filter


		// Compute the vertical inverse for the left two bands //

		// Apply the even reconstruction filter to the lowpass band
		even += 5 * llline3[column];
		even += 4 * llline2[column];
		even -= 1 * llline1[column];
		even += ROUNDING(even,8);
		even = DivideByShift(even, 3);

		// Add the highpass correction
		even += hlline[column];
		even = DivideByShift(even, 1);

		// Place the even result in the even row
		even_lowpass[column] = SATURATE(even);

		// Apply the odd reconstruction filter to the lowpass band
		odd += 11 * llline3[column];
		odd -=  4 * llline2[column];
		odd +=  1 * llline1[column];
		odd += ROUNDING(odd,8);
		odd = DivideByShift(odd, 3);

		// Subtract the highpass correction
		odd -= hlline[column];
		odd = DivideByShift(odd, 1);

		// Place the odd result in the odd row
		odd_lowpass[column] = SATURATE(odd);


		// Compute the vertical inverse for the right two bands //

		even = 0;
		odd = 0;

		// Apply the even reconstruction filter to the lowpass band
		even += 5 * lhline3[column];
		even += 4 * lhline2[column];
		even -= 1 * lhline1[column];
		even += ROUNDING(even,8);
		even = DivideByShift(even, 3);

		// Add the highpass correction
		even += hhline[column];
		even = DivideByShift(even, 1);

		// Place the even result in the even row
		even_highpass[column] = SATURATE(even);

		// Apply the odd reconstruction filter to the lowpass band
		odd += 11 * lhline3[column];
		odd -=  4 * lhline2[column];
		odd +=  1 * lhline1[column];
		odd += ROUNDING(odd,8);
		odd = DivideByShift(odd, 3);

		// Subtract the highpass correction
		odd -= hhline[column];
		odd = DivideByShift(odd, 1);

		// Place the odd result in the odd row
		odd_highpass[column] = SATURATE(odd);
	}

	// Apply the inverse horizontal transform to the even and odd rows
	InvertHorizontalStrip16s(lowpass, lowpass_pitch,
							 highpass, highpass_pitch,
							 output, output_row_size, strip);
  }


#endif


#if _PROCESSOR_PENTIUM_4

  #if _PROCESSOR_DISPATCH
  __declspec(cpu_specific(Pentium_4))
  #endif

  void InvertSpatial16sTo16s(PIXEL16S *lowlow_band, int lowlow_pitch,
						  PIXEL16S *lowhigh_band, int lowhigh_pitch,
						  PIXEL16S *highlow_band, int highlow_pitch,
						  PIXEL16S *highhigh_band, int highhigh_pitch,
						  PIXEL16S *output_image, int output_pitch,
						  ROI roi, PIXEL *buffer, int quantization[],
						  PIXEL *line_buffer)
  {
	PIXEL16S *lowlow = lowlow_band;
	PIXEL16S *lowhigh = lowhigh_band;
	PIXEL16S *highlow = highlow_band;
	PIXEL16S *highhigh = highhigh_band;
	PIXEL16S *output = output_image;
	PIXEL *even_lowpass;
	PIXEL *even_highpass;
	PIXEL *odd_lowpass;
	PIXEL *odd_highpass;
	PIXEL *lowpass;					// Strip of horizontal coefficients
	PIXEL *highpass;
	int lowpass_pitch;				// Distance between strip rows in bytes
	int highpass_pitch;
	ROI strip;						// Dimensions of the processing strip
	size_t buffer_row_size;
	size_t output_row_size = output_pitch;
	int buffer_half_pitch;
	int buffer_width;
	int buffer_pitch;
	int last_row = roi.height - 1;
	int row, column;

	PIXEL *llline1;		// Dequantized lowlow band row 1
	PIXEL *llline2;		// Dequantized lowlow band row 2
	PIXEL *llline3;		// Dequantized lowlow band row 3
	PIXEL *lhline1;		// Dequantized lowhigh band row 1
	PIXEL *lhline2;		// Dequantized lowhigh band row 2
	PIXEL *lhline3;		// Dequantized lowhigh band row 3
	PIXEL *hlline;		// Dequantized highlow band row
	PIXEL *hhline;		// Dequantized highhigh band row
	PIXEL *temp;

	//int lowlow_quantization = quantization[LL_BAND];
	//int highlow_quantization = quantization[HL_BAND];
	//int lowhigh_quantization = quantization[LH_BAND];
	//int highhigh_quantization = quantization[HH_BAND];

	// Convert pitch from bytes to pixels
	lowlow_pitch /= sizeof(PIXEL16S);
	lowhigh_pitch /= sizeof(PIXEL16S);
	highlow_pitch /= sizeof(PIXEL16S);
	highhigh_pitch /= sizeof(PIXEL16S);
	output_pitch /= sizeof(PIXEL16S);

	// Compute positions within the temporary buffer for each row of horizontal lowpass
	// and highpass intermediate coefficients computed by the vertical inverse transform
	buffer_row_size = roi.width * sizeof(PIXEL);
	buffer_row_size = ALIGN16(buffer_row_size);
	buffer_half_pitch = (int)buffer_row_size/sizeof(PIXEL);
	buffer_pitch = 2 * buffer_half_pitch;
	buffer_width = roi.width;

	// Check that the buffer is large enough to hold four rows of highpass coefficients
	//assert(buffer_size >= (4 * buffer_row_size));

	// Set the dimensions of the processing strip
	strip.width = buffer_width;
	strip.height = 2;

	// Compute the positions of the even and odd rows of coefficients
	even_lowpass = &buffer[0];
	even_highpass = &buffer[buffer_half_pitch];
	odd_lowpass = &buffer[2 * buffer_half_pitch];
	odd_highpass = &buffer[3 * buffer_half_pitch];

	// Compute the positions of the dequantized highpass rows
	llline1 = line_buffer;
	llline2 = llline1 + lowlow_pitch;
	llline3 = llline2 + lowlow_pitch;
	lhline1 = llline3 + lowlow_pitch;
	lhline2 = lhline1 + lowhigh_pitch;
	lhline3 = lhline2 + lowhigh_pitch;
	hlline = lhline3 + lowhigh_pitch;
	hhline = hlline + highlow_pitch;

	// Pointers into the strip of horizontal coefficients
	lowpass = even_lowpass;
	highpass = even_highpass;
	lowpass_pitch = (int)(2 * buffer_row_size);
	highpass_pitch = (int)(2 * buffer_row_size);

	// Apply the vertical border filter to the first row
	row = 0;

	// Undo quantization
#if _DEQUANTIZE_IN_FSM
	llline1 = lowlow;
	llline2 = lowlow+lowlow_pitch;
	llline3 = lowlow+2*lowlow_pitch;

	lhline1 = lowhigh;
	lhline2 = lowhigh+lowhigh_pitch;
	lhline3 = lowhigh+2*lowhigh_pitch;

	hlline = highlow;
	hhline = highhigh;
#else
	DequantizeBandRow16s(lowlow, roi.width, lowlow_quantization, llline1);
	DequantizeBandRow16s(lowlow+lowlow_pitch, roi.width, lowlow_quantization, llline2);
	DequantizeBandRow16s(lowlow+2*lowlow_pitch, roi.width, lowlow_quantization, llline3);

	DequantizeBandRow16s(lowhigh, roi.width, lowhigh_quantization, lhline1);
	DequantizeBandRow16s(lowhigh+lowhigh_pitch, roi.width, lowhigh_quantization, lhline2);
	DequantizeBandRow16s(lowhigh+2*lowhigh_pitch, roi.width, lowhigh_quantization, lhline3);

	DequantizeBandRow16s(highlow, roi.width, highlow_quantization, hlline);
	DequantizeBandRow16s(highhigh, roi.width, highhigh_quantization, hhline);
#endif

	for (column = 0; column < roi.width; column++)
	{
		int32_t even = 0;		// Result of convolution with even filter
		int32_t odd = 0;		// Result of convolution with odd filter


		// Compute the vertical inverse for the left two bands //

		// Apply the even reconstruction filter to the lowpass band
		even += 11 * llline1[column];
		even -=  4 * llline2[column];
		even +=  1 * llline3[column];
		even += ROUNDING(even,8);
		even = DivideByShift(even, 3);

		// Add the highpass correction
		even += hlline[column];
		even = DivideByShift(even, 1);

		// Place the even result in the even row
		even_lowpass[column] = SATURATE(even);

		// Apply the odd reconstruction filter to the lowpass band
		odd += 5 * llline1[column];
		odd += 4 * llline2[column];
		odd -= 1 * llline3[column];
		odd += ROUNDING(odd,8);
		odd = DivideByShift(odd, 3);

		// Subtract the highpass correction
		odd -= hlline[column];
		odd = DivideByShift(odd, 1);

		// Place the odd result in the odd row
		odd_lowpass[column] = SATURATE(odd);


		// Compute the vertical inverse for the right two bands //

		even = 0;
		odd = 0;

		// Apply the even reconstruction filter to the lowpass band
		even += 11 * lhline1[column];
		even -=  4 * lhline2[column];
		even +=  1 * lhline3[column];
		even += ROUNDING(even,8);
		even = DivideByShift(even, 3);

		// Add the highpass correction
		even += hhline[column];
		even = DivideByShift(even, 1);

		// Place the even result in the even row
		even_highpass[column] = SATURATE(even);

		// Apply the odd reconstruction filter to the lowpass band
		odd += 5 * lhline1[column];
		odd += 4 * lhline2[column];
		odd -= 1 * lhline3[column];
		odd += ROUNDING(odd,8);
		odd = DivideByShift(odd, 3);

		// Subtract the highpass correction
		odd -= hhline[column];
		odd = DivideByShift(odd, 1);

		// Place the odd result in the odd row
		odd_highpass[column] = SATURATE(odd);
	}

	// Apply the inverse horizontal transform to the even and odd rows
	InvertHorizontalStrip16s(lowpass, lowpass_pitch,
							 highpass, highpass_pitch,
							 output, (int)output_row_size, strip);

	// Advance to the next pair of even and odd output rows
	output += 2 * output_pitch;

	// Do not advance the lowpass row pointers until after the fast loop
	//lowlow += lowlow_pitch;
	//lowhigh += lowhigh_pitch;

	// Always advance the highpass row pointers
	highlow += highlow_pitch;
	highhigh += highhigh_pitch;

	// Advance the row index
	row++;

	// Process the middle rows using the interior reconstruction filters
	for (; row < last_row; row++)
	{
#if (1 && XMMOPT)
		int column_step = 8;
		int post_column = roi.width - (roi.width % column_step);
		__m128i *even_lowpass_ptr = (__m128i *)even_lowpass;
		__m128i *even_highpass_ptr = (__m128i *)even_highpass;
		__m128i *odd_lowpass_ptr = (__m128i *)odd_lowpass;
		__m128i *odd_highpass_ptr = (__m128i *)odd_highpass;
		int quad_pitch;
#endif

		// Undo quantization to highpass bands
	#if _DEQUANTIZE_IN_FSM
		hlline = highlow;
		hhline = highhigh;
	#else
		DequantizeBandRow16s(highlow, roi.width, highlow_quantization, hlline);
		DequantizeBandRow16s(highhigh, roi.width, highhigh_quantization, hhline);
	#endif

		// Start at the first column
		column = 0;

#if (1 && XMMOPT)

		// Process groups of four coefficients along the row
		for (; column < post_column; column += column_step)
		{
			__m128i *lowlow_ptr1 = (__m128i *)&llline1[column];
			__m128i *lowlow_ptr2 = (__m128i *)&llline2[column];
			__m128i *lowlow_ptr3 = (__m128i *)&llline3[column];
			__m128i *highlow_ptr = (__m128i *)&hlline[column];
			__m128i *lowhigh_ptr1 = (__m128i *)&lhline1[column];
			__m128i *lowhigh_ptr2 = (__m128i *)&lhline2[column];
			__m128i *lowhigh_ptr3 = (__m128i *)&lhline3[column];
			__m128i *highhigh_ptr = (__m128i *)&hhline[column];
			__m128i quad_epi16;
			__m128i even_epi16;
			__m128i odd_epi16;


			// Compute the vertical inverse for the left two bands //

			// Set the pitch for the lowpass band used in this section of code
			quad_pitch = (lowlow_pitch * sizeof(PIXEL))/sizeof(__m128i);

			// Accumulate parallel sums for the even and odd filters
			quad_epi16 = _mm_load_si128(lowlow_ptr1);	// Get four lowpass coefficients
			//lowlow_ptr += quad_pitch;					// Advance to the next row

			even_epi16 = quad_epi16;
			odd_epi16 = _mm_setzero_si128();
			odd_epi16 = _mm_subs_epi16(odd_epi16, quad_epi16);

			quad_epi16 = _mm_load_si128(lowlow_ptr2);	// Get four lowpass coefficients
			//lowlow_ptr += quad_pitch;					// Advance to the next row

			// Multiply the lowpass coefficients by eight
			quad_epi16 = _mm_slli_epi16(quad_epi16, 3);

			even_epi16 = _mm_adds_epi16(even_epi16, quad_epi16);
			odd_epi16 = _mm_adds_epi16(odd_epi16, quad_epi16);

			quad_epi16 = _mm_load_si128(lowlow_ptr3);	// Get four lowpass coefficients

			even_epi16 = _mm_subs_epi16(even_epi16, quad_epi16);
			odd_epi16 = _mm_adds_epi16(odd_epi16, quad_epi16);

			// Apply the rounding adjustment
			even_epi16 = _mm_adds_epi16(even_epi16, _mm_set1_epi16(4));
			// Divide by eight
			even_epi16 = _mm_srai_epi16(even_epi16, 3);

			// Apply the rounding adjustment
			odd_epi16 = _mm_adds_epi16(odd_epi16, _mm_set1_epi16(4));
			// Divide by eight
			odd_epi16 = _mm_srai_epi16(odd_epi16, 3);

			// Add the highpass correction to the even result and divide by two
			quad_epi16 = _mm_load_si128(highlow_ptr);
			even_epi16 = _mm_adds_epi16(even_epi16, quad_epi16);
			even_epi16 = _mm_srai_epi16(even_epi16, 1);

			// Subtract the highpass correction from the odd result and divide by two
			odd_epi16 = _mm_subs_epi16(odd_epi16, quad_epi16);
			odd_epi16 = _mm_srai_epi16(odd_epi16, 1);

			// Store the even and odd groups of horizontal lowpass coefficients
			_mm_store_si128(even_lowpass_ptr++, even_epi16);
			_mm_store_si128(odd_lowpass_ptr++, odd_epi16);


			// Compute the vertical inverse for the right two bands //

			// Set the pitch for the lowpass band used in this section of code
			quad_pitch = (lowhigh_pitch * sizeof(PIXEL))/sizeof(__m128i);

			// Accumulate parallel sums for the even and odd filters

			quad_epi16 = _mm_load_si128(lowhigh_ptr1);	// Get four lowpass coefficients
			//lowhigh_ptr += quad_pitch;				// Advance to the next row

			even_epi16 = quad_epi16;
			odd_epi16 = _mm_setzero_si128();
			odd_epi16 = _mm_subs_epi16(odd_epi16, quad_epi16);

			quad_epi16 = _mm_load_si128(lowhigh_ptr2);	// Get four lowpass coefficients
			//lowhigh_ptr += quad_pitch;				// Advance to the next row

			// Multiply the lowpass coefficients by eight
			quad_epi16 = _mm_slli_epi16(quad_epi16, 3);

			even_epi16 = _mm_adds_epi16(even_epi16, quad_epi16);
			odd_epi16 = _mm_adds_epi16(odd_epi16, quad_epi16);

			quad_epi16 = _mm_load_si128(lowhigh_ptr3);	// Get four lowpass coefficients

			even_epi16 = _mm_subs_epi16(even_epi16, quad_epi16);
			odd_epi16 = _mm_adds_epi16(odd_epi16, quad_epi16);

			// Apply the rounding adjustment
			even_epi16 = _mm_adds_epi16(even_epi16, _mm_set1_epi16(4));
			// Divide by eight
			even_epi16 = _mm_srai_epi16(even_epi16, 3);

			// Apply the rounding adjustment
			odd_epi16 = _mm_adds_epi16(odd_epi16, _mm_set1_epi16(4));
			// Divide by eight
			odd_epi16 = _mm_srai_epi16(odd_epi16, 3);

			// Add the highpass correction to the even result and divide by two
			quad_epi16 = _mm_load_si128(highhigh_ptr);
			even_epi16 = _mm_adds_epi16(even_epi16, quad_epi16);
			even_epi16 = _mm_srai_epi16(even_epi16, 1);

			// Subtract the highpass correction from the odd result and divide by two
			odd_epi16 = _mm_subs_epi16(odd_epi16, quad_epi16);
			odd_epi16 = _mm_srai_epi16(odd_epi16, 1);

			// Store the even and odd groups of horizontal highpass coefficients
			_mm_store_si128(even_highpass_ptr++, even_epi16);
			_mm_store_si128(odd_highpass_ptr++, odd_epi16);
		}

		// Should have exited the loop at the post processing column
		assert(column == post_column);

#endif

		// Process the rest of the row
		for (; column < roi.width; column++)
		{
			int32_t even = 0;		// Result of convolution with even filter
			int32_t odd = 0;		// Result of convolution with odd filter


			// Compute the vertical inverse for the left two bands //

			// Apply the even reconstruction filter to the lowpass band
			even += llline1[column];
			even -= llline3[column];
			even += ROUNDING(even,8);
			even = DivideByShift(even, 3);
			even += llline2[column];

			// Add the highpass correction
			even += hlline[column];
			even = DivideByShift(even, 1);

			// Place the even result in the even row
			even_lowpass[column] = SATURATE(even);

			// Apply the odd reconstruction filter to the lowpass band
			odd -= llline1[column];
			odd += llline3[column];
			odd += ROUNDING(odd,8);
			odd = DivideByShift(odd, 3);
			odd += llline2[column];

			// Subtract the highpass correction
			odd -= hlline[column];
			odd = DivideByShift(odd, 1);

			// Place the odd result in the odd row
			odd_lowpass[column] = SATURATE(odd);


			// Compute the vertical inverse for the right two bands //

			even = 0;
			odd = 0;

			// Apply the even reconstruction filter to the lowpass band
			even += lhline1[column];
			even -= lhline3[column];
			even += ROUNDING(even,8);
			even = DivideByShift(even, 3);
			even += lhline2[column];

			// Add the highpass correction
			even += hhline[column];
			even = DivideByShift(even, 1);

			// Place the even result in the even row
			even_highpass[column] = SATURATE(even);

			// Apply the odd reconstruction filter to the lowpass band
			odd -= lhline1[column];
			odd += lhline3[column];
			odd += ROUNDING(odd,8);
			odd = DivideByShift(odd, 3);
			odd += lhline2[column];

			// Subtract the highpass correction
			odd -= hhline[column];
			odd = DivideByShift(odd, 1);

			// Place the odd result in the odd row
			odd_highpass[column] = SATURATE(odd);
		}

		// Apply the inverse horizontal transform to the even and odd rows
		InvertHorizontalStrip16s(lowpass, lowpass_pitch,
								 highpass, highpass_pitch,
								 output, (int)output_row_size, strip);

		// Advance to the next input rows and skip the next output row
		lowlow += lowlow_pitch;
		lowhigh += lowhigh_pitch;
		highlow += highlow_pitch;
		highhigh += highhigh_pitch;
		output += 2 * output_pitch;

		if (row < last_row - 1) {
			temp = llline1;
			llline1 = llline2;
			llline2 = llline3;
			llline3 = temp;

			// Undo quantization for the new row in lowlow band
		#if _DEQUANTIZE_IN_FSM
			llline3 = lowlow+2*lowlow_pitch;
		#else
			DequantizeBandRow16s(lowlow+2*lowlow_pitch, roi.width, lowlow_quantization, llline3);
		#endif

			temp = lhline1;
			lhline1 = lhline2;
			lhline2 = lhline3;
			lhline3 = temp;

			// Undo quantization for the new row in lowhigh band
		#if _DEQUANTIZE_IN_FSM
			lhline3 = lowhigh+2*lowhigh_pitch;
		#else
			DequantizeBandRow16s(lowhigh+2*lowhigh_pitch, roi.width, lowhigh_quantization, lhline3);
		#endif
		}
	}

	//_mm_empty();	// Clear the mmx register state

#if (1 && XMMOPT)
	// Need to advance the lowpass pointer if using SIMD instructions
	lowlow += lowlow_pitch;
	lowhigh += lowhigh_pitch;
#endif

	// Should have exited the loop at the last row
	assert(row == last_row);

	// Undo quantization for the highlow and highhigh bands
#if _DEQUANTIZE_IN_FSM
	hlline = highlow;
	hhline = highhigh;
#else
	DequantizeBandRow16s(highlow, roi.width, highlow_quantization, hlline);
	DequantizeBandRow16s(highhigh, roi.width, highhigh_quantization, hhline);
#endif

	// Apply the vertical border filter to the last row
	for (column = 0; column < roi.width; column++)
	{
		int32_t even = 0;		// Result of convolution with even filter
		int32_t odd = 0;		// Result of convolution with odd filter


		// Compute the vertical inverse for the left two bands //

		// Apply the even reconstruction filter to the lowpass band
		even += 5 * llline3[column];
		even += 4 * llline2[column];
		even -= 1 * llline1[column];
		even += ROUNDING(even,8);
		even = DivideByShift(even, 3);

		// Add the highpass correction
		even += hlline[column];
		even = DivideByShift(even, 1);

		// Place the even result in the even row
		even_lowpass[column] = SATURATE(even);

		// Apply the odd reconstruction filter to the lowpass band
		odd += 11 * llline3[column];
		odd -=  4 * llline2[column];
		odd +=  1 * llline1[column];
		odd += ROUNDING(odd,8);
		odd = DivideByShift(odd, 3);

		// Subtract the highpass correction
		odd -= hlline[column];
		odd = DivideByShift(odd, 1);

		// Place the odd result in the odd row
		odd_lowpass[column] = SATURATE(odd);


		// Compute the vertical inverse for the right two bands //

		even = 0;
		odd = 0;

		// Apply the even reconstruction filter to the lowpass band
		even += 5 * lhline3[column];
		even += 4 * lhline2[column];
		even -= 1 * lhline1[column];
		even += ROUNDING(even,8);
		even = DivideByShift(even, 3);

		// Add the highpass correction
		even += hhline[column];
		even = DivideByShift(even, 1);

		// Place the even result in the even row
		even_highpass[column] = SATURATE(even);

		// Apply the odd reconstruction filter to the lowpass band
		odd += 11 * lhline3[column];
		odd -=  4 * lhline2[column];
		odd +=  1 * lhline1[column];
		odd += ROUNDING(odd,8);
		odd = DivideByShift(odd, 3);

		// Subtract the highpass correction
		odd -= hhline[column];
		odd = DivideByShift(odd, 1);

		// Place the odd result in the odd row
		odd_highpass[column] = SATURATE(odd);
	}

	// Apply the inverse horizontal transform to the even and odd rows
	InvertHorizontalStrip16s(lowpass, lowpass_pitch,
							 highpass, highpass_pitch,
							 output, (int)output_row_size, strip);
  }
#endif //P4 InvertSpatial16sTo16s

#if 1

// Slow version of InvertHorizontalStrip8s (the MMX instructions are not used)

// Apply the inverse horizontal transform to reconstruct a strip of rows
void InvertHorizontalStrip8s(PIXEL8S *lowpass_band,	// Horizontal lowpass coefficients
						 	 int lowpass_pitch,		// Distance between rows in bytes
							 PIXEL8S *highpass_band,// Horizontal highpass coefficients
							 int highpass_pitch,	// Distance between rows in bytes
							 PIXEL8S *output_image,	// Row of reconstructed results
							 int output_pitch,		// Distance between rows in bytes
							 ROI roi)			// Height and width of the strip
{
	int row, column;
	PIXEL8S *lowpass = lowpass_band;
	PIXEL8S *highpass = highpass_band;
	PIXEL8S *output = output_image;

	// Convert the pitch to units of pixels
	lowpass_pitch /= sizeof(PIXEL8S);
	highpass_pitch /= sizeof(PIXEL8S);
	output_pitch /= sizeof(PIXEL8S);

	for (row = 0; row < roi.height; row++)
	{
		PIXEL8S *outptr = output;
		const int column_step = 1;
		int last_column = roi.width - column_step;
		int32_t even;
		int32_t odd;

		column = 0;

		// Process the first two output points with special filters for the left border
		even = 0;
		odd = 0;

		// Apply the even reconstruction filter to the lowpass band
		even += 11 * lowpass[column + 0];
		even -=  4 * lowpass[column + 1];
		even +=  1 * lowpass[column + 2];
		even += ROUNDING(even,8);
		even = DivideByShift(even, 3);

		// Add the highpass correction
		even += highpass[column];
		even = DivideByShift(even, 1);

		// Place the even result in the even column
		*(outptr++) = SATURATE_8S(even);

		// Apply the odd reconstruction filter to the lowpass band
		odd += 5 * lowpass[column + 0];
		odd += 4 * lowpass[column + 1];
		odd -= 1 * lowpass[column + 2];
		odd += ROUNDING(odd,8);
		odd = DivideByShift(odd, 3);

		// Subtract the highpass correction
		odd -= highpass[column];
		odd = DivideByShift(odd, 1);

		// Place the odd result in the odd column
		*(outptr++) = SATURATE_8S(odd);

		column++;

		for (; column < last_column; column += column_step)
		{
			int32_t even = 0;		// Result of convolution with even filter
			int32_t odd = 0;		// Result of convolution with odd filter

			// Apply the even reconstruction filter to the lowpass band
			even += lowpass[column - 1];
			even -= lowpass[column + 1];
			even += ROUNDING(even,8);
			even = DivideByShift(even, 3);
			even += lowpass[column + 0];

			// Add the highpass correction
			even += highpass[column];
			even = DivideByShift(even, 1);

			// Place the even result in the even column
			*(outptr++) = SATURATE_8S(even);

			// Apply the odd reconstruction filter to the lowpass band
			odd -= lowpass[column - 1];
			odd += lowpass[column + 1];
			odd += ROUNDING(odd,8);
			odd = DivideByShift(odd, 3);
			odd += lowpass[column + 0];

			// Subtract the highpass correction
			odd -= highpass[column];
			odd = DivideByShift(odd, 1);

			// Place the odd result in the odd column
			*(outptr++) = SATURATE_8S(odd);
		}

		// Should have exited the loop with the column equal to the last column
		assert(column == last_column);

		// Process the last two output points with special filters for the right border
		even = 0;
		odd = 0;

		// Apply the even reconstruction filter to the lowpass band
		even += 5 * lowpass[column + 0];
		even += 4 * lowpass[column - 1];
		even -= 1 * lowpass[column - 2];
		even += ROUNDING(even,8);
		even = DivideByShift(even, 3);

		// Add the highpass correction
		even += highpass[column];
		even = DivideByShift(even, 1);

		// Place the even result in the even column
		*(outptr++) = SATURATE_8S(even);

		// Apply the odd reconstruction filter to the lowpass band
		odd += 11 * lowpass[column + 0];
		odd -=  4 * lowpass[column - 1];
		odd +=  1 * lowpass[column - 2];
		odd += ROUNDING(odd,8);
		odd = DivideByShift(odd, 3);

		// Subtract the highpass correction
		odd -= highpass[column];
		odd = DivideByShift(odd, 1);

		// Place the odd result in the odd column
		*(outptr++) = SATURATE_8S(odd);

		// Advance to the next row
		lowpass += lowpass_pitch;
		highpass += highpass_pitch;
		output += output_pitch;
	}
}
#endif






// Apply the inverse spatial filter to the top row and pack the results into 8-bit YUV
void
InvertSpatialTopRow16sToPackedYUV8u(PIXEL *lowlow_band[], int lowlow_band_pitch[],
									PIXEL *lowhigh_band[], int lowhigh_band_pitch[],
									PIXEL *highlow_band[], int highlow_band_pitch[],
									PIXEL *highhigh_band[], int highhigh_band_pitch[],
									uint8_t *output, int output_pitch, int output_width,
									int format, int row, int luma_band_width,
									PIXEL *buffer, size_t buffer_size, int precision)
{
	int num_channels = CODEC_NUM_CHANNELS;

	PIXEL *even_lowpass[CODEC_MAX_CHANNELS];
	PIXEL *even_highpass[CODEC_MAX_CHANNELS];
	PIXEL *odd_lowpass[CODEC_MAX_CHANNELS];
	PIXEL *odd_highpass[CODEC_MAX_CHANNELS];

	// Distance between strip rows in bytes
	int lowpass_pitch[CODEC_MAX_CHANNELS];
	int highpass_pitch[CODEC_MAX_CHANNELS];

	size_t output_row_size = output_pitch;

	// Set the dimensions of the processing strip
	ROI strip = {luma_band_width, 2};

	int channel;

	// Compute pointers into the buffers for temporary results
	for (channel = 0; channel < num_channels; channel++)
	{
		size_t buffer_row_size;
		int buffer_half_pitch;
		//int buffer_width;
		int buffer_pitch;

		int width = luma_band_width;

		// Compute positions within the temporary buffer for each row of horizontal lowpass
		// and highpass intermediate coefficients computed by the vertical inverse transform
		buffer_row_size = width * sizeof(PIXEL);
		buffer_row_size = ALIGN16(buffer_row_size);
		buffer_half_pitch = (int)buffer_row_size/sizeof(PIXEL);
		buffer_pitch = 2 * buffer_half_pitch;
		//buffer_width = width;

		// Check that the buffer is large enough to hold four rows of coefficients
		assert(buffer_size >= (4 * buffer_row_size));

		// Compute the positions of the even and odd rows of coefficients
		even_lowpass[channel] = &buffer[0];
		even_highpass[channel] = &buffer[buffer_half_pitch];
		odd_lowpass[channel] = &buffer[2 * buffer_half_pitch];
		odd_highpass[channel] = &buffer[3 * buffer_half_pitch];

		// Pointers into the strip of horizontal coefficients
		lowpass_pitch[channel] = (int)(2 * buffer_row_size);
		highpass_pitch[channel] = (int)(2 * buffer_row_size);

		buffer = &buffer[4 * buffer_half_pitch];
		buffer_size -= 4 * buffer_row_size;
	}

	// This routine should be called for the first row
	assert(row == 0);

	for (channel = 0; channel < num_channels; channel++)
	{
		PIXEL *lowlow = lowlow_band[channel];
		PIXEL *lowhigh = lowhigh_band[channel];
		PIXEL *highlow = highlow_band[channel];
		PIXEL *highhigh = highhigh_band[channel];

		// Convert pitch from bytes to pixels
		int lowlow_pitch = lowlow_band_pitch[channel] / sizeof(PIXEL);
		int lowhigh_pitch = lowhigh_band_pitch[channel] / sizeof(PIXEL);
		//int highlow_pitch = highlow_band_pitch[channel] / sizeof(PIXEL);
		//int highhigh_pitch = highhigh_band_pitch[channel] / sizeof(PIXEL);

		int width = luma_band_width;

		// Start at the first column
		int column = 0;

		// Apply the vertical border filter to the first row
		for (; column < width; column++)
		{
			int32_t even = 0;		// Result of convolution with even filter
			int32_t odd = 0;		// Result of convolution with odd filter


			/***** Compute the vertical inverse for the left two bands *****/

			// Apply the even reconstruction filter to the lowpass band
			even += 11 * lowlow[column + 0 * lowlow_pitch];
			even -=  4 * lowlow[column + 1 * lowlow_pitch];
			even +=  1 * lowlow[column + 2 * lowlow_pitch];
			even += ROUNDING(even,8);
			even = DivideByShift(even, 3);

			// Add the highpass correction
			even += highlow[column];
			even = DivideByShift(even, 1);

			// Place the even result in the even row
			even_lowpass[channel][column] = SATURATE(even);

			// Apply the odd reconstruction filter to the lowpass band
			odd += 5 * lowlow[column + 0 * lowlow_pitch];
			odd += 4 * lowlow[column + 1 * lowlow_pitch];
			odd -= 1 * lowlow[column + 2 * lowlow_pitch];
			odd += ROUNDING(odd,8);
			odd = DivideByShift(odd, 3);

			// Subtract the highpass correction
			odd -= highlow[column];
			odd = DivideByShift(odd, 1);

			// Place the odd result in the odd row
			odd_lowpass[channel][column] = SATURATE(odd);


			/***** Compute the vertical inverse for the right two bands *****/

			even = 0;
			odd = 0;

			// Apply the even reconstruction filter to the lowpass band
			even += 11 * lowhigh[column + 0 * lowhigh_pitch];
			even -=  4 * lowhigh[column + 1 * lowhigh_pitch];
			even +=  1 * lowhigh[column + 2 * lowhigh_pitch];
			even += ROUNDING(even,8);
			even = DivideByShift(even, 3);

			// Add the highpass correction
			even += highhigh[column];
			even = DivideByShift(even, 1);

			// Place the even result in the even row
			even_highpass[channel][column] = SATURATE(even);

			// Apply the odd reconstruction filter to the lowpass band
			odd += 5 * lowhigh[column + 0 * lowhigh_pitch];
			odd += 4 * lowhigh[column + 1 * lowhigh_pitch];
			odd -= 1 * lowhigh[column + 2 * lowhigh_pitch];
			odd += ROUNDING(odd,8);
			odd = DivideByShift(odd, 3);

			// Subtract the highpass correction
			odd -= highhigh[column];
			odd = DivideByShift(odd, 1);

			// Place the odd result in the odd row
			odd_highpass[channel][column] = SATURATE(odd);
		}
	}

	// Apply the inverse horizontal transform to the even and odd rows
	InvertHorizontalStripRGB16sToPackedYUV8u(even_lowpass, lowpass_pitch,
											 even_highpass, highpass_pitch,
											 output, (int)output_row_size, strip,
											 precision);
}



// Apply the inverse spatial filter to the bottom row and pack the results into 8-bit YUV
void
InvertSpatialBottomRow16sToPackedYUV8u(PIXEL *lowlow_band[], int lowlow_band_pitch[],
									   PIXEL *lowhigh_band[], int lowhigh_band_pitch[],
									   PIXEL *highlow_band[], int highlow_band_pitch[],
									   PIXEL *highhigh_band[], int highhigh_band_pitch[],
									   uint8_t *output, int output_pitch, int output_width,
									   int format, int row, int luma_band_width,
									   PIXEL *buffer, size_t buffer_size, int precision)
{
	int num_channels = CODEC_NUM_CHANNELS;

	PIXEL *even_lowpass[CODEC_MAX_CHANNELS];
	PIXEL *even_highpass[CODEC_MAX_CHANNELS];
	PIXEL *odd_lowpass[CODEC_MAX_CHANNELS];
	PIXEL *odd_highpass[CODEC_MAX_CHANNELS];

	// Distance between strip rows in bytes
	int lowpass_pitch[CODEC_MAX_CHANNELS];
	int highpass_pitch[CODEC_MAX_CHANNELS];

	size_t output_row_size = output_pitch;

	// Set the dimensions of the processing strip
	ROI strip = {luma_band_width, 2};

	int channel;

	// Compute pointers into the buffers for temporary results
	for (channel = 0; channel < num_channels; channel++)
	{
		size_t buffer_row_size;
		int buffer_half_pitch;
		//int buffer_width;
		int buffer_pitch;

		int width = luma_band_width;

		// Compute positions within the temporary buffer for each row of horizontal lowpass
		// and highpass intermediate coefficients computed by the vertical inverse transform
		buffer_row_size = width * sizeof(PIXEL);
		buffer_row_size = ALIGN16(buffer_row_size);
		buffer_half_pitch = (int)buffer_row_size/sizeof(PIXEL);
		buffer_pitch = 2 * buffer_half_pitch;
		//buffer_width = width;

		// Check that the buffer is large enough to hold four rows of coefficients
		assert(buffer_size >= (4 * buffer_row_size));

		// Compute the positions of the even and odd rows of coefficients
		even_lowpass[channel] = &buffer[0];
		even_highpass[channel] = &buffer[buffer_half_pitch];
		odd_lowpass[channel] = &buffer[2 * buffer_half_pitch];
		odd_highpass[channel] = &buffer[3 * buffer_half_pitch];

		// Pointers into the strip of horizontal coefficients
		lowpass_pitch[channel] = (int)(2 * buffer_row_size);
		highpass_pitch[channel] = (int)(2 * buffer_row_size);

		buffer = &buffer[4 * buffer_half_pitch];
		buffer_size -= 4 * buffer_row_size;
	}

	for (channel = 0; channel < num_channels; channel++)
	{
		PIXEL *lowlow = lowlow_band[channel];
		PIXEL *lowhigh = lowhigh_band[channel];
		PIXEL *highlow = highlow_band[channel];
		PIXEL *highhigh = highhigh_band[channel];

		// Convert pitch from bytes to pixels
		int lowlow_pitch = lowlow_band_pitch[channel] / sizeof(PIXEL);
		int lowhigh_pitch = lowhigh_band_pitch[channel] / sizeof(PIXEL);
		int highlow_pitch = highlow_band_pitch[channel] / sizeof(PIXEL);
		int highhigh_pitch = highhigh_band_pitch[channel] / sizeof(PIXEL);

		int width = luma_band_width;

		// Start at the first column
		int column = 0;

		// Compute the address of the first row for processing in each wavelet band
		lowlow += row * lowlow_pitch;
		lowhigh += row * lowhigh_pitch;
		highlow += row * highlow_pitch;
		highhigh += row * highhigh_pitch;

		// Apply the vertical border filter to the last row
		for (column = 0; column < width; column++)
		{
			int32_t even = 0;		// Result of convolution with even filter
			int32_t odd = 0;		// Result of convolution with odd filter


			// Compute the vertical inverse for the left two bands //

			// Apply the even reconstruction filter to the lowpass band
			even += 5 * lowlow[column + 0 * lowlow_pitch];
			even += 4 * lowlow[column - 1 * lowlow_pitch];
			even -= 1 * lowlow[column - 2 * lowlow_pitch];
			even += ROUNDING(even,8);
			even = DivideByShift(even, 3);

			// Add the highpass correction
			even += highlow[column];
			even = DivideByShift(even, 1);

			// Place the even result in the even row
			even_lowpass[channel][column] = SATURATE(even);

			// Apply the odd reconstruction filter to the lowpass band
			odd += 11 * lowlow[column + 0 * lowlow_pitch];
			odd -=  4 * lowlow[column - 1 * lowlow_pitch];
			odd +=  1 * lowlow[column - 2 * lowlow_pitch];
			odd += ROUNDING(odd,8);
			odd = DivideByShift(odd, 3);

			// Subtract the highpass correction
			odd -= highlow[column];
			odd = DivideByShift(odd, 1);

			// Place the odd result in the odd row
			odd_lowpass[channel][column] = SATURATE(odd);


			// Compute the vertical inverse for the right two bands //

			even = 0;
			odd = 0;

			// Apply the even reconstruction filter to the lowpass band
			even += 5 * lowhigh[column + 0 * lowhigh_pitch];
			even += 4 * lowhigh[column - 1 * lowhigh_pitch];
			even -= 1 * lowhigh[column - 2 * lowhigh_pitch];
			even += ROUNDING(even,8);
			even = DivideByShift(even, 3);

			// Add the highpass correction
			even += highhigh[column];
			even = DivideByShift(even, 1);

			// Place the even result in the even row
			even_highpass[channel][column] = SATURATE(even);

			// Apply the odd reconstruction filter to the lowpass band
			odd += 11 * lowhigh[column + 0 * lowhigh_pitch];
			odd -=  4 * lowhigh[column - 1 * lowhigh_pitch];
			odd +=  1 * lowhigh[column - 2 * lowhigh_pitch];
			odd += ROUNDING(odd,8);
			odd = DivideByShift(odd, 3);

			// Subtract the highpass correction
			odd -= highhigh[column];
			odd = DivideByShift(odd, 1);

			// Place the odd result in the odd row
			odd_highpass[channel][column] = SATURATE(odd);
		}
	}

	// Apply the inverse horizontal transform to the even and odd rows
	InvertHorizontalStripRGB16sToPackedYUV8u(even_lowpass, lowpass_pitch,
											 even_highpass, highpass_pitch,
											 output, (int)output_row_size, strip,
											 precision);
}

// Adapted from InvertHorizontalStrip16sRGB2YUV
void InvertHorizontalStripRGB16sToPackedYUV8u(PIXEL *lowpass_band[],	// Horizontal lowpass coefficients
										 int lowpass_pitch[],		// Distance between rows in bytes
										 PIXEL *highpass_band[],	// Horizontal highpass coefficients
										 int highpass_pitch[],	// Distance between rows in bytes
										 uint8_t *output_image,		// Row of reconstructed results
										 int output_pitch,		// Distance between rows in bytes
										 ROI roi,					// Height and width of the strip
										 int precision)			// Precision of the original video
{
	int num_channels = CODEC_NUM_CHANNELS;
	int height = roi.height;
	int width = roi.width;

	// Note that the u and v chroma values are swapped
	PIXEL *gg_lowpass_ptr = lowpass_band[0];
	PIXEL *rg_lowpass_ptr = lowpass_band[1];
	PIXEL *bg_lowpass_ptr = lowpass_band[2];
	PIXEL *gg_highpass_ptr = highpass_band[0];
	PIXEL *rg_highpass_ptr = highpass_band[1];
	PIXEL *bg_highpass_ptr = highpass_band[2];

	uint8_t *output = output_image;

	// Process 8 luma coefficients per loop iteration
	const int column_step = 8;

	// Need to process two luma coefficients up to the last column to allow for chroma output
	const int last_column = width;
	int post_column = last_column - (last_column % column_step);

	// Need at least four luma values of border processing up to the last column
	//const int post_border = 2;

	int channel;
	int row;

	// Compute the amount of scaling required to reduce the output precision
	int descale_shift = (precision - 8);

	int shift = 8;
	float scale;

	float fy_rmult,fy_gmult,fy_bmult,fy_offset;
	float fu_rmult,fu_gmult,fu_bmult,fu_offset;
	float fv_rmult,fv_gmult,fv_bmult,fv_offset;

	int color_space = COLOR_SPACE_BT_709; // This code is not active, should be  decoder->frame.colorspace;

	const float rgb2yuv709[3][4] =
	{
        {0.183f, 0.614f, 0.062f, 16.0f/255.0f},
        {-0.101f,-0.338f, 0.439f, 128.0f/255.0f},
        {0.439f,-0.399f,-0.040f, 128.0f/255.0f}
	};
	const float rgb2yuv601[3][4] =
	{
        {0.257f, 0.504f, 0.098f, 16.0f/255.0f},
        {-0.148f,-0.291f, 0.439f, 128.0f/255.0f},
        {0.439f,-0.368f,-0.071f, 128.0f/255.0f}
	};
	const float rgb2yuvVS601[3][4] =
	{
        {0.299f,0.587f,0.114f, 0},
        {-0.172f,-0.339f,0.511f,128.0f/255.0f},
        {0.511f,-0.428f,-0.083f,128.0f/255.0f}
	};
	const float rgb2yuvVS709[3][4] =
	{
        {0.213f,0.715f,0.072f, 0},
        {-0.117f,-0.394f,0.511f,128.0f/255.0f},
        {0.511f,-0.464f,-0.047f,128.0f/255.0f}
	};
	float rgb2yuv[3][4];
	//int yoffset = 16;

	switch(color_space & COLORSPACE_MASK)
	{
	case COLOR_SPACE_CG_601:
		memcpy(rgb2yuv, rgb2yuv601, 12*sizeof(float));
		break;
	default: assert(0);
	case COLOR_SPACE_CG_709:
		memcpy(rgb2yuv, rgb2yuv709, 12*sizeof(float));
		break;
	case COLOR_SPACE_VS_601:
		memcpy(rgb2yuv, rgb2yuvVS601, 12*sizeof(float));
		break;
	case COLOR_SPACE_VS_709:
		memcpy(rgb2yuv, rgb2yuvVS709, 12*sizeof(float));
		break;
	}

	//_mm_empty();

	scale = 64.0;

	fy_rmult = ((rgb2yuv[0][0]) * scale);
	fy_gmult = ((rgb2yuv[0][1]) * scale);
	fy_bmult = ((rgb2yuv[0][2]) * scale);
	fy_offset= ((rgb2yuv[0][3]) * 16384.0f);

	fu_rmult = ((rgb2yuv[1][0]) * scale);
	fu_gmult = ((rgb2yuv[1][1]) * scale);
	fu_bmult = ((rgb2yuv[1][2]) * scale);
	fu_offset= ((rgb2yuv[1][3]) * 16384.0f);

	fv_rmult = ((rgb2yuv[2][0]) * scale);
	fv_gmult = ((rgb2yuv[2][1]) * scale);
	fv_bmult = ((rgb2yuv[2][2]) * scale);
	fv_offset= ((rgb2yuv[2][3]) * 16384.0f);

	shift-=2;


	// Convert the pitch to units of pixels
	for (channel = 0; channel < num_channels; channel++)
	{
		lowpass_pitch[channel] /= sizeof(PIXEL);
		highpass_pitch[channel] /= sizeof(PIXEL);
	}

	output_pitch /= sizeof(uint8_t);

	// Adjust the end of the fast loop if necessary for border processing
	//if (post_column > (last_column - post_border))  // DAN08112004 - ignore end row calc -- use SSE to edge.
	//	post_column -= column_step;

	// Check that there is enough margin to accommodate border processing
//	assert(post_column <= (last_column - post_border));

	// Process each row of the strip
	for (row = 0; row < height; row++)
	{
#if (1 && XMMOPT)
		__m128i gg_low1_epi16;		// Lowpass coefficients
		__m128i gg_low2_epi16;
		__m128i bg_low1_epi16;
		__m128i bg_low2_epi16;
		__m128i rg_low1_epi16;
		__m128i rg_low2_epi16;

		__m128i gg_high1_epi16;		// Highpass coefficients
		__m128i gg_high2_epi16;
		__m128i bg_high1_epi16;
		__m128i bg_high2_epi16;
		__m128i rg_high1_epi16;
		__m128i rg_high2_epi16;

		// The fast loop merges values from different phases to allow aligned stores
		__m128i *outptr = (__m128i *)&output[0];

		const __m128i mask_epi32 = _mm_set1_epi32(0xffff);

		__m128i limiterRGB = _mm_set1_epi16(0x7fff - 0x00ff);
		__m128i limiter = _mm_set1_epi16(0x7fff - 0x3fff);

#endif
		uint8_t *colptr = (uint8_t *)&output[0];

		int32_t gg_even_value;
		int32_t bg_even_value;
		int32_t rg_even_value;
		int32_t gg_odd_value;
		int32_t bg_odd_value;
		int32_t rg_odd_value;


		// Start processing at the beginning of the row
		int column = 0;

		// Process the first two luma output points with special filters for the left border
		int32_t even = 0;
		int32_t odd = 0;


		__m128i rounding1_pi16 = _mm_set1_epi16(0); // for 6bit matm
		__m128i rounding2_pi16 = _mm_set1_epi16(0); // for 6bit matm

		if(descale_shift>=2)
		{
			int mask = (1<<(descale_shift-1))-1;
			rounding1_pi16 = _mm_insert_epi16(rounding1_pi16, rand()&mask, 0);
			rounding1_pi16 = _mm_insert_epi16(rounding1_pi16, rand()&mask, 1);
			rounding1_pi16 = _mm_insert_epi16(rounding1_pi16, rand()&mask, 2);
			rounding1_pi16 = _mm_insert_epi16(rounding1_pi16, rand()&mask, 3);
			rounding1_pi16 = _mm_insert_epi16(rounding1_pi16, rand()&mask, 4);
			rounding1_pi16 = _mm_insert_epi16(rounding1_pi16, rand()&mask, 5);
			rounding1_pi16 = _mm_insert_epi16(rounding1_pi16, rand()&mask, 6);
			rounding1_pi16 = _mm_insert_epi16(rounding1_pi16, rand()&mask, 7);

			rounding2_pi16 = _mm_insert_epi16(rounding2_pi16, rand()&mask, 0);
			rounding2_pi16 = _mm_insert_epi16(rounding2_pi16, rand()&mask, 1);
			rounding2_pi16 = _mm_insert_epi16(rounding2_pi16, rand()&mask, 2);
			rounding2_pi16 = _mm_insert_epi16(rounding2_pi16, rand()&mask, 3);
			rounding2_pi16 = _mm_insert_epi16(rounding2_pi16, rand()&mask, 4);
			rounding2_pi16 = _mm_insert_epi16(rounding2_pi16, rand()&mask, 5);
			rounding2_pi16 = _mm_insert_epi16(rounding2_pi16, rand()&mask, 6);
			rounding2_pi16 = _mm_insert_epi16(rounding2_pi16, rand()&mask, 7);

			rounding1_pi16 = _mm_adds_epi16(rounding1_pi16, _mm_set1_epi16(10*mask/32)); //DAN20090601
			rounding2_pi16 = _mm_adds_epi16(rounding2_pi16, _mm_set1_epi16(10*mask/32));
		}



		// Apply the even reconstruction filter to the lowpass band
		even += 11 * gg_lowpass_ptr[column + 0];
		even -=  4 * gg_lowpass_ptr[column + 1];
		even +=  1 * gg_lowpass_ptr[column + 2];
		even += ROUNDING(even,8);
		even = DivideByShift(even, 3);

		// Add the highpass correction
		even += gg_highpass_ptr[column];
		even = DivideByShift(even, 1);

		// Reduce the precision to eight bits
		even >>= descale_shift;

		// Save the value for use in the fast loop
		gg_even_value = even;

		// Apply the odd reconstruction filter to the lowpass band
		odd += 5 * gg_lowpass_ptr[column + 0];
		odd += 4 * gg_lowpass_ptr[column + 1];
		odd -= 1 * gg_lowpass_ptr[column + 2];
		odd += ROUNDING(odd,8);
		odd = DivideByShift(odd, 3);

		// Subtract the highpass correction
		odd -= gg_highpass_ptr[column];
		odd = DivideByShift(odd, 1);

		// Reduce the precision to eight bits
		odd >>= descale_shift;

		// Save the value for use in the fast loop
		gg_odd_value = odd;


		// Process the first two u chroma output points with special filters for the left border
		even = 0;
		odd = 0;

		// Apply the even reconstruction filter to the lowpass band
		even += 11 * bg_lowpass_ptr[column + 0];
		even -=  4 * bg_lowpass_ptr[column + 1];
		even +=  1 * bg_lowpass_ptr[column + 2];
		even += ROUNDING(even,8);
		even = DivideByShift(even, 3);

		// Add the highpass correction
		even += bg_highpass_ptr[column];
		even = DivideByShift(even, 1);

		// Reduce the precision to eight bits
		even >>= descale_shift;

		// Save the value for use in the fast loop
		bg_even_value = even;

		// Apply the odd reconstruction filter to the lowpass band
		odd += 5 * bg_lowpass_ptr[column + 0];
		odd += 4 * bg_lowpass_ptr[column + 1];
		odd -= 1 * bg_lowpass_ptr[column + 2];
		odd += ROUNDING(odd,8);
		odd = DivideByShift(odd, 3);

		// Subtract the highpass correction
		odd -= bg_highpass_ptr[column];
		odd = DivideByShift(odd, 1);

		// Reduce the precision to eight bits
		odd >>= descale_shift;

		// Save the value for use in the fast loop
		bg_odd_value = odd;


		// Process the first two v chroma output points with special filters for the left border
		even = 0;
		odd = 0;

		// Apply the even reconstruction filter to the lowpass band
		even += 11 * rg_lowpass_ptr[column + 0];
		even -=  4 * rg_lowpass_ptr[column + 1];
		even +=  1 * rg_lowpass_ptr[column + 2];
		even += ROUNDING(even,8);
		even = DivideByShift(even, 3);

		// Add the highpass correction
		even += rg_highpass_ptr[column];
		even = DivideByShift(even, 1);

		// Reduce the precision to eight bits
		even >>= descale_shift;

		// Save the value for use in the fast loop
		rg_even_value = even;

		// Apply the odd reconstruction filter to the lowpass band
		odd += 5 * rg_lowpass_ptr[column + 0];
		odd += 4 * rg_lowpass_ptr[column + 1];
		odd -= 1 * rg_lowpass_ptr[column + 2];
		odd += ROUNDING(odd,8);
		odd = DivideByShift(odd, 3);

		// Subtract the highpass correction
		odd -= rg_highpass_ptr[column];
		odd = DivideByShift(odd, 1);

		// Reduce the precision to eight bits
		odd >>= descale_shift;

		// Save the value for use in the fast loop
		rg_odd_value = odd;

#if (1 && XMMOPT)

		// Preload the first eight lowpass luma coefficients
		gg_low1_epi16 = _mm_load_si128((__m128i *)&gg_lowpass_ptr[0]);

		// Preload the first eight highpass luma coefficients
		gg_high1_epi16 = _mm_load_si128((__m128i *)&gg_highpass_ptr[0]);

		// Preload the first eight lowpass u chroma coefficients
		bg_low1_epi16 = _mm_load_si128((__m128i *)&bg_lowpass_ptr[0]);

		// Preload the first eight highpass u chroma coefficients
		bg_high1_epi16 = _mm_load_si128((__m128i *)&bg_highpass_ptr[0]);

		// Preload the first eight lowpass v chroma coefficients
		rg_low1_epi16 = _mm_load_si128((__m128i *)&rg_lowpass_ptr[0]);

		// Preload the first eight highpass v chroma coefficients
 		rg_high1_epi16 = _mm_load_si128((__m128i *)&rg_highpass_ptr[0]);


		// The reconstruction filters use pixels starting at the first column
		for (; column < post_column; column += column_step)
		{
			__m128i g1_output_epi16;
			__m128i g2_output_epi16;
			__m128i r1_output_epi16;
			__m128i r2_output_epi16;
			__m128i b1_output_epi16;
			__m128i b2_output_epi16;

			__m128i gg1_output_epi16;
			__m128i gg2_output_epi16;
			__m128i rg1_output_epi16;
			__m128i rg2_output_epi16;
			__m128i bg1_output_epi16;
			__m128i bg2_output_epi16;

			__m128i y1_output_epi16;
			__m128i y2_output_epi16;
			__m128i u1_output_epi16;
			__m128i u2_output_epi16;
			__m128i v1_output_epi16;
			__m128i v2_output_epi16;

			__m128i urg_epi16;
			__m128i yuv1_epi16;
			__m128i yuv2_epi16;
			__m128i yuv1_epi8;
			__m128i yuv2_epi8;

			__m128i even_epi16;		// Result of convolution with even filter
			__m128i odd_epi16;		// Result of convolution with odd filter
			__m128i temp_epi16;
			__m128i temp_epi32;
			__m128i tempB_epi32;
			__m128i rgb_epi32;
			__m128i zero_epi128;
			__m128  temp_ps;
			__m128  rgb_ps;
			__m128	y1a_ps;
			__m128	y1b_ps;
			__m128	u1a_ps;
			__m128	u1b_ps;
			__m128	v1a_ps;
			__m128	v1b_ps;


			__m128i out_epi16;		// Reconstructed data
			//__m128i mask_epi16;
			//__m128i lsb_epi16;
			//__m128i sign_epi16;
			//__m128i high_epi16;

			__m128i low1_epi16;
			__m128i low2_epi16;
			__m128i high1_epi16;
			__m128i high2_epi16;

			//DAN031304 -- correct inverse filter
			__m128i half_epi16 = _mm_set1_epi16(4);
			__m128i offset_epi16 = _mm_set1_epi16(2048);

			uint32_t temp;		// Temporary register for last two values


			/***** Compute the first eight luma output values *****/

			// Preload the second eight lowpass coefficients
			gg_low2_epi16 = _mm_load_si128((__m128i *)&gg_lowpass_ptr[column + 8]);

			// Preload the second eight highpass coefficients
			gg_high2_epi16 = _mm_load_si128((__m128i *)&gg_highpass_ptr[column + 8]);

			// Move the current set of coefficients to working registers
			low1_epi16 = gg_low1_epi16;
			high1_epi16 = gg_high1_epi16;

			// Apply the even reconstruction filter to the lowpass band
			even_epi16 = low1_epi16;
			temp_epi16 = _mm_srli_si128(even_epi16, 2*2);
			even_epi16 = _mm_subs_epi16(even_epi16, temp_epi16);
			even_epi16 = _mm_adds_epi16(even_epi16, half_epi16);
			even_epi16 = _mm_srai_epi16(even_epi16, 3);
			temp_epi16 = _mm_srli_si128(low1_epi16, 1*2);
			even_epi16 = _mm_adds_epi16(even_epi16, temp_epi16);

			// Shift the highpass correction by one column
			high1_epi16 = _mm_srli_si128(high1_epi16, 1*2);

			// Add the highpass correction and divide by two
			even_epi16 = _mm_adds_epi16(even_epi16, offset_epi16);
			even_epi16 = _mm_adds_epi16(even_epi16, high1_epi16);
			even_epi16 = _mm_subs_epu16(even_epi16, offset_epi16);
			even_epi16 = _mm_srai_epi16(even_epi16, 1);

			// Apply the odd reconstruction filter to the lowpass band
			odd_epi16 = _mm_srli_si128(low1_epi16, 2*2);
			temp_epi16 = low1_epi16;
			odd_epi16 = _mm_subs_epi16(odd_epi16, temp_epi16);
			odd_epi16 = _mm_adds_epi16(odd_epi16, half_epi16);
			odd_epi16 = _mm_srai_epi16(odd_epi16, 3);
			temp_epi16 = _mm_srli_si128(low1_epi16, 1*2);
			odd_epi16 = _mm_adds_epi16(odd_epi16, temp_epi16);

			// Subtract the highpass correction and divide by two
			odd_epi16 = _mm_adds_epi16(odd_epi16, offset_epi16);
			odd_epi16 = _mm_subs_epi16(odd_epi16, high1_epi16);
			odd_epi16 = _mm_subs_epu16(odd_epi16, offset_epi16);
			odd_epi16 = _mm_srai_epi16(odd_epi16, 1);


			// Interleave the four even and four odd results
			out_epi16 = _mm_unpacklo_epi16(even_epi16, odd_epi16);

			// Reduce the precision to eight bits
			out_epi16 = _mm_adds_epi16(out_epi16, rounding1_pi16);
			out_epi16 = _mm_srli_epi16(out_epi16, descale_shift);

			// Combine the new output values with the two values from the previous phase
			out_epi16 = _mm_shuffle_epi32(out_epi16, _MM_SHUFFLE(2, 1, 0, 3));
			temp = _mm_cvtsi128_si32(out_epi16);
			out_epi16 = _mm_insert_epi16(out_epi16, gg_even_value, 0);
			out_epi16 = _mm_insert_epi16(out_epi16, gg_odd_value, 1);

			// Save the eight luma values for packing later
			gg1_output_epi16 = out_epi16;

			// Save the remaining two output values
			gg_even_value = (short)temp;
			gg_odd_value = (short)(temp >> 16);


			/***** Compute the second eight luma output values *****/

			// Move the next set of coefficients to working registers
			low2_epi16 = gg_low2_epi16;
			high2_epi16 = gg_high2_epi16;

			// Shift in the new pixels for the next stage of the loop
			low1_epi16 = _mm_srli_si128(low1_epi16, 4*2);
			temp_epi16 = _mm_slli_si128(low2_epi16, 4*2);
			low1_epi16 = _mm_or_si128(low1_epi16, temp_epi16);

			// Apply the even reconstruction filter to the lowpass band
			even_epi16 = low1_epi16;
			temp_epi16 = _mm_srli_si128(even_epi16, 2*2);
			even_epi16 = _mm_subs_epi16(even_epi16, temp_epi16);
			even_epi16 = _mm_adds_epi16(even_epi16, half_epi16);
			even_epi16 = _mm_srai_epi16(even_epi16, 3);
			temp_epi16 = _mm_srli_si128(low1_epi16, 1*2);
			even_epi16 = _mm_adds_epi16(even_epi16, temp_epi16);

			// Shift in the next four highpass coefficients
			high1_epi16 = _mm_srli_si128(high1_epi16, 4*2);
			temp_epi16 = _mm_slli_si128(high2_epi16, 3*2);
			high1_epi16 = _mm_or_si128(high1_epi16, temp_epi16);

			// Add the highpass correction and divide by two
			even_epi16 = _mm_adds_epi16(even_epi16, offset_epi16);
			even_epi16 = _mm_adds_epi16(even_epi16, high1_epi16);
			even_epi16 = _mm_subs_epu16(even_epi16, offset_epi16);
			even_epi16 = _mm_srai_epi16(even_epi16, 1);

			// Apply the odd reconstruction filter to the lowpass band
			odd_epi16 = _mm_srli_si128(low1_epi16, 2*2);
			temp_epi16 = low1_epi16;
			odd_epi16 = _mm_subs_epi16(odd_epi16, temp_epi16);
			odd_epi16 = _mm_adds_epi16(odd_epi16, half_epi16);
			odd_epi16 = _mm_srai_epi16(odd_epi16, 3);
			temp_epi16 = _mm_srli_si128(low1_epi16, 1*2);
			odd_epi16 = _mm_adds_epi16(odd_epi16, temp_epi16);

			// Subtract the highpass correction and divide by two
			odd_epi16 = _mm_adds_epi16(odd_epi16, offset_epi16);
			odd_epi16 = _mm_subs_epi16(odd_epi16, high1_epi16);
			odd_epi16 = _mm_subs_epu16(odd_epi16, offset_epi16);
			odd_epi16 = _mm_srai_epi16(odd_epi16, 1);

			// Interleave the four even and four odd results
			out_epi16 = _mm_unpacklo_epi16(even_epi16, odd_epi16);

			// Reduce the precision to eight bits
			out_epi16 = _mm_adds_epi16(out_epi16, rounding2_pi16);
			out_epi16 = _mm_srli_epi16(out_epi16, descale_shift);

			// Combine the new output values with the two values from the previous phase
			out_epi16 = _mm_shuffle_epi32(out_epi16, _MM_SHUFFLE(2, 1, 0, 3));
			temp = _mm_cvtsi128_si32(out_epi16);
			out_epi16 = _mm_insert_epi16(out_epi16, gg_even_value, 0);
			out_epi16 = _mm_insert_epi16(out_epi16, gg_odd_value, 1);

			// Save the eight luma values for packing later
			gg2_output_epi16 = out_epi16;

			// Save the remaining two output values
			gg_even_value = (short)temp;
			gg_odd_value = (short)(temp >> 16);

			// The second eight lowpass coefficients are used later in the loop
			gg_low1_epi16 = gg_low2_epi16;

			// The second eight highpass coefficients are used later in the loop
			gg_high1_epi16 = gg_high2_epi16;


			/***** Compute the first eight u chroma output values *****/

			// Preload the second eight lowpass coefficients
			bg_low2_epi16 = _mm_load_si128((__m128i *)&bg_lowpass_ptr[column + 8]);

			// Preload the second eight highpass coefficients
			bg_high2_epi16 = _mm_load_si128((__m128i *)&bg_highpass_ptr[column + 8]);

			// Move the current set of coefficients to working registers
			low1_epi16 = bg_low1_epi16;
			high1_epi16 = bg_high1_epi16;

			// Apply the even reconstruction filter to the lowpass band
			even_epi16 = low1_epi16;
			temp_epi16 = _mm_srli_si128(even_epi16, 2*2);
			even_epi16 = _mm_subs_epi16(even_epi16, temp_epi16);
			even_epi16 = _mm_adds_epi16(even_epi16, half_epi16);
			even_epi16 = _mm_srai_epi16(even_epi16, 3);
			temp_epi16 = _mm_srli_si128(low1_epi16, 1*2);
			even_epi16 = _mm_adds_epi16(even_epi16, temp_epi16);

			// Shift the highpass correction by one column
			high1_epi16 = _mm_srli_si128(high1_epi16, 1*2);

			// Add the highpass correction and divide by two
			even_epi16 = _mm_adds_epi16(even_epi16, offset_epi16);
			even_epi16 = _mm_adds_epi16(even_epi16, high1_epi16);
			even_epi16 = _mm_subs_epu16(even_epi16, offset_epi16);
			even_epi16 = _mm_srai_epi16(even_epi16, 1);

			// Apply the odd reconstruction filter to the lowpass band
			odd_epi16 = _mm_srli_si128(low1_epi16, 2*2);
			temp_epi16 = low1_epi16;
			odd_epi16 = _mm_subs_epi16(odd_epi16, temp_epi16);
			odd_epi16 = _mm_adds_epi16(odd_epi16, half_epi16);
			odd_epi16 = _mm_srai_epi16(odd_epi16, 3);
			temp_epi16 = _mm_srli_si128(low1_epi16, 1*2);
			odd_epi16 = _mm_adds_epi16(odd_epi16, temp_epi16);

			// Subtract the highpass correction and divide by two
			odd_epi16 = _mm_adds_epi16(odd_epi16, offset_epi16);
			odd_epi16 = _mm_subs_epi16(odd_epi16, high1_epi16);
			odd_epi16 = _mm_subs_epu16(odd_epi16, offset_epi16);
			odd_epi16 = _mm_srai_epi16(odd_epi16, 1);

			// Interleave the four even and four odd results
			out_epi16 = _mm_unpacklo_epi16(even_epi16, odd_epi16);

			// Reduce the precision to eight bits
			out_epi16 = _mm_adds_epi16(out_epi16, rounding1_pi16);
			out_epi16 = _mm_srli_epi16(out_epi16, descale_shift);

			// Combine the new output values with the two values from the previous phase
			out_epi16 = _mm_shuffle_epi32(out_epi16, _MM_SHUFFLE(2, 1, 0, 3));
			temp = _mm_cvtsi128_si32(out_epi16);
			out_epi16 = _mm_insert_epi16(out_epi16, bg_even_value, 0);
			out_epi16 = _mm_insert_epi16(out_epi16, bg_odd_value, 1);

			// Save the eight u chroma values for packing later
			bg1_output_epi16 = out_epi16;

			// Save the remaining two output values
			bg_even_value = (short)temp;
			bg_odd_value = (short)(temp >> 16);


			/***** Compute the second eight u chroma output values *****/

			// Move the next set of coefficients to working registers
			low2_epi16 = bg_low2_epi16;
			high2_epi16 = bg_high2_epi16;

			// Shift in the new pixels for the next stage of the loop
			low1_epi16 = _mm_srli_si128(low1_epi16, 4*2);
			temp_epi16 = _mm_slli_si128(low2_epi16, 4*2);
			low1_epi16 = _mm_or_si128(low1_epi16, temp_epi16);

			// Apply the even reconstruction filter to the lowpass band
			even_epi16 = low1_epi16;
			temp_epi16 = _mm_srli_si128(even_epi16, 2*2);
			even_epi16 = _mm_subs_epi16(even_epi16, temp_epi16);
			even_epi16 = _mm_adds_epi16(even_epi16, half_epi16);
			even_epi16 = _mm_srai_epi16(even_epi16, 3);
			temp_epi16 = _mm_srli_si128(low1_epi16, 1*2);
			even_epi16 = _mm_adds_epi16(even_epi16, temp_epi16);

			// Shift in the next four highpass coefficients
			high1_epi16 = _mm_srli_si128(high1_epi16, 4*2);
			temp_epi16 = _mm_slli_si128(high2_epi16, 3*2);
			high1_epi16 = _mm_or_si128(high1_epi16, temp_epi16);

			// Add the highpass correction and divide by two
			even_epi16 = _mm_adds_epi16(even_epi16, offset_epi16);
			even_epi16 = _mm_adds_epi16(even_epi16, high1_epi16);
			even_epi16 = _mm_subs_epu16(even_epi16, offset_epi16);
			even_epi16 = _mm_srai_epi16(even_epi16, 1);

			// Apply the odd reconstruction filter to the lowpass band
			odd_epi16 = _mm_srli_si128(low1_epi16, 2*2);
			temp_epi16 = low1_epi16;
			odd_epi16 = _mm_subs_epi16(odd_epi16, temp_epi16);
			odd_epi16 = _mm_adds_epi16(odd_epi16, half_epi16);
			odd_epi16 = _mm_srai_epi16(odd_epi16, 3);
			temp_epi16 = _mm_srli_si128(low1_epi16, 1*2);
			odd_epi16 = _mm_adds_epi16(odd_epi16, temp_epi16);

			// Subtract the highpass correction and divide by two
			odd_epi16 = _mm_adds_epi16(odd_epi16, offset_epi16);
			odd_epi16 = _mm_subs_epi16(odd_epi16, high1_epi16);
			odd_epi16 = _mm_subs_epu16(odd_epi16, offset_epi16);
			odd_epi16 = _mm_srai_epi16(odd_epi16, 1);

			// Interleave the four even and four odd results
			out_epi16 = _mm_unpacklo_epi16(even_epi16, odd_epi16);

			// Reduce the precision to eight bits
			out_epi16 = _mm_adds_epi16(out_epi16, rounding2_pi16);
			out_epi16 = _mm_srli_epi16(out_epi16, descale_shift);

			// Combine the new output values with the two values from the previous phase
			out_epi16 = _mm_shuffle_epi32(out_epi16, _MM_SHUFFLE(2, 1, 0, 3));
			temp = _mm_cvtsi128_si32(out_epi16);
			out_epi16 = _mm_insert_epi16(out_epi16, bg_even_value, 0);
			out_epi16 = _mm_insert_epi16(out_epi16, bg_odd_value, 1);

			// Save the eight u chroma values for packing later
			bg2_output_epi16 = out_epi16;

			// Save the remaining two output values
			bg_even_value = (short)temp;
			bg_odd_value = (short)(temp >> 16);

			// The second eight lowpass coefficients are the current values in the next iteration
			bg_low1_epi16 = bg_low2_epi16;

			// The second eight highpass coefficients are the current values in the next iteration
			bg_high1_epi16 = bg_high2_epi16;



			/***** Compute the first eight v chroma output values *****/

			// Preload the second eight lowpass coefficients
			rg_low2_epi16 = _mm_load_si128((__m128i *)&rg_lowpass_ptr[column + 8]);

			// Preload the second eight highpass coefficients
			rg_high2_epi16 = _mm_load_si128((__m128i *)&rg_highpass_ptr[column + 8]);

			// Move the current set of coefficients to working registers
			low1_epi16 = rg_low1_epi16;
			high1_epi16 = rg_high1_epi16;

			// Apply the even reconstruction filter to the lowpass band
			even_epi16 = low1_epi16;
			temp_epi16 = _mm_srli_si128(even_epi16, 2*2);
			even_epi16 = _mm_subs_epi16(even_epi16, temp_epi16);
			even_epi16 = _mm_adds_epi16(even_epi16, half_epi16);
			even_epi16 = _mm_srai_epi16(even_epi16, 3);
			temp_epi16 = _mm_srli_si128(low1_epi16, 1*2);
			even_epi16 = _mm_adds_epi16(even_epi16, temp_epi16);

			// Shift the highpass correction by one column
			high1_epi16 = _mm_srli_si128(high1_epi16, 1*2);

			// Add the highpass correction and divide by two
			even_epi16 = _mm_adds_epi16(even_epi16, offset_epi16);
			even_epi16 = _mm_adds_epi16(even_epi16, high1_epi16);
			even_epi16 = _mm_subs_epu16(even_epi16, offset_epi16);
			even_epi16 = _mm_srai_epi16(even_epi16, 1);

			// Apply the odd reconstruction filter to the lowpass band
			odd_epi16 = _mm_srli_si128(low1_epi16, 2*2);
			temp_epi16 = low1_epi16;
			odd_epi16 = _mm_subs_epi16(odd_epi16, temp_epi16);
			odd_epi16 = _mm_adds_epi16(odd_epi16, half_epi16);
			odd_epi16 = _mm_srai_epi16(odd_epi16, 3);
			temp_epi16 = _mm_srli_si128(low1_epi16, 1*2);
			odd_epi16 = _mm_adds_epi16(odd_epi16, temp_epi16);

			// Subtract the highpass correction and divide by two
			odd_epi16 = _mm_adds_epi16(odd_epi16, offset_epi16);
			odd_epi16 = _mm_subs_epi16(odd_epi16, high1_epi16);
			odd_epi16 = _mm_subs_epu16(odd_epi16, offset_epi16);
			odd_epi16 = _mm_srai_epi16(odd_epi16, 1);

			// Interleave the four even and four odd results
			out_epi16 = _mm_unpacklo_epi16(even_epi16, odd_epi16);

			// Reduce the precision to eight bits
			out_epi16 = _mm_adds_epi16(out_epi16, rounding1_pi16);
			out_epi16 = _mm_srli_epi16(out_epi16, descale_shift);

			// Combine the new output values with the two values from the previous phase
			out_epi16 = _mm_shuffle_epi32(out_epi16, _MM_SHUFFLE(2, 1, 0, 3));
			temp = _mm_cvtsi128_si32(out_epi16);
			out_epi16 = _mm_insert_epi16(out_epi16, rg_even_value, 0);
			out_epi16 = _mm_insert_epi16(out_epi16, rg_odd_value, 1);

			// Save the eight u chroma values for packing later
			rg1_output_epi16 = out_epi16;

			// Save the remaining two output values
			rg_even_value = (short)temp;
			rg_odd_value = (short)(temp >> 16);


			/***** Compute the second eight v chroma output values *****/

			// Move the next set of coefficients to working registers
			low2_epi16 = rg_low2_epi16;
			high2_epi16 = rg_high2_epi16;

			// Shift in the new pixels for the next stage of the loop
			low1_epi16 = _mm_srli_si128(low1_epi16, 4*2);
			temp_epi16 = _mm_slli_si128(low2_epi16, 4*2);
			low1_epi16 = _mm_or_si128(low1_epi16, temp_epi16);

			// Apply the even reconstruction filter to the lowpass band
			even_epi16 = low1_epi16;
			temp_epi16 = _mm_srli_si128(even_epi16, 2*2);
			even_epi16 = _mm_subs_epi16(even_epi16, temp_epi16);
			even_epi16 = _mm_adds_epi16(even_epi16, half_epi16);
			even_epi16 = _mm_srai_epi16(even_epi16, 3);
			temp_epi16 = _mm_srli_si128(low1_epi16, 1*2);
			even_epi16 = _mm_adds_epi16(even_epi16, temp_epi16);

			// Shift in the next four highpass coefficients
			high1_epi16 = _mm_srli_si128(high1_epi16, 4*2);
			temp_epi16 = _mm_slli_si128(high2_epi16, 3*2);
			high1_epi16 = _mm_or_si128(high1_epi16, temp_epi16);

			// Add the highpass correction and divide by two
			even_epi16 = _mm_adds_epi16(even_epi16, offset_epi16);
			even_epi16 = _mm_adds_epi16(even_epi16, high1_epi16);
			even_epi16 = _mm_subs_epu16(even_epi16, offset_epi16);
			even_epi16 = _mm_srai_epi16(even_epi16, 1);

			// Apply the odd reconstruction filter to the lowpass band
			odd_epi16 = _mm_srli_si128(low1_epi16, 2*2);
			temp_epi16 = low1_epi16;
			odd_epi16 = _mm_subs_epi16(odd_epi16, temp_epi16);
			odd_epi16 = _mm_adds_epi16(odd_epi16, half_epi16);
			odd_epi16 = _mm_srai_epi16(odd_epi16, 3);
			temp_epi16 = _mm_srli_si128(low1_epi16, 1*2);
			odd_epi16 = _mm_adds_epi16(odd_epi16, temp_epi16);

			// Subtract the highpass correction and divide by two
			odd_epi16 = _mm_adds_epi16(odd_epi16, offset_epi16);
			odd_epi16 = _mm_subs_epi16(odd_epi16, high1_epi16);
			odd_epi16 = _mm_subs_epu16(odd_epi16, offset_epi16);
			odd_epi16 = _mm_srai_epi16(odd_epi16, 1);

			// Interleave the four even and four odd results
			out_epi16 = _mm_unpacklo_epi16(even_epi16, odd_epi16);

			// Reduce the precision to eight bits
			out_epi16 = _mm_adds_epi16(out_epi16, rounding2_pi16);
			out_epi16 = _mm_srli_epi16(out_epi16, descale_shift);

			// Combine the new output values with the two values from the previous phase
			out_epi16 = _mm_shuffle_epi32(out_epi16, _MM_SHUFFLE(2, 1, 0, 3));
			temp = _mm_cvtsi128_si32(out_epi16);
			out_epi16 = _mm_insert_epi16(out_epi16, rg_even_value, 0);
			out_epi16 = _mm_insert_epi16(out_epi16, rg_odd_value, 1);

			// Save the eight u chroma values for packing later
			rg2_output_epi16 = out_epi16;

			// Save the remaining two output values
			rg_even_value = (short)temp;
			rg_odd_value = (short)(temp >> 16);

			// The second eight lowpass coefficients are the current values in the next iteration
			rg_low1_epi16 = rg_low2_epi16;

			// The second eight highpass coefficients are the current values in the next iteration
			rg_high1_epi16 = rg_high2_epi16;












			//r_output_epi16  = ((rg_output_epi16 - 32768)<<1)+gg_output_epi16
			//r_output_epi16  = ((rg_output_epi16>>3 - 32768>>3))+gg_output_epi16>>4


			g1_output_epi16 = gg1_output_epi16;

			r1_output_epi16 = rg1_output_epi16;//_mm_srli_epi16(rg1_output_epi16,2);
		//	r1_output_epi16 = _mm_subs_epi16(r1_output_epi16, value128_epi32);
		//	r1_output_epi16 = _mm_slli_epi16(r1_output_epi16,1);
		//	r1_output_epi16 = _mm_adds_epi16(r1_output_epi16, g1_output_epi16);

			b1_output_epi16 = bg1_output_epi16;//_mm_srli_epi16(bg1_output_epi16,2);
		//	b1_output_epi16 = _mm_subs_epi16(b1_output_epi16, value128_epi32);
		//	b1_output_epi16 = _mm_slli_epi16(b1_output_epi16,1);
		//	b1_output_epi16 = _mm_adds_epi16(b1_output_epi16, g1_output_epi16);


			 r1_output_epi16 = _mm_adds_epi16(r1_output_epi16, limiterRGB);
			 r1_output_epi16 = _mm_subs_epu16(r1_output_epi16, limiterRGB);

			 g1_output_epi16 = _mm_adds_epi16(g1_output_epi16, limiterRGB);
			 g1_output_epi16 = _mm_subs_epu16(g1_output_epi16, limiterRGB);

			 b1_output_epi16 = _mm_adds_epi16(b1_output_epi16, limiterRGB);
			 b1_output_epi16 = _mm_subs_epu16(b1_output_epi16, limiterRGB);


			zero_epi128 = _mm_setzero_si128();


			// Compute Y,U,V
			rgb_epi32 = _mm_unpacklo_epi16(r1_output_epi16, zero_epi128);
			rgb_ps = _mm_cvtepi32_ps(rgb_epi32);
			y1a_ps = _mm_mul_ps(_mm_set_ps1(fy_rmult), rgb_ps);
			u1a_ps = _mm_mul_ps(_mm_set_ps1(fu_rmult), rgb_ps);
			v1a_ps = _mm_mul_ps(_mm_set_ps1(fv_rmult), rgb_ps);
			rgb_epi32 = _mm_unpackhi_epi16(r1_output_epi16, zero_epi128);
			rgb_ps = _mm_cvtepi32_ps(rgb_epi32);
			y1b_ps = _mm_mul_ps(_mm_set_ps1(fy_rmult), rgb_ps);
			u1b_ps = _mm_mul_ps(_mm_set_ps1(fu_rmult), rgb_ps);
			v1b_ps = _mm_mul_ps(_mm_set_ps1(fv_rmult), rgb_ps);

			rgb_epi32 = _mm_unpacklo_epi16(g1_output_epi16, zero_epi128);
			rgb_ps = _mm_cvtepi32_ps(rgb_epi32);
			temp_ps = _mm_mul_ps(_mm_set_ps1(fy_gmult), rgb_ps);
			y1a_ps = _mm_add_ps(y1a_ps, temp_ps);
			temp_ps = _mm_mul_ps(_mm_set_ps1(fu_gmult), rgb_ps);
			u1a_ps = _mm_add_ps(u1a_ps, temp_ps);
			temp_ps = _mm_mul_ps(_mm_set_ps1(fv_gmult), rgb_ps);
			v1a_ps = _mm_add_ps(v1a_ps, temp_ps);
			rgb_epi32 = _mm_unpackhi_epi16(g1_output_epi16, zero_epi128);
			rgb_ps = _mm_cvtepi32_ps(rgb_epi32);
			temp_ps = _mm_mul_ps(_mm_set_ps1(fy_gmult), rgb_ps);
			y1b_ps = _mm_add_ps(y1b_ps, temp_ps);
			temp_ps = _mm_mul_ps(_mm_set_ps1(fu_gmult), rgb_ps);
			u1b_ps = _mm_add_ps(u1b_ps, temp_ps);
			temp_ps = _mm_mul_ps(_mm_set_ps1(fv_gmult), rgb_ps);
			v1b_ps = _mm_add_ps(v1b_ps, temp_ps);

			rgb_epi32 = _mm_unpacklo_epi16(b1_output_epi16, zero_epi128);
			rgb_ps = _mm_cvtepi32_ps(rgb_epi32);
			temp_ps = _mm_mul_ps(_mm_set_ps1(fy_bmult), rgb_ps);
			y1a_ps = _mm_add_ps(y1a_ps, temp_ps);
			temp_ps = _mm_mul_ps(_mm_set_ps1(fu_bmult), rgb_ps);
			u1a_ps = _mm_add_ps(u1a_ps, temp_ps);
			temp_ps = _mm_mul_ps(_mm_set_ps1(fv_bmult), rgb_ps);
			v1a_ps = _mm_add_ps(v1a_ps, temp_ps);
			rgb_epi32 = _mm_unpackhi_epi16(b1_output_epi16, zero_epi128);
			rgb_ps = _mm_cvtepi32_ps(rgb_epi32);
			temp_ps = _mm_mul_ps(_mm_set_ps1(fy_bmult), rgb_ps);
			y1b_ps = _mm_add_ps(y1b_ps, temp_ps);
			temp_ps = _mm_mul_ps(_mm_set_ps1(fu_bmult), rgb_ps);
			u1b_ps = _mm_add_ps(u1b_ps, temp_ps);
			temp_ps = _mm_mul_ps(_mm_set_ps1(fv_bmult), rgb_ps);
			v1b_ps = _mm_add_ps(v1b_ps, temp_ps);

			temp_ps = _mm_set_ps1(fy_offset);
			y1a_ps = _mm_add_ps(y1a_ps, temp_ps);
			y1b_ps = _mm_add_ps(y1b_ps, temp_ps);
			temp_ps = _mm_set_ps1(fu_offset);
			u1a_ps = _mm_add_ps(u1a_ps, temp_ps);
			u1b_ps = _mm_add_ps(u1b_ps, temp_ps);
			temp_ps = _mm_set_ps1(fv_offset);
			v1a_ps = _mm_add_ps(v1a_ps, temp_ps);
			v1b_ps = _mm_add_ps(v1b_ps, temp_ps);

			temp_epi32 = _mm_cvtps_epi32(y1a_ps);
			tempB_epi32 = _mm_cvtps_epi32(y1b_ps);
			y1_output_epi16 = _mm_packs_epi32(temp_epi32, tempB_epi32);
			y1_output_epi16 = _mm_adds_epi16(y1_output_epi16, limiter);
			y1_output_epi16 = _mm_subs_epu16(y1_output_epi16, limiter);
			y1_output_epi16 = _mm_srli_epi16(y1_output_epi16, shift);

			temp_epi32 = _mm_cvtps_epi32(u1a_ps);
			tempB_epi32 = _mm_cvtps_epi32(u1b_ps);
			u1_output_epi16 = _mm_packs_epi32(temp_epi32, tempB_epi32);
			u1_output_epi16 = _mm_adds_epi16(u1_output_epi16, limiter);
			u1_output_epi16 = _mm_subs_epu16(u1_output_epi16, limiter);
			u1_output_epi16 = _mm_srli_epi16(u1_output_epi16, shift);

			temp_epi32 = _mm_cvtps_epi32(v1a_ps);
			tempB_epi32 = _mm_cvtps_epi32(v1b_ps);
			v1_output_epi16 = _mm_packs_epi32(temp_epi32, tempB_epi32);
			v1_output_epi16 = _mm_adds_epi16(v1_output_epi16, limiter);
			v1_output_epi16 = _mm_subs_epu16(v1_output_epi16, limiter);
			v1_output_epi16 = _mm_srli_epi16(v1_output_epi16, shift);






			g2_output_epi16 = gg2_output_epi16;//_mm_srli_epi16(gg2_output_epi16,2);

			r2_output_epi16 = rg2_output_epi16;//_mm_srli_epi16(rg2_output_epi16,2);
		//	r2_output_epi16 = _mm_subs_epi16(r2_output_epi16, value128_epi32);
		//	r2_output_epi16 = _mm_slli_epi16(r2_output_epi16,1);
		//	r2_output_epi16 = _mm_adds_epi16(r2_output_epi16, g2_output_epi16);

			b2_output_epi16 = bg2_output_epi16;//_mm_srli_epi16(bg2_output_epi16,2);
		//	b2_output_epi16 = _mm_subs_epi16(b2_output_epi16, value128_epi32);
		//	b2_output_epi16 = _mm_slli_epi16(b2_output_epi16,1);
		//	b2_output_epi16 = _mm_adds_epi16(b2_output_epi16, g2_output_epi16);



			 r2_output_epi16 = _mm_adds_epi16(r2_output_epi16, limiterRGB);
			 r2_output_epi16 = _mm_subs_epu16(r2_output_epi16, limiterRGB);

			 g2_output_epi16 = _mm_adds_epi16(g2_output_epi16, limiterRGB);
			 g2_output_epi16 = _mm_subs_epu16(g2_output_epi16, limiterRGB);

			 b2_output_epi16 = _mm_adds_epi16(b2_output_epi16, limiterRGB);
			 b2_output_epi16 = _mm_subs_epu16(b2_output_epi16, limiterRGB);


			// Compute Y,U,V
			rgb_epi32 = _mm_unpacklo_epi16(r2_output_epi16, zero_epi128);
			rgb_ps = _mm_cvtepi32_ps(rgb_epi32);
			y1a_ps = _mm_mul_ps(_mm_set_ps1(fy_rmult), rgb_ps);
			u1a_ps = _mm_mul_ps(_mm_set_ps1(fu_rmult), rgb_ps);
			v1a_ps = _mm_mul_ps(_mm_set_ps1(fv_rmult), rgb_ps);
			rgb_epi32 = _mm_unpackhi_epi16(r2_output_epi16, zero_epi128);
			rgb_ps = _mm_cvtepi32_ps(rgb_epi32);
			y1b_ps = _mm_mul_ps(_mm_set_ps1(fy_rmult), rgb_ps);
			u1b_ps = _mm_mul_ps(_mm_set_ps1(fu_rmult), rgb_ps);
			v1b_ps = _mm_mul_ps(_mm_set_ps1(fv_rmult), rgb_ps);

			rgb_epi32 = _mm_unpacklo_epi16(g2_output_epi16, zero_epi128);
			rgb_ps = _mm_cvtepi32_ps(rgb_epi32);
			temp_ps = _mm_mul_ps(_mm_set_ps1(fy_gmult), rgb_ps);
			y1a_ps = _mm_add_ps(y1a_ps, temp_ps);
			temp_ps = _mm_mul_ps(_mm_set_ps1(fu_gmult), rgb_ps);
			u1a_ps = _mm_add_ps(u1a_ps, temp_ps);
			temp_ps = _mm_mul_ps(_mm_set_ps1(fv_gmult), rgb_ps);
			v1a_ps = _mm_add_ps(v1a_ps, temp_ps);
			rgb_epi32 = _mm_unpackhi_epi16(g2_output_epi16, zero_epi128);
			rgb_ps = _mm_cvtepi32_ps(rgb_epi32);
			temp_ps = _mm_mul_ps(_mm_set_ps1(fy_gmult), rgb_ps);
			y1b_ps = _mm_add_ps(y1b_ps, temp_ps);
			temp_ps = _mm_mul_ps(_mm_set_ps1(fu_gmult), rgb_ps);
			u1b_ps = _mm_add_ps(u1b_ps, temp_ps);
			temp_ps = _mm_mul_ps(_mm_set_ps1(fv_gmult), rgb_ps);
			v1b_ps = _mm_add_ps(v1b_ps, temp_ps);

			rgb_epi32 = _mm_unpacklo_epi16(b2_output_epi16, zero_epi128);
			rgb_ps = _mm_cvtepi32_ps(rgb_epi32);
			temp_ps = _mm_mul_ps(_mm_set_ps1(fy_bmult), rgb_ps);
			y1a_ps = _mm_add_ps(y1a_ps, temp_ps);
			temp_ps = _mm_mul_ps(_mm_set_ps1(fu_bmult), rgb_ps);
			u1a_ps = _mm_add_ps(u1a_ps, temp_ps);
			temp_ps = _mm_mul_ps(_mm_set_ps1(fv_bmult), rgb_ps);
			v1a_ps = _mm_add_ps(v1a_ps, temp_ps);
			rgb_epi32 = _mm_unpackhi_epi16(b2_output_epi16, zero_epi128);
			rgb_ps = _mm_cvtepi32_ps(rgb_epi32);
			temp_ps = _mm_mul_ps(_mm_set_ps1(fy_bmult), rgb_ps);
			y1b_ps = _mm_add_ps(y1b_ps, temp_ps);
			temp_ps = _mm_mul_ps(_mm_set_ps1(fu_bmult), rgb_ps);
			u1b_ps = _mm_add_ps(u1b_ps, temp_ps);
			temp_ps = _mm_mul_ps(_mm_set_ps1(fv_bmult), rgb_ps);
			v1b_ps = _mm_add_ps(v1b_ps, temp_ps);

			temp_ps = _mm_set_ps1(fy_offset);
			y1a_ps = _mm_add_ps(y1a_ps, temp_ps);
			y1b_ps = _mm_add_ps(y1b_ps, temp_ps);
			temp_ps = _mm_set_ps1(fu_offset);
			u1a_ps = _mm_add_ps(u1a_ps, temp_ps);
			u1b_ps = _mm_add_ps(u1b_ps, temp_ps);
			temp_ps = _mm_set_ps1(fv_offset);
			v1a_ps = _mm_add_ps(v1a_ps, temp_ps);
			v1b_ps = _mm_add_ps(v1b_ps, temp_ps);

			temp_epi32 = _mm_cvtps_epi32(y1a_ps);
			tempB_epi32 = _mm_cvtps_epi32(y1b_ps);
			y2_output_epi16 = _mm_packs_epi32(temp_epi32, tempB_epi32);
			y2_output_epi16 = _mm_adds_epi16(y2_output_epi16, limiter);
			y2_output_epi16 = _mm_subs_epu16(y2_output_epi16, limiter);
			y2_output_epi16 = _mm_srli_epi16(y2_output_epi16, shift);

			temp_epi32 = _mm_cvtps_epi32(u1a_ps);
			tempB_epi32 = _mm_cvtps_epi32(u1b_ps);
			u2_output_epi16 = _mm_packs_epi32(temp_epi32, tempB_epi32);
			u2_output_epi16 = _mm_adds_epi16(u2_output_epi16, limiter);
			u2_output_epi16 = _mm_subs_epu16(u2_output_epi16, limiter);
			u2_output_epi16 = _mm_srli_epi16(u2_output_epi16, shift);

			temp_epi32 = _mm_cvtps_epi32(v1a_ps);
			tempB_epi32 = _mm_cvtps_epi32(v1b_ps);
			v2_output_epi16 = _mm_packs_epi32(temp_epi32, tempB_epi32);
			v2_output_epi16 = _mm_adds_epi16(v2_output_epi16, limiter);
			v2_output_epi16 = _mm_subs_epu16(v2_output_epi16, limiter);
			v2_output_epi16 = _mm_srli_epi16(v2_output_epi16, shift);


			// 4:4:4 to 4:2:2
			temp_epi16 = _mm_srli_si128(u1_output_epi16, 2);
			u1_output_epi16 = _mm_adds_epi16(u1_output_epi16, temp_epi16);
			u1_output_epi16 = _mm_srli_epi16(u1_output_epi16, 1);
			temp_epi16 = _mm_srli_si128(u2_output_epi16, 2);
			u2_output_epi16 = _mm_adds_epi16(u2_output_epi16, temp_epi16);
			u2_output_epi16 = _mm_srli_epi16(u2_output_epi16, 1);
			temp_epi16 = _mm_srli_si128(v1_output_epi16, 2);
			v1_output_epi16 = _mm_adds_epi16(v1_output_epi16, temp_epi16);
			v1_output_epi16 = _mm_srli_epi16(v1_output_epi16, 1);
			temp_epi16 = _mm_srli_si128(v2_output_epi16, 2);
			v2_output_epi16 = _mm_adds_epi16(v2_output_epi16, temp_epi16);
			v2_output_epi16 = _mm_srli_epi16(v2_output_epi16, 1);
			u1_output_epi16 = _mm_and_si128(u1_output_epi16, mask_epi32);
			u2_output_epi16 = _mm_and_si128(u2_output_epi16, mask_epi32);
			v1_output_epi16 = _mm_and_si128(v1_output_epi16, mask_epi32);
			v2_output_epi16 = _mm_and_si128(v2_output_epi16, mask_epi32);

			u1_output_epi16 = _mm_packs_epi32 (u1_output_epi16, u2_output_epi16);
			v1_output_epi16 = _mm_packs_epi32 (v1_output_epi16, v2_output_epi16);



			/***** Interleave the luma and chroma values *****/

			// Interleave the first four values from each chroma channel
			urg_epi16 = _mm_unpacklo_epi16(u1_output_epi16, v1_output_epi16);

			// Interleave the first eight chroma values with the first eight luma values
			yuv1_epi16 = _mm_unpacklo_epi16(y1_output_epi16, urg_epi16);
			yuv2_epi16 = _mm_unpackhi_epi16(y1_output_epi16, urg_epi16);

			// Pack the first sixteen bytes of luma and chroma
			yuv1_epi8 = _mm_packus_epi16(yuv1_epi16, yuv2_epi16);

			// Store the first sixteen bytes of output values
			_mm_store_si128(outptr++, yuv1_epi8);

			// Interleave the second four values from each chroma channel
			urg_epi16 = _mm_unpackhi_epi16(u1_output_epi16, v1_output_epi16);

			// Interleave the second eight chroma values with the second eight luma values
			yuv1_epi16 = _mm_unpacklo_epi16(y2_output_epi16, urg_epi16);
			yuv2_epi16 = _mm_unpackhi_epi16(y2_output_epi16, urg_epi16);

			// Pack the second sixteen bytes of luma and chroma
			yuv2_epi8 = _mm_packus_epi16(yuv1_epi16, yuv2_epi16);

			// Store the second sixteen bytes of output values
			_mm_store_si128(outptr++, yuv2_epi8);

		}

		// Should have exited the loop with the column equal to the post processing column
	//	assert(column == post_column);

		colptr = (uint8_t *)outptr;
#endif

		// Process the rest of the columns up to the last column in the row
		for (; column < last_column; column ++)
		{
			int re,ge,be;
			int ro,go,bo;
			int ye,yo,u,v;


			/***** First pair of luma output values *****/

			// Apply the even reconstruction filter to the lowpass band
			even = 0;
			even += gg_lowpass_ptr[column - 1];
			even -= gg_lowpass_ptr[column + 1];
			even += 4; //DAN20050921
			even >>= 3;
			even += gg_lowpass_ptr[column + 0];

			// Add the highpass correction
			even += gg_highpass_ptr[column];
			even = DivideByShift(even, 1);

			// Reduce the precision to eight bits
		//	even >>= descale_shift;

			// Save the luma result for later output in the correct order
		//	y1_even_value = even;
			ge = even;

			// Apply the odd reconstruction filter to the lowpass band
			odd = 0;
			odd -= gg_lowpass_ptr[column - 1];
			odd += gg_lowpass_ptr[column + 1];
			odd += 4; //DAN20050921
			odd >>= 3;
			odd += gg_lowpass_ptr[column + 0];

			// Subtract the highpass correction
			odd -= gg_highpass_ptr[column];
			odd = DivideByShift(odd, 1);

			// Reduce the precision to eight bits
		//	odd >>= descale_shift;

			// Save the luma result for later output in the correct order
		//	y1_odd_value = odd;
			go = odd;


			/***** Pair of u chroma output values *****/

			// Apply the even reconstruction filter to the lowpass band
			even = 0;
			even += bg_lowpass_ptr[column - 1];
			even -= bg_lowpass_ptr[column + 1];
			even += 4; //DAN20050921
			even >>= 3;
			even += bg_lowpass_ptr[column + 0];

			// Add the highpass correction
			even += bg_highpass_ptr[column];
			even = DivideByShift(even, 1);

			// Reduce the precision to eight bits
		//	even >>= descale_shift;

			// Save the u chroma result for later output in the correct order
		//	bg_even_value = even;
			be = even;

			// Apply the odd reconstruction filter to the lowpass band
			odd = 0;
			odd -= bg_lowpass_ptr[column - 1];
			odd += bg_lowpass_ptr[column + 1];
			odd += 4; //DAN20050921
			odd >>= 3;
			odd += bg_lowpass_ptr[column + 0];

			// Subtract the highpass correction
			odd -= bg_highpass_ptr[column];
			odd = DivideByShift(odd, 1);

			// Reduce the precision to eight bits
		//	odd >>= descale_shift;

			// Save the u chroma result for later output in the correct order
		//	bg_odd_value = odd;
			bo = odd;



			// Apply the even reconstruction filter to the lowpass band
			even = 0;
			even += rg_lowpass_ptr[column - 1];
			even -= rg_lowpass_ptr[column + 1];
			even += 4; //DAN20050921
			even >>= 3;
			even += rg_lowpass_ptr[column + 0];

			// Add the highpass correction
			even += rg_highpass_ptr[column];
			even = DivideByShift(even, 1);

			// Reduce the precision to eight bits
		//	even >>= descale_shift;

			// Save the v chroma result for later output in the correct order
		//	rg_even_value = even;
			re = even;

			// Apply the odd reconstruction filter to the lowpass band
			odd = 0;
			odd -= rg_lowpass_ptr[column - 1];
			odd += rg_lowpass_ptr[column + 1];
			odd += 4; //DAN20050921
			odd >>= 3;
			odd += rg_lowpass_ptr[column + 0];

			// Subtract the highpass correction
			odd -= rg_highpass_ptr[column];
			odd = DivideByShift(odd, 1);

			// Reduce the precision to eight bits
		//	odd >>= descale_shift;

			// Save the v chroma result for later output in the correct order
		//	rg_odd_value = odd;
			ro = odd;


		// We use 16-bit fixed-point arithmetic to approximate the color conversion coefficients
		//
		// Floating point arithmetic is
		//
			ye = ((int)((fy_rmult * (float)re + fy_gmult * (float)ge + fy_bmult * (float)be)) >> (descale_shift + 6)) + 16;
			yo = ((int)((fy_rmult * (float)ro + fy_gmult * (float)go + fy_bmult * (float)bo)) >> (descale_shift + 6)) + 16;
			u  = ((int)((fu_rmult * (float)(re+ro) + fu_gmult * (float)(ge+go) + fu_bmult * (float)(be+bo))) >> (1 + descale_shift + 6)) + 128;
			v  = ((int)((fv_rmult * (float)(re+ro) + fv_gmult * (float)(ge+go) + fv_bmult * (float)(be+bo))) >> (1 + descale_shift + 6)) + 128;

			// Output the luma and chroma values in the correct order
			*(colptr++) = SATURATE_8U(ye);
			*(colptr++) = SATURATE_8U(u);
			*(colptr++) = SATURATE_8U(yo);
			*(colptr++) = SATURATE_8U(v);
		}

		// Should have exited the loop at the column for right border processing
	//	assert(column == last_column);
/*

		column = last_column - 1;
		colptr -= 4;

		// Process the last luma output points with special filters for the right border
		even = 0;
		odd = 0;

		// Apply the even border filter to the lowpass band
		even += 5 * gg_lowpass_ptr[column + 0];
		even += 4 * gg_lowpass_ptr[column - 1];
		even -= 1 * gg_lowpass_ptr[column - 2];
		even += ROUNDING(even,8);
		even = DivideByShift(even, 3);

		// Add the highpass correction
		even += gg_highpass_ptr[column];
		even = DivideByShift(even, 1);

		// Reduce the precision to eight bits
		//even >>= descale_shift;

		// Save the luma result for later output in the correct order
		gg_even_value = even;

		// Apply the odd border filter to the lowpass band
		odd += 11 * gg_lowpass_ptr[column + 0];
		odd -=  4 * gg_lowpass_ptr[column - 1];
		odd +=  1 * gg_lowpass_ptr[column - 2];
		odd += ROUNDING(odd,8);
		odd = DivideByShift(odd, 3);

		// Subtract the highpass correction
		odd -= gg_highpass_ptr[column];
		odd = DivideByShift(odd, 1);

		// Reduce the precision to eight bits
		//odd >>= descale_shift;

		// Save the luma result for later output in the correct order
		gg_odd_value = odd;

		// Process the last u chroma output points with special filters for the right border
		even = 0;
		odd = 0;

		// Apply the even border filter to the lowpass band
		even += 5 * bg_lowpass_ptr[column + 0];
		even += 4 * bg_lowpass_ptr[column - 1];
		even -= 1 * bg_lowpass_ptr[column - 2];
		even += ROUNDING(even,8);
		even = DivideByShift(even, 3);

		// Add the highpass correction
		even += bg_highpass_ptr[column];
		even = DivideByShift(even, 1);

		// Reduce the precision to eight bits
		//even >>= descale_shift;

		// Save the u chroma result for later output in the correct order
		bg_even_value = even;

		// Apply the odd reconstruction filter to the lowpass band
		odd += 11 * bg_lowpass_ptr[column + 0];
		odd -=  4 * bg_lowpass_ptr[column - 1];
		odd +=  1 * bg_lowpass_ptr[column - 2];
		odd += ROUNDING(odd,8);
		odd = DivideByShift(odd, 3);

		// Subtract the highpass correction
		odd -= bg_highpass_ptr[column];
		odd = DivideByShift(odd, 1);

		// Reduce the precision to eight bits
		//odd >>= descale_shift;

		// Save the u chroma result for later output in the correct order
		bg_odd_value = odd;

		// Process the last v chroma output points with special filters for the right border
		even = 0;
		odd = 0;

		// Apply the even border filter to the lowpass band
		even += 5 * rg_lowpass_ptr[column + 0];
		even += 4 * rg_lowpass_ptr[column - 1];
		even -= 1 * rg_lowpass_ptr[column - 2];
		even += ROUNDING(even,8);
		even = DivideByShift(even, 3);

		// Add the highpass correction
		even += rg_highpass_ptr[column];
		even = DivideByShift(even, 1);

		// Reduce the precision to eight bits
		//even >>= descale_shift;

		// Save the v chroma result for later output in the correct order
		rg_even_value = even;

		// Apply the odd reconstruction filter to the lowpass band
		odd += 11 * rg_lowpass_ptr[column + 0];
		odd -=  4 * rg_lowpass_ptr[column - 1];
		odd +=  1 * rg_lowpass_ptr[column - 2];
		odd += ROUNDING(odd,8);
		odd = DivideByShift(odd, 3);

		// Subtract the highpass correction
		odd -= rg_highpass_ptr[column];
		odd = DivideByShift(odd, 1);

		// Reduce the precision to eight bits
		//odd >>= descale_shift;

		// Save the v chroma result for later output in the correct order
		rg_odd_value = odd;

		//DAN06052005 - Fix for PSNR errors in UV on right edge
		colptr-=4;
		colptr++; // Y fine
		*(colptr++) = SATURATE_8U(bg_even_value);
		colptr++; // Y2 fine
		*(colptr++) = SATURATE_8U(rg_even_value);

		// Output the last luma and chroma values in the correct order
		*(colptr++) = SATURATE_8U(gg_even_value);
		*(colptr++) = SATURATE_8U(bg_odd_value);
		*(colptr++) = SATURATE_8U(gg_odd_value);
		*(colptr++) = SATURATE_8U(rg_odd_value);
*/
		// Advance to the next row of coefficients in each channel
		gg_lowpass_ptr += lowpass_pitch[0];
		bg_lowpass_ptr += lowpass_pitch[1];
		rg_lowpass_ptr += lowpass_pitch[2];
		gg_highpass_ptr += highpass_pitch[0];
		bg_highpass_ptr += highpass_pitch[1];
		rg_highpass_ptr += highpass_pitch[2];

		// Advance the output pointer to the next row
		output += output_pitch;
	}

	//_mm_empty();	// Clear the mmx register state
}

void
InvertHorizontalStripYUV16sToPackedRGB32(HorizontalFilterParams)			// Target pixel format
{
	//int num_channels = CODEC_NUM_CHANNELS;
	int height = roi.height;
	int width = roi.width;

	// Note that the u and v chroma values are swapped
	PIXEL *y_lowpass_ptr = lowpass_band[0];
	PIXEL *u_lowpass_ptr = lowpass_band[2];
	PIXEL *v_lowpass_ptr = lowpass_band[1];

	PIXEL *y_highpass_ptr = highpass_band[0];
	PIXEL *u_highpass_ptr = highpass_band[2];
	PIXEL *v_highpass_ptr = highpass_band[1];

	int y_lowpass_pitch = lowpass_pitch[0];
	int u_lowpass_pitch = lowpass_pitch[2];
	int v_lowpass_pitch = lowpass_pitch[1];

	int y_highpass_pitch = highpass_pitch[0];
	int u_highpass_pitch = highpass_pitch[2];
	int v_highpass_pitch = highpass_pitch[1];

	uint8_t *output_row_ptr = output_image;

	// Process eight luma values per loop iteration
	const int column_step = 16;

	// Need to process two luma coefficients up to the last column to allow for chroma output
	const int last_column = width - 2;
	int post_column = width - (width % column_step);

	// Need enough luma and chroma values for border processing up to the last column
	const int post_border = 2;

	// Color conversion from YUV to RGB is done using the 709 color space
	int color_space = decoder->frame.colorspace;

	// Coefficients for color conversion (YUV to RGB)
	COLOR_CONVERSION conversion_data;
	COLOR_CONVERSION *conversion = &conversion_data;

	//TODO: Modify this routine to take the color conversion coefficients as an argument


	// Should the value for alpha be passed in the color conversion coefficients?
	const int alpha = 255;

	int ymult;
	int r_vmult;
	int g_umult;
	int g_vmult;
	int b_umult;
	int y_offset;
	int shift;

	int row;

	// The even and odd luma and chroma values yield two sets of RGBA values
	int r1, g1, b1;
	int r2, g2, b2;


	// Compute the shift that reduces the precision of the reconstructed values to 8 bits
	int descale_shift = (precision - 8);

	//TODO: Eliminate descaling in the inverse filter and performing descaling during color conversion

	int luma_offset;
	int chroma_offset;

	//TODO: Move the code for computing the coefficients outside of this routine
	ComputeColorCoefficientsYUVToRGB(&conversion_data, color_space);

	//TODO: Need to scale the precision of the color conversion coefficients to 8-bits if larger
	ymult = conversion->array[0][0];
	r_vmult = conversion->array[0][2];
	g_umult = conversion->array[1][1];
	g_vmult = conversion->array[1][2];
	b_umult = conversion->array[2][1];
	y_offset = conversion->array[0][3];

	// Store the scale of the coefficients
	shift = conversion->shift;

	// Adjust the luma offset for the scale of the coefficients
	//luma_offset = conversion->luma_offset << descale_shift;
	//chroma_offset = (128 << descale_shift);

	// Apply the luma and chroma offsets after descaling
	luma_offset = conversion->luma_offset;
	chroma_offset = 128;

	// Convert the lowpass and highpass pitch to units of pixels
	y_lowpass_pitch /= sizeof(PIXEL);
	u_lowpass_pitch /= sizeof(PIXEL);
	v_lowpass_pitch /= sizeof(PIXEL);

	y_highpass_pitch /= sizeof(PIXEL);
	u_highpass_pitch /= sizeof(PIXEL);
	v_highpass_pitch /= sizeof(PIXEL);

	// Convert the output pitch to units of pixels
	output_pitch /= sizeof(uint8_t);

	// Adjust the end of the fast loop if necessary for border processing
	// DAN08112004 - ignore end row calc -- use SSE to edge.
	while (post_column > (last_column - post_border)) {
		post_column -= column_step;
	}

	// Check that there is enough margin to accommodate border processing
	assert(post_column <= (last_column - post_border));

	//*****DEBUG*****
	//post_column -= 16 * column_step;


	// Process each row of the strip
	for (row = 0; row < height; row++)
	{
#if (1 && XMMOPT)
		__m128i y_low1_epi16;		// Lowpass coefficients
		__m128i y_low2_epi16;
		__m128i u_low1_epi16;
		__m128i u_low2_epi16;
		__m128i v_low1_epi16;
		__m128i v_low2_epi16;

		__m128i y_high1_epi16;		// Highpass coefficients
		__m128i y_high2_epi16;
		__m128i u_high1_epi16;
		__m128i u_high2_epi16;
		__m128i v_high1_epi16;
		__m128i v_high2_epi16;

		// The fast loop merges values from different phases to allow aligned stores
		__m128i *output_ptr = (__m128i *)&output_row_ptr[0];

		__m128i limiterRGB = _mm_set1_epi16(0x7fff - 0x00ff);

#endif
		uint8_t *outptr = (uint8_t *)&output_row_ptr[0];

		int32_t y_even_value;
		int32_t u_even_value;
		int32_t v_even_value;
		int32_t y_odd_value;
		int32_t u_odd_value;
		int32_t v_odd_value;


		// Start processing at the beginning of the row
		int column = 0;

		// Process the first two luma output points with special filters for the left border
		int32_t even = 0;
		int32_t odd = 0;

		__m128i rounding1_epi16 = _mm_set1_epi16(0);	// for 6 bit matm
		__m128i rounding2_epi16 = _mm_set1_epi16(0);	// for 6 bit matm

		int chroma_column;

#if 0
		if (descale_shift)
		{
			//TODO: Change this code to set all values at once rather than using insert
			int mask = (1 << descale_shift) - 1;

			rounding1_epi16 = _mm_insert_epi16(rounding1_epi16, rand() & mask, 0);
			rounding1_epi16 = _mm_insert_epi16(rounding1_epi16, rand() & mask, 1);
			rounding1_epi16 = _mm_insert_epi16(rounding1_epi16, rand() & mask, 2);
			rounding1_epi16 = _mm_insert_epi16(rounding1_epi16, rand() & mask, 3);
			rounding1_epi16 = _mm_insert_epi16(rounding1_epi16, rand() & mask, 4);
			rounding1_epi16 = _mm_insert_epi16(rounding1_epi16, rand() & mask, 5);
			rounding1_epi16 = _mm_insert_epi16(rounding1_epi16, rand() & mask, 6);
			rounding1_epi16 = _mm_insert_epi16(rounding1_epi16, rand() & mask, 7);

			rounding2_epi16 = _mm_insert_epi16(rounding2_epi16, rand() & mask, 0);
			rounding2_epi16 = _mm_insert_epi16(rounding2_epi16, rand() & mask, 1);
			rounding2_epi16 = _mm_insert_epi16(rounding2_epi16, rand() & mask, 2);
			rounding2_epi16 = _mm_insert_epi16(rounding2_epi16, rand() & mask, 3);
			rounding2_epi16 = _mm_insert_epi16(rounding2_epi16, rand() & mask, 4);
			rounding2_epi16 = _mm_insert_epi16(rounding2_epi16, rand() & mask, 5);
			rounding2_epi16 = _mm_insert_epi16(rounding2_epi16, rand() & mask, 6);
			rounding2_epi16 = _mm_insert_epi16(rounding2_epi16, rand() & mask, 7);
		}
#endif

		// Apply the even reconstruction filter to the lowpass band
		even += 11 * y_lowpass_ptr[column + 0];
		even -=  4 * y_lowpass_ptr[column + 1];
		even +=  1 * y_lowpass_ptr[column + 2];
		even += ROUNDING(even,8);
		even = DivideByShift(even, 3);

		// Add the highpass correction
		even += y_highpass_ptr[column];
		even = DivideByShift(even, 1);

		// Reduce the precision to eight bits
		even >>= descale_shift;

		// Save the value for use in the fast loop
		y_even_value = even;

		// Apply the odd reconstruction filter to the lowpass band
		odd += 5 * y_lowpass_ptr[column + 0];
		odd += 4 * y_lowpass_ptr[column + 1];
		odd -= 1 * y_lowpass_ptr[column + 2];
		odd += ROUNDING(odd,8);
		odd = DivideByShift(odd, 3);

		// Subtract the highpass correction
		odd -= y_highpass_ptr[column];
		odd = DivideByShift(odd, 1);

		// Reduce the precision to eight bits
		odd >>= descale_shift;

		// Save the value for use in the fast loop
		y_odd_value = odd;


		// Process the first two u chroma output points with special filters for the left border
		even = 0;
		odd = 0;

		// Apply the even reconstruction filter to the lowpass band
		even += 11 * u_lowpass_ptr[column + 0];
		even -=  4 * u_lowpass_ptr[column + 1];
		even +=  1 * u_lowpass_ptr[column + 2];
		even += ROUNDING(even,8);
		even = DivideByShift(even, 3);

		// Add the highpass correction
		even += u_highpass_ptr[column];
		even = DivideByShift(even, 1);

		// Reduce the precision to eight bits
		even >>= descale_shift;

		// Save the value for use in the fast loop
		u_even_value = even;

		// Apply the odd reconstruction filter to the lowpass band
		odd += 5 * u_lowpass_ptr[column + 0];
		odd += 4 * u_lowpass_ptr[column + 1];
		odd -= 1 * u_lowpass_ptr[column + 2];
		odd += ROUNDING(odd,8);
		odd = DivideByShift(odd, 3);

		// Subtract the highpass correction
		odd -= u_highpass_ptr[column];
		odd = DivideByShift(odd, 1);

		// Reduce the precision to eight bits
		odd >>= descale_shift;

		// Save the value for use in the fast loop
		u_odd_value = odd;


		// Process the first two v chroma output points with special filters for the left border
		even = 0;
		odd = 0;

		// Apply the even reconstruction filter to the lowpass band
		even += 11 * v_lowpass_ptr[column + 0];
		even -=  4 * v_lowpass_ptr[column + 1];
		even +=  1 * v_lowpass_ptr[column + 2];
		even += ROUNDING(even,8);
		even = DivideByShift(even, 3);

		// Add the highpass correction
		even += v_highpass_ptr[column];
		even = DivideByShift(even, 1);

		// Reduce the precision to eight bits
		even >>= descale_shift;

		// Save the value for use in the fast loop
		v_even_value = even;

		// Apply the odd reconstruction filter to the lowpass band
		odd += 5 * v_lowpass_ptr[column + 0];
		odd += 4 * v_lowpass_ptr[column + 1];
		odd -= 1 * v_lowpass_ptr[column + 2];
		odd += ROUNDING(odd,8);
		odd = DivideByShift(odd, 3);

		// Subtract the highpass correction
		odd -= v_highpass_ptr[column];
		odd = DivideByShift(odd, 1);

		// Reduce the precision to eight bits
		odd >>= descale_shift;

		// Save the value for use in the fast loop
		v_odd_value = odd;

#if (1 && XMMOPT)

		// Preload the first eight lowpass luma coefficients
		y_low1_epi16 = _mm_load_si128((__m128i *)&y_lowpass_ptr[0]);

		// Preload the first eight highpass luma coefficients
		y_high1_epi16 = _mm_load_si128((__m128i *)&y_highpass_ptr[0]);

		// Preload the first eight lowpass u chroma coefficients
		u_low1_epi16 = _mm_load_si128((__m128i *)&u_lowpass_ptr[0]);

		// Preload the first eight highpass u chroma coefficients
		u_high1_epi16 = _mm_load_si128((__m128i *)&u_highpass_ptr[0]);

		// Preload the first eight lowpass v chroma coefficients
		v_low1_epi16 = _mm_load_si128((__m128i *)&v_lowpass_ptr[0]);

		// Preload the first eight highpass v chroma coefficients
 		v_high1_epi16 = _mm_load_si128((__m128i *)&v_highpass_ptr[0]);


		// The reconstruction filters use pixels starting at the first column
		for (; column < post_column; column += column_step)
		{
			__m128i y1_output_epi16;
			__m128i y2_output_epi16;
			__m128i u1_output_epi16;
			__m128i u2_output_epi16;
			__m128i y3_output_epi16;
			__m128i y4_output_epi16;
			__m128i v1_output_epi16;
			__m128i v2_output_epi16;
			
			__m128i even_epi16;		// Result of convolution with even filter
			__m128i odd_epi16;		// Result of convolution with odd filter

			__m128i temp_epi16;

			__m128i yy_epi16;
			__m128i uu_epi16;
			__m128i vv_epi16;

			__m128i out_epi16;		// Reconstructed data

			__m128i low1_epi16;
			__m128i low2_epi16;
			__m128i high1_epi16;
			__m128i high2_epi16;

			//DAN031304 -- correct inverse filter
			__m128i half_epi16 = _mm_set1_epi16(4);
			__m128i offset_epi16 = _mm_set1_epi16(2048);

			__m128i r1_epi16;
			__m128i g1_epi16;
			__m128i b1_epi16;

			__m128i r2_epi16;
			__m128i g2_epi16;
			__m128i b2_epi16;

			__m128i t1_epi16;
			__m128i t2_epi16;

			__m128i r_epi8;
			__m128i g_epi8;
			__m128i b_epi8;

			__m128i luma_offset_epi16 = _mm_set1_epi16(luma_offset);
			__m128i chroma_offset_epi16 = _mm_set1_epi16(chroma_offset);

			__m128i alpha_epi8 = _mm_set1_epi8(alpha);

			__m128i rg_epi8;
			__m128i ba_epi8;
			__m128i rgba_epi8;

			__m128i rounding_epi16 = _mm_set1_epi16(32);	// 6 bit half

			uint32_t temp;		// Temporary register for last two values

			// Chroma is 4:2:2 subsampled relative to the overall image
			chroma_column = column / 2;


			/***** Compute the first eight luma output values *****/

			// Preload the next eight lowpass coefficients
			y_low2_epi16 = _mm_load_si128((__m128i *)&y_lowpass_ptr[column + 8]);

			// Preload the next eight highpass coefficients
			y_high2_epi16 = _mm_load_si128((__m128i *)&y_highpass_ptr[column + 8]);

			// Move the current set of luma values to the working registers
			low1_epi16 = y_low1_epi16;
			high1_epi16 = y_high1_epi16;

			// Apply the even reconstruction filter to the lowpass band
			even_epi16 = low1_epi16;
			temp_epi16 = _mm_srli_si128(even_epi16, 2*2);
			even_epi16 = _mm_subs_epi16(even_epi16, temp_epi16);
			even_epi16 = _mm_adds_epi16(even_epi16, half_epi16);
			even_epi16 = _mm_srai_epi16(even_epi16, 3);
			temp_epi16 = _mm_srli_si128(low1_epi16, 1*2);
			even_epi16 = _mm_adds_epi16(even_epi16, temp_epi16);

			// Shift the highpass correction by one column
			high1_epi16 = _mm_srli_si128(high1_epi16, 1*2);

			// Add the highpass correction and divide by two
			even_epi16 = _mm_adds_epi16(even_epi16, offset_epi16);
			even_epi16 = _mm_adds_epi16(even_epi16, high1_epi16);
			even_epi16 = _mm_subs_epu16(even_epi16, offset_epi16);
			even_epi16 = _mm_srai_epi16(even_epi16, 1);

			// Apply the odd reconstruction filter to the lowpass band
			odd_epi16 = _mm_srli_si128(low1_epi16, 2*2);
			temp_epi16 = low1_epi16;
			odd_epi16 = _mm_subs_epi16(odd_epi16, temp_epi16);
			odd_epi16 = _mm_adds_epi16(odd_epi16, half_epi16);
			odd_epi16 = _mm_srai_epi16(odd_epi16, 3);
			temp_epi16 = _mm_srli_si128(low1_epi16, 1*2);
			odd_epi16 = _mm_adds_epi16(odd_epi16, temp_epi16);

			// Subtract the highpass correction and divide by two
			odd_epi16 = _mm_adds_epi16(odd_epi16, offset_epi16);
			odd_epi16 = _mm_subs_epi16(odd_epi16, high1_epi16);
			odd_epi16 = _mm_subs_epu16(odd_epi16, offset_epi16);
			odd_epi16 = _mm_srai_epi16(odd_epi16, 1);

			// Interleave the four even and four odd results
			out_epi16 = _mm_unpacklo_epi16(even_epi16, odd_epi16);

			// Reduce the precision to eight bits
			out_epi16 = _mm_adds_epi16(out_epi16, rounding1_epi16);
			out_epi16 = _mm_srli_epi16(out_epi16, descale_shift);

			// Combine the new output values with the two values from the previous phase
			out_epi16 = _mm_shuffle_epi32(out_epi16, _MM_SHUFFLE(2, 1, 0, 3));
			temp = _mm_cvtsi128_si32(out_epi16);
			out_epi16 = _mm_insert_epi16(out_epi16, y_even_value, 0);
			out_epi16 = _mm_insert_epi16(out_epi16, y_odd_value, 1);

			// Save the eight luma values for packing later
			y1_output_epi16 = out_epi16;

			// Save the remaining two output values
			y_even_value = (short)temp;
			y_odd_value = (short)(temp >> 16);


			/***** Compute the second eight luma output values *****/

			// Move the next set of luma values to the working registers
			low2_epi16 = y_low2_epi16;
			high2_epi16 = y_high2_epi16;

			// Shift in the new pixels for the next stage of the loop
			low1_epi16 = _mm_srli_si128(low1_epi16, 4*2);
			temp_epi16 = _mm_slli_si128(low2_epi16, 4*2);
			low1_epi16 = _mm_or_si128(low1_epi16, temp_epi16);

			// Apply the even reconstruction filter to the lowpass band
			even_epi16 = low1_epi16;
			temp_epi16 = _mm_srli_si128(even_epi16, 2*2);
			even_epi16 = _mm_subs_epi16(even_epi16, temp_epi16);
			even_epi16 = _mm_adds_epi16(even_epi16, half_epi16);
			even_epi16 = _mm_srai_epi16(even_epi16, 3);
			temp_epi16 = _mm_srli_si128(low1_epi16, 1*2);
			even_epi16 = _mm_adds_epi16(even_epi16, temp_epi16);

			// Shift in the next four highpass coefficients
			high1_epi16 = _mm_srli_si128(high1_epi16, 4*2);
			temp_epi16 = _mm_slli_si128(high2_epi16, 3*2);
			high1_epi16 = _mm_or_si128(high1_epi16, temp_epi16);

			// Add the highpass correction and divide by two
			even_epi16 = _mm_adds_epi16(even_epi16, offset_epi16);
			even_epi16 = _mm_adds_epi16(even_epi16, high1_epi16);
			even_epi16 = _mm_subs_epu16(even_epi16, offset_epi16);
			even_epi16 = _mm_srai_epi16(even_epi16, 1);

			// Apply the odd reconstruction filter to the lowpass band
			odd_epi16 = _mm_srli_si128(low1_epi16, 2*2);
			temp_epi16 = low1_epi16;
			odd_epi16 = _mm_subs_epi16(odd_epi16, temp_epi16);
			odd_epi16 = _mm_adds_epi16(odd_epi16, half_epi16);
			odd_epi16 = _mm_srai_epi16(odd_epi16, 3);
			temp_epi16 = _mm_srli_si128(low1_epi16, 1*2);
			odd_epi16 = _mm_adds_epi16(odd_epi16, temp_epi16);

			// Subtract the highpass correction and divide by two
			odd_epi16 = _mm_adds_epi16(odd_epi16, offset_epi16);
			odd_epi16 = _mm_subs_epi16(odd_epi16, high1_epi16);
			odd_epi16 = _mm_subs_epu16(odd_epi16, offset_epi16);
			odd_epi16 = _mm_srai_epi16(odd_epi16, 1);

			// Interleave the four even and four odd results
			out_epi16 = _mm_unpacklo_epi16(even_epi16, odd_epi16);

			// Reduce the precision to eight bits
			out_epi16 = _mm_adds_epi16(out_epi16, rounding2_epi16);
			out_epi16 = _mm_srli_epi16(out_epi16, descale_shift);

			// Combine the new output values with the two values from the previous phase
			out_epi16 = _mm_shuffle_epi32(out_epi16, _MM_SHUFFLE(2, 1, 0, 3));
			temp = _mm_cvtsi128_si32(out_epi16);
			out_epi16 = _mm_insert_epi16(out_epi16, y_even_value, 0);
			out_epi16 = _mm_insert_epi16(out_epi16, y_odd_value, 1);

			// Save the eight luma values for packing later
			y2_output_epi16 = out_epi16;

			// Save the remaining two output values
			y_even_value = (short)temp;
			y_odd_value = (short)(temp >> 16);

			// Use the second eight lowpass and highpass coefficients later in this loop
			y_low1_epi16 = y_low2_epi16;
			y_high1_epi16 = y_high2_epi16;


			/***** Compute the first eight u chroma output values *****/

			// Preload the next eight lowpass coefficients
			u_low2_epi16 = _mm_load_si128((__m128i *)&u_lowpass_ptr[chroma_column + 8]);

			// Preload the next eight highpass coefficients
			u_high2_epi16 = _mm_load_si128((__m128i *)&u_highpass_ptr[chroma_column + 8]);

			// Move the current set of chroma values to the working registers
			low1_epi16 = u_low1_epi16;
			high1_epi16 = u_high1_epi16;

			// Apply the even reconstruction filter to the lowpass band
			even_epi16 = low1_epi16;
			temp_epi16 = _mm_srli_si128(even_epi16, 2*2);
			even_epi16 = _mm_subs_epi16(even_epi16, temp_epi16);
			even_epi16 = _mm_adds_epi16(even_epi16, half_epi16);
			even_epi16 = _mm_srai_epi16(even_epi16, 3);
			temp_epi16 = _mm_srli_si128(low1_epi16, 1*2);
			even_epi16 = _mm_adds_epi16(even_epi16, temp_epi16);

			// Shift the highpass correction by one column
			high1_epi16 = _mm_srli_si128(high1_epi16, 1*2);

			// Add the highpass correction and divide by two
			even_epi16 = _mm_adds_epi16(even_epi16, offset_epi16);
			even_epi16 = _mm_adds_epi16(even_epi16, high1_epi16);
			even_epi16 = _mm_subs_epu16(even_epi16, offset_epi16);
			even_epi16 = _mm_srai_epi16(even_epi16, 1);

			// Apply the odd reconstruction filter to the lowpass band
			odd_epi16 = _mm_srli_si128(low1_epi16, 2*2);
			temp_epi16 = low1_epi16;
			odd_epi16 = _mm_subs_epi16(odd_epi16, temp_epi16);
			odd_epi16 = _mm_adds_epi16(odd_epi16, half_epi16);
			odd_epi16 = _mm_srai_epi16(odd_epi16, 3);
			temp_epi16 = _mm_srli_si128(low1_epi16, 1*2);
			odd_epi16 = _mm_adds_epi16(odd_epi16, temp_epi16);

			// Subtract the highpass correction and divide by two
			odd_epi16 = _mm_adds_epi16(odd_epi16, offset_epi16);
			odd_epi16 = _mm_subs_epi16(odd_epi16, high1_epi16);
			odd_epi16 = _mm_subs_epu16(odd_epi16, offset_epi16);
			odd_epi16 = _mm_srai_epi16(odd_epi16, 1);

			// Interleave the four even and four odd results
			out_epi16 = _mm_unpacklo_epi16(even_epi16, odd_epi16);

			// Reduce the precision to eight bits
			out_epi16 = _mm_adds_epi16(out_epi16, rounding1_epi16);
			out_epi16 = _mm_srli_epi16(out_epi16, descale_shift);

			// Combine the new output values with the two values from the previous phase
			out_epi16 = _mm_shuffle_epi32(out_epi16, _MM_SHUFFLE(2, 1, 0, 3));
			temp = _mm_cvtsi128_si32(out_epi16);
			out_epi16 = _mm_insert_epi16(out_epi16, u_even_value, 0);
			out_epi16 = _mm_insert_epi16(out_epi16, u_odd_value, 1);

			// Save the eight u chroma values for packing later
			u1_output_epi16 = out_epi16;

			// Save the remaining two output values
			u_even_value = (short)temp;
			u_odd_value = (short)(temp >> 16);


			/***** Compute the second eight u chroma output values *****/

			// Move the next set of coefficients to working registers
			low2_epi16 = u_low2_epi16;
			high2_epi16 = u_high2_epi16;

			// Shift in the new pixels for the next stage of the loop
			low1_epi16 = _mm_srli_si128(low1_epi16, 4*2);
			temp_epi16 = _mm_slli_si128(low2_epi16, 4*2);
			low1_epi16 = _mm_or_si128(low1_epi16, temp_epi16);

			// Apply the even reconstruction filter to the lowpass band
			even_epi16 = low1_epi16;
			temp_epi16 = _mm_srli_si128(even_epi16, 2*2);
			even_epi16 = _mm_subs_epi16(even_epi16, temp_epi16);
			even_epi16 = _mm_adds_epi16(even_epi16, half_epi16);
			even_epi16 = _mm_srai_epi16(even_epi16, 3);
			temp_epi16 = _mm_srli_si128(low1_epi16, 1*2);
			even_epi16 = _mm_adds_epi16(even_epi16, temp_epi16);

			// Shift in the next four highpass coefficients
			high1_epi16 = _mm_srli_si128(high1_epi16, 4*2);
			temp_epi16 = _mm_slli_si128(high2_epi16, 3*2);
			high1_epi16 = _mm_or_si128(high1_epi16, temp_epi16);

			// Add the highpass correction and divide by two
			even_epi16 = _mm_adds_epi16(even_epi16, offset_epi16);
			even_epi16 = _mm_adds_epi16(even_epi16, high1_epi16);
			even_epi16 = _mm_subs_epu16(even_epi16, offset_epi16);
			even_epi16 = _mm_srai_epi16(even_epi16, 1);

			// Apply the odd reconstruction filter to the lowpass band
			odd_epi16 = _mm_srli_si128(low1_epi16, 2*2);
			temp_epi16 = low1_epi16;
			odd_epi16 = _mm_subs_epi16(odd_epi16, temp_epi16);
			odd_epi16 = _mm_adds_epi16(odd_epi16, half_epi16);
			odd_epi16 = _mm_srai_epi16(odd_epi16, 3);
			temp_epi16 = _mm_srli_si128(low1_epi16, 1*2);
			odd_epi16 = _mm_adds_epi16(odd_epi16, temp_epi16);

			// Subtract the highpass correction and divide by two
			odd_epi16 = _mm_adds_epi16(odd_epi16, offset_epi16);
			odd_epi16 = _mm_subs_epi16(odd_epi16, high1_epi16);
			odd_epi16 = _mm_subs_epu16(odd_epi16, offset_epi16);
			odd_epi16 = _mm_srai_epi16(odd_epi16, 1);

			// Interleave the four even and four odd results
			out_epi16 = _mm_unpacklo_epi16(even_epi16, odd_epi16);

			// Reduce the precision to eight bits
			out_epi16 = _mm_adds_epi16(out_epi16, rounding2_epi16);
			out_epi16 = _mm_srli_epi16(out_epi16, descale_shift);

			// Combine the new output values with the two values from the previous phase
			out_epi16 = _mm_shuffle_epi32(out_epi16, _MM_SHUFFLE(2, 1, 0, 3));
			temp = _mm_cvtsi128_si32(out_epi16);
			out_epi16 = _mm_insert_epi16(out_epi16, u_even_value, 0);
			out_epi16 = _mm_insert_epi16(out_epi16, u_odd_value, 1);

			// Save the eight u chroma values for packing later
			u2_output_epi16 = out_epi16;

			// Save the remaining two output values
			u_even_value = (short)temp;
			u_odd_value = (short)(temp >> 16);

			// Use the second eight lowpass and highpass coefficients in the next iteration
			u_low1_epi16 = u_low2_epi16;
			u_high1_epi16 = u_high2_epi16;


			/***** Compute the third eight luma output values *****/

			// Preload the next eight lowpass coefficients
			y_low2_epi16 = _mm_load_si128((__m128i *)&y_lowpass_ptr[column + 16]);

			// Preload the second eight highpass coefficients
			y_high2_epi16 = _mm_load_si128((__m128i *)&y_highpass_ptr[column + 16]);

			// Move the current set of luma values to the working registers
			low1_epi16 = y_low1_epi16;
			high1_epi16 = y_high1_epi16;

			// Apply the even reconstruction filter to the lowpass band
			even_epi16 = low1_epi16;
			temp_epi16 = _mm_srli_si128(even_epi16, 2*2);
			even_epi16 = _mm_subs_epi16(even_epi16, temp_epi16);
			even_epi16 = _mm_adds_epi16(even_epi16, half_epi16);
			even_epi16 = _mm_srai_epi16(even_epi16, 3);
			temp_epi16 = _mm_srli_si128(low1_epi16, 1*2);
			even_epi16 = _mm_adds_epi16(even_epi16, temp_epi16);

			// Shift the highpass correction by one column
			high1_epi16 = _mm_srli_si128(high1_epi16, 1*2);

			// Add the highpass correction and divide by two
			even_epi16 = _mm_adds_epi16(even_epi16, offset_epi16);
			even_epi16 = _mm_adds_epi16(even_epi16, high1_epi16);
			even_epi16 = _mm_subs_epu16(even_epi16, offset_epi16);
			even_epi16 = _mm_srai_epi16(even_epi16, 1);

			// Apply the odd reconstruction filter to the lowpass band
			odd_epi16 = _mm_srli_si128(low1_epi16, 2*2);
			temp_epi16 = low1_epi16;
			odd_epi16 = _mm_subs_epi16(odd_epi16, temp_epi16);
			odd_epi16 = _mm_adds_epi16(odd_epi16, half_epi16);
			odd_epi16 = _mm_srai_epi16(odd_epi16, 3);
			temp_epi16 = _mm_srli_si128(low1_epi16, 1*2);
			odd_epi16 = _mm_adds_epi16(odd_epi16, temp_epi16);

			// Subtract the highpass correction and divide by two
			odd_epi16 = _mm_adds_epi16(odd_epi16, offset_epi16);
			odd_epi16 = _mm_subs_epi16(odd_epi16, high1_epi16);
			odd_epi16 = _mm_subs_epu16(odd_epi16, offset_epi16);
			odd_epi16 = _mm_srai_epi16(odd_epi16, 1);

			// Interleave the four even and four odd results
			out_epi16 = _mm_unpacklo_epi16(even_epi16, odd_epi16);

			// Reduce the precision to eight bits
			out_epi16 = _mm_adds_epi16(out_epi16, rounding1_epi16);
			out_epi16 = _mm_srli_epi16(out_epi16, descale_shift);

			// Combine the new output values with the two values from the previous phase
			out_epi16 = _mm_shuffle_epi32(out_epi16, _MM_SHUFFLE(2, 1, 0, 3));
			temp = _mm_cvtsi128_si32(out_epi16);
			out_epi16 = _mm_insert_epi16(out_epi16, y_even_value, 0);
			out_epi16 = _mm_insert_epi16(out_epi16, y_odd_value, 1);

			// Save the eight luma values for packing later
			y3_output_epi16 = out_epi16;

			// Save the remaining two output values
			y_even_value = (short)temp;
			y_odd_value = (short)(temp >> 16);


			/***** Compute the fourth eight luma output values *****/

			// Move the next set of luma values to the working registers
			low2_epi16 = y_low2_epi16;
			high2_epi16 = y_high2_epi16;

			// Shift in the new pixels for the next stage of the loop
			low1_epi16 = _mm_srli_si128(low1_epi16, 4*2);
			temp_epi16 = _mm_slli_si128(low2_epi16, 4*2);
			low1_epi16 = _mm_or_si128(low1_epi16, temp_epi16);

			// Apply the even reconstruction filter to the lowpass band
			even_epi16 = low1_epi16;
			temp_epi16 = _mm_srli_si128(even_epi16, 2*2);
			even_epi16 = _mm_subs_epi16(even_epi16, temp_epi16);
			even_epi16 = _mm_adds_epi16(even_epi16, half_epi16);
			even_epi16 = _mm_srai_epi16(even_epi16, 3);
			temp_epi16 = _mm_srli_si128(low1_epi16, 1*2);
			even_epi16 = _mm_adds_epi16(even_epi16, temp_epi16);

			// Shift in the next four highpass coefficients
			high1_epi16 = _mm_srli_si128(high1_epi16, 4*2);
			temp_epi16 = _mm_slli_si128(high2_epi16, 3*2);
			high1_epi16 = _mm_or_si128(high1_epi16, temp_epi16);

			// Add the highpass correction and divide by two
			even_epi16 = _mm_adds_epi16(even_epi16, offset_epi16);
			even_epi16 = _mm_adds_epi16(even_epi16, high1_epi16);
			even_epi16 = _mm_subs_epu16(even_epi16, offset_epi16);
			even_epi16 = _mm_srai_epi16(even_epi16, 1);

			// Apply the odd reconstruction filter to the lowpass band
			odd_epi16 = _mm_srli_si128(low1_epi16, 2*2);
			temp_epi16 = low1_epi16;
			odd_epi16 = _mm_subs_epi16(odd_epi16, temp_epi16);
			odd_epi16 = _mm_adds_epi16(odd_epi16, half_epi16);
			odd_epi16 = _mm_srai_epi16(odd_epi16, 3);
			temp_epi16 = _mm_srli_si128(low1_epi16, 1*2);
			odd_epi16 = _mm_adds_epi16(odd_epi16, temp_epi16);

			// Subtract the highpass correction and divide by two
			odd_epi16 = _mm_adds_epi16(odd_epi16, offset_epi16);
			odd_epi16 = _mm_subs_epi16(odd_epi16, high1_epi16);
			odd_epi16 = _mm_subs_epu16(odd_epi16, offset_epi16);
			odd_epi16 = _mm_srai_epi16(odd_epi16, 1);

			// Interleave the four even and four odd results
			out_epi16 = _mm_unpacklo_epi16(even_epi16, odd_epi16);

			// Reduce the precision to eight bits
			out_epi16 = _mm_adds_epi16(out_epi16, rounding2_epi16);
			out_epi16 = _mm_srli_epi16(out_epi16, descale_shift);

			// Combine the new output values with the two values from the previous phase
			out_epi16 = _mm_shuffle_epi32(out_epi16, _MM_SHUFFLE(2, 1, 0, 3));
			temp = _mm_cvtsi128_si32(out_epi16);
			out_epi16 = _mm_insert_epi16(out_epi16, y_even_value, 0);
			out_epi16 = _mm_insert_epi16(out_epi16, y_odd_value, 1);

			// Save the eight luma values for packing later
			y4_output_epi16 = out_epi16;

			// Save the remaining two output values
			y_even_value = (short)temp;
			y_odd_value = (short)(temp >> 16);

			// Use the second eight lowpass and highpass coefficients in the next iteration
			y_low1_epi16 = y_low2_epi16;
			y_high1_epi16 = y_high2_epi16;


			/***** Compute the first eight v chroma output values *****/

			// Preload the next eight lowpass coefficients
			v_low2_epi16 = _mm_load_si128((__m128i *)&v_lowpass_ptr[chroma_column + 8]);

			// Preload the next eight highpass coefficients
			v_high2_epi16 = _mm_load_si128((__m128i *)&v_highpass_ptr[chroma_column + 8]);

			// Move the current set of coefficients to working registers
			low1_epi16 = v_low1_epi16;
			high1_epi16 = v_high1_epi16;

			// Apply the even reconstruction filter to the lowpass band
			even_epi16 = low1_epi16;
			temp_epi16 = _mm_srli_si128(even_epi16, 2*2);
			even_epi16 = _mm_subs_epi16(even_epi16, temp_epi16);
			even_epi16 = _mm_adds_epi16(even_epi16, half_epi16);
			even_epi16 = _mm_srai_epi16(even_epi16, 3);
			temp_epi16 = _mm_srli_si128(low1_epi16, 1*2);
			even_epi16 = _mm_adds_epi16(even_epi16, temp_epi16);

			// Shift the highpass correction by one column
			high1_epi16 = _mm_srli_si128(high1_epi16, 1*2);

			// Add the highpass correction and divide by two
			even_epi16 = _mm_adds_epi16(even_epi16, offset_epi16);
			even_epi16 = _mm_adds_epi16(even_epi16, high1_epi16);
			even_epi16 = _mm_subs_epu16(even_epi16, offset_epi16);
			even_epi16 = _mm_srai_epi16(even_epi16, 1);

			// Apply the odd reconstruction filter to the lowpass band
			odd_epi16 = _mm_srli_si128(low1_epi16, 2*2);
			temp_epi16 = low1_epi16;
			odd_epi16 = _mm_subs_epi16(odd_epi16, temp_epi16);
			odd_epi16 = _mm_adds_epi16(odd_epi16, half_epi16);
			odd_epi16 = _mm_srai_epi16(odd_epi16, 3);
			temp_epi16 = _mm_srli_si128(low1_epi16, 1*2);
			odd_epi16 = _mm_adds_epi16(odd_epi16, temp_epi16);

			// Subtract the highpass correction and divide by two
			odd_epi16 = _mm_adds_epi16(odd_epi16, offset_epi16);
			odd_epi16 = _mm_subs_epi16(odd_epi16, high1_epi16);
			odd_epi16 = _mm_subs_epu16(odd_epi16, offset_epi16);
			odd_epi16 = _mm_srai_epi16(odd_epi16, 1);

			// Interleave the four even and four odd results
			out_epi16 = _mm_unpacklo_epi16(even_epi16, odd_epi16);

			// Reduce the precision to eight bits
			out_epi16 = _mm_adds_epi16(out_epi16, rounding1_epi16);
			out_epi16 = _mm_srli_epi16(out_epi16, descale_shift);

			// Combine the new output values with the two values from the previous phase
			out_epi16 = _mm_shuffle_epi32(out_epi16, _MM_SHUFFLE(2, 1, 0, 3));
			temp = _mm_cvtsi128_si32(out_epi16);
			out_epi16 = _mm_insert_epi16(out_epi16, v_even_value, 0);
			out_epi16 = _mm_insert_epi16(out_epi16, v_odd_value, 1);

			// Save the eight v chroma values for packing later
			v1_output_epi16 = out_epi16;

			// Save the remaining two output values
			v_even_value = (short)temp;
			v_odd_value = (short)(temp >> 16);


			/***** Compute the second eight v chroma output values *****/

			// Move the next set of coefficients to working registers
			low2_epi16 = v_low2_epi16;
			high2_epi16 = v_high2_epi16;

			// Shift in the new pixels for the next stage of the loop
			low1_epi16 = _mm_srli_si128(low1_epi16, 4*2);
			temp_epi16 = _mm_slli_si128(low2_epi16, 4*2);
			low1_epi16 = _mm_or_si128(low1_epi16, temp_epi16);

			// Apply the even reconstruction filter to the lowpass band
			even_epi16 = low1_epi16;
			temp_epi16 = _mm_srli_si128(even_epi16, 2*2);
			even_epi16 = _mm_subs_epi16(even_epi16, temp_epi16);
			even_epi16 = _mm_adds_epi16(even_epi16, half_epi16);
			even_epi16 = _mm_srai_epi16(even_epi16, 3);
			temp_epi16 = _mm_srli_si128(low1_epi16, 1*2);
			even_epi16 = _mm_adds_epi16(even_epi16, temp_epi16);

			// Shift in the next four highpass coefficients
			high1_epi16 = _mm_srli_si128(high1_epi16, 4*2);
			temp_epi16 = _mm_slli_si128(high2_epi16, 3*2);
			high1_epi16 = _mm_or_si128(high1_epi16, temp_epi16);

			// Add the highpass correction and divide by two
			even_epi16 = _mm_adds_epi16(even_epi16, offset_epi16);
			even_epi16 = _mm_adds_epi16(even_epi16, high1_epi16);
			even_epi16 = _mm_subs_epu16(even_epi16, offset_epi16);
			even_epi16 = _mm_srai_epi16(even_epi16, 1);

			// Apply the odd reconstruction filter to the lowpass band
			odd_epi16 = _mm_srli_si128(low1_epi16, 2*2);
			temp_epi16 = low1_epi16;
			odd_epi16 = _mm_subs_epi16(odd_epi16, temp_epi16);
			odd_epi16 = _mm_adds_epi16(odd_epi16, half_epi16);
			odd_epi16 = _mm_srai_epi16(odd_epi16, 3);
			temp_epi16 = _mm_srli_si128(low1_epi16, 1*2);
			odd_epi16 = _mm_adds_epi16(odd_epi16, temp_epi16);

			// Subtract the highpass correction and divide by two
			odd_epi16 = _mm_adds_epi16(odd_epi16, offset_epi16);
			odd_epi16 = _mm_subs_epi16(odd_epi16, high1_epi16);
			odd_epi16 = _mm_subs_epu16(odd_epi16, offset_epi16);
			odd_epi16 = _mm_srai_epi16(odd_epi16, 1);

			// Interleave the four even and four odd results
			out_epi16 = _mm_unpacklo_epi16(even_epi16, odd_epi16);

			// Reduce the precision to eight bits
			out_epi16 = _mm_adds_epi16(out_epi16, rounding2_epi16);
			out_epi16 = _mm_srli_epi16(out_epi16, descale_shift);

			// Combine the new output values with the two values from the previous phase
			out_epi16 = _mm_shuffle_epi32(out_epi16, _MM_SHUFFLE(2, 1, 0, 3));
			temp = _mm_cvtsi128_si32(out_epi16);
			out_epi16 = _mm_insert_epi16(out_epi16, v_even_value, 0);
			out_epi16 = _mm_insert_epi16(out_epi16, v_odd_value, 1);

			// Save the eight u chroma values for packing later
			v2_output_epi16 = out_epi16;

			// Save the remaining two output values
			v_even_value = (short)temp;
			v_odd_value = (short)(temp >> 16);

			// Use the second eight lowpass and highpass coefficients in the next iteration
			v_low1_epi16 = v_low2_epi16;
			v_high1_epi16 = v_high2_epi16;


			/***** Have computed 32 luma values and 16 of each chroma value *****/

#if (0 && DEBUG)
			u1_output_epi16 = chroma_offset_epi16;
			u2_output_epi16 = chroma_offset_epi16;
			v1_output_epi16 = chroma_offset_epi16;
			v2_output_epi16 = chroma_offset_epi16;
#endif

			/***** Compute the first set of eight RGBA output values *****/

			// Duplicate the first four chroma values
			uu_epi16 = _mm_unpacklo_epi16(u1_output_epi16, u1_output_epi16);
			vv_epi16 = _mm_unpacklo_epi16(v1_output_epi16, v1_output_epi16);

			// Convert YUV to eight RGB tuples
			yy_epi16 = _mm_subs_epi16(y1_output_epi16, luma_offset_epi16);

			// This code fixed overflow case where very bright pixels
			// with some color produced interim values larger than 32768

			yy_epi16 = _mm_adds_epi16(yy_epi16, limiterRGB); // Y to 0 to 255  -- DAN20101102
			yy_epi16 = _mm_subs_epu16(yy_epi16, limiterRGB);
			uu_epi16 = _mm_adds_epi16(uu_epi16, limiterRGB); // U to 0 to 255  -- DAN20101102
			uu_epi16 = _mm_subs_epu16(uu_epi16, limiterRGB);
			vv_epi16 = _mm_adds_epi16(vv_epi16, limiterRGB); // V to 0 to 255  -- DAN20101102
			vv_epi16 = _mm_subs_epu16(vv_epi16, limiterRGB);

			uu_epi16 = _mm_subs_epi16(uu_epi16, chroma_offset_epi16);
			vv_epi16 = _mm_subs_epi16(vv_epi16, chroma_offset_epi16);

			yy_epi16 = _mm_slli_epi16(yy_epi16, 7);
			yy_epi16 = _mm_mulhi_epi16(yy_epi16, _mm_set1_epi16(ymult));
			yy_epi16 = _mm_slli_epi16(yy_epi16, 1);

			// Calculate red
			t1_epi16 = _mm_set1_epi16(r_vmult);
			t1_epi16 = _mm_mullo_epi16(vv_epi16, t1_epi16);
			t1_epi16 = _mm_srai_epi16(t1_epi16, 1);		// 7 bits to 6 bits
			r1_epi16 = _mm_adds_epi16(yy_epi16, t1_epi16);
			//r1_epi16 = _mm_adds_epi16(yy_epi16, t1_epi16);
			r1_epi16 = _mm_adds_epi16(r1_epi16, rounding_epi16);
			r1_epi16 = _mm_srai_epi16(r1_epi16, 6);

			// Calculate green
			t1_epi16 = _mm_set1_epi16(g_vmult);
			t1_epi16 = _mm_mullo_epi16(vv_epi16, t1_epi16);
			t1_epi16 = _mm_srai_epi16(t1_epi16, 2);		// 8 bits to 6 bits
			g1_epi16 = _mm_subs_epi16(yy_epi16, t1_epi16);
			t1_epi16 = _mm_set1_epi16(g_umult);
			t1_epi16 = _mm_mullo_epi16(uu_epi16, t1_epi16);
			t1_epi16 = _mm_srai_epi16(t1_epi16, 2);		// 8 bits to 6 bits
			g1_epi16 = _mm_subs_epi16(g1_epi16, t1_epi16);
			g1_epi16 = _mm_adds_epi16(g1_epi16, rounding_epi16);
			g1_epi16 = _mm_srai_epi16(g1_epi16, 6);

			// Calculate blue
			t1_epi16 = _mm_set1_epi16(b_umult);
			t1_epi16 = _mm_mullo_epi16(uu_epi16, t1_epi16);
			b1_epi16 = _mm_adds_epi16(yy_epi16, t1_epi16);
			b1_epi16 = _mm_adds_epi16(b1_epi16, rounding_epi16);
			b1_epi16 = _mm_srai_epi16(b1_epi16, 6);


			/***** Compute the second set of eight RGBA output values *****/

			// Duplicate the second four chroma values
			uu_epi16 = _mm_unpackhi_epi16(u1_output_epi16, u1_output_epi16);
			vv_epi16 = _mm_unpackhi_epi16(v1_output_epi16, v1_output_epi16);

			// Convert YUV to eight RGB tuples
			yy_epi16 = _mm_subs_epi16(y2_output_epi16, luma_offset_epi16);
			
			yy_epi16 = _mm_adds_epi16(yy_epi16, limiterRGB); // Y to 0 to 255  -- DAN20101102
			yy_epi16 = _mm_subs_epu16(yy_epi16, limiterRGB);
			uu_epi16 = _mm_adds_epi16(uu_epi16, limiterRGB); // U to 0 to 255  -- DAN20101102
			uu_epi16 = _mm_subs_epu16(uu_epi16, limiterRGB);
			vv_epi16 = _mm_adds_epi16(vv_epi16, limiterRGB); // V to 0 to 255  -- DAN20101102
			vv_epi16 = _mm_subs_epu16(vv_epi16, limiterRGB);

			uu_epi16 = _mm_subs_epi16(uu_epi16, chroma_offset_epi16);
			vv_epi16 = _mm_subs_epi16(vv_epi16, chroma_offset_epi16);

			// This code fixed overflow case where very bright pixels
			// with some color produced interim values larger than 32768
			yy_epi16 = _mm_slli_epi16(yy_epi16, 7);
			yy_epi16 = _mm_mulhi_epi16(yy_epi16, _mm_set1_epi16(ymult));
			yy_epi16 = _mm_slli_epi16(yy_epi16, 1);

			// Calculate red
			t2_epi16 = _mm_set1_epi16(r_vmult);
			t2_epi16 = _mm_mullo_epi16(vv_epi16, t2_epi16);
			t2_epi16 = _mm_srai_epi16(t2_epi16, 1);		// 7 bits to 6 bits
			r2_epi16 = _mm_adds_epi16(yy_epi16, t2_epi16);
			//r2_epi16 = _mm_adds_epi16(yy_epi16, t2_epi16);
			r2_epi16 = _mm_adds_epi16(r2_epi16, rounding_epi16);
			r2_epi16 = _mm_srai_epi16(r2_epi16, 6);

			// Calculate green
			t2_epi16 = _mm_set1_epi16(g_vmult);
			t2_epi16 = _mm_mullo_epi16(vv_epi16, t2_epi16);
			t2_epi16 = _mm_srai_epi16(t2_epi16, 2);		// 8 bits to 6 bits
			g2_epi16 = _mm_subs_epi16(yy_epi16, t2_epi16);
			t2_epi16 = _mm_set1_epi16(g_umult);
			t2_epi16 = _mm_mullo_epi16(uu_epi16, t2_epi16);
			t2_epi16 = _mm_srai_epi16(t2_epi16, 2);		// 8 bits to 6 bits
			g2_epi16 = _mm_subs_epi16(g2_epi16, t2_epi16);
			g2_epi16 = _mm_adds_epi16(g2_epi16, rounding_epi16);
			g2_epi16 = _mm_srai_epi16(g2_epi16, 6);

			// Calculate blue
			t2_epi16 = _mm_set1_epi16(b_umult);
			t2_epi16 = _mm_mullo_epi16(uu_epi16, t2_epi16);
			b2_epi16 = _mm_adds_epi16(yy_epi16, t2_epi16);
			b2_epi16 = _mm_adds_epi16(b2_epi16, rounding_epi16);
			b2_epi16 = _mm_srai_epi16(b2_epi16, 6);


			/**** Pack and store the first sixteen RGBA tuples *****/

			// Pack the RGBA values
			r_epi8 = _mm_packus_epi16(b1_epi16, b2_epi16);		// Swapped with red
			g_epi8 = _mm_packus_epi16(g1_epi16, g2_epi16);
			b_epi8 = _mm_packus_epi16(r1_epi16, r2_epi16);		// Swapped with blue

			// Interleave the first eight red and green values
			rg_epi8 = _mm_unpacklo_epi8(r_epi8, g_epi8);

			// Interleave the first eight blue values with alpha
			ba_epi8 = _mm_unpacklo_epi8(b_epi8, alpha_epi8);

			// Interleave the first set of four RGBA tuples
			rgba_epi8 = _mm_unpacklo_epi16(rg_epi8, ba_epi8);

			// Store the first set of four RGBA tuples
			//*(output_ptr++) = rgba_epi8;
			_mm_storeu_si128(output_ptr++, rgba_epi8);

			// Interleave the second set of four RGBA tuples
			rgba_epi8 = _mm_unpackhi_epi16(rg_epi8, ba_epi8);

			// Store the second set of four RGBA tuples
			//*(output_ptr++) = rgba_epi8;
			_mm_storeu_si128(output_ptr++, rgba_epi8);

			// Interleave the second eight red and green values
			rg_epi8 = _mm_unpackhi_epi8(r_epi8, g_epi8);

			// Interleave the second eight blue values with alpha
			ba_epi8 = _mm_unpackhi_epi8(b_epi8, alpha_epi8);

			// Interleave the third set of four RGBA tuples
			rgba_epi8 = _mm_unpacklo_epi16(rg_epi8, ba_epi8);

			// Store the third set of four RGBA tuples
			//*(output_ptr++) = rgba_epi8;
			_mm_storeu_si128(output_ptr++, rgba_epi8);

			// Interleave the fourth set of four RGBA tuples
			rgba_epi8 = _mm_unpackhi_epi16(rg_epi8, ba_epi8);

			// Store the fourth set of four RGBA values
			//*(output_ptr++) = rgba_epi8;
			_mm_storeu_si128(output_ptr++, rgba_epi8);


			/***** Compute the third set of eight RGBA output values *****/

			// Duplicate the first four chroma values
			uu_epi16 = _mm_unpacklo_epi16(u2_output_epi16, u2_output_epi16);
			vv_epi16 = _mm_unpacklo_epi16(v2_output_epi16, v2_output_epi16);

			// Convert YUV to eight RGB tuples
			yy_epi16 = _mm_subs_epi16(y3_output_epi16, luma_offset_epi16);
			
			yy_epi16 = _mm_adds_epi16(yy_epi16, limiterRGB); // Y to 0 to 255  -- DAN20101102
			yy_epi16 = _mm_subs_epu16(yy_epi16, limiterRGB);
			uu_epi16 = _mm_adds_epi16(uu_epi16, limiterRGB); // U to 0 to 255  -- DAN20101102
			uu_epi16 = _mm_subs_epu16(uu_epi16, limiterRGB);
			vv_epi16 = _mm_adds_epi16(vv_epi16, limiterRGB); // V to 0 to 255  -- DAN20101102
			vv_epi16 = _mm_subs_epu16(vv_epi16, limiterRGB);

			uu_epi16 = _mm_subs_epi16(uu_epi16, chroma_offset_epi16);
			vv_epi16 = _mm_subs_epi16(vv_epi16, chroma_offset_epi16);

			// This code fixed overflow case where very bright pixels
			// with some color produced interim values larger than 32768
			yy_epi16 = _mm_slli_epi16(yy_epi16, 7);
			yy_epi16 = _mm_mulhi_epi16(yy_epi16, _mm_set1_epi16(ymult));
			yy_epi16 = _mm_slli_epi16(yy_epi16, 1);

			// Calculate red
			t1_epi16 = _mm_set1_epi16(r_vmult);
			t1_epi16 = _mm_mullo_epi16(vv_epi16, t1_epi16);
			t1_epi16 = _mm_srai_epi16(t1_epi16, 1);		// 7 bits to 6 bits
			r1_epi16 = _mm_adds_epi16(yy_epi16, t1_epi16);
			//r1_epi16 = _mm_adds_epi16(yy_epi16, t1_epi16);
			r1_epi16 = _mm_adds_epi16(r1_epi16, rounding_epi16);
			r1_epi16 = _mm_srai_epi16(r1_epi16, 6);

			// Calculate green
			t1_epi16 = _mm_set1_epi16(g_vmult);
			t1_epi16 = _mm_mullo_epi16(vv_epi16, t1_epi16);
			t1_epi16 = _mm_srai_epi16(t1_epi16, 2);		// 8 bits to 6 bits
			g1_epi16 = _mm_subs_epi16(yy_epi16, t1_epi16);
			t1_epi16 = _mm_set1_epi16(g_umult);
			t1_epi16 = _mm_mullo_epi16(uu_epi16, t1_epi16);
			t1_epi16 = _mm_srai_epi16(t1_epi16, 2);		// 8 bits to 6 bits
			g1_epi16 = _mm_subs_epi16(g1_epi16, t1_epi16);
			g1_epi16 = _mm_adds_epi16(g1_epi16, rounding_epi16);
			g1_epi16 = _mm_srai_epi16(g1_epi16, 6);

			// Calculate blue
			t1_epi16 = _mm_set1_epi16(b_umult);
			t1_epi16 = _mm_mullo_epi16(uu_epi16, t1_epi16);
			b1_epi16 = _mm_adds_epi16(yy_epi16, t1_epi16);
			b1_epi16 = _mm_adds_epi16(b1_epi16, rounding_epi16);
			b1_epi16 = _mm_srai_epi16(b1_epi16, 6);


			/***** Compute the fourth set of eight RGBA output values *****/

			// Duplicate the second four chroma values
			uu_epi16 = _mm_unpackhi_epi16(u2_output_epi16, u2_output_epi16);
			vv_epi16 = _mm_unpackhi_epi16(v2_output_epi16, v2_output_epi16);

			// Convert YUV to eight RGB tuples
			yy_epi16 = _mm_subs_epi16(y4_output_epi16, luma_offset_epi16);
			
			yy_epi16 = _mm_adds_epi16(yy_epi16, limiterRGB); // Y to 0 to 255  -- DAN20101102
			yy_epi16 = _mm_subs_epu16(yy_epi16, limiterRGB);
			uu_epi16 = _mm_adds_epi16(uu_epi16, limiterRGB); // U to 0 to 255  -- DAN20101102
			uu_epi16 = _mm_subs_epu16(uu_epi16, limiterRGB);
			vv_epi16 = _mm_adds_epi16(vv_epi16, limiterRGB); // V to 0 to 255  -- DAN20101102
			vv_epi16 = _mm_subs_epu16(vv_epi16, limiterRGB);

			uu_epi16 = _mm_subs_epi16(uu_epi16, chroma_offset_epi16);
			vv_epi16 = _mm_subs_epi16(vv_epi16, chroma_offset_epi16);

			// This code fixed overflow case where very bright pixels
			// with some color produced interim values larger than 32768
			yy_epi16 = _mm_slli_epi16(yy_epi16, 7);
			yy_epi16 = _mm_mulhi_epi16(yy_epi16, _mm_set1_epi16(ymult));
			yy_epi16 = _mm_slli_epi16(yy_epi16, 1);

			// Calculate red
			t2_epi16 = _mm_set1_epi16(r_vmult);
			t2_epi16 = _mm_mullo_epi16(vv_epi16, t2_epi16);
			t2_epi16 = _mm_srai_epi16(t2_epi16, 1);		// 7 bits to 6 bits
			r2_epi16 = _mm_adds_epi16(yy_epi16, t2_epi16);
			//r2_epi16 = _mm_adds_epi16(yy_epi16, t2_epi16);
			r2_epi16 = _mm_adds_epi16(r2_epi16, rounding_epi16);
			r2_epi16 = _mm_srai_epi16(r2_epi16, 6);

			// Calculate green
			t2_epi16 = _mm_set1_epi16(g_vmult);
			t2_epi16 = _mm_mullo_epi16(vv_epi16, t2_epi16);
			t2_epi16 = _mm_srai_epi16(t2_epi16, 2);		// 8 bits to 6 bits
			g2_epi16 = _mm_subs_epi16(yy_epi16, t2_epi16);
			t2_epi16 = _mm_set1_epi16(g_umult);
			t2_epi16 = _mm_mullo_epi16(uu_epi16, t2_epi16);
			t2_epi16 = _mm_srai_epi16(t2_epi16, 2);		// 8 bits to 6 bits
			g2_epi16 = _mm_subs_epi16(g2_epi16, t2_epi16);
			g2_epi16 = _mm_adds_epi16(g2_epi16, rounding_epi16);
			g2_epi16 = _mm_srai_epi16(g2_epi16, 6);

			// Calculate blue
			t2_epi16 = _mm_set1_epi16(b_umult);
			t2_epi16 = _mm_mullo_epi16(uu_epi16, t2_epi16);
			b2_epi16 = _mm_adds_epi16(yy_epi16, t2_epi16);
			b2_epi16 = _mm_adds_epi16(b2_epi16, rounding_epi16);
			b2_epi16 = _mm_srai_epi16(b2_epi16, 6);


			/**** Pack and store the second sixteen RGBA tuples *****/

			// Pack the RGBA values
			r_epi8 = _mm_packus_epi16(b1_epi16, b2_epi16);		// Swapped with red
			g_epi8 = _mm_packus_epi16(g1_epi16, g2_epi16);
			b_epi8 = _mm_packus_epi16(r1_epi16, r2_epi16);		// Swapped with blue

			// Interleave the first eight red and green values
			rg_epi8 = _mm_unpacklo_epi8(r_epi8, g_epi8);

			// Interleave the first eight blue values with alpha
			ba_epi8 = _mm_unpacklo_epi8(b_epi8, alpha_epi8);

			// Interleave the first set of four RGBA tuples
			rgba_epi8 = _mm_unpacklo_epi16(rg_epi8, ba_epi8);

			// Store the first set of four RGBA tuples
			//*(output_ptr++) = rgba_epi8;
			_mm_storeu_si128(output_ptr++, rgba_epi8);

			// Interleave the second set of four RGBA tuples
			rgba_epi8 = _mm_unpackhi_epi16(rg_epi8, ba_epi8);

			// Store the second set of four RGBA tuples
			//*(output_ptr++) = rgba_epi8;
			_mm_storeu_si128(output_ptr++, rgba_epi8);

			// Interleave the second eight red and green values
			rg_epi8 = _mm_unpackhi_epi8(r_epi8, g_epi8);

			// Interleave the second eight blue values with alpha
			ba_epi8 = _mm_unpackhi_epi8(b_epi8, alpha_epi8);

			// Interleave the third set of four RGBA tuples
			rgba_epi8 = _mm_unpacklo_epi16(rg_epi8, ba_epi8);

			// Store the third set of four RGBA tuples
			//*(output_ptr++) = rgba_epi8;
			_mm_storeu_si128(output_ptr++, rgba_epi8);

			// Interleave the fourth set of four RGBA tuples
			rgba_epi8 = _mm_unpackhi_epi16(rg_epi8, ba_epi8);

			// Store the fourth set of four RGBA values
			//*(output_ptr++) = rgba_epi8;
			_mm_storeu_si128(output_ptr++, rgba_epi8);
		}

		// Should have exited the loop with the column equal to the post processing column
		assert(column == post_column);

		outptr = (uint8_t *)output_ptr;
#endif
		// Have already computed the next luma and chroma output values

		// Process the rest of the columns up to the last column in the row
		for (; column < last_column; column++)
		{
			int y1_even_value;
			int y2_even_value;

			int y1_odd_value;
			int y2_odd_value;

			int u1_even_value;
			int v1_even_value;

			int u1_odd_value;
			int v1_odd_value;

			// Chroma is 4:2:2 subsampled relative to the overall image
			int chroma_column = column / 2;


			/***** First pair of even and odd luma values *****/

			// Apply the even reconstruction filter to the lowpass band
			even = 0;
			even += y_lowpass_ptr[column - 1];
			even -= y_lowpass_ptr[column + 1];
			even += 4; //DAN20050921
			even >>= 3;
			even += y_lowpass_ptr[column + 0];

			// Add the highpass correction
			even += y_highpass_ptr[column];
			even = DivideByShift(even, 1);

			// Reduce the precision to eight bits
			even >>= descale_shift;

			// Save the luma result for later output in the correct order
			y1_even_value = even;

			// Apply the odd reconstruction filter to the lowpass band
			odd = 0;
			odd -= y_lowpass_ptr[column - 1];
			odd += y_lowpass_ptr[column + 1];
			odd += 4; //DAN20050921
			odd >>= 3;
			odd += y_lowpass_ptr[column + 0];

			// Subtract the highpass correction
			odd -= y_highpass_ptr[column];
			odd = DivideByShift(odd, 1);

			// Reduce the precision to eight bits
			odd >>= descale_shift;

			// Save the luma result for later output in the correct order
			y1_odd_value = odd;


			/***** Even and odd pair of u chroma output values *****/

			// Apply the even reconstruction filter to the lowpass band
			even = 0;
			even += u_lowpass_ptr[chroma_column - 1];
			even -= u_lowpass_ptr[chroma_column + 1];
			even += 4; //DAN20050921
			even >>= 3;
			even += u_lowpass_ptr[chroma_column + 0];

			// Add the highpass correction
			even += u_highpass_ptr[chroma_column];
			even = DivideByShift(even, 1);

			// Reduce the precision to eight bits
			even >>= descale_shift;

			// Save the u chroma result for later output in the correct order
			u1_even_value = even;

			// Apply the odd reconstruction filter to the lowpass band
			odd = 0;
			odd -= u_lowpass_ptr[chroma_column - 1];
			odd += u_lowpass_ptr[chroma_column + 1];
			odd += 4; //DAN20050921
			odd >>= 3;
			odd += u_lowpass_ptr[chroma_column + 0];

			// Subtract the highpass correction
			odd -= u_highpass_ptr[chroma_column];
			odd = DivideByShift(odd, 1);

			// Reduce the precision to eight bits
			odd >>= descale_shift;

			// Save the u chroma result for later output in the correct order
			u1_odd_value = odd;


			/***** Even and odd pair of v chroma output values *****/

			// Apply the even reconstruction filter to the lowpass band
			even = 0;
			even += v_lowpass_ptr[chroma_column - 1];
			even -= v_lowpass_ptr[chroma_column + 1];
			even += 4; //DAN20050921
			even >>= 3;
			even += v_lowpass_ptr[chroma_column + 0];

			// Add the highpass correction
			even += v_highpass_ptr[chroma_column];
			even = DivideByShift(even, 1);

			// Reduce the precision to eight bits
			even >>= descale_shift;

			// Save the v chroma result for later output in the correct order
			v1_even_value = even;

			// Apply the odd reconstruction filter to the lowpass band
			odd = 0;
			odd -= v_lowpass_ptr[chroma_column - 1];
			odd += v_lowpass_ptr[chroma_column + 1];
			odd += 4; //DAN20050921
			odd >>= 3;
			odd += v_lowpass_ptr[chroma_column + 0];

			// Subtract the highpass correction
			odd -= v_highpass_ptr[chroma_column];
			odd = DivideByShift(odd, 1);

			// Reduce the precision to eight bits
			odd >>= descale_shift;

			// Save the v chroma result for later output in the correct order
			v1_odd_value = odd;

#if (0 && DEBUG)
			u1_even_value = 128;
			v1_even_value = 128;

			u1_odd_value = 128;
			v1_odd_value = 128;
#endif

			/***** Convert the first set of YUV values to RGBA *****/

			// Remove the luma and chroma offsets from the even and odd values
			y1_even_value -= luma_offset;
			u1_even_value -= chroma_offset;
			v1_even_value -= chroma_offset;

			y1_odd_value -= luma_offset;
			u1_odd_value -= chroma_offset;
			v1_odd_value -= chroma_offset;

			// Convert the even luma and chroma values to RGBA
			y1_even_value = (y1_even_value * ymult) >> 7;

			r1 = (y1_even_value                                   + r_vmult * v1_even_value +  64) >> 7;
			g1 = (y1_even_value * 2 -     g_umult * u1_even_value - g_vmult * v1_even_value + 128) >> 8;
			b1 = (y1_even_value     + 2 * b_umult * u1_even_value                           +  64) >> 7;

			// Output the first RGBA tuple
            *(outptr++) = SATURATE_8U(b1);
			*(outptr++) = SATURATE_8U(g1);
			*(outptr++) = SATURATE_8U(r1);
			*(outptr++) = alpha;

			// Convert the odd luma and chroma values to RGBA
			y1_odd_value = (y1_odd_value * ymult) >> 7;

			r2 = (y1_odd_value                                   + r_vmult * v1_even_value +  64) >> 7;
			g2 = (y1_odd_value * 2 -     g_umult * u1_even_value - g_vmult * v1_even_value + 128) >> 8;
			b2 = (y1_odd_value     + 2 * b_umult * u1_even_value                           +  64) >> 7;

			// Output the first RGBA tuple
            *(outptr++) = SATURATE_8U(b2);
			*(outptr++) = SATURATE_8U(g2);
			*(outptr++) = SATURATE_8U(r2);
			*(outptr++) = alpha;

			column++;

			/***** Second pair of even and odd luma values *****/

			// Apply the even reconstruction filter to the lowpass band
			even = 0;
			even += y_lowpass_ptr[column - 1];
			even -= y_lowpass_ptr[column + 1];
			even += 4; //DAN20050921
			even >>= 3;
			even += y_lowpass_ptr[column + 0];

			// Add the highpass correction
			even += y_highpass_ptr[column];
			even = DivideByShift(even, 1);

			// Reduce the precision to eight bits
			even >>= descale_shift;

			// Save the luma result for later output in the correct order
			y2_even_value = even;

			// Apply the odd reconstruction filter to the lowpass band
			odd = 0;
			odd -= y_lowpass_ptr[column - 1];
			odd += y_lowpass_ptr[column + 1];
			odd += 4; //DAN20050921
			odd >>= 3;
			odd += y_lowpass_ptr[column + 0];

			// Subtract the highpass correction
			odd -= y_highpass_ptr[column];
			odd = DivideByShift(odd, 1);

			// Reduce the precision to eight bits
			odd >>= descale_shift;

			// Save the luma result for later output in the correct order
			y2_odd_value = odd;


			/***** Convert the second set of YUV values to RGBA *****/

			// Remove the luma offsets from the even and odd values
			y2_even_value -= luma_offset;
			y2_odd_value -= luma_offset;

			// Convert the even luma and chroma values to RGBA
			y2_even_value = (y2_even_value * ymult) >> 7;

			r1 = (y2_even_value                                   + r_vmult * v1_odd_value +  64) >> 7;
			g1 = (y2_even_value * 2 -     g_umult * u1_odd_value  - g_vmult * v1_odd_value + 128) >> 8;
			b1 = (y2_even_value     + 2 * b_umult * u1_odd_value                           +  64) >> 7;

			// Output the first RGBA tuple
            *(outptr++) = SATURATE_8U(b1);
			*(outptr++) = SATURATE_8U(g1);
			*(outptr++) = SATURATE_8U(r1);
			*(outptr++) = alpha;

			// Convert the odd luma and chroma values to RGBA
			y2_odd_value = (y2_odd_value * ymult) >> 7;

			r2 = (y2_odd_value                                  + r_vmult * v1_odd_value +  64) >> 7;
			g2 = (y2_odd_value * 2 -     g_umult * u1_odd_value - g_vmult * v1_odd_value + 128) >> 8;
			b2 = (y2_odd_value     + 2 * b_umult * u1_odd_value                          +  64) >> 7;

			// Output the first RGBA tuple
            *(outptr++) = SATURATE_8U(b2);
			*(outptr++) = SATURATE_8U(g2);
			*(outptr++) = SATURATE_8U(r2);
			*(outptr++) = alpha;


		}

		// Should have exited the loop at the column for right border processing
		assert(column == last_column);

		{
			int last_y[4];
			int last_u[2];
			int last_v[2];

			// Apply the even reconstruction filter to the lowpass band
			even = 0;
			even += y_lowpass_ptr[column - 1];
			even -= y_lowpass_ptr[column + 1];
			even += 4; //DAN20050921
			even >>= 3;
			even += y_lowpass_ptr[column + 0];

			// Add the highpass correction
			even += y_highpass_ptr[column];
			even = DivideByShift(even, 1);

			// Reduce the precision to eight bits
			even >>= descale_shift;

			// Save the luma result for later output in the correct order
			last_y[0] = even - luma_offset;


			// Apply the odd reconstruction filter to the lowpass band
			odd = 0;
			odd -= y_lowpass_ptr[column - 1];
			odd += y_lowpass_ptr[column + 1];
			odd += 4; //DAN20050921
			odd >>= 3;
			odd += y_lowpass_ptr[column + 0];

			// Subtract the highpass correction
			odd -= y_highpass_ptr[column];
			odd = DivideByShift(odd, 1);

			// Reduce the precision to eight bits
			odd >>= descale_shift;

			// Save the luma result for later output in the correct order
			last_y[1] = odd - luma_offset;

			column++;


			/***** Process the last column in the luma channel *****/

			// Compute the last column in the chroma channels
			chroma_column = (width / 2) - 1;

			// Process the last two output points with special filters for the right border
			even = 0;
			odd = 0;

			// Apply the even reconstruction filter to the luma lowpass band
			even += 5 * y_lowpass_ptr[column + 0];
			even += 4 * y_lowpass_ptr[column - 1];
			even -= 1 * y_lowpass_ptr[column - 2];
			even += ROUNDING(even,8);
			even = DivideByShift(even, 3);

			// Add the highpass correction
			even += y_highpass_ptr[column];
			even = DivideByShift(even, 1);

			// Reduce the precision to eight bits
			even >>= descale_shift;

			// Save the result for color conversion later
			last_y[2] = even - luma_offset;

			// Apply the odd reconstruction filter to the lowpass band
			odd += 11 * y_lowpass_ptr[column + 0];
			odd -=  4 * y_lowpass_ptr[column - 1];
			odd +=  1 * y_lowpass_ptr[column - 2];
			odd += ROUNDING(odd,8);
			odd = DivideByShift(odd, 3);

			// Subtract the highpass correction
			odd -= y_highpass_ptr[column];
			odd = DivideByShift(odd, 1);

			// Reduce the precision to eight bits
			odd >>= descale_shift;

			// Save the result for color conversion later
			last_y[3] = odd - luma_offset;


			/***** Process the last column in the u chroma channel *****/

			// Compute the last column in the chroma channels
			chroma_column = (width / 2) - 1;

			// Process the last two output points with special filters for the right border
			even = 0;
			odd = 0;

			// Apply the even reconstruction filter to the luma lowpass band
			even += 5 * u_lowpass_ptr[chroma_column + 0];
			even += 4 * u_lowpass_ptr[chroma_column - 1];
			even -= 1 * u_lowpass_ptr[chroma_column - 2];
			even += ROUNDING(even,8);
			even = DivideByShift(even, 3);

			// Add the highpass correction
			even += u_highpass_ptr[chroma_column];
			even = DivideByShift(even, 1);

			// Reduce the precision to eight bits
			even >>= descale_shift;

			// Save the result for color conversion later
			last_u[0] = even - chroma_offset;

			// Apply the odd reconstruction filter to the lowpass band
			odd += 11 * u_lowpass_ptr[chroma_column + 0];
			odd -=  4 * u_lowpass_ptr[chroma_column - 1];
			odd +=  1 * u_lowpass_ptr[chroma_column - 2];
			odd += ROUNDING(odd,8);
			odd = DivideByShift(odd, 3);

			// Subtract the highpass correction
			odd -= u_highpass_ptr[chroma_column];
			odd = DivideByShift(odd, 1);

			// Reduce the precision to eight bits
			odd >>= descale_shift;

			// Save the result for color conversion later
			last_u[1] = odd - chroma_offset;


			/***** Process the last column in the v chroma channel *****/

			// Process the last two output points with special filters for the right border
			even = 0;
			odd = 0;

			// Apply the even reconstruction filter to the luma lowpass band
			even += 5 * v_lowpass_ptr[chroma_column + 0];
			even += 4 * v_lowpass_ptr[chroma_column - 1];
			even -= 1 * v_lowpass_ptr[chroma_column - 2];
			even += ROUNDING(even,8);
			even = DivideByShift(even, 3);

			// Add the highpass correction
			even += v_highpass_ptr[chroma_column];
			even = DivideByShift(even, 1);

			// Reduce the precision to eight bits
			even >>= descale_shift;

			// Save the result for color conversion later
			last_v[0] = even - chroma_offset;

			// Apply the odd reconstruction filter to the lowpass band
			odd += 11 * v_lowpass_ptr[chroma_column + 0];
			odd -=  4 * v_lowpass_ptr[chroma_column - 1];
			odd +=  1 * v_lowpass_ptr[chroma_column - 2];
			odd += ROUNDING(odd,8);
			odd = DivideByShift(odd, 3);

			// Subtract the highpass correction
			odd -= v_highpass_ptr[chroma_column];
			odd = DivideByShift(odd, 1);

			// Reduce the precision to eight bits
			odd >>= descale_shift;

			// Save the result for color conversion later
			last_v[1] = odd - chroma_offset;


			// Convert the even luma and chroma values to RGBA
			last_y[0] = (last_y[0] * ymult) >> 7;
			last_y[1] = (last_y[1] * ymult) >> 7;
			last_y[2] = (last_y[2] * ymult) >> 7;
			last_y[3] = (last_y[3] * ymult) >> 7;

			r1 = (last_y[0]                               + r_vmult * last_v[0] +  64) >> 7;
			g1 = (last_y[0] * 2 -     g_umult * last_u[0] - g_vmult * last_v[0] + 128) >> 8;
			b1 = (last_y[0]     + 2 * b_umult * last_u[0]                       +  64) >> 7;

			*(outptr++) = SATURATE_8U(b1);
			*(outptr++) = SATURATE_8U(g1);
			*(outptr++) = SATURATE_8U(r1);
			*(outptr++) = alpha;


			r1 = (last_y[1]                               + r_vmult * last_v[0] +  64) >> 7;
			g1 = (last_y[1] * 2 -     g_umult * last_u[0] - g_vmult * last_v[0] + 128) >> 8;
			b1 = (last_y[1]     + 2 * b_umult * last_u[0]                       +  64) >> 7;

			*(outptr++) = SATURATE_8U(b1);
			*(outptr++) = SATURATE_8U(g1);
			*(outptr++) = SATURATE_8U(r1);
			*(outptr++) = alpha;

			
			r1 = (last_y[2]                               + r_vmult * last_v[1] +  64) >> 7;
			g1 = (last_y[2] * 2 -     g_umult * last_u[1] - g_vmult * last_v[1] + 128) >> 8;
			b1 = (last_y[2]     + 2 * b_umult * last_u[1]                       +  64) >> 7;

			*(outptr++) = SATURATE_8U(b1);
			*(outptr++) = SATURATE_8U(g1);
			*(outptr++) = SATURATE_8U(r1);
			*(outptr++) = alpha;


			r1 = (last_y[3]                               + r_vmult * last_v[1] +  64) >> 7;
			g1 = (last_y[3] * 2 -     g_umult * last_u[1] - g_vmult * last_v[1] + 128) >> 8;
			b1 = (last_y[3]     + 2 * b_umult * last_u[1]                       +  64) >> 7;

			*(outptr++) = SATURATE_8U(b1);
			*(outptr++) = SATURATE_8U(g1);
			*(outptr++) = SATURATE_8U(r1);
			*(outptr++) = alpha;
		}

		// Advance to the next row of coefficients in each channel
		y_lowpass_ptr += y_lowpass_pitch;
		u_lowpass_ptr += u_lowpass_pitch;
		v_lowpass_ptr += v_lowpass_pitch;

		y_highpass_ptr += y_highpass_pitch;
		u_highpass_ptr += u_highpass_pitch;
		v_highpass_ptr += v_highpass_pitch;

		// Advance the output pointer to the next row
		output_row_ptr += output_pitch;
	}
}






// Apply the inverse spatial filter to the top row and convert the results to the output format
void
InvertSpatialTopRow16sToOutput(DECODER *decoder, int thread_index, PIXEL *lowlow_band[], int lowlow_band_pitch[],
							   PIXEL *lowhigh_band[], int lowhigh_band_pitch[],
							   PIXEL *highlow_band[], int highlow_band_pitch[],
							   PIXEL *highhigh_band[], int highhigh_band_pitch[],
							   uint8_t *output, int output_pitch, int output_width,
							   int format, int colorspace, int row, int channel_width[],
							   PIXEL *buffer, size_t buffer_size, int precision,
							   HorizontalInverseFilterOutputProc horizontal_filter_proc)
{
	int num_channels = decoder->codec.num_channels;// = CODEC_NUM_CHANNELS;

	PIXEL *even_lowpass[CODEC_MAX_CHANNELS];
	PIXEL *even_highpass[CODEC_MAX_CHANNELS];
	PIXEL *odd_lowpass[CODEC_MAX_CHANNELS];
	PIXEL *odd_highpass[CODEC_MAX_CHANNELS];
	
	// Distance between strip rows in bytes
	int lowpass_pitch[CODEC_MAX_CHANNELS];
	int highpass_pitch[CODEC_MAX_CHANNELS];

	size_t output_row_size = output_pitch;

	// The width of the first channel is the overall width
	int luma_band_width = channel_width[0];

	// Set the dimensions of the processing strip
	ROI strip = {luma_band_width, 2};

	int channel;

	// Compute pointers into the buffers for temporary results
	for (channel = 0; channel < num_channels; channel++)
	{
		size_t buffer_row_size;
		int buffer_half_pitch;
		//int buffer_width;
		int buffer_pitch;

		//int width = luma_band_width;
		int width = channel_width[channel];

		// Compute positions within the temporary buffer for each row of horizontal lowpass
		// and highpass intermediate coefficients computed by the vertical inverse transform
		buffer_row_size = width * sizeof(PIXEL);
		buffer_row_size = ALIGN16(buffer_row_size);
		buffer_half_pitch = (int)buffer_row_size/sizeof(PIXEL);
		buffer_pitch = 2 * buffer_half_pitch;
		//buffer_width = width;

		// Check that the buffer is large enough to hold four rows of coefficients
		assert(buffer_size >= (4 * buffer_row_size));

		// Compute the positions of the even and odd rows of coefficients
		even_lowpass[channel] = &buffer[0];
		even_highpass[channel] = &buffer[buffer_half_pitch];
		odd_lowpass[channel] = &buffer[2 * buffer_half_pitch];
		odd_highpass[channel] = &buffer[3 * buffer_half_pitch];

		// Pointers into the strip of horizontal coefficients
		lowpass_pitch[channel] = (int)(2 * buffer_row_size);
		highpass_pitch[channel] = (int)(2 * buffer_row_size);

		buffer = &buffer[4 * buffer_half_pitch];
		buffer_size -= 4 * buffer_row_size;
	}

	// This routine should be called for the first row
	assert(row == 0);

	for (channel = 0; channel < num_channels; channel++)
	{
		PIXEL *lowlow = lowlow_band[channel];
		PIXEL *lowhigh = lowhigh_band[channel];
		PIXEL *highlow = highlow_band[channel];
		PIXEL *highhigh = highhigh_band[channel];

		// Convert pitch from bytes to pixels
		int lowlow_pitch = lowlow_band_pitch[channel] / sizeof(PIXEL);
		int lowhigh_pitch = lowhigh_band_pitch[channel] / sizeof(PIXEL);
		//int highlow_pitch = highlow_band_pitch[channel] / sizeof(PIXEL);
		//int highhigh_pitch = highhigh_band_pitch[channel] / sizeof(PIXEL);

		//int width = luma_band_width;
		int width = channel_width[channel];

		// Start at the first column
		int column = 0;

		// Apply the vertical border filter to the first row
		for (; column < width; column++)
		{
			int32_t even = 0;		// Result of convolution with even filter
			int32_t odd = 0;		// Result of convolution with odd filter


			/***** Compute the vertical inverse for the left two bands *****/

			// Apply the even reconstruction filter to the lowpass band
			even += 11 * lowlow[column + 0 * lowlow_pitch];
			even -=  4 * lowlow[column + 1 * lowlow_pitch];
			even +=  1 * lowlow[column + 2 * lowlow_pitch];
			even += ROUNDING(even,8);
			even = DivideByShift(even, 3);

			// Add the highpass correction
			even += highlow[column];
			even = DivideByShift(even, 1);

			// Place the even result in the even row
			even_lowpass[channel][column] = SATURATE(even);

			// Apply the odd reconstruction filter to the lowpass band
			odd += 5 * lowlow[column + 0 * lowlow_pitch];
			odd += 4 * lowlow[column + 1 * lowlow_pitch];
			odd -= 1 * lowlow[column + 2 * lowlow_pitch];
			odd += ROUNDING(odd,8);
			odd = DivideByShift(odd, 3);

			// Subtract the highpass correction
			odd -= highlow[column];
			odd = DivideByShift(odd, 1);

			// Place the odd result in the odd row
			odd_lowpass[channel][column] = SATURATE(odd);


			/***** Compute the vertical inverse for the right two bands *****/

			even = 0;
			odd = 0;

			// Apply the even reconstruction filter to the lowpass band
			even += 11 * lowhigh[column + 0 * lowhigh_pitch];
			even -=  4 * lowhigh[column + 1 * lowhigh_pitch];
			even +=  1 * lowhigh[column + 2 * lowhigh_pitch];
			even += ROUNDING(even,8);
			even = DivideByShift(even, 3);

			// Add the highpass correction
			even += highhigh[column];
			even = DivideByShift(even, 1);

			// Place the even result in the even row
			even_highpass[channel][column] = SATURATE(even);

			// Apply the odd reconstruction filter to the lowpass band
			odd += 5 * lowhigh[column + 0 * lowhigh_pitch];
			odd += 4 * lowhigh[column + 1 * lowhigh_pitch];
			odd -= 1 * lowhigh[column + 2 * lowhigh_pitch];
			odd += ROUNDING(odd,8);
			odd = DivideByShift(odd, 3);

			// Subtract the highpass correction
			odd -= highhigh[column];
			odd = DivideByShift(odd, 1);

			// Place the odd result in the odd row
			odd_highpass[channel][column] = SATURATE(odd);
		}
	}

	// Apply the inverse horizontal transform to the even and odd rows
	horizontal_filter_proc(decoder, thread_index, even_lowpass, lowpass_pitch,
						   even_highpass, highpass_pitch,
						   output, (int)output_row_size, strip,
						   precision, format);
}

// Apply the inverse spatial filter to the middle row and convert the results to the output format
void
InvertSpatialMiddleRow16sToOutput(DECODER *decoder, int thread_index, PIXEL *lowlow_band[], int lowlow_band_pitch[],
								  PIXEL *lowhigh_band[], int lowhigh_band_pitch[],
								  PIXEL *highlow_band[], int highlow_band_pitch[],
								  PIXEL *highhigh_band[], int highhigh_band_pitch[],
								  uint8_t *output, int output_pitch, int output_width,
								  int format, int colorspace, int row, int channel_width[],
								  PIXEL *buffer, size_t buffer_size, int precision,
								  HorizontalInverseFilterOutputProc horizontal_filter_proc,
								  int outputlines)
{
	int num_channels = decoder->codec.num_channels;//CODEC_NUM_CHANNELS;

	PIXEL *lowlow_band_row[CODEC_MAX_CHANNELS];
	PIXEL *lowhigh_band_row[CODEC_MAX_CHANNELS];
	PIXEL *highlow_band_row[CODEC_MAX_CHANNELS];
	PIXEL *highhigh_band_row[CODEC_MAX_CHANNELS];

	int lowlow_pitch[CODEC_MAX_CHANNELS];
	int lowhigh_pitch[CODEC_MAX_CHANNELS];
	int highlow_pitch[CODEC_MAX_CHANNELS];
	int highhigh_pitch[CODEC_MAX_CHANNELS];

	PIXEL *even_lowpass[CODEC_MAX_CHANNELS];
	PIXEL *even_highpass[CODEC_MAX_CHANNELS];
	PIXEL *odd_lowpass[CODEC_MAX_CHANNELS];
	PIXEL *odd_highpass[CODEC_MAX_CHANNELS];
	
	// Distance between strip rows in bytes
	int lowpass_pitch[CODEC_MAX_CHANNELS];
	int highpass_pitch[CODEC_MAX_CHANNELS];

	size_t output_row_size = output_pitch;

	// The width of the first channel is the overall width
	int luma_band_width = channel_width[0];

	// Set the dimensions of the processing strip
	ROI strip = {luma_band_width, outputlines};

	int channel;
	int skip_highpass = 0;
	int lowpass_only = 0;

	if(decoder->channel_decodes > 1 && 
		(decoder->channel_blend_type == BLEND_STACKED_ANAMORPHIC || decoder->channel_blend_type == BLEND_LINE_INTERLEAVED)
		 && decoder->frame.format == DECODED_FORMAT_YUYV)
	{
		lowpass_only = 1;
		strip.height = 1;
	}

	if((decoder->channel_blend_type == BLEND_SIDEBYSIDE_ANAMORPHIC || decoder->channel_blend_type == BLEND_FREEVIEW) && decoder->frame.format == DECODED_FORMAT_YUYV)
		skip_highpass = 1;

	if(decoder->frame.resolution == DECODED_RESOLUTION_HALF_HORIZONTAL)
		skip_highpass = 1;



	// Compute pointers into the buffers for temporary results
	for (channel = 0; channel < num_channels; channel++)
	{
		size_t buffer_row_size;
		int buffer_half_pitch;
		//int buffer_width;
		int buffer_pitch;

		//int width = luma_band_width;
		int width = channel_width[channel];

		// Compute positions within the temporary buffer for each row of horizontal lowpass
		// and highpass intermediate coefficients computed by the vertical inverse transform
		buffer_row_size = width * sizeof(PIXEL);
		buffer_row_size = ALIGN16(buffer_row_size);
		buffer_half_pitch = (int)buffer_row_size/sizeof(PIXEL);
		buffer_pitch = 2 * buffer_half_pitch;
		//buffer_width = width;

		// Check that the buffer is large enough to hold four rows of coefficients
		assert(buffer_size >= (4 * buffer_row_size));

		// Compute the positions of the even and odd rows of coefficients
		even_lowpass[channel] = &buffer[0];
		even_highpass[channel] = &buffer[buffer_half_pitch];
		odd_lowpass[channel] = &buffer[2 * buffer_half_pitch];
		odd_highpass[channel] = &buffer[3 * buffer_half_pitch];

		// Pointers into the strip of horizontal coefficients
		lowpass_pitch[channel] = (int)(2 * buffer_row_size);
		highpass_pitch[channel] = (int)(2 * buffer_row_size);

		// Convert pitch from bytes to pixels
		lowlow_pitch[channel] = lowlow_band_pitch[channel] / sizeof(PIXEL);
		lowhigh_pitch[channel] = lowhigh_band_pitch[channel] / sizeof(PIXEL);
		highlow_pitch[channel] = highlow_band_pitch[channel] / sizeof(PIXEL);
		highhigh_pitch[channel] = highhigh_band_pitch[channel] / sizeof(PIXEL);

		// Compute the address of the first row for processing in each wavelet band
		lowlow_band_row[channel] = lowlow_band[channel] + (row - 1) * lowlow_pitch[channel];
		lowhigh_band_row[channel] = lowhigh_band[channel] + (row - 1) * lowhigh_pitch[channel];
		highlow_band_row[channel] = highlow_band[channel] + row * highlow_pitch[channel];
		highhigh_band_row[channel] = highhigh_band[channel] + row * highhigh_pitch[channel];

		buffer = &buffer[4 * buffer_half_pitch];
		buffer_size -= 4 * buffer_row_size;
	}

	// This routine should not be called to process the first row
	assert(row > 0);

	for (channel = 0; channel < num_channels; channel++)
	{
		//int width = luma_band_width;
		int width = channel_width[channel];

		// Start at the first column
		int column = 0;

#if (1 && XMMOPT)

		const int column_step = 8;
		int post_column = width - (width % column_step);

		__m128i *even_lowpass_ptr = (__m128i *)even_lowpass[channel];
		__m128i *even_highpass_ptr = (__m128i *)even_highpass[channel];
		__m128i *odd_lowpass_ptr = (__m128i *)odd_lowpass[channel];
		__m128i *odd_highpass_ptr = (__m128i *)odd_highpass[channel];

		// Process groups of four coefficients along the row
		for (; column < post_column; column += column_step)
		{
			__m128i *lowlow_ptr = (__m128i *)&lowlow_band_row[channel][column];
			__m128i *highlow_ptr = (__m128i *)&highlow_band_row[channel][column];
			__m128i *lowhigh_ptr = (__m128i *)&lowhigh_band_row[channel][column];
			__m128i *highhigh_ptr = (__m128i *)&highhigh_band_row[channel][column];
			__m128i group_epi16;
			__m128i even_epi16;
			__m128i odd_epi16;
			__m128i mid_epi16;
			__m128i half_epi16 = _mm_set1_epi16(4); //DAN031604 4 to 6


			/***** Compute the vertical inverse for the left two bands *****/

			// Set the pitch for the lowpass band used in this section of code
			int group_pitch = (lowlow_pitch[channel] * sizeof(PIXEL))/sizeof(__m128i);

			// Accumulate parallel sums for the even and odd filters

			if(lowpass_only == 1) // acceleration for 3D
			{
				group_epi16 = _mm_load_si128(lowlow_ptr);
				lowlow_ptr += group_pitch;
				group_epi16 = _mm_srai_epi16(group_epi16, 1);

				_mm_store_si128(even_lowpass_ptr++, group_epi16);
			//	_mm_store_si128(odd_lowpass_ptr++, group_epi16);

				group_epi16 = _mm_load_si128(lowhigh_ptr);
				lowhigh_ptr += group_pitch;
				group_epi16 = _mm_srai_epi16(group_epi16, 1);

				_mm_store_si128(even_highpass_ptr++, group_epi16);
			//	_mm_store_si128(odd_highpass_ptr++, group_epi16);
			}
			else
			{

				// Load eight lowpass coefficients and advance to the next row
				group_epi16 = _mm_load_si128(lowlow_ptr);
				lowlow_ptr += group_pitch;

				even_epi16 = group_epi16;
				odd_epi16 = _mm_subs_epi16(_mm_setzero_si128(), group_epi16);

				// Load eight lowpass coefficients and advance to the next row
				mid_epi16 = _mm_load_si128(lowlow_ptr);
				lowlow_ptr += group_pitch;

				// Load the last group of lowpass coefficients
				group_epi16 = _mm_load_si128(lowlow_ptr);

				even_epi16 = _mm_subs_epi16(even_epi16, group_epi16);
				odd_epi16 = _mm_adds_epi16(odd_epi16, group_epi16);

				even_epi16 = _mm_adds_epi16(even_epi16, half_epi16);
				odd_epi16 = _mm_adds_epi16(odd_epi16, half_epi16);

				even_epi16 = _mm_srai_epi16(even_epi16, 3);
				odd_epi16 = _mm_srai_epi16(odd_epi16, 3);

				even_epi16 = _mm_adds_epi16(even_epi16, mid_epi16);
				odd_epi16 = _mm_adds_epi16(odd_epi16, mid_epi16);

				// Add the highpass correction to the even result and divide by two
				group_epi16 = *highlow_ptr;
				even_epi16 = _mm_adds_epi16(even_epi16, group_epi16);
				even_epi16 = _mm_srai_epi16(even_epi16, 1);

				// Subtract the highpass correction from the odd result and divide by two
				odd_epi16 = _mm_subs_epi16(odd_epi16, group_epi16);
				odd_epi16 = _mm_srai_epi16(odd_epi16, 1);

				// Store the even and odd groups of horizontal lowpass coefficients
				_mm_store_si128(even_lowpass_ptr++, even_epi16);
				_mm_store_si128(odd_lowpass_ptr++, odd_epi16);


				/***** Compute the vertical inverse for the right two bands *****/
				if(!skip_highpass) // side by side,
				{
					// Set the pitch for the lowpass band used in this section of code
					group_pitch = (lowhigh_pitch[channel] * sizeof(PIXEL))/sizeof(__m128i);

					// Accumulate parallel sums for the even and odd filters

					// Load eight lowpass coefficients and advance to the next row
					group_epi16 = _mm_load_si128(lowhigh_ptr);
					lowhigh_ptr += group_pitch;

					even_epi16 = group_epi16;
					odd_epi16 = _mm_subs_epi16(_mm_setzero_si128(), group_epi16);

					// Load eight lowpass coefficients and advance to the next row
					mid_epi16 = _mm_load_si128(lowhigh_ptr);
					lowhigh_ptr += group_pitch;

					// Load the last group of lowpass coefficients
					group_epi16 = _mm_load_si128(lowhigh_ptr);

					even_epi16 = _mm_subs_epi16(even_epi16, group_epi16);
					odd_epi16 = _mm_adds_epi16(odd_epi16, group_epi16);

					even_epi16 = _mm_adds_epi16(even_epi16, half_epi16);
					odd_epi16 = _mm_adds_epi16(odd_epi16, half_epi16);

					even_epi16 = _mm_srai_epi16(even_epi16, 3);
					odd_epi16 = _mm_srai_epi16(odd_epi16, 3);

					even_epi16 = _mm_adds_epi16(even_epi16, mid_epi16);
					odd_epi16 = _mm_adds_epi16(odd_epi16, mid_epi16);

					// Add the highpass correction to the even result and divide by two
					group_epi16 = *highhigh_ptr;
					even_epi16 = _mm_adds_epi16(even_epi16, group_epi16);
					even_epi16 = _mm_srai_epi16(even_epi16, 1);

					// Subtract the highpass correction from the odd result and divide by two
					odd_epi16 = _mm_subs_epi16(odd_epi16, group_epi16);
					odd_epi16 = _mm_srai_epi16(odd_epi16, 1);

					// Store the even and odd groups of horizontal highpass coefficients
					_mm_store_si128(even_highpass_ptr++, even_epi16);
					_mm_store_si128(odd_highpass_ptr++, odd_epi16);
				}
			}
		}

		// Should have exited the loop at the post processing column
		assert(column == post_column);
#endif

#if (0 && XMMOPT)

		// Fix the compiler errors so this loop can be used after the fast loop
		{
			const int column_step = 4;
			int post_column = width - (width % column_step);

			__m64 *even_lowpass_ptr = (__m64 *)&even_lowpass[channel][column];
			__m64 *even_highpass_ptr = (__m64 *)&even_highpass[channel][column];
			__m64 *odd_lowpass_ptr = (__m64 *)&odd_lowpass[channel][column];
			__m64 *odd_highpass_ptr = (__m64 *)&odd_highpass[channel][column];

			// Process groups of four coefficients along the row
			for (; column < post_column; column += column_step)
			{
				__m64 *lowlow_ptr = (__m64 *)&lowlow_band_row[channel][column];
				__m64 *highlow_ptr = (__m64 *)&highlow_band_row[channel][column];
				__m64 *lowhigh_ptr = (__m64 *)&lowhigh_band_row[channel][column];
				__m64 *highhigh_ptr = (__m64 *)&highhigh_band_row[channel][column];
				__m64 quad_pi16;
				__m64 even_pi16;
				__m64 odd_pi16;
				__m64 mid_pi16;
				__m64 half_pi16 = _mm_set1_pi16(4); //DAN031604 4 to 6


				/***** Compute the vertical inverse for the left two bands *****/

				// Set the pitch for the lowpass band used in this section of code
				int quad_pitch = (lowlow_pitch[channel] * sizeof(PIXEL))/sizeof(__m64);

				// Accumulate parallel sums for the even and odd filters
				quad_pi16 = *lowlow_ptr;	// Get four lowpass coefficients
				lowlow_ptr += quad_pitch;	// Advance to the next row

				even_pi16 = quad_pi16;
				odd_pi16 = _mm_subs_pi16(_mm_setzero_si64(), quad_pi16);

				mid_pi16 = *lowlow_ptr;		// Get four lowpass coefficients
				lowlow_ptr += quad_pitch;	// Advance to the next row

				quad_pi16 = *lowlow_ptr;	// Get four lowpass coefficients

				even_pi16 = _mm_subs_pi16(even_pi16, quad_pi16);
				odd_pi16 = _mm_adds_pi16(odd_pi16, quad_pi16);

				even_pi16 = _mm_adds_pi16(even_pi16, half_pi16);
				odd_pi16 = _mm_adds_pi16(odd_pi16, half_pi16);

				even_pi16 = _mm_srai_pi16(even_pi16, 3);
				odd_pi16 = _mm_srai_pi16(odd_pi16, 3);

				even_pi16 = _mm_adds_pi16(even_pi16, mid_pi16);
				odd_pi16 = _mm_adds_pi16(odd_pi16, mid_pi16);


				// Add the highpass correction to the even result and divide by two
				quad_pi16 = *highlow_ptr;
				even_pi16 = _mm_adds_pi16(even_pi16, quad_pi16);
				even_pi16 = _mm_srai_pi16(even_pi16, 1);

				// Subtract the highpass correction from the odd result and divide by two
				odd_pi16 = _mm_subs_pi16(odd_pi16, quad_pi16);
				odd_pi16 = _mm_srai_pi16(odd_pi16, 1);

				// Store the even and odd groups of horizontal lowpass coefficients
				*(even_lowpass_ptr++) = even_pi16;
				*(odd_lowpass_ptr++) = odd_pi16;


				/***** Compute the vertical inverse for the right two bands *****/

				// Set the pitch for the lowpass band used in this section of code
				quad_pitch = (lowhigh_pitch[channel] * sizeof(PIXEL))/sizeof(__m64);

				// Accumulate parallel sums for the even and odd filters
				quad_pi16 = *lowhigh_ptr;	// Get four lowpass coefficients
				lowhigh_ptr += quad_pitch;	// Advance to the next row

				even_pi16 = quad_pi16;
				odd_pi16 = _mm_subs_pi16(_mm_setzero_si64(), quad_pi16);

				mid_pi16 = *lowhigh_ptr;	// Get four lowpass coefficients
				lowhigh_ptr += quad_pitch;	// Advance to the next row

				quad_pi16 = *lowhigh_ptr;	// Get four lowpass coefficients

				even_pi16 = _mm_subs_pi16(even_pi16, quad_pi16);
				odd_pi16 = _mm_adds_pi16(odd_pi16, quad_pi16);

				even_pi16 = _mm_adds_pi16(even_pi16, half_pi16);
				odd_pi16 = _mm_adds_pi16(odd_pi16, half_pi16);

				even_pi16 = _mm_srai_pi16(even_pi16, 3);
				odd_pi16 = _mm_srai_pi16(odd_pi16, 3);

				even_pi16 = _mm_adds_pi16(even_pi16, mid_pi16);
				odd_pi16 = _mm_adds_pi16(odd_pi16, mid_pi16);


				// Add the highpass correction to the even result and divide by two
				quad_pi16 = *highhigh_ptr;
				even_pi16 = _mm_adds_pi16(even_pi16, quad_pi16);
				even_pi16 = _mm_srai_pi16(even_pi16, 1);

				// Subtract the highpass correction from the odd result and divide by two
				odd_pi16 = _mm_subs_pi16(odd_pi16, quad_pi16);
				odd_pi16 = _mm_srai_pi16(odd_pi16, 1);

				// Store the even and odd groups of horizontal highpass coefficients
				*(even_highpass_ptr++) = even_pi16;
				*(odd_highpass_ptr++) = odd_pi16;
			}
			// Should have exited the loop at the post processing column
			assert(column == post_column);
		}
#endif

		// Process the rest of the row
		for (; column < width; column++)
		{
			int32_t even = 0;		// Result of convolution with even filter
			int32_t odd = 0;		// Result of convolution with odd filter


			/***** Compute the vertical inverse for the left two bands (first luma) *****/

			// Apply the even reconstruction filter to the lowpass band
			even += lowlow_band_row[channel][column + 0 * lowlow_pitch[channel]];
			even -= lowlow_band_row[channel][column + 2 * lowlow_pitch[channel]];
			even += 4; //DAN20050921
			even >>= 3;
			even += lowlow_band_row[channel][column + 1 * lowlow_pitch[channel]];

			// Add the highpass correction
			even += highlow_band_row[channel][column];
			even = DivideByShift(even, 1);

			// Place the even result in the even row
			even_lowpass[channel][column] = SATURATE(even);

			// Apply the odd reconstruction filter to the lowpass band
			odd -= lowlow_band_row[channel][column + 0 * lowlow_pitch[channel]];
			odd += lowlow_band_row[channel][column + 2 * lowlow_pitch[channel]];
			odd += 4; //DAN20050921
			odd >>= 3;
			odd += lowlow_band_row[channel][column + 1 * lowlow_pitch[channel]];

			// Subtract the highpass correction
			odd -= highlow_band_row[channel][column];
			odd = DivideByShift(odd, 1);

			// Place the odd result in the odd row
			odd_lowpass[channel][column] = SATURATE(odd);


			/***** Compute the vertical inverse for the right two bands (first luma) *****/

			even = 0;
			odd = 0;

			// Apply the even reconstruction filter to the lowpass band
			even += lowhigh_band_row[channel][column + 0 * lowhigh_pitch[channel]];
			even -= lowhigh_band_row[channel][column + 2 * lowhigh_pitch[channel]];
			even += 4; //DAN20050921
			even >>= 3;
			even += lowhigh_band_row[channel][column + 1 * lowhigh_pitch[channel]];

			// Add the highpass correction
			even += highhigh_band_row[channel][column];
			even = DivideByShift(even, 1);

			// Place the even result in the even row
			even_highpass[channel][column] = SATURATE(even);

			// Apply the odd reconstruction filter to the lowpass band
			odd -= lowhigh_band_row[channel][column + 0 * lowhigh_pitch[channel]];
			odd += lowhigh_band_row[channel][column + 2 * lowhigh_pitch[channel]];
			odd += 4; //DAN20050921
			odd >>= 3;
			odd += lowhigh_band_row[channel][column + 1 * lowhigh_pitch[channel]];

			// Subtract the highpass correction
			odd -= highhigh_band_row[channel][column];
			odd = DivideByShift(odd, 1);

			// Place the odd result in the odd row
			odd_highpass[channel][column] = SATURATE(odd);
		}
	}

	// Apply the inverse horizontal transform to the even and odd rows
	horizontal_filter_proc(decoder, thread_index, even_lowpass, lowpass_pitch,
						   even_highpass, highpass_pitch,
						   output, (int)output_row_size, strip,
						   precision, format);

	//_mm_empty();	// Clear the mmx register state
}

// Apply the inverse spatial filter to the bottom row and convert the results to the output format
void
InvertSpatialBottomRow16sToOutput(DECODER *decoder, int thread_index, PIXEL *lowlow_band[], int lowlow_band_pitch[],
								  PIXEL *lowhigh_band[], int lowhigh_band_pitch[],
								  PIXEL *highlow_band[], int highlow_band_pitch[],
								  PIXEL *highhigh_band[], int highhigh_band_pitch[],
								  uint8_t *output, int output_pitch, int output_width,
								  int format, int colorspace, int row, int channel_width[],
								  PIXEL *buffer, size_t buffer_size, int precision, int odd_height,
								  HorizontalInverseFilterOutputProc horizontal_filter_proc)
{
	int num_channels = decoder->codec.num_channels;//CODEC_NUM_CHANNELS;

	PIXEL *even_lowpass[CODEC_MAX_CHANNELS];
	PIXEL *even_highpass[CODEC_MAX_CHANNELS];
	PIXEL *odd_lowpass[CODEC_MAX_CHANNELS];
	PIXEL *odd_highpass[CODEC_MAX_CHANNELS];
	
	// Distance between strip rows in bytes
	int lowpass_pitch[CODEC_MAX_CHANNELS];
	int highpass_pitch[CODEC_MAX_CHANNELS];

	size_t output_row_size = output_pitch;

	// The width of the first channel is the overall width
	int luma_band_width = channel_width[0];

	// Set the dimensions of the processing strip
	ROI strip = {luma_band_width, 2};

	int channel;

	if(odd_height)
	{
		strip.height = 1;
	}

	// Compute pointers into the buffers for temporary results
	for (channel = 0; channel < num_channels; channel++)
	{
		size_t buffer_row_size;
		int buffer_half_pitch;
		//int buffer_width;
		int buffer_pitch;

		//int width = luma_band_width;
		int width = channel_width[channel];

		// Compute positions within the temporary buffer for each row of horizontal lowpass
		// and highpass intermediate coefficients computed by the vertical inverse transform
		buffer_row_size = width * sizeof(PIXEL);
		buffer_row_size = ALIGN16(buffer_row_size);
		buffer_half_pitch = (int)buffer_row_size/sizeof(PIXEL);
		buffer_pitch = 2 * buffer_half_pitch;
		//buffer_width = width;

		// Check that the buffer is large enough to hold four rows of coefficients
		assert(buffer_size >= (4 * buffer_row_size));

		// Compute the positions of the even and odd rows of coefficients
		even_lowpass[channel] = &buffer[0];
		even_highpass[channel] = &buffer[buffer_half_pitch];
		odd_lowpass[channel] = &buffer[2 * buffer_half_pitch];
		odd_highpass[channel] = &buffer[3 * buffer_half_pitch];

		// Pointers into the strip of horizontal coefficients
		lowpass_pitch[channel] = (int)(2 * buffer_row_size);
		highpass_pitch[channel] = (int)(2 * buffer_row_size);

		buffer = &buffer[4 * buffer_half_pitch];
		buffer_size -= 4 * buffer_row_size;
	}

	for (channel = 0; channel < num_channels; channel++)
	{
		PIXEL *lowlow = lowlow_band[channel];
		PIXEL *lowhigh = lowhigh_band[channel];
		PIXEL *highlow = highlow_band[channel];
		PIXEL *highhigh = highhigh_band[channel];

		// Convert pitch from bytes to pixels
		int lowlow_pitch = lowlow_band_pitch[channel] / sizeof(PIXEL);
		int lowhigh_pitch = lowhigh_band_pitch[channel] / sizeof(PIXEL);
		int highlow_pitch = highlow_band_pitch[channel] / sizeof(PIXEL);
		int highhigh_pitch = highhigh_band_pitch[channel] / sizeof(PIXEL);

		//int width = luma_band_width;
		int width = channel_width[channel];

		// Start at the first column
		int column = 0;

		// Compute the address of the first row for processing in each wavelet band
		lowlow += row * lowlow_pitch;
		lowhigh += row * lowhigh_pitch;
		highlow += row * highlow_pitch;
		highhigh += row * highhigh_pitch;

		// Apply the vertical border filter to the last row
		for (column = 0; column < width; column++)
		{
			int32_t even = 0;		// Result of convolution with even filter
			int32_t odd = 0;		// Result of convolution with odd filter


			// Compute the vertical inverse for the left two bands //

			// Apply the even reconstruction filter to the lowpass band
			even += 5 * lowlow[column + 0 * lowlow_pitch];
			even += 4 * lowlow[column - 1 * lowlow_pitch];
			even -= 1 * lowlow[column - 2 * lowlow_pitch];
			even += ROUNDING(even,8);
			even = DivideByShift(even, 3);

			// Add the highpass correction
			even += highlow[column];
			even = DivideByShift(even, 1);

			// Place the even result in the even row
			even_lowpass[channel][column] = SATURATE(even);

			// Apply the odd reconstruction filter to the lowpass band
			odd += 11 * lowlow[column + 0 * lowlow_pitch];
			odd -=  4 * lowlow[column - 1 * lowlow_pitch];
			odd +=  1 * lowlow[column - 2 * lowlow_pitch];
			odd += ROUNDING(odd,8);
			odd = DivideByShift(odd, 3);

			// Subtract the highpass correction
			odd -= highlow[column];
			odd = DivideByShift(odd, 1);

			// Place the odd result in the odd row
			odd_lowpass[channel][column] = SATURATE(odd);


			// Compute the vertical inverse for the right two bands //

			even = 0;
			odd = 0;

			// Apply the even reconstruction filter to the lowpass band
			even += 5 * lowhigh[column + 0 * lowhigh_pitch];
			even += 4 * lowhigh[column - 1 * lowhigh_pitch];
			even -= 1 * lowhigh[column - 2 * lowhigh_pitch];
			even += ROUNDING(even,8);
			even = DivideByShift(even, 3);

			// Add the highpass correction
			even += highhigh[column];
			even = DivideByShift(even, 1);

			// Place the even result in the even row
			even_highpass[channel][column] = SATURATE(even);

			// Apply the odd reconstruction filter to the lowpass band
			odd += 11 * lowhigh[column + 0 * lowhigh_pitch];
			odd -=  4 * lowhigh[column - 1 * lowhigh_pitch];
			odd +=  1 * lowhigh[column - 2 * lowhigh_pitch];
			odd += ROUNDING(odd,8);
			odd = DivideByShift(odd, 3);

			// Subtract the highpass correction
			odd -= highhigh[column];
			odd = DivideByShift(odd, 1);

			// Place the odd result in the odd row
			odd_highpass[channel][column] = SATURATE(odd);
		}
	}

	// Apply the inverse horizontal transform to the even and odd rows
	horizontal_filter_proc(decoder, thread_index, even_lowpass, lowpass_pitch,
						   even_highpass, highpass_pitch,
						   output, (int)output_row_size, strip,
						   precision, format);
}

